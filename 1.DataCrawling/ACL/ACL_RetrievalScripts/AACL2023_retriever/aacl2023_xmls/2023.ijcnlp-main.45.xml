<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity</title>
				<funder ref="#_rZDQM6b #_FDY2NCw #_VtTqFh3 #_YaGwaMj">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_gHZBMpR #_QzBwuaB">
					<orgName type="full">Hong Kong Research Grants Council</orgName>
				</funder>
				<funder ref="#_4eNcJvg">
					<orgName type="full">Association for Computational Linguistics</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yejin</forename><surname>Bang</surname></persName>
							<email>yjbang@connect.ust.hk</email>
						</author>
						<author>
							<persName><forename type="first">Samuel</forename><surname>Cahyawijaya</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nayeon</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wenliang</forename><surname>Dai</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dan</forename><surname>Su</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Bryan</forename><forename type="middle">Wilie</forename><surname>Holy</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Lovenia</forename><surname>Ziwei</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ji</forename><surname>Tiezheng</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yu</forename><surname>Willy</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chung</forename><surname>Quyet</surname></persName>
						</author>
						<author>
							<persName><forename type="first">V</forename><surname>Do</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yan</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Pascale</forename><forename type="middle">2022a</forename><surname>Fung</surname></persName>
							<email>pascale@ece.ust.hk</email>
						</author>
						<author>
							<persName><forename type="first">Alham</forename><surname>Fikri</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Aji</forename><surname>Genta</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Indra</forename><surname>Winata</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Fajri</forename><surname>Koto</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ade</forename><surname>Romadhony</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rahmad</forename><surname>Ma- Hendra</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kemal</forename><surname>Kurniawan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Moeljadi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Radi- Tyo</forename><forename type="middle">Eko</forename><surname>Prasojo</surname></persName>
						</author>
						<author>
							<persName><roleName>Jey</roleName><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Han</forename><surname>Lau</surname></persName>
						</author>
						<author>
							<persName><forename type="first">David</forename><forename type="middle">G W 2022</forename><surname>Birch</surname></persName>
						</author>
						<author>
							<persName><surname>Chatgpt</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Alexandre</forename><surname>Blanco-Gonzalez</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Alfonso</forename><surname>Cabezon</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ale- Jandro</forename><surname>Seco-Gonzalez</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Conde-Torres</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Paula</forename><surname>Antelo-Riveiro</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Angel</forename><surname>Pineiro</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Holy</forename><surname>Lovenia</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Alham</forename><forename type="middle">Fikri</forename><surname>Aji</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Indra</forename><surname>Genta</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Bryan</forename><surname>Winata</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rahmad</forename><surname>Wilie</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Christian</forename><surname>Mahendra</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ade</forename><surname>Wibisono</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Karissa</forename><surname>Romadhony</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Fajri</forename><surname>Vin- Centio</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jennifer</forename><surname>Koto</surname></persName>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Santoso</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Cahya</forename><surname>Moeljadi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Frederikus</forename><surname>Wirawan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ivan</forename><surname>Hudi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Parmo- Nangan</forename><surname>Halim</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ika</forename><surname>Alfina</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Muhammad</forename><forename type="middle">Satrio</forename><surname>Wicaksono</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Il- Ham</forename><forename type="middle">Firdausi</forename><surname>Putra</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Samsul</forename><surname>Rahmadani</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yulianti</forename><surname>Oe- Nang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ali</forename><forename type="middle">Akbar</forename><surname>Septiandri</surname></persName>
						</author>
						<author>
							<persName><forename type="first">James</forename><surname>Jaya</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kaustubh</forename><forename type="middle">D</forename><surname>Dhole</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Arie</forename><forename type="middle">Ardiyanti</forename><surname>Suryani</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Afina</forename><surname>Rifki</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dan</forename><surname>Putri</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Keith</forename><surname>Su</surname></persName>
						</author>
						<author>
							<persName><roleName>Made</roleName><forename type="first">Nindyatama</forename><surname>Stevens</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Muhammad</forename><forename type="middle">Farid</forename><surname>Nityasya</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ryan</forename><surname>Adilazuarda</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ryan- Dito</forename><surname>Ignatius</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tiezheng</forename><surname>Diandaru</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Vito</forename><surname>Yu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wenliang</forename><surname>Ghifari</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yan</forename><surname>Dai</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dyah</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Cuk</forename><surname>Damapuspita</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ichwanul</forename><surname>Tho</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Karo</forename><surname>Muslim</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tirana</forename><forename type="middle">Noor</forename><surname>Karo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ziwei</forename><surname>Fatyanosa</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Pascale</forename><surname>Ji</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Graham</forename><surname>Fung</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Timothy</forename><surname>Neubig</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sebastian</forename><surname>Baldwin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Herry</forename><surname>Ruder</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sakriani</forename><surname>Sujaini</surname></persName>
						</author>
						<author>
							<persName><surname>Sakti</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Karissa</forename><surname>Wilie</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xiaohong</forename><surname>Vincentio</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Adhiguna</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sebastian</forename><surname>Kun- Coro</surname></persName>
						</author>
						<author>
							<persName><surname>Ruder</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yuan</forename><surname>Zhi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Syafri</forename><surname>Lim</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Masayu</forename><surname>Ba- Har</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ayu</forename><surname>Khodra</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Pascale</forename><surname>Purwarianti</surname></persName>
						</author>
						<author>
							<persName><surname>Fung</surname></persName>
						</author>
						<author>
							<persName><surname>Indonlg</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jonathan</forename><forename type="middle">H</forename><surname>Choi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kristin</forename><forename type="middle">E</forename><surname>Hickman</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Amy</forename><surname>Monahan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Aakanksha</forename><surname>Chowdhery</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Gaurav</forename><surname>Mishra</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
						</author>
						<author>
							<persName><roleName>Hyung</roleName><forename type="first">Paul</forename><surname>Barham</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Won</forename><surname>Chung</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Charles</forename><surname>Sutton</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Parker</forename><surname>Schuh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kensen</forename><surname>Shi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sasha</forename><surname>Tsvyashchenko</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Joshua</forename><surname>Maynez</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Abhishek</forename><surname>Rao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Parker</forename><surname>Barnes</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Vin- Odkumar</forename><surname>Prabhakaran</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Emily</forename><surname>Reif</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nan</forename><surname>Du</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ben</forename><surname>Hutchinson</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Reiner</forename><surname>Pope</surname></persName>
						</author>
						<author>
							<persName><forename type="first">James</forename><surname>Bradbury</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jacob</forename><surname>Austin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Isard</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Guy</forename><surname>Gur-Ari</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Pengcheng</forename><surname>Yin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Toju</forename><surname>Duke</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Anselm</forename><surname>Levskaya</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sunipa</forename><surname>Dev</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Henryk</forename><surname>Michalewski</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xavier</forename><surname>Garcia</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Vedant</forename><surname>Misra</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kevin</forename><surname>Robinson</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Liam</forename><surname>Fedus</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Daphne</forename><surname>Ippolito</surname></persName>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Luan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hyeontaek</forename><surname>Lim</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Alexander</forename><surname>Spiridonov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ryan</forename><surname>Sepassi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Dohan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shivani</forename><surname>Agrawal</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mark</forename><surname>Omernick</surname></persName>
						</author>
						<author>
							<persName><forename type="first">An- Drew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Thanumalayan</forename><surname>Sankaranarayana</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Marie</forename><surname>Pellat</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Aitor</forename><surname>Lewkowycz</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Erica</forename><surname>Moreira</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Oleksandr</forename><surname>Polozov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zongwei</forename><surname>Zhou</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Brennan</forename><surname>Saeta</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mark</forename><surname>Diaz</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Orhan</forename><surname>Firat</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Michele</forename><surname>Catasta</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kathy</forename><surname>Meier-Hellstern</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Douglas</forename><surname>Eck</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Slav</forename><surname>Petrov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jordan</forename><surname>Hoffmann</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Arthur</forename><surname>Mensch</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Trevor</forename><surname>Cai</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Eliza</forename><surname>Rutherford</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Diego</forename><surname>De</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Las</forename><surname>Casas</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Lisa</forename><forename type="middle">Anne</forename><surname>Hendricks</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Aidan</forename><surname>Clark</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tom</forename><surname>Hennigan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Eric</forename><surname>Noland</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Katie</forename><surname>Millican</surname></persName>
						</author>
						<author>
							<persName><forename type="first">George</forename><surname>Van Den Driessche</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Bogdan</forename><surname>Damoc</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Aurelia</forename><surname>Guy</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Simon</forename><surname>Osindero</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Karen</forename><surname>Si- Monyan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Erich</forename><surname>Elsen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jack</forename><forename type="middle">W</forename><surname>Rae</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Katharina</forename><surname>Jeblick</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Balthasar</forename><surname>Schachtner</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jakob</forename><surname>Dexl</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Andreas</forename><surname>Mittermeier</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Anna</forename><forename type="middle">Theresa</forename><surname>Stüber</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Johanna</forename><surname>Topalis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tobias</forename><surname>Weber</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Philipp</forename><surname>Wesp</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Bastian</forename><surname>Sabel</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ziwei</forename><surname>Ji</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rita</forename><surname>Frieske</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tiezheng</forename><surname>Yu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yan</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Etsuko</forename><surname>Ishii</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Andrea</forename><surname>Madotto</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Max</forename><surname>Huang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Maximin</forename><surname>Coavoux</surname></persName>
						</author>
						<author>
							<persName><roleName>Mike</roleName><forename type="first">Mayank</forename><surname>Singh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tian-Jian</forename><surname>Jiang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Minh</forename><forename type="middle">Chien</forename><surname>Vu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Moham- Mad</forename><forename type="middle">A</forename><surname>Jauhar</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mustafa</forename><surname>Ghaleb</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nishant</forename><surname>Subramani</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nora</forename><surname>Kassner</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nurulaqilla</forename><surname>Khamis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Olivier</forename><surname>Nguyen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Omar</forename><surname>Espejel</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ona</forename><surname>De Gibert</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Paulo</forename><surname>Villegas</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Pe- Ter</forename><surname>Henderson</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Pierre</forename><surname>Colombo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Priscilla</forename><surname>Amuok</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Quentin</forename><surname>Lhoest</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rheza</forename><surname>Harliman</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Roberto</forename><surname>Luis López</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rui</forename><surname>Ribeiro</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Salomey</forename><surname>Osei</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sebastian</forename><surname>Nagel</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shamik</forename><surname>Bose</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shamsuddeen</forename><forename type="middle">Hassan</forename><surname>Muhammad</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shanya</forename><surname>Sharma</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shayne</forename><surname>Longpre</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Somaieh</forename><surname>Nikpoor</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Stanislav</forename><surname>Silber- Berg</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Suhas</forename><surname>Pai</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sydney</forename><surname>Zink</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tiago</forename><surname>Timponi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Timo</forename><surname>Schick</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tristan</forename><surname>Thrush</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Valentin</forename><surname>Danchev</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Vassilina</forename><surname>Nikoulina</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Veronika</forename><surname>Laippala</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Violette</forename><surname>Lepercq</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Vrinda</forename><surname>Prabhu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zaid</forename><surname>Alyafeai</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zeerak</forename><surname>Ta- Lat</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Arun</forename><surname>Raja</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Benjamin</forename><surname>Heinzerling</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chenglei</forename><surname>Si</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Emre</forename><surname>Davut</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Elizabeth</forename><surname>Taşar</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sabrina</forename><forename type="middle">J</forename><surname>Salesky</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wilson</forename><forename type="middle">Y</forename><surname>Mielke</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Abheesht</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Andrea</forename><surname>Sharma</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Antoine</forename><surname>Santilli</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Arnaud</forename><surname>Chaffin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Debajy- Oti</forename><surname>Stiegler</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Eliza</forename><surname>Datta</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Gunjan</forename><surname>Szczechla</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Han</forename><surname>Chhablani</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Harshit</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hendrik</forename><surname>Pandey</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jason</forename><forename type="middle">Alan</forename><surname>Strobelt</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jos</forename><surname>Fries</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Leo</forename><surname>Rozen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Lintang</forename><surname>Gao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">M</forename><surname>Sutawika</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Maged</forename><forename type="middle">S</forename><surname>Sai- Ful Bari</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Matteo</forename><surname>Al-Shaibani</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ni- Hal</forename><surname>Manica</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ryan</forename><surname>Nayak</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Samuel</forename><surname>Teehan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sheng</forename><surname>Albanie</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Srulik</forename><surname>Shen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Stephen</forename><forename type="middle">H</forename><surname>Ben-David</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Taewoon</forename><surname>Bach</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tali</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Thibault</forename><surname>Bers</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Trishala</forename><surname>Fevry</surname></persName>
						</author>
						<author>
							<persName><surname>Neeraj</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Deepak</forename><surname>Narayanan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hatim</forename><surname>Bourfoune</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jared</forename><surname>Casper</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jeff</forename><surname>Rasley</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Max</forename><surname>Ryabinin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mayank</forename><surname>Mishra</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Minjia</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mohammad</forename><surname>Shoeybi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Myriam</forename><surname>Peyrounette</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nicolas</forename><surname>Patry</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nouamane</forename><surname>Tazi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Omar</forename><surname>Sanseviero</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Patrick</forename><surname>Von Platen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Pierre</forename><surname>Cornette</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Pierre</forename><forename type="middle">François</forename><surname>Lavallée</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rémi</forename><surname>Lacroix</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Samyam</forename><surname>Rajbhandari</surname></persName>
						</author>
						<author>
							<persName><forename type="first">San- Chit</forename><surname>Gandhi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shaden</forename><surname>Smith</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Stéphane</forename><surname>Requena</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Suraj</forename><surname>Patil</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tim</forename><surname>Dettmers</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ahmed</forename><surname>Baruwa</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Anastasia</forename><surname>Cheveleva</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Anne-Laure</forename><surname>Ligozat</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Arjun</forename><surname>Subramonian</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Aurélie</forename><surname>Névéol</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dan</forename><surname>Garrette</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Deepak</forename><surname>Tunuguntla</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ehud</forename><surname>Reiter</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ekaterina</forename><surname>Taktasheva</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ekaterina</forename><surname>Voloshina</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Eli</forename><surname>Bog- Danov, Genta</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hailey</forename><surname>Schoelkopf</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jan- Christoph</forename><surname>Kalo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jekaterina</forename><surname>Novikova</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jessica</forename><forename type="middle">Zosa</forename><surname>Forde</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jordan</forename><surname>Clive</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jungo</forename><surname>Kasai</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ken</forename><surname>Kawamura</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Liam</forename><surname>Hazan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Miruna</forename><surname>Clinciu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Na- Joung</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Newton</forename><surname>Cheng</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Oleg</forename><surname>Serikov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Omer</forename><surname>Antverg</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Oskar</forename><surname>Van Der Wal</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rui</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ruochen</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shachar</forename><surname>Mirkin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shani</forename><surname>Pais</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tatiana</forename><surname>Shavrina</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Scialom</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tian</forename><surname>Yun</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tomasz</forename><surname>Limisiewicz</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Verena</forename><surname>Rieser</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Vitaly</forename><surname>Protasov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Vladislav</forename><surname>Mikhailov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yada</forename><surname>Pruksachatkun</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yonatan</forename><surname>Belinkov</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zachary</forename><surname>Bamberger</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zdeněk</forename><surname>Kasner</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Al- Ice</forename><surname>Rueda</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Amanda</forename><surname>Pestana</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Amir</forename><surname>Feizpour</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ammar</forename><surname>Khan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Amy</forename><surname>Faranak</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ana</forename><surname>Santos</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Anthony</forename><surname>Hevia</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Antigona</forename><surname>Unldreaj</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Arash</forename><surname>Aghagol</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Arezoo</forename><surname>Abdol- Lahi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Aycha</forename><surname>Tammour</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Azadeh</forename><surname>Hajihosseini</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Bahareh</forename><surname>Behroozi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Benjamin</forename><surname>Ajibade</surname></persName>
						</author>
						<author>
							<persName><roleName>Car- los</roleName><forename type="first">Bharat</forename><surname>Saxena</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Muñoz</forename><surname>Ferrandis</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Danish</forename><surname>Contractor</surname></persName>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Lan- Sky</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Davis</forename><surname>David</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Duong</forename><forename type="middle">A</forename><surname>Nguyen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Edward</forename><surname>Tan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Emi</forename><surname>Baylor</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ezinwanne</forename><surname>Ozoani</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Fa- Tima</forename><surname>Mirza</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Frankline</forename><surname>Ononiwu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Habib</forename><surname>Rezanejad</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hessie</forename><surname>Jones</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Indrani</forename><surname>Bhattacharya</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Irene</forename><surname>Solaiman</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Irina</forename><surname>Sedenko</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Isar</forename><surname>Nejadgholi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jesse</forename><surname>Passmore</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Josh</forename><surname>Seltzer</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Julio</forename><surname>Bonis Sanz</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Livia</forename><surname>Dutra</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mairon</forename><surname>Sama- Gaio</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Maraim</forename><surname>Elbadri</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Margot</forename><surname>Mieskes</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Marissa</forename><surname>Ger- Chick</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Martha</forename><surname>Akinlolu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Mckenna</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mike</forename><surname>Qiu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Muhammed</forename><surname>Ghauri</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mykola</forename><surname>Burynok</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nafis</forename><surname>Abrar</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nazneen</forename><surname>Rajani</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nour</forename><surname>Elkott</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nour</forename><surname>Fahmy</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Olanrewaju</forename><surname>Samuel</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ran</forename><surname>An</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rasmus</forename><surname>Kromann</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ryan</forename><surname>Hao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Samira</forename><surname>Alizadeh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sarmad</forename><surname>Shubber</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Silas</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sourav</forename><surname>Roy</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sylvain</forename><surname>Viguier</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Thanh</forename><surname>Le</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tobi</forename><surname>Oyebade</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Trieu</forename><surname>Le</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yoyo</forename><surname>Yang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zach</forename><surname>Nguyen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ramesh</forename><surname>Kashyap</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Alfredo</forename><surname>Palasciano</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Al- Ison</forename><surname>Callahan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Anima</forename><surname>Shukla</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Antonio</forename><surname>Miranda- Escalada</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ayush</forename><surname>Singh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Benjamin</forename><surname>Beilharz</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Bo</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Caio</forename><surname>Brito</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chenxi</forename><surname>Zhou</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chirag</forename><surname>Jain</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chuxin</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Clémentine</forename><surname>Fourrier</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><forename type="middle">León</forename><surname>Periñán</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Molano</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dian</forename><surname>Yu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Enrique</forename><surname>Manjavacas</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Fabio</forename><surname>Barth</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Florian</forename><surname>Fuhrimann</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Gabriel</forename><surname>Altay</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Giyased- Din</forename><surname>Bayrak</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Gully</forename><surname>Burns</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Helena</forename><forename type="middle">U</forename><surname>Vrabec</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Imane</forename><surname>Bello</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ishani</forename><surname>Dash</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jihyun</forename><surname>Kang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">John</forename><surname>Giorgi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jonas</forename><surname>Golde</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jose</forename><forename type="middle">David</forename><surname>Posada</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Karthik</forename><surname>Rangasai</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Lokesh</forename><surname>Bulchandani</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Lu</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Luisa</forename><surname>Shinzato</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Madeleine</forename><surname>Hahn De Bykhovetz</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Maiko</forename><surname>Takeuchi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Marc</forename><surname>Pàmies</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Maria</forename><forename type="middle">A</forename><surname>Castillo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Marianna</forename><surname>Nezhurina</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mario</forename><surname>Sänger</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Matthias</forename><surname>Samwald</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Cullan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Weinberg</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Michiel</forename><surname>De Wolf</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mina</forename><surname>Mihalj- Cic</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Minna</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Moritz</forename><surname>Freidank</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Myungsun</forename><surname>Kang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Natasha</forename><surname>Seelam</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nathan</forename><surname>Dahlberg</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nicholas</forename><surname>Michio Broad</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nikolaus</forename><surname>Muellner</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Patrick</forename><surname>Haller</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ramya</forename><surname>Chandrasekhar</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Renata</forename><surname>Eisenberg</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Robert</forename><surname>Martin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rodrigo</forename><surname>Canalli</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rosaline</forename><surname>Su</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ruisi</forename><surname>Su</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Samuele</forename><surname>Garda</surname></persName>
						</author>
						<author>
							<persName><forename type="first">S</forename><surname>Shlok</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shubhanshu</forename><surname>Deshmukh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sid</forename><surname>Mishra</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Si- Mon</forename><surname>Kiblawi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sinee</forename><surname>Ott</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Srishti</forename><surname>Sang-Aroonsiri</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ste- Fan</forename><surname>Kumar</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sushil</forename><surname>Schweter</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tanmay</forename><surname>Bharati</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Théo</forename><surname>Laud</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tomoya</forename><surname>Gigant</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wojciech</forename><surname>Kainuma</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yanis</forename><surname>Kusa</surname></persName>
						</author>
						<author>
							<persName><surname>Labrak</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shailesh</forename><surname>Yash</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yash</forename><surname>Bajaj</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yi- Fan</forename><surname>Venkatraman</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yingxin</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yu</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zhe</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zhongli</forename><surname>Tan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zi- Fan</forename><surname>Xie</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mathilde</forename><surname>Ye</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yan</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName><roleName>Genta</roleName><forename type="first">Zihan</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Centre for Artificial Intelligence Research (CAiRE)</orgName>
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Hyung Won Chung</orgName>
								<address>
									<addrLine>Vikas Raunak, Zheng-Xin Yong, Yallow Uri, Hadar Tojarieh, Jaesung Tae, Jason Phang, Ofir Press</addrLine>
									<settlement>Ur-mish Thakker, Xiangru Tang, Zhiqing Sun, Shaked Brody, Adam Roberts, Conglong Li</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EE21A4B63E2C335163533AB1E2179BD7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-05-29T13:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Challenges</term>
					<term>opportunities</term>
					<term>and strategies. arXiv preprint arXiv:2212.08104 An exploratory case study on simplified radiology reports. arXiv preprint arXiv:2212.14882</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper proposes a framework for quantitatively evaluating interactive LLMs such as ChatGPT using publicly available data sets, using 23 data sets covering 8 different common NLP application tasks. We extensively evaluate the multitask, multilingual, and multi-modal aspects of ChatGPT based on these data sets and a newly designed multimodal dataset. We find that ChatGPT outperforms LLMs with zeroshot learning on most tasks and even outperforms fine-tuned models on some tasks. We find that it is better at understanding non-Latin script languages than generating them. It is able to generate multimodal content from textual prompts via an intermediate code generation step. Moreover, we find that ChatGPT is 63.41% accurate on average in 10 different reasoning categories under logical reasoning, non-textual reasoning, and commonsense reasoning, hence making it an unreliable reasoner. ChatGPT suffers from hallucination problems like other LLMs. Finally, the interactive feature of ChatGPT enables human collaboration with the underlying LLM to improve its performance, i.e., 8% ROUGE-1 on summarization and 2% ChrF++ on machine translation, in a multi-turn "prompt engineering" fashion. We release a code for evaluation set extraction. 1 * Equal Contribution. 1 https://github.com/HLTCHKUST/chatgpt-evaluat ion References 2023. Chatgpt vs satya nadella over biryani: The chatbot is learning from its mistakes.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>ChatGPT is a successor of the large language model (LLM) InstructGPT <ref type="bibr" target="#b29">(Ouyang et al., 2022)</ref> with a dialog interface that is fine-tuned using the Reinforcement Learning with Human Feedback (RLHF) <ref type="bibr" target="#b0">(Christiano et al., 2017)</ref> approach. Chat-GPT has gathered 100 million monthly active users in such a short period of time <ref type="bibr">(Hu, 2023)</ref> and is being used by businesses and consumers alike for a myriad of mostly textual tasks. One reason for its unprecedented popularity is that ChatGPT, through its scale and via RLHF, has shown impressive abilities in many areas of NLP as well as emergent abilities. Another reason is that its dialog interface allows users to interact with the underlying LLM more effectively and efficiently via interactive chats that are akin to multi-turn prompting.</p><p>However, despite its powerful abilities, anecdotal reports on ChatGPT consistently showed remaining challenges -for example, it fails in some elementary mathematical <ref type="bibr" target="#b15">(Gilson et al., 2022;</ref><ref type="bibr" target="#b17">Goldberg, 2023;</ref><ref type="bibr" target="#b13">Frieder et al., 2023;</ref><ref type="bibr" target="#b34">Choi et al., 2023;</ref><ref type="bibr">Davis, 2023b)</ref> and commonsense reasoning tasks <ref type="bibr" target="#b22">(Guo et al., 2023;</ref><ref type="bibr">Davis, 2023b)</ref>; it hallucinates with human-like fluency and eloquence on things that are not based on truth <ref type="bibr" target="#b46">(Shen et al., 2023;</ref><ref type="bibr" target="#b63">Thorp, 2023;</ref><ref type="bibr">Smith, 2023)</ref>; and as a generalpurpose language model trained from everything on the web, its language coverage is questionable <ref type="bibr">(Lu et al., 2022;</ref><ref type="bibr">Jiao et al., 2023)</ref>. Consequently, it is not clear what people can or cannot use ChatGPT for despite its popularity.</p><p>Since OpenAI never published any benchmarking results on ChatGPT at the time, seeing this need, in February 2023, we proposed a comprehensive framework for quantitatively evaluating interactive LLMs such as ChatGPT through standard public test sets on major NLP tasks such as question answering, reasoning, summarization, machine translation, sentiment analysis, language identification, task-oriented dialogue, and misinformation detection. We evaluate its multilingual performance as well as vision-language multimodal abilities. With additional experiments, we also quantitatively evaluated its primary limitations in reasoning and hallucination. In addition, we conducted experiments to test its multi-turn interactivity as a means for better prompt engineering. We aimed to provide insights to users of ChatGPT on the strengths mentioned above and limitations, as well as how they can improve outcomes with interactivity. To the best of our knowledge, this is the first published benchmark of ChatGPT from a third party. More recently, the GPT-4 technical report <ref type="bibr" target="#b27">(OpenAI, 2023)</ref> published a number of human task benchmarks.</p><p>The true scope of all emergent capabilities of generative models, including ChatGPT, is still unclear. Thus, any benchmarking exercise cannot be 100% "comprehensive" in the scientific sense. We aim to show not just researchers but also users what ChatGPT can and cannot do by presenting interpretable benchmarking results in a zero-shot setting without access to APIs so that the general audience can replicate our evaluation with the test sets we have provided in a zero-shot setting. This version of ChatGPT is 15 December 2022.</p><p>The following are the major insights we have gained from the evaluations:</p><p>Multitask, Multimodal, and Multilingual: For 9/13 NLP datasets, ChatGPT outperforms previous LLMs with zero-shot learning. It even outperforms fully fine-tuned task-specific LMs on 4 different tasks. In other cases, ChatGPT is on par or slightly lower than fully fine-tuned for specific NLP tasks; ChatGPT fails to generalize to lowresource and extremely low-resource languages (e.g., Marathi, Sundanese, and Buginese). There is an overall performance degradation in low-resource languages, especially in non-Latin scripts in the case of translation; its weakness lies in generation rather than understanding part of the translation process; ChatGPT enables a code intermediate medium to bridge vision and language, even though the multi-modality ability is still elementary compared to vision-language models.</p><p>Reasoning: We tested 10 different reasoning categories with 634 samples in total. Based on our experiments, ChatGPT shows more weakness in inductive reasoning than in deductive or abductive reasoning. ChatGPT also lacks spatial and mathematical reasoning while showing better temporal reasoning. Further, we found that ChatGPT is relatively better at commonsense reasoning than nontextual semantic reasoning. Finally, while Chat-GPT shows acceptable performance in causal and analogical reasoning, it is bad at multi-hop reasoning capability, similar to other LLMs' weakness <ref type="bibr" target="#b28">(Ott et al., 2023)</ref>.</p><p>Hallucination: Similar to other LLMs <ref type="bibr" target="#b36">(Radford et al., 2019;</ref><ref type="bibr">Muennighoff et al., 2022;</ref><ref type="bibr">Workshop et al., 2022)</ref>, ChatGPT suffers from the hallucination problem. It generates more extrinsic hallucinations -factual statements that cannot be verified from the source.</p><p>Interactivity: One of the primary differentiating factors of ChatGPT from its predecessors is its multi-turn dialog interactivity. This enables ChatGPT to perform multiple tasks within a dialog session. There is also significant performance improvement (8% ROUGE-1 on summarization and 2% ChrF++ on low-resource machine translation) via multi-turn interactivity in various standard NLP tasks. This process is akin to prompt engineering with feedback from the system.</p><p>2 Multitask, Multilingual, and Multimodal Evaluations of ChatGPT</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Multitask Ability of ChatGPT</head><p>ChatGPT has become very well-known in such a short period of time to general public users, not just those who are in AI, machine learning, and NLP communities who might be more familiar with LLMs. One of the main reasons is that, in addition to media reports, innumerable use cases of ChatGPT are shared by both non-academic and academic users online <ref type="bibr">(Marr, 2022;</ref><ref type="bibr" target="#b18">Gordon, 2023;</ref><ref type="bibr" target="#b45">Shankland, 2023)</ref>. There have been debates and panels on whether ChatGPT is approaching Artificial General Intelligence, as it seems to be able to carry out a multitude of tasks without specific fine-tuning <ref type="bibr" target="#b9">(Desk, 2023;</ref><ref type="bibr">Johnson, 2023;</ref><ref type="bibr">Kingson, 2023)</ref>. On the other hand, there has also been as much sharing of its failures in simple tasks <ref type="bibr" target="#b15">(Gilson et al., 2022;</ref><ref type="bibr" target="#b34">Choi et al., 2023;</ref><ref type="bibr" target="#b46">Shen et al., 2023)</ref>. Instead of relying on anecdotal examples, we first evaluate ChatGPT's performance in various standard NLP tasks in a zero-shot manner to obtain a basic/better understanding of its multi-task ability. We compile results from the existing literature on ChatGPT and compare them with the stateof-the-art fully-fine-tuned and zero-shot models across multiple tasks. We evaluate ChatGPT performances on 21 datasets covering 8 tasks, i.e., summarization, machine translation, sentiment analysis, question answering, task-oriented dialogue, open-domain knowledge-grounded dialogue, and misinformation detection tasks. We sample testing cases from existing standard test sets for each task with a sample size ranging from 30 to 200 samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multitask Generalization of ChatGPT</head><p>The result of the multitask evaluation is shown in Table <ref type="table">1</ref>. ChatGPT is shown to achieve remarkable zero-shot performances on multiple tasks, surpassing pre- Table <ref type="table">1</ref>: Performance of ChatGPT compared to state-of-the-art fully-fine-tuned models (Fine-Tuned SOTA) and LLM in zero-shot settings (Zero-Shot SOTA). The referenced performances are evaluation results on full test sets, while the ChatGPT performances are computed on subsets of the corresponding dataset using 30 to 200 data samples for each task. For Machine Translation (MT) tasks, we follow the definitions of high-resource language (HRL) and low-resource language (LRL) from NLLB <ref type="bibr" target="#b60">(Team et al., 2022)</ref> and take subsets of languages to represent each group. JGA denotes joint goal accuracy. Average of performances for CNN and DM from <ref type="bibr" target="#b20">Goyal et al. (2022)</ref>.</p><p>LMs in zero-shot settings are as follows. Summarization: InstructGPT, MT: NLLB-200, Sentiment Analysis: XLM-R LARGE, QA: ST-MoE-32B, ZeroQA, GPT-3, Misinformation Detection: GPT-2, Task-Oriented Dialogue: D3ST, Open-Domain KGD: GPT-Jurassic-6B.</p><p>vious state-of-the-art zero-shot models on 9 out of 13 evaluation datasets with reported zero-shot LLMs' performances. In most tasks, especially task-oriented and knowledge-grounded dialogue tasks, task-specific fully-fine-tuned models outperform ChatGPT. Compared to the latter, ChatGPT yields lower performance in most tasks while still surpassing the performance on 4 datasets. Furthermore, from the evaluation results, we also observe several limitations of ChatGPT: 1) limited language understanding and generation capabilities on low-resource languages, 2) lacking reasoning ability as shown from the results in QA, and 3) performing task-oriented and knowledge-grounded dialogue tasks. More detailed experimental setup and analysis for each task are shared in Appendix §C. We also provide the complete list of all the datasets used in our evaluation in Appendix I.</p><p>ChatGPT on Dialogue Tasks Given that Chat-GPT has the ability to generate conversation-like responses, we test it on conventional dialogue tasks: 1) knowledge-grounded open-domain dialogue and 2) Task-oriented dialogue. Task setups are ex-plained in Appendix C.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Knowledge-Grounded Open-Domain Dialogue</head><p>To quantitatively measure ChatGPT's performance on knowledge-grounded dialogue, we utilize 50 samples from the test set of OpenDialKG <ref type="bibr">(Moon et al., 2019)</ref>, which contains open-ended dialogues grounded on a knowledge path. According to human judgment, the responses from ChatGPT are of high quality with fluent response generation and incorporating the provided knowledge in the response. However, the automatic evaluation results are relatively low compared with fine-tuned GPT2.</p><p>We postulate this is because ChatGPT responses are longer than the golden answers and include content from its parametrized knowledge injected during pre-training.</p><p>Task-Oriented Dialogue We investigate and discuss how ChatGPT's emergent abilities and interactivity could potentially be leveraged for ToD as well in two setups. Firstly, A) modular approach: testing dialogue state tracking (DST) and response generation using oracle actions. DST is mediocre  while ChatGPT successfully leverages all information provided while answering the questions with a 71.1% inform rate and 5.65 BLEU score. Next, B) Unified approach: a direct approach to simulate the ToD interaction while leveraging information in a structured database. We observed the limitations of ChatGPT: 1) ChatGPT cannot keep the belief state across multiple turns within the interaction, 2) ChatGPT's response tends to be wrong if the query introduces a basic level of reasoning 3) ChatGPT tends to generate hallucinated information beyond the given knowledge, which is not desirable for ToD. We provide details and examples of the modular and unified approaches in Appendix C.6.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Evaluating Multilinguality of ChatGPT</head><p>Training data size affects language understanding and generation ability of LMs <ref type="bibr" target="#b38">(Raffel et al., 2022;</ref><ref type="bibr">Cahyawijaya et al., 2021;</ref><ref type="bibr">Rae et al., 2021;</ref><ref type="bibr">Workshop et al., 2022;</ref><ref type="bibr">Chowdhery et al., 2022;</ref><ref type="bibr">Hoffmann et al., 2022)</ref>. As an LLM, the same premise also applies to ChatGPT, but the question is to what extent. We investigate this question through a series of experiments by analyzing 1) the language understanding capability through sentiment analysis (SA) and language identification (LID) tasks, and 2) the language generation capability through machine translation using English as the pivot language.</p><p>Based on the size proportion in CommonCrawl (i.e., the primary source of language pre-training data used in various LLMs) , we group languages into 4 language resource categories, i.e., high-resource language (HRL) (&lt;≥1%), medium-resource language (MRL) (≥0.01%), low-resource language (LRL) (≥0.0001%), and extremely low-resource language (X-LRL) (&lt;0.0001%). The statistics of the languages are shown in Table <ref type="table" target="#tab_13">9</ref> and other details are described in Appendix D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Language Understanding</head><p>We investigate the language understanding ability of ChatGPT on 4 languages from different language categories in NusaX <ref type="bibr" target="#b79">(Winata et al., 2022)</ref>, i.e. English, Indonesian, Javanese, and Buginese,  through sentiment analysis and language identification tasks. ChatGPT fails to generalize to extremely low-resource languages. As shown in Table 2, there is a clear correlation between Chat-GPT performance with the language resource category. This result aligns with the findings from prior works <ref type="bibr">(Chowdhery et al., 2022;</ref><ref type="bibr">Workshop et al., 2022;</ref><ref type="bibr">Muennighoff et al., 2022)</ref>, where LLMs, including ChatGPT, yield a lower performance for lower resource languages. Interestingly, the performance gap between English, Indonesian, and Javanese is considered marginal compared to the performance gap with Buginese. This suggests that ChatGPT has a limitation in generalizing toward extremely low-resource languages. Furthermore, we also find that ChatGPT can understand low-resource languages, such as Javanese, without having the knowledge to identify the language itself. Moreover, ChatGPT displays better humanpreferred responses when it has no knowledge about the language. For instance, as illustrated in 8, ChatGPT lets the user know that its prediction is uncertain when it does not completely understand the language and also provides broader information regarding the language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Language Generation</head><p>We assess the multilingual language generation ability of ChatGPT through machine translation.</p><p>We experiment with 6 languages: French, Chinese, Indonesian, Korean, Javanese, and Sundanese from the FLORES-200 dataset <ref type="bibr" target="#b60">(Team et al., 2022;</ref><ref type="bibr" target="#b19">Goyal et al., 2021)</ref>. For each language, we sample 30 English-XXX parallel sentences and perform two directions of translation using English as the pivot language. The correctness of the translation results is manually validated by a native speaker of the corresponding language.</p><p>Based on our evaluation results (Table <ref type="table" target="#tab_4">3</ref>), similar to other LLMs <ref type="bibr">(Workshop et al., 2022;</ref><ref type="bibr">Muennighoff et al., 2022)</ref>, ChatGPT produces better English translation quality from high-resource languages, such as French and Chinese. While for low-resource languages, such as Javanese and Sundanese, ChatGPT tends to generate several mistranslated words/phrases and sometimes even hallucinate some objects. Moreover, we also observe that sometimes ChatGPT translates the English sentence into a different but related language other than the requested target language (see §H.2). This fact suggests that the generalization of LLMs, including ChatGPT, to low-resource languages, remains an open challenge. Moreover, we also find that ChatGPT can handle Latin script languages better than non-Latin script languages, especially in generating sentences using those scripts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Evaluating Multimodality of ChatGPT</head><p>Since ChatGPT is a purely text-prompted language model, it is unlikely to explore its multimodal capabilities with visual inputs like contemporary visionlanguage works <ref type="bibr" target="#b43">(Rombach et al., 2022;</ref><ref type="bibr" target="#b39">Ramesh et al., 2021;</ref><ref type="bibr">Yu et al., 2021a;</ref><ref type="bibr" target="#b35">Radford et al., 2021;</ref><ref type="bibr" target="#b3">Dai et al., 2022;</ref><ref type="bibr">Lovenia et al., 2022;</ref><ref type="bibr">Dai et al., 2023a)</ref>. However, thanks to its code understanding and generation abilities, programming codes can serve as the intermediate medium to bridge vision and language <ref type="bibr" target="#b40">(Rasheed, 2020;</ref><ref type="bibr" target="#b49">Shiryaev, 2022)</ref>. Given textual prompts, ChatGPT can generate code representations of visual images using the SVG (Scalable Vector Graphics) format or APIs (e.g., HTML Canvas element, Python Turtle graphics). For example, as shown in Figure <ref type="figure" target="#fig_1">1</ref>, ChatGPT can generate a well-formed and suitable intermediate representation in code format to synthesize images given the dialogue context and user prompts.</p><p>In this way, even though the generated images are symbolic and their quality is not comparable to the ones generated by modern text-to-image models <ref type="bibr" target="#b39">(Ramesh et al., 2021;</ref><ref type="bibr" target="#b43">Rombach et al., 2022)</ref>, it is worth exploring due to three reasons. Firstly, it helps us investigate the visual understanding and reasoning abilities of ChatGPT, which can be seen as an emergent skill after the very large-scale pretraining on text and code data. Furthermore, representing images with code is a more explainable way to understand the model's behaviors and rationales in text-to-image generation. Third, it is a natural way to evaluate ChatGPT's ability on multi-turn interaction by asking for post-editing and corrections of the generated images.</p><p>To systematically evaluate the image generation ability of ChatGPT through code generation, we designed a national flag drawing task. This task  tests how ChatGPT's textually described knowledge (language) converts into the drawing (vision) through the SVG (code), using multi-turn conversations. The task contains three steps. Firstly, we ask ChatGPT to illustrate the appearance of the flag. Next, based on the description, we ask ChatGPT to generate the SVG code of that flag. Finally, if the generated image contains errors, we iteratively ask ChatGPT to fix them. There are four types of errors: 1) layout, 2) color, 3) missing components, 4) shape/size. We uniformly collect 50 national flags from different continents and conduct the flagdrawing task on ChatGPT. The prompts and full results are shown in Appendix E. The generated flag images are evaluated by the aforementioned four error types as criteria. We further assess the image quality with five grades, A ∼ E, which indicate zero to four (or above) errors. An overview of the result evaluation is provided in Table <ref type="table">4</ref>. We share our major two findings from the task: 1) ChatGPT is capable of drawing, yet better with a self-generated textual description. As demonstrated in Table <ref type="table">4</ref> and Appendix E, by following the task formulation, ChatGPT can generate plausible national flags using the SVG format. To better understand the behavior of ChatGPT, we perform an ablation study by removing the description generation step. As illustrated by Figure <ref type="figure" target="#fig_1">1</ref>, the performance drops dramatically without first prompting the textual flag description, which is generated by ChatGPT itself. Explicitly describing the appearance of the flag and then drawing disentangles the image generation process, which can be considered as a chain-of-thought reasoning. 2) ChatGPT is an elementary illustrator. Among the four error types, the majority lies in the shape/size error, which happens 68% of the time. For the other three error types (layout, color, missing components), they appear 34%, 20%, and 18% of the time, respectively. For instance, ChatGPT cannot generate the exact shape of the maple leaf in the Canadian flag while it gets the layout and color correctly (Figure <ref type="figure" target="#fig_3">3</ref>). This is a natural defect of text-only language models as they never see actual visual data and textual data is usually conceptual.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Reasoning Evaluations of ChatGPT</head><p>Reasoning is one of the most actively discussed and debated abilities of LLMs as scaling the model parameter size also increases the implicit knowledge in LLMs <ref type="bibr">(Wei et al., 2022a;</ref><ref type="bibr" target="#b69">Wang et al., 2022;</ref><ref type="bibr">Huang and Chang, 2022)</ref>. Mahowald et al. eloquently argues that "language ability does not equal to thinking" or "reasoning" in LLMs, and that LLMs have poor reasoning skills despite possessing human-level language skills.</p><p>In the NLP literature, evaluating a model's reasoning often means evaluating its various skills in arithmetic, commonsense, and symbolic reasoning in different NLP tasks that require such skills <ref type="bibr" target="#b58">(Talmor et al., 2020;</ref><ref type="bibr" target="#b85">Zelikman et al., 2022;</ref><ref type="bibr">Wei et al., 2022b)</ref>. However, the reasoning itself is a much broader concept thus it is hard to conclude whether a model can "reason" or not based on those aforementioned, and current works on reasoning are scattered. This is in line with the anecdotal experience of users with ChatGPT -some of the examples demonstrate surprisingly good "reasoning" abilities compared to previously introduced LLMs but at the same time ChatGPT fails in very simple reasoning problems <ref type="bibr">(the, 2023;</ref><ref type="bibr" target="#b64">Venuto, 2023;</ref><ref type="bibr" target="#b33">Qiao et al., 2022;</ref><ref type="bibr" target="#b2">Cookup.ai, 2022;</ref><ref type="bibr">Labs, 2022)</ref>. Thus, we investigate the reasoning ability of ChatGPT in a more fine-grained manner, which includes deductive, inductive, abductive, analogical, causal, multi-hop, mathematical, temporal, and spatial reasoning, via question-answering tasks. We categorize available QA tasks into each category by avoiding overlap (i.e., choosing testsets that require mainly one specific category of reasoning). Composed results and corresponding datasets for each category are shown in Table <ref type="table" target="#tab_6">5</ref>. For evaluation, we manually check the accuracy of the answer as well as verify the rationales and explanations generated by ChatGPT. A detailed explanation of task setup is explained in Appendix F.</p><p>Logical Reasoning Inductive, deductive, and abductive reasoning are common forms of logical reasoning, a process of deriving a conclusion or judgment based on given evidence or past experience and observations <ref type="bibr" target="#b42">(Rogers et al., 2022;</ref><ref type="bibr" target="#b71">Wason and Johnson-Laird, 1972;</ref><ref type="bibr">Huang and Chang, 2022)</ref>. We first investigate basic reasoning skills with bAbI tasks <ref type="bibr">(Weston et al., 2016b)</ref>, 30 examples each from task 15 (inductive) and task 16 (deductive). One major investigation is that ChatGPT is a lazy reasoner that suffers more from induction. Interestingly, when ChatGPT was asked to answer a question given premises without any prompt engineering, it performed poorly in induction (0 out of 30) while it achieved much better performance in deduction (19 out of 30). However, when Chat-GPT is explicitly asked for reasonable inference inductive reasoning increases to 20 out of 30. Yet, it is still not as good as in deduction. When we repeat the analysis on advanced tasks, specifically on CLUTRR <ref type="bibr" target="#b51">(Sinha et al., 2019)</ref> for induction and En-tailmentBank for deduction <ref type="bibr" target="#b6">(Dalvi et al., 2021)</ref>, the same conclusion holds based on our experiment.</p><p>Non-textual semantic reasoning It is often investigated in public sharing about ChatGPT errors cases that it lacks the reasoning ability that requires non-text semantic understanding such as mathematical, temporal, and spatial reasoning. Not surprisingly, it could only score 23.33% (7/30) for the MATH dataset <ref type="bibr" target="#b44">(Saxton et al., 2019)</ref>  it often fails to understand clock direction (e.g., "W is at K's 3 o'clock") and diagonal spatial relations.</p><p>Commonsense Reasoning It is understanding and reasoning about everyday concepts and knowledge that most people are familiar with, to make judgments and predictions about new situations <ref type="bibr" target="#b53">(Storks et al., 2019)</ref>. Recent works show that LLMs perform impressively well on commonsense reasoning benchmarks <ref type="bibr" target="#b33">(Qiao et al., 2022;</ref><ref type="bibr">Huang and Chang, 2022;</ref><ref type="bibr">Bhargava and Ng, 2022)</ref>. Based on our evaluation with CommonsenseQA <ref type="bibr" target="#b59">(Talmor et al., 2018</ref><ref type="bibr">), PiQA (Bisk et al., 2020)</ref> and Pep-3k <ref type="bibr">(Wang et al., 2018b)</ref>, ChatGPT shows surprisingly good commonsense reasoning capability, perhaps due to its large parametric memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Factuality and Hallucination</head><p>LLMs are known to be susceptible to generating nonfactual, untruthful information, which is referred to as hallucination <ref type="bibr">(Lee et al., 2022;</ref><ref type="bibr">Ji et al., 2022a,b;</ref><ref type="bibr" target="#b54">Su et al., 2022;</ref><ref type="bibr">Dai et al., 2023b;</ref><ref type="bibr">Xu et al., 2023)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluating Interactivity in ChatGPT</head><p>ChatGPT has a built-in interactive ability thanks to conversational data fine-tuning and RLHF. We further delve into the benefit of exploiting this interactive ability of ChatGPT in three NLP tasks, summarization, machine translation, and multimodal generation. Our experiments demonstrate the potential of employing multi-turn interaction to refine the quality of the generated responses and improve the task performance of ChatGPT.</p><p>Interactivity on Summarization Summarization models aim to extract essential information from documents and to generate short, concise, and readable text <ref type="bibr">(Yu et al., 2021b;</ref><ref type="bibr" target="#b55">Su et al., 2021)</ref>. In real-world applications, people may want to improve the summary based on the previously generated summary. We ran experiments with 50 documents from SAMSum <ref type="bibr" target="#b16">(Gliwa et al., 2019)</ref> and conducted a two-turn iterative prompt approach.</p><p>ChatGPT usually generates an overly long summary. By adding a follow-up prompt after the first summary, "Please make the summary shorter", ChatGPT could provide a much shorter summary than the first response. Experimental results show that with the second length control prompt, the refined summaries achieve 7.99 and 1.64 gains on ROUGE-1 and ROUGE-2 respectively. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Interactivity on Multimodal Generation</head><p>The multi-turn interaction ability of ChatGPT enables the refinement of text-to-image generation. It is one of the most natural ways for humans to create artwork or product designs by requesting an AI tool iteratively. Through interaction with ChatGPT over multiple turns, a process of creating an interesting painting can be achieved (Figure <ref type="figure" target="#fig_7">7</ref>).</p><p>To quantitatively study how this ability impacts image generation, we conduct at most three rounds of post-editing for the flag-drawing task. As shown in Figure <ref type="figure" target="#fig_5">4</ref>, in the first round of generation, Chat-GPT rarely generates errorless SVG images except for some simple flags (e.g., Nigerian and German). We observe that 34% and 36% of samples experience improvement (i.e., fewer errors) from turn 1 to 2 and from turn 2 to 3, respectively. We also tested with the InstructGPT, which has the same backbone model as ChatGPT but lacks conversation ability. InstructGPT cannot achieve salient improvements by directly putting the intermediate results in the input context (Appendix H.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Discussion</head><p>Multitask, Multilingual, Multimodal ChatGPT outperforms SOTA LLMs in a zero-shot manner on various tasks and even surpasses fine-tuned models on some tasks. However, there are still some failure cases ( §2.1) and it produces responses with altered nuance and meaning. Therefore, dealing with these special cases is a complex but important task. In terms of multilinguality, ChatGPT achieves strong performance in many high-resource and mediumresource languages. Nevertheless, ChatGPT still lacks the ability to understand and generate sentences in low-resource languages ( §2.2), which is also supported by <ref type="bibr">Lai et al. (2023)</ref>. Additionally, ChatGPT lacks the generation ability of non-Latin script languages ( §2.2.2), despite the languages being high-resource. These raise the concern of language diversity and inclusivity in <ref type="bibr">ChatGPT (Joshi et al., 2020;</ref><ref type="bibr" target="#b79">Aji et al., 2022)</ref>. Regarding multimodality, our flag drawing experiments showed the potential of ChatGPT's multimodal ability. It would be an interesting research direction to further explore ChatGPT's multimodal ability to answer "can textual models like ChatGPT switch to a multimodal backbone?"</p><p>Reasoning The impressive performance of Chat-GPT has sparked interest in expanding its usage beyond traditional NLP tasks into more complex domains requiring sophisticated reasoning such as problem-solving, decision-making, and planning. Our evaluation of its reasoning abilities shows that they are not reliable. Specifically, our findings indicate that ChatGPT exhibits a tendency to be a lazy reasoner and that its capabilities are inconsistent across various reasoning abilities; To support the further expansion of its use cases, it is necessary to prioritize the development of systems with robust complex reasoning capabilities, which should also be facilitated by the creation of more comprehensive benchmarks for assessing these abilities, such as works by <ref type="bibr">Laskar et al. (2023b)</ref>; <ref type="bibr" target="#b34">Qin et al. (2023)</ref>; <ref type="bibr">Davis (2023a)</ref>, particularly when multiple abilities are required to complete the tasks.</p><p>Factuality&amp;Hallucinations ChatGPT, like other LLMs, still makes things up <ref type="bibr">(Ji et al., 2022a)</ref>.</p><p>To ensure factuality, it is possible to build LLMs with an interface to an external knowledge source, like Blenderbot 3.0 <ref type="bibr" target="#b50">(Shuster et al., 2022)</ref> and LaMDa <ref type="bibr" target="#b62">(Thoppilan et al., 2022)</ref>. Meanwhile, there are many forms of hallucinations that are not necessarily counterfactual but still undesirable. The RLHF process of ChatGPT can ensure human feedback to mitigate undesirable responses. However, researchers need to work on coming up with more automatic and scalable methods to detect and mitigate hallucinations and other undesirable artifacts.</p><p>Interactivity Compared with the previous LLMs, the interactive ability of ChatGPT has made a leap according to both qualitative and quantitative measures. Through interactivity, ChatGPT can recite from its own description, which is a very important ability. A similar exploration of this ability in LLMs has also been explored in other research works <ref type="bibr" target="#b56">(Sun et al., 2022;</ref><ref type="bibr" target="#b70">Wang et al., 2023)</ref>. However, sometimes ChatGPT retains the wrong answer even after receiving multiple rounds of prompts from the user. Improving the ability of ChatGPT to handle multiple rounds of user feedback is also an important challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitation</head><p>The experiments are done with the UI of Chat-GPT provided by OpenAI (15 December 2019 version), before the ChatGPT API was released, thus, the number of samples for evaluation is limited (30-200). However, tasks of evaluation should not be affected much because most of the recent updates/releases of ChatGPT are related to safety concerns. Moreover, It is possible to augment our benchmarks with other technical benchmarks for research purposes, especially now that the Chat-GPT APIs are available. There has been recent automatic or human-in-the-loop evaluations such as <ref type="bibr">(Laskar et al., 2023a)</ref> Nevertheless, many of the benchmarks are not necessarily interpretable to laypeople for general purposes, such as named entity recognition and etc. Our paper provides an easier-to-follow guideline.</p><p>Due to the page limit, many parts of the experimental setup details are added to the Appendix while the overall structure of evaluation and major insights stay in the main content. This may cause the reader inconvenience to follow the experiments. However, we publicly release the codebase that can help the community replicate the exact same evaluation either on ChatGPT or other LLMs easily.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics Statement</head><p>Responsible Generative AI Previous works have discussed the ethical implications or concerns associated with ChatGPT (and other LLMs) <ref type="bibr">(Jabotinsky and Sarel, 2022;</ref><ref type="bibr" target="#b57">Susnjak, 2022;</ref><ref type="bibr">Blanco-Gonzalez et al., 2022;</ref><ref type="bibr">Aydın and Karaarslan, 2022;</ref><ref type="bibr">Jeblick et al., 2022)</ref>. Agreeing with the previous literature, the responsible design and usage of LLMs including ChatGPT is an important and pressing challenge today. There are common issues with these models, such as fairness, toxicity, demographic bias, and safety, which need to be addressed. In the case of ChatGPT, Ope-nAI constructs safety layers and uses RLHF and potentially other means to filter out undesirable system responses. However, this is still not perfect and requires future research to further improve the robustness of the safety layer. This process is resource-intensive and opaque to the public. We hope to see a more open discussion and sharing of responsible design of LLMs from various organizations including OpenAI in the future.</p><p>Use of Scientific Artifacts/Data This paper conducts an evaluation of ChatGPT for academic purposes only. We comply with the terms and conditions of ChatGPT stated in https://openai.com /policies/terms-of-use. Moreover, we comply with all the licenses of all the data (i.e., test sets/benchmarks) that are used in this evaluation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head><p>The appendix consists the following content:</p><p>• A: Background and Related Work  <ref type="bibr" target="#b0">(Christiano et al., 2017)</ref>. Conventional natural language generation models, including dialogue models, are trained with maximum likelihood estimation (MLE) and might not be aligned with human preferences. For instance, for dialogue systems, humanness, engagement, and groundedness are some examples of essential criteria for success. Such discrepancy between training objectives and evaluation metrics becomes a bottleneck to performance improvement. By using RLHF, ChatGPT aligns more closely with human preferences in generating text than by using MLE.</p><p>Discussion on its Capability As ChatGPT has become available to public users through an easily accessible UI, there have been many discussions from a wide range of communities, not just from AI or NLP, but also from other disciplines. A line of discussion is the specific emergent ability and strength of ChatGPT in more technical perspectives. <ref type="bibr" target="#b22">Guo et al. (2023)</ref> conducts linguistic analyses of ChatGPT's writing against human experts and found that ChatGPT responses are strictly focused on the given question, more formal, objective, and less emotional. <ref type="bibr" target="#b26">Nov et al. (2023)</ref> also studies ChatGPT's generated medical advice if it passes the Turing test. <ref type="bibr" target="#b13">Frieder et al. (2023)</ref> show that "significantly below those of an average mathematics graduate student." There are many investigations of ChatGPT's understanding and potential applications in different fields such as law <ref type="bibr" target="#b34">(Choi et al., 2023)</ref>, medical domain <ref type="bibr">(Blanco-Gonzalez et al., 2022;</ref><ref type="bibr">Jeblick et al., 2022)</ref> and finance <ref type="bibr">(Birch, 2022;</ref><ref type="bibr" target="#b11">Dowling and Lucey, 2023)</ref>. Jeblick et al. ( <ref type="formula">2022</ref>) conduct a case study of the application of ChatGPT on simplified radiology reports. Another important line of discussion is the ethical concerns over the use of ChatGPT. The most active discussion is over the use of academic writing and exam integrity <ref type="bibr">(Jabotinsky and Sarel, 2022;</ref><ref type="bibr" target="#b57">Susnjak, 2022)</ref>. OpenAI also discusses the misuse of LM for disinformation and remedies.<ref type="foot" target="#foot_0">2</ref> Zhuo et al. study AI ethics of ChatGPT in criteria of bias, reliability, robustness, and toxicity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 LLM benchmark and evaluation</head><p>With the advancement of LLMs' generalization ability, there have been efforts to understand their capabilities, limitations, and risks. Recently, several benchmarks with a collection of a large number of NLP datasets, such as BIG-Bench <ref type="bibr" target="#b52">(Srivastava et al., 2022)</ref> and AI LM Harness <ref type="bibr" target="#b14">(Gao et al., 2021)</ref>, have been introduced. Moreover, HELM <ref type="bibr">(Liang et al., 2022)</ref> is proposed to conduct a holistic evaluation of LLMs that considers scenarios and metrics with a top-down approach. In this work, we instead focus on specific limitations and unique findings of ChatGPT that had not been discussed with previous LLMs.</p><p>There are also other works that discuss LLMs' emergent abilities through thorough surveys or case studies. <ref type="bibr">Mahowald et al. (2023)</ref> thoroughly studies LLMs capabilities by distinguishing formal and functional linguistic competence with reference to cognitive science, psychology, and NLP to clarify the discourse surrounding LLMs' potential. Other works focus on more specific abilities such as mathematical skills <ref type="bibr">(Davis, 2023b)</ref>, reasoning <ref type="bibr">(Webb et al., 2022a;</ref><ref type="bibr" target="#b33">Qiao et al., 2022)</ref>. Also, there have been overviews of existing LLMs (Gozalo-Brizuela and Garrido-Merchan, 2023; Wolfe, 2023)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 ChatGPT Evaluation</head><p>To the best of our knowledge, this benchmarking exercise is the first of its kind. Since the introduction of ChatGPT with its advancement, there has been a huge amount of assessments of ChatGPT to understand its limits. <ref type="bibr">Mao et al. (2023)</ref>  a tool's usefulness to society by evaluating ChatGPT's capabilities on 25 diverse analytical NLP tasks, most of them subjective even to humans. After the introduction of ChatGPT, GPT-4 has been introduced by OpenAI. However, OpenAI is not disclosing any internal benchmarking of ChatGPT. Even in their GPT-4 technical report <ref type="bibr" target="#b27">(OpenAI, 2023)</ref>, they have shown the performance of GPT4 in terms of human-level exams. So, it is important that there are 3rd party evaluations of generative models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B General Experimental Details</head><p>The experiments were done with the UI (15 December 2019 version) of ChatGPT provided by OpenAI, before the ChatGPT API was released. The number of samples for evaluation is 30-200. We've prioritized sample diversity, hand-picking tasks that encapsulate the abroad spectrum of scenarios a language model is likely to encounter, thus creating a representative snapshot of potential realworld applications. All experiments are single-run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Multitask Evaluation of ChatGPT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Summarization</head><p>We test on 100 samples from two common summarization datasets: half from SAMSum <ref type="bibr" target="#b16">(Gliwa et al., 2019)</ref>, a dialogue summarization dataset, and another half from CNN/DM <ref type="bibr" target="#b24">(Hermann et al., 2015;</ref><ref type="bibr">Nallapati et al., 2016)</ref>, news summarization datasets. The large version of <ref type="bibr">Bart (Lewis et al., 2020b</ref>) model fine-tuned on both datasets is conducted for comparison. Moreover, OpenAI's textdavinci-002 is used as the previous SOTA zero-shot model. We calculate ROUGE-1 scores for evaluating the generated summary. According to the evaluation, ChatGPT achieves a similar zero-shot performance with text-davinci-002, which is expected since they evolved from the same GPT3 pretrained checkpoint. However, the fine-tuned Bart still outperforms zero-shot ChatGPT by a large margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Machine Translation</head><p>We evaluate the machine translation ability of Chat-GPT on both high-resource and low-resource languages using the ChrF++ metric <ref type="bibr" target="#b30">(Popović, 2015)</ref>. Specifically, we incorporate 8 high-resource languages, i.e., French (fra), Spanish (spa), Chinese (zho), Arabic (ara), Japanese (jpn), Indonesian (ind), Korean (kor), and Vietnamese (vie), and 4 low-resource languages, i.e., Javanese (jav), Sundanese (sun), Marathi (mar), and Buginese (bug) for our evaluation. <ref type="foot" target="#foot_1">3</ref> For each language pair, we sample 30 Eng↔XXX parallel sentences from the FLORES-200 dataset <ref type="bibr" target="#b60">(Team et al., 2022;</ref><ref type="bibr" target="#b19">Goyal et al., 2021)</ref>. The result of our experiment suggests that ChatGPT can well perform XXX→Eng translation, but it still lacks the ability to perform Eng→XXX translation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Sentiment Analysis</head><p>Sentiment analysis has been widely explored for both high-resource and low-resource languages <ref type="bibr">(Wang et al., 2018a;</ref><ref type="bibr" target="#b78">Wilie et al., 2020;</ref><ref type="bibr">Ilmania et al., 2018)</ref>.</p><p>We explore the sentiment analysis ability of ChatGPT through 4 languages with diverse amounts of resources in NusaX <ref type="bibr" target="#b79">(Winata et al., 2022)</ref>: English (eng), Indonesian (ind), Javanese (jav), and Buginese (bug). For each language, we sample 50 sentences from the corresponding dataset for our experiment and measure the macro F1 score as the evaluation metric. We compare the results with two baselines, i. This shows that ChatGPT still has a limited understanding of extremely low-resource languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4 Question Answering</head><p>Since Question Answering (QA) is a broad topic, we classify QA datasets into different categories based on the knowledge/reasoning type required to do the task, e.g commonsense reasoning, spatial reasoning, temporal reasoning, etc., to have a clearer analysis on ChatGPT's abilities. For each category, we select several datasets, and for each dataset, we sample 30 instances and test ChatGPT on the subset. Based on our experiment results, ChatGPT outperforms the existing zero-shot and some of the fine-tuned state-of-the-art performance on question answering. Furthermore, ChatGPT achieves near-perfect scores on three tasks, i.e., bAbI task 15, EntailmentBank, and Pep-3k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.5 Misinformation Detection</head><p>We test ChatGPT's ability to detect misinformation with the test sets that consist of scientific and social claims related to <ref type="bibr">COVID-19 (Lee et al., 2021)</ref> with 100 samples. We take half from scientific (covid-scientific) and another half from social (covid-social) sets. We evaluate the accuracy of the veracity by manually checking the generated text. ChatGPT could detect misinformation 92% (46/50) and 73.33% (22/30, excluding verificationrefusing cases) accuracy on covid-scientific and covid-social respectively.</p><p>C.6 ChatGPT on Dialogue Tasks C.6.1 Knowledge-Grounded Open-Domain Dialogue</p><p>Open-domain dialogue systems interact with humans with generated responses automatically and aim to provide users with an engaging experience.</p><p>To boost informativeness, these systems leverage external knowledge, including structured knowledge such as knowledge graphs <ref type="bibr" target="#b88">(Zhao et al., 2020;</ref><ref type="bibr">Ji et al., 2022b)</ref> and unstructured knowledge such as free text <ref type="bibr">(Xu et al., 2022</ref><ref type="bibr">(Xu et al., , 2023))</ref>. Prompt used for experiment: "Can we try dialogue generation? I will give you turns, and you can generate the next turn, but only one.\n \n You can also consider the knowledge of XXX for your reference in the dialogue."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.6.2 Task-Oriented Dialogue Experimental</head><p>Setups Setup A: Modular Approach We investigate ChatGPT's ability for both dialogue state tracking and response generation in 50 dialogue turn samples taken from MultiWOZ2.2 <ref type="bibr" target="#b84">(Zang et al., 2020)</ref>. In detail, we ask the model to provide the belief state as domain-intent: [slot1, value1], . . . in the prompt following previous zero-shot <ref type="bibr">(Lin et al., 2021)</ref> and few-shot (Madotto et al., 2021) approaches, and provide an exhaustive list of domainintent-slot-value for the given dialogue. For the response generation, we provide only the oracle dialogue actions (e.g. 'Hotel-Inform':['area', 'centre']), and ask ChatGPT to generate a TOD response given the dialogue history. We assess DST with joint goal accuracy (JGA), the ratio of dialogue turns where the predicted dialogue state is exactly the ground truth, and response generation with BLEU and inform rate(%) Setup B: Unified Approach We explore Chat-GPT's ability to simulate a TOD interaction in an end-to-end manner by providing nothing more than a structured database and giving the instruction: "Use the following knowledge base to complete the task of recommending a restaurant as a task-oriented dialogue system".</p><p>Result Analysis: We could investigate whether ChatGPT is able to complete basic retrieval queries and respond to users' requests such as "Give me some restaurants that serve Italian food" or "I would prefer cheap options please". However, there are several limitations that we could investigate as follow.</p><p>• Long-term Multi-turn Dependency: Chat-GPT cannot keep the belief state across multiple turns within the interaction. For instance, asking for Italian food will overwrite the previous turn's belief state by asking for restaurants with a rating of 3 or higher. However, if the user explicitly asks to recall the earlier preferences, ChatGPT is able to correct the retrieved information and incorporate the previous belief state. This is interesting as it shows that the information previously given in multi-turn is still usable, but needs to be called explicitly.</p><p>• Basic Reasoning Failure: ChatGPT's response tends to be wrong if the query introduces a basic level of reasoning such as when it is asked for "recommendation for restaurants with European food" (ChatGPT has to filter the types of cuisine which are based on countries) or "recommendation for restaurants with a rating of 3 or higher" (ChatGPT needs to understand rating 3, 4 and 5). Even with a basic knowledge base, ChatGPT fails to answer correctly 66% of the time.</p><p>• Extrinsic Hallucination: ChatGPT tends to generate hallucinated information beyond the given knowledge. This is especially harmful in TOD as ChatGPT will sometimes hallucinate some prices for hotel booking, or availability for restaurants.</p><p>We provide the example for the modular and unified approaches for Task-Oriented Dialogue in Table <ref type="table">6</ref> and<ref type="table">Table 7</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ChatGPT</head><p>Based on the information provided in the knowledge base, I would recommend Papa John and Pizza House for Italian food. Papa John is rated 4 out of 5 and is classified as "Moderate" in terms of price, while Pizza House is rated 2 out of 5 and is also classified as "Moderate". Papa John is located on 3rd street, while Pizza House is located on 3rd street as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prompt</head><p>Did you forget I only wanted restaurants rated 3 or higher?</p><p>ChatGPT I apologize, I must have misunderstood your previous request. Based on the knowledge base provided, The only Italian restaurant that is rated 3 or higher is Papa John which is rated 4 out of 5 and is located on 3rd street. It is classified as "Moderate" in terms of price.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prompt</head><p>Great thanks for your help.</p><p>ChatGPT You're welcome! I hope you enjoy your meal at Papa John. If you have any other questions or need further assistance, feel free to ask.</p><p>Table <ref type="table">7</ref>: Example of multi-turn unified approach for Task-Oriented Dialogue using ChatGPT</p><p>ChatGPT InstructGPT text-davinci-003</p><p>The language of the text appears to be a variant of the Bugis language spoken in Indonesia.</p><p>The language of the text is the Sasak language, spoken in Lombok, Indonesia.</p><p>The text is written in Buginese.</p><p>I am sorry, I do not recognize the language of the text.</p><p>The language of the text is Koyukon Athabascan.</p><p>The text is in the Balinese language.</p><p>The language of the text appears to be a dialect of the Indonesian language.</p><p>The language of the text is Indonesian.</p><p>The language of the text is Indonesian.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D ChatGPT on Multilinguality</head><p>We present the statistics of language under study in Table <ref type="table" target="#tab_13">9</ref>. In the following section, we provide the insights that we find during our experiment in exploring multilingual capability of ChatGPT.</p><p>ChatGPT understands LRL sentences but fails to identify their language As shown in Table <ref type="table" target="#tab_15">10</ref>, ChatGPT correctly classifies the languages for English and Indonesian 100% of the time. While for the language identification for Javenese and Buginese, ChatGPT either misclassifies the samples as other languages or is unable to determine the language. Nevertheless, ChatGPT performance on the sentiment analysis in Javanese is only slightly lower compared to English and Indonesian which suggests that ChatGPT can understand the semantic meaning of sentences in low-resource languages without having the knowledge to identify the language itself. This limitation of language identification in LMs aligns with the result from BIGbench <ref type="bibr" target="#b52">(Srivastava et al., 2022)</ref>.</p><p>ChatGPT displays better human-preferred responses As shown in Table <ref type="table" target="#tab_12">8</ref>, ChatGPT lets the user know that its prediction is uncertain when it does not completely understand the language and also provides broader information regarding the language, such as location and tribe of which the predicted language is spoken. This fact provides evidence regarding the benefit of using the RLHF approach compared to other training approaches for aligning LLMs with human preferences.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Multimodality: Flag Drawing Task</head><p>Task Formulation We uniformly collect 50 national flags from different continents and conduct the flag-drawing task on ChatGPT. The flagdrawing task contains three steps:</p><p>1. Ask ChatGPT to illustrate the appearance of the flag using the prompt "Describe how the &lt;NATION&gt; flag looks like".</p><p>2. Based on the description, ask ChatGPT to generate the SVG code of that flag by prompting "Generate a code snippet to represent that flag in SVG format".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">If the generated image contains errors, we iteratively ask ChatGPT to fix them.</head><p>There are four types of evaluation criteria: 1) layout 2) color 3) missing components 4) shape/size. In each round of fixing, we ask ChatGPT to revise only one type of error with the prompt "&lt;ERROR DESCRIPTION&gt;. Revise the image". We terminate the conversation once the generated flag becomes perfect or we have already passed two rounds of fixing.</p><p>Evaluation The generated flag images are evaluated by the aforementioned four error types as criteria. We further assess the image quality with five grades, A ∼ E, which indicate zero to four (or above) errors. We assign grades to each round so that we can assess the number of improvements and degradation through conversational interactions (post-editing). The full results are shown in Figure <ref type="figure" target="#fig_5">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Details for Reasoning Evaluations</head><p>Table <ref type="table" target="#tab_17">11</ref> shows the categories of reasoning that are evaluated in this paper as well as corresponding datasets. The following section introduces each of the categories and detailed experimental setup and/or analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.1 Logical Reasoning</head><p>Inductive and deductive are categorized by "a degree to which the premise supports the conclusion" based on logic and philosophy <ref type="bibr" target="#b33">(Qiao et al., 2022;</ref><ref type="bibr" target="#b42">Rogers et al., 2022;</ref><ref type="bibr" target="#b23">Hawthorne, 2021)</ref>. Inductive reasoning is based on "observations or evidence" while deductive is based on "truth of the premises" (i.e., necessarily true inference) <ref type="bibr" target="#b10">(Douven, 2017)</ref>.</p><p>Another way to categorize is based on the "direction of reasoning" -deductive is from premise to conclusion while abductive is from conclusion to the most probable premise that supports the conclusion <ref type="bibr" target="#b65">(Walton, 2014)</ref>.</p><p>Inductive and deductive reasoning are common forms of logical reasoning that are categorized by "a degree to which the premise supports the conclusion" based on logic and philosophy <ref type="bibr">(Qiao et al.,</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Categories Dataset</head><p>Deductive EntailmentBank <ref type="bibr" target="#b6">(Dalvi et al., 2021)</ref> bAbI (task 15) <ref type="bibr">(Weston et al., 2016b)</ref> Inductive CLUTRR <ref type="bibr" target="#b51">(Sinha et al., 2019)</ref> bAbI (task16) <ref type="bibr">(Weston et al.,</ref>   2022; <ref type="bibr" target="#b42">Rogers et al., 2022;</ref><ref type="bibr" target="#b23">Hawthorne, 2021)</ref>. Deductive reasoning involves processes of driving specific conclusions based on more general premises.</p><p>On the contrary inductive reasoning involves specific observation of patterns, processing them on increasingly abstract cycles of hypothetico-deductive reasoning to draw a more general conclusion <ref type="bibr">(Lawson, 2005)</ref>. Comparing the two types of reasoning, deduction requires less "guessing" from the perspective of ChatGPT, as induction requires figuring out rules <ref type="bibr" target="#b42">(Rogers et al., 2022)</ref>. The former can be viewed as top-down while the latter is bottom-up.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.1.1 Deductive vs. Inductive Reasoning</head><p>Deductive reasoning involves processes of driving specific conclusions based on more general premises. On the contrary, inductive reasoning involves specific observation of patterns, processing them on increasingly abstract cycles of hypotheticodeductive reasoning to draw a more general conclusion <ref type="bibr">(Lawson, 2005)</ref>. Comparing the two types of reasoning, deduction requires less "guessing" from the perspective of ChatGPT, as induction requires figuring out rules <ref type="bibr" target="#b42">(Rogers et al., 2022)</ref>. The former can be viewed as top-down while the latter is bottom-up.</p><p>We explore ChatGPT's ability of inductive and deductive reasoning in two different levels: 1) basic and 2) advanced. Basic-level tasks are the prerequisites to probe reasoning. While solving these tasks does not necessarily indicate full reasoning capability, if ChatGPT fails on any of these tasks, then  there are likely real-world tasks that it will fail on too if they require similar reasoning mechanisms. Consequently, the advanced-level tasks are there to probe those capabilities in real-world tasks where the noises are present, and solving them requires a more systematic generalization. Additionally, we choose tasks that do not require or are dependent on external knowledge and the solution could be only derived by premises to focus on dissecting the capability of each reasoning mechanism.</p><p>Results &amp; Detailed Analysis ChatGPT answers "It is not specified what &lt;attribute&gt; &lt;entity&gt; is." for most of the time when it was asked a question requiring inductive reasoning. However, when ChatGPT is explicitly asked for reasonable inference with a prompt "Based on the given facts, do a reasonable inference on this question using inductive reasoning:", its ability for inductive reasoning increases. Yet, it is still not as good as in deduction as the same prompt engineering also helps increases its ability for deductive reasoning.</p><p>We could derive similar insight as ChatGPT only correctly answered for half of the time while it could make inferences deductively well for 90% of the time. CLUTRR <ref type="bibr" target="#b51">(Sinha et al., 2019)</ref> requires induction on extracting relations between entities, and in the ChatGPT responses, it often asks for more information to make inferences. An interesting finding along with CLUTRR was that Chat-GPT can't differentiate son and grandson but can differentiate daughter and granddaughter when it induces the logical rules governing kinship relationships. We show all performances in Table <ref type="table" target="#tab_19">12</ref> and some of the prompting samples in Table <ref type="table" target="#tab_4">13</ref>. We follow <ref type="bibr" target="#b33">(Qiao et al., 2022)</ref> categorization on the deductive and inductive reasoning datasets, but we only use the QA part of EntailmentBank, that the authors took from ARC dataset <ref type="bibr" target="#b1">(Clark et al., 2018)</ref>, as we aim to test for reasoning capability. Regarding EntailmentBank, it might trigger the universe-related knowledge out of ChatGPT, which could help the model to derive the correct answer, although the test set is designed to test deductive reasoning skills. One of the future explorations would be with checking the rationale of ChatGPT as a follow-up question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.1.2 Abductive Reasoning</head><p>Abductive reasoning is the inference to the most plausible explanation given observations. For instance, "if Jenny finds her house in a mess when she returns from work, and remembers that she left a window open, she can hypothesize that a thief broke into her house and caused the mess"<ref type="foot" target="#foot_2">4</ref> . We test ChatGPT's language-based abductive reasoning ability with 30 samples from αNLI dataset <ref type="bibr">(Bhagavatula et al., 2020)</ref>, which requires the model to select the most plausible explanation given the conclusion. Based on our test, it could achieve 86.7% (26 out of 30) accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2 Non-textual Semantic Reasoning</head><p>Mathematical reasoning Mathematical capabilities or numerical reasoning has been frequently mentioned to be lacking for LLMs, not only Chat-GPT <ref type="bibr" target="#b13">(Frieder et al., 2023)</ref>. <ref type="bibr">Frieder et al. test</ref> Chat-GPT's capability with publicly available datasets as well as the human-curated dataset, which consists of 728 prompts. The shared findings for ChatGPT's mathematical capabilities include 1) ChatGPT often understands the question but fails to provide correct solutions; 2) it shows inconsistent poor performance on graduate-level advanced mathematics; 3) it has a great ability to search for mathematical objects. <ref type="foot" target="#foot_3">5</ref> We also test separately on MATH dataset. Not surprisingly, it could only score 23.33% (7/30) for the MATH dataset <ref type="bibr" target="#b44">(Saxton et al., 2019)</ref>, which tests mathematical reasoning.</p><p>Temporal reasoning Temporal reasoning is mentioned a few times in the literature but is less common than others. It tests the understanding of the time duration of and the relation between events. For this category, we conduct experiments on the dataset TimeDial <ref type="bibr" target="#b34">(Qin et al., 2021)</ref>, which solely requires temporal reasoning. We follow the format of  the task in the BIG-bench benchmark <ref type="bibr" target="#b52">(Srivastava et al., 2022)</ref>, which is multiple-choice (single correct answer), Overall, ChatGPT correctly answers 86.67% of the time (26/30), suggesting that it has a decent temporal reasoning ability. Also, compared to Chinchilla and Gopher which have the accuracy of 68.8% and 50.9% respectively, ChatGPT shows a promising improvement for LLMs in that aspect.</p><p>Spatial Reasoning Spatial reasoning is using an understanding of spatial relations among different objects and spaces. For spatial reasoning, we utilize two existing datasets: SpartQA (Mirzaee et al., 2021) and StepGame <ref type="bibr">(Shi et al., 2022a)</ref>, which compose of story-question pairs about k relations of k+1 (where k is up to 10) entities written in natural language. ChatGPT is asked to answer spatial relations between two entities based on the provided descriptions of different entities. ChatGPT falls short of the spatial reasoning tasks, as shown in Table <ref type="table" target="#tab_21">15</ref>, with overall success rates of 43.33% for StepGame and 43.75% for SpartQA. ChatGPT could only score 25% on SpartQA (hard), which covers multiple spatial reasoning sub-types, and 23.33% for stepGame (Hard) with k=9. ChatGPT could not provide any spatial relations but instead generated "It is not specified in the given description". Even with the fine-tuned models, as the number of relations (k) increases in context description, performance drops <ref type="bibr">(Shi et al., 2022a)</ref>.</p><p>To understand spatial reasoning ability at a more elementary level, we test with less complicated examples from StepGame which we refer to as StepGame (Basic). It does not involve multi-hop reasoning but purely spatial relation between two entities. (e.g, "C is sitting at the top position to Y. What is the relation of the agent Y to the agent C?"). We test for basic spatial relations with 8 labels from StepGame {left, right, above, below, lowerleft, lower-right, upper-left, upper-right}. When we test on StepGame (Basic), ChatGPT scores higher (63.33%).</p><p>We investigate the errors that it often fails to understand clock direction (e.g., "W is at K's 3 o'clock") and diagonal spatial relations. We further analyze the results by breaking down the test examples of StepGame (Basic) into two comparisons: i) types of directions (basic cardinal vs. diagonal) and ii) ways of spatial description for cardinal directions (basic cardinal<ref type="foot" target="#foot_4">6</ref> vs. clock-position cardinal). We take 20 more samples for each category (basic cardinal, diagonal, clock-position cardinal) and tested them as illustrated in Table <ref type="table">14</ref>.</p><p>• ChatGPT poorly infers with clock-position description. Although it is a simple cardinal direction, ChatGPT could only correctly answer for 5 samples (25%), which is clearly poorer performance in comparison to performance with the basic cardinal description (17 correct answers).</p><p>• ChatGPT is worse at the diagonal position. It correctly answers around half of the time (55%), which is worse than basic cardinal points (85%). Even with analysis from StepGame (Hard), among the correct 7 answers, there is only one diagonal direction that ChatGPT gets correctly while the others are all cardinal points. For those answers that require diagonal points, ChatGPT only could infer cardinal points for some examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.3 Commonsense Reasoning</head><p>To evaluate ChatGPT's capability on commonsense reasoning, we first test it on two widely used benchmark datasets CommonsenseQA <ref type="bibr" target="#b59">(Talmor et al., 2018)</ref> and <ref type="bibr">PiQA (Bisk et al., 2020)</ref>. Common-senseQA focuses on general commonsense question answering such as "Where is a business restaurant likely to be located?", and PiQA is about physical commonsense reasoning: given a sentence such as "When boiling butter, when it's ready, you can ", the goal is to fill in the blank with one of two answer options, "Pour it onto a plate" and "Pour Prompt Please judge if this predicate is (likely) plausible or implausible: "knife chop rock"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ChatGPT Answer</head><p>It is implausible that a knife could chop through a rock. Knives are made to cut through softer materials such as food, paper, or wood. Rocks are much harder than these materials and a knife would not be able to make a dent in a rock, let alone chop it.</p><p>Table <ref type="table">17</ref>: An example from Pep-3k <ref type="bibr">(Wang et al., 2018b)</ref> for commonsense reasoning of ChatGPT. We make the main answer bold, and highlight the explanation by green color.</p><p>it onto a jar". We use the validation split for both of the datasets since there are no labels provided on the test set that we retrieve. We also further probe ChatGPT by evaluating a more challenging commonsense reasoning dataset in a more comprehensive way. We use Pep-3k <ref type="bibr">(Wang et al., 2018b)</ref>, which requires the model to recognize plausible but possibly novel events, such as "man swallow paintball". Each instance in the Pep-3k is an s-v-o predicate, and the task is to judge if the predicate is plausible or not. But instead of evaluating Chat-GPT's performance only based on the binary judgment, we also check if the answer contains relevant rationales (explanations) that lead to its judgment.</p><p>For the Pep-3k samples, we prepend the s-v-o predicate with "Please judge if this predicate is (likely) plausible or implausible:" to prompt Chat-GPT. We show the results in Table <ref type="table" target="#tab_22">16</ref>. As we see, ChatGPT performs quite well on the three datasets in terms of answer accuracy, which matches our anticipation. Furthermore, as we also check the rationales in ChatGPT's answer when evaluating Pep-3k samples, we can see that ChatGPT does quite well not only in terms of answer accuracy but also in generating reasonable reasoning procedures to support its answer. We show a concrete example in Table <ref type="table">17</ref>. As we can see, ChatGPT's answer explains well what kinds of materials are usually cut through with knives (i.e., food, paper, or wood). Then, it reasons why rocks cannot be chopped with a knife by explaining 'rocks are much harder than these materials.' While our findings are based on 30 samples from each dataset, we see the potential in ChatGPT's commonsense reasoning capability, and further large-scale investigation is worth exploring. F.4 Causal, Multi-Hop, and Analogical Reasoning</p><p>Causal Reasoning Causal reasoning is the process of identifying the relationship between causes/actions and effects/changes (i.e., causality) <ref type="bibr" target="#b61">(Thomason, 2018;</ref><ref type="bibr">Huang and Chang, 2022)</ref>. We test ChatGPT on 30 samples of human-annotated explainable CAusal REasoning dataset (E-CARE) <ref type="bibr" target="#b12">(Du et al., 2022)</ref> and it could score 24 samples correctly (80%). Note that our evaluation is mainly based on whether the model can make a judgment on correct causes or effects instead of its generated explanation of why the causation exists.</p><p>Multi-hop Reasoning To be able to reason over a larger context, a system has to perform multi-hop reasoning over more than one piece of information to arrive at the answer <ref type="bibr">(Mavi et al., 2022)</ref>. We test ChatGPT's multi-hop reasoning capability on 30 samples of HotpotQA dataset <ref type="bibr">(Yang et al., 2018)</ref> and we find that ChatGPT has difficulty performing with such capability, only answering 8 samples correctly, although the questions posed are only 2-hops. It is worth noting that ChatGPT oftentimes generates the answer in a short passage of explanations, thus we evaluate manually each of the Chat-GPT responses to check its accuracy. This aligns with the findings that LLMs are also limited in several ways, and fail to produce accurate predictions due to their inability to accomplish complex reasoning, such as solving tasks that require multi-hop reasoning <ref type="bibr" target="#b28">(Ott et al., 2023)</ref>.</p><p>Analogical Reasoning Analogical reasoning is a way of thinking that relies upon an analogy, comparing two or more objects or systems of objects (Bartha, 2013) to drive a conclusion. We test with 30 samples from <ref type="bibr">Webb et al. (2022b)</ref> and evaluate based on human evaluation, to see if the generated answer match with/contain the gold answer. Chat-GPT could correctly answer all 30 examples, which may reveal that ChatGPT has a good capability in analogical reasoning skills.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Details for Hallucination Evaluations</head><p>There exist two categories of hallucination <ref type="bibr">(Ji et al., 2022a)</ref>. Intrinsic hallucinations that refers to the LLM generation that contradicts the source/input content. Extrinsic hallucinations that refers to the LLM generations that cannot be verified from the source/input content (i.e., output that can neither be supported nor contradicted by the source). In Table <ref type="table" target="#tab_13">19</ref>, we share examples of these hallucination types detected from different task explorations. With the setting of tasks we test, we often find extrinsic hallucinations, including both untruthful and factual ones, across various tasks such as Machine Translation, Question answering. The intrinsic hallucinations are barely found. For instance, in the abstractive summarization task, in which neural models usually suffer from intrinsic hallucination, ChatGPT's generated summarisation did not include any intrinsic hallucination examples based on our experiments. It rather shows a factual extrinsic hallucination, for instance, Chat-GPT could correctly paraphrase "Britain and five other countries" from source input into "P5+1 (US, UK, France, China, Russia, and Germany)," which is assessed to be factual. We could also observe an interesting intrinsic hallucination for our proposed multi-modal task, the flag drawing task. ChatGPT is first asked to generate a description of how the flags look before it is asked to generate code for the flag. Although it generates the correct description as "The flag of Mexico consists of three vertical bands [...]", the final drawing (SVG code) consists of horizontal bands.</p><p>However, extrinsic hallucinations often happen, including both untruthful and factual ones. In the QA task, we often find extrinsic hallucination to be non-factual which harms the final performance. For instance, in the question of asking for the relationship among entities, although step kindship is never mentioned in the question, ChatGPT answers the question with step kinship, as illustrated in Table <ref type="table" target="#tab_13">19</ref>. We could also observe that ChatGPT's weakness with extrinsic hallucination also degrades machine translation. When it is asked to translate the text "Like some other experts, he is skeptical about whether diabetes can be cured, noting that these findings have no relevance to people who already have Type 1 diabetes." into Korean, it contains a piece of information that was not found in the source, "ᄌ ᅥᄌ ᅮᄑ ᅡ ᄎ ᅵᄅ ᅭ" (transcutaneous electrical nerve stimulation) in the translated text. English sentence. 9  As shown on Table <ref type="table" target="#tab_2">20</ref>, the single-turn translation without post-editing produces a slightly better evaluation score on the Marathi language, but the multi-turn with post-editing consistently yields better evaluation performance on the back-translated English text on all metrics. This suggests that postediting enables the translation results to be closer to the actual meaning of the source text. Nevertheless, the translation to the Marathi language is much worse compared to the baseline MT provided from the APE 2022 shared task <ref type="bibr">(Bhattacharyya et al., 2022)</ref> which further supports the limitations of ChatGPT on generating sentences in low-resource and non-Latin script languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H.3 Interactivity on Multimodal Generation</head><p>We show an example of a multi-turn flag drawing of InstructGPT, which has the same backbone model as ChatGPT but lacks conversation ability, Figure <ref type="figure" target="#fig_6">6</ref>. to ChatGPT, InstructGPT can revise the generated flag image in each turn, although the generation quality is still elementary. Figure <ref type="figure" target="#fig_7">7</ref> shows the process of creating an interesting painting by prompting ChatGPT with varied requirements through multiple turns.</p><p>9 the back translation process is done via Google Translate (https://translate.google.com/). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I List of Evaluation Datasets</head><p>We provide a detailed list of all the datasets used in our experiment on Table <ref type="table" target="#tab_26">21</ref>  <ref type="formula">20</ref>) QA bAbI tasks that a set of proxy tasks that evaluate reading comprehension via question answering. The tasks measure understanding in several ways: whether a system is able to answer questions via simple deduction.</p><p>The tasks are designed to be prerequisites for any system that aims to be capable of conversing with a human.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Weston et al. (2016b) 1000</head><p>bAbI task 16 QA This basic induction bAbI tasks is taken from the (20) QA bAbI tasks that a set of proxy tasks that evaluate reading comprehension via question answering. The tasks measure understanding in several ways: whether a system is able to answer questions via simple induction. The tasks are designed to be prerequisites for any system that aims to be capable of conversing with a human.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chinese</head><p>Although three people were inside the house when the car impacted it, none of them were hurt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>虽然车撞到房子时，房子里面有</head><formula xml:id="formula_0">三个人，但最后并没有人受伤。 尽 管 有 三 个 人 在 汽 车 撞 上 房 子 的时候在屋里，但他们都没有受 伤。 尽管汽车撞上房子时有三个人在 屋里，但他们都没有受伤。</formula><p>Chinese 34 per cent of those in the poll share this view, wanting Queen Elizabeth II to be Australia's last monarch.</p><formula xml:id="formula_1">34% 的受访者一致表示，希望英 国女王伊丽莎白二世成为澳大利 亚的最后一任君主。 这项民意调查显示，34%的人希望 伊丽莎白二世是澳大利亚的最后 一位君主。 根据民意调查显示，34%的人希望 伊丽莎白二世成为澳大利亚的最 后一位君主。</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chinese</head><p>The qualities that determine a subculture as distinct may be linguistic, aesthetic, religious, political, sexual, geographical, or a combination of factors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>让亚文化变得与众不同的特质，</head><formula xml:id="formula_2">可 能 是 语 言 、 美 学 、 宗 教 、 政 治、性别、地理或多种因素的组 合。 什么决定一个亚文化作为不同的 特质可能是语言的、审美的、宗 教的、政治的、性的、地理的， 或者这些因素的组合。 决定一个亚文化与众不同的特质 可 能 是 语 言 的 、 审 美 的 、 宗 教 的、政治的、性的、地理的，或 者是这些因素的组合。</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chinese</head><p>New Kingdom ancient Egyptians marvelled at their predecessors monuments, which were then well over a thousand year old.</p><formula xml:id="formula_3">新王国时期的古埃及人惊叹于其 前辈的已有一千多年历史的纪念 碑。 新王朝古埃及人惊叹于他们的前 人的纪念碑，当时已经有一千多 年的历史了。 新王朝的古埃及人惊叹于他们前 人留下的纪念碑，当时已经有超 过一千年的历史。</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chinese</head><p>The U.S. Corps of Engineers estimated that 6 inches of rainfall could breach the previously damaged levees.</p><formula xml:id="formula_4">美国陆军工兵部队估计，6 英寸的 降雨量就可能冲垮之前损坏的堤 坝。 美国工程兵部队估计，6英寸的降 雨可能会破坏先前受损的堤坝。 美国工程兵部队估计，6英寸的降 雨可能会使先前受损的堤坝再次 损坏。</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Korean</head><p>Although three people were inside the house when the car impacted it, none of them were hurt.</p><formula xml:id="formula_5">ᄎ ᅡᄀ ᅡ ᄌ ᅵ ᆸᄋ ᅦ ᄎ ᅮ ᆼᄃ ᅩ ᆯᄒ ᅢ ᆻᄋ ᅳ ᆯ ᄄ ᅢ ᄉ ᅦ ᄆ ᅧ ᆼᄋ ᅵ ᄋ ᅡ ᆫ ᄋ ᅦ ᄋ ᅵ ᆻᄋ ᅥ ᆻᄌ ᅵᄆ ᅡ ᆫ, ᄀ ᅳᄃ ᅳ ᆯ ᄌ ᅮ ᆼ ᄒ ᅡ ᆫ ᄆ ᅧ ᆼᄃ ᅩ ᄃ ᅡᄎ ᅵ ᄌ ᅵ ᄋ ᅡ ᆭᄋ ᅡ ᆻᄃ ᅡ. ᄎ ᅡᄀ ᅡ ᄌ ᅵ ᆸᄋ ᅦ ᄇ ᅮᄃ ᅵ ᆽᄒ ᅵᄌ ᅡ ᄌ ᅵ ᆸ ᄋ ᅡ ᆫᄋ ᅦ ᄉ ᅦ ᄉ ᅡ ᄅ ᅡ ᆷᄋ ᅵ ᄋ ᅵ ᆻᄋ ᅥ ᆻᄌ ᅵᄆ ᅡ ᆫ, ᄋ ᅡᄆ ᅮᄃ ᅩ ᄃ ᅡᄎ ᅵᄌ ᅵ ᄋ ᅡ ᆭ ᄋ ᅡ ᆻᄉ ᅳ ᆸᄂ ᅵᄃ ᅡ. ᄎ ᅡᄀ ᅡ ᄌ ᅵ ᆸᄋ ᅦ ᄇ ᅮᄃ ᅵ ᆽᄒ ᅵᄌ ᅡ ᄌ ᅵ ᆸ ᄋ ᅡ ᆫᄋ ᅦ ᄉ ᅦ ᄉ ᅡ ᄅ ᅡ ᆷᄋ ᅵ ᄋ ᅵ ᆻᄋ ᅥ ᆻᄌ ᅵᄆ ᅡ ᆫ, ᄋ ᅡᄆ ᅮᄃ ᅩ ᄉ ᅡ ᆼᄒ ᅢᄅ ᅳ ᆯ ᄋ ᅵ ᆸ ᄌ ᅵ ᄋ ᅡ ᆭᄋ ᅡ ᆻᄉ ᅳ ᆸᄂ ᅵᄃ ᅡ.</formula><p>Korean 34 per cent of those in the poll share this view, wanting Queen Elizabeth II to be Australia's last monarch.</p><formula xml:id="formula_6">ᄋ ᅧᄅ ᅩ ᆫ ᄌ ᅩᄉ ᅡᄋ ᅦᄉ ᅥ 34 ᄑ ᅥᄉ ᅦ ᆫᄐ ᅳᄀ ᅡ ᄋ ᅦ ᆯᄅ ᅵᄌ ᅡ ᄇ ᅦᄉ ᅳ 2ᄉ ᅦᄀ ᅡ ᄒ ᅩᄌ ᅮᄋ ᅴ ᄆ ᅡᄌ ᅵᄆ ᅡ ᆨ ᄀ ᅮ ᆫᄌ ᅮᄋ ᅵ ᄀ ᅵ ᆯ ᄇ ᅡᄅ ᅡ ᆫᄃ ᅡᄂ ᅳ ᆫ ᄋ ᅴᄀ ᅧ ᆫᄋ ᅳ ᆯ ᄇ ᅩᄋ ᅧ ᆻᄉ ᅳ ᆸᄂ ᅵᄃ ᅡ. 34%ᄀ ᅡ ᄋ ᅵ ᄋ ᅴᄀ ᅧ ᆫᄋ ᅳ ᆯ ᄀ ᅩ ᆼᄀ ᅡ ᆷᄒ ᅡᄆ ᅧ, ᄋ ᅡᄉ ᅳ ᄐ ᅳᄅ ᅦᄋ ᅵ ᆯᄅ ᅵᄋ ᅡᄋ ᅴ ᄎ ᅬᄒ ᅮᄋ ᅴ ᄋ ᅪ ᆼᄌ ᅩᄀ ᅡ ᄋ ᅦ ᆯᄅ ᅵ ᄌ ᅡᄇ ᅦᄉ ᅳ 2ᄉ ᅦᄀ ᅡ ᄃ ᅬᄀ ᅵᄅ ᅳ ᆯ ᄋ ᅯ ᆫᄒ ᅡ ᆫᄃ ᅡ. ᄋ ᅵ ᄌ ᅩᄉ ᅡᄋ ᅦᄉ ᅥᄂ ᅳ ᆫ 34%ᄀ ᅡ ᄋ ᅦ ᆯᄅ ᅵᄌ ᅡᄇ ᅦᄉ ᅳ 2ᄉ ᅦᄀ ᅡ ᄋ ᅡᄉ ᅳᄐ ᅳᄅ ᅦᄋ ᅵ ᆯᄅ ᅵᄋ ᅡᄋ ᅴ ᄎ ᅬᄒ ᅮᄋ ᅴ ᄋ ᅪ ᆼᄌ ᅩᄀ ᅡ ᄃ ᅬᄀ ᅵᄅ ᅳ ᆯ ᄋ ᅯ ᆫᄒ ᅡ ᆫᄃ ᅡᄂ ᅳ ᆫ ᄋ ᅴᄀ ᅧ ᆫᄋ ᅳ ᆯ ᄀ ᅩ ᆼᄀ ᅡ ᆷᄒ ᅡ ᆫᄃ ᅡ.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Korean</head><p>The qualities that determine a subculture as distinct may be linguistic, aesthetic, religious, political, sexual, geographical, or a combination of factors.</p><formula xml:id="formula_7">ᄒ ᅡᄋ ᅱᄆ ᅮ ᆫᄒ ᅪᄅ ᅳ ᆯ ᄆ ᅧ ᆼᄒ ᅪ ᆨᄒ ᅡᄀ ᅦ ᄀ ᅮᄇ ᅮ ᆫᄒ ᅡᄂ ᅳ ᆫ ᄐ ᅳ ᆨ ᄌ ᅵ ᆼᄋ ᅳ ᆫ ᄋ ᅥ ᆫᄋ ᅥᄌ ᅥ ᆨ, ᄆ ᅵᄌ ᅥ ᆨ, ᄌ ᅩ ᆼᄀ ᅭᄌ ᅥ ᆨ, ᄌ ᅥ ᆼᄎ ᅵᄌ ᅥ ᆨ, ᄉ ᅥ ᆼᄌ ᅥ ᆨ, ᄌ ᅵᄅ ᅵᄌ ᅥ ᆨ ᄋ ᅭᄉ ᅩᄀ ᅡ ᄋ ᅵ ᆻᄋ ᅳᄆ ᅧ, ᄋ ᅵᄅ ᅥ ᄒ ᅡ ᆫ ᄋ ᅭᄉ ᅩᄃ ᅳ ᆯᄋ ᅴ ᄀ ᅧ ᆯᄒ ᅡ ᆸᄋ ᅵ ᆯ ᄉ ᅮᄃ ᅩ ᄋ ᅵ ᆻᄃ ᅡ. "ᄃ ᅡᄋ ᅳ ᆷ ᄆ ᅮ ᆫᄌ ᅡ ᆼᄋ ᅴ ᄒ ᅡ ᆫᄀ ᅮ ᆨᄋ ᅥ ᄇ ᅥ ᆫᄋ ᅧ ᆨᄋ ᅳ ᆫ ᄆ ᅮᄋ ᅥ ᆺ ᄋ ᅵ ᆸᄂ ᅵᄁ ᅡ? ᄇ ᅮᄆ ᅮ ᆫᄆ ᅮ ᆫᄒ ᅪᄅ ᅳ ᆯ ᄀ ᅮᄇ ᅧ ᆯᄃ ᅬᄀ ᅦ ᄒ ᅡ ᄂ ᅳ ᆫ ᄐ ᅳ ᆨᄉ ᅥ ᆼᄋ ᅳ ᆫ ᄋ ᅥ ᆫᄋ ᅥ, ᄋ ᅨᄉ ᅮ ᆯ, ᄌ ᅩ ᆼᄀ ᅭ, ᄌ ᅥ ᆼᄎ ᅵ, ᄉ ᅥ ᆼ, ᄌ ᅵᄅ ᅵ ᄋ ᅭᄉ ᅩᄋ ᅵ ᆯ ᄉ ᅮ ᄋ ᅵ ᆻᄀ ᅥᄂ ᅡ ᄋ ᅵᄃ ᅳ ᆯ ᄋ ᅭ ᄉ ᅩᄋ ᅴ ᄌ ᅩᄒ ᅡ ᆸᄋ ᅵ ᆯ ᄉ ᅮᄃ ᅩ ᄋ ᅵ ᆻᄉ ᅳ ᆸᄂ ᅵᄃ ᅡ." ᄇ ᅮᄆ ᅮ ᆫᄆ ᅮ ᆫᄒ ᅪᄀ ᅡ ᄀ ᅮᄇ ᅧ ᆯᄃ ᅬᄂ ᅳ ᆫ ᄐ ᅳ ᆨᄉ ᅥ ᆼᄋ ᅳ ᆫ ᄋ ᅥ ᆫᄋ ᅥ ᄌ ᅥ ᆨ, ᄋ ᅨᄉ ᅮ ᆯᄌ ᅥ ᆨ, ᄌ ᅩ ᆼᄀ ᅭᄌ ᅥ ᆨ, ᄌ ᅥ ᆼᄎ ᅵᄌ ᅥ ᆨ, ᄉ ᅥ ᆼᄌ ᅥ ᆨ, ᄌ ᅵᄅ ᅵᄌ ᅥ ᆨ ᄋ ᅭᄉ ᅩ ᄌ ᅮ ᆼ ᄒ ᅡᄂ ᅡᄋ ᅵ ᆯ ᄉ ᅮᄃ ᅩ ᄋ ᅵ ᆻᄀ ᅩ, ᄋ ᅵᄃ ᅳ ᆯ ᄋ ᅭᄉ ᅩᄋ ᅴ ᄌ ᅩᄒ ᅡ ᆸᄋ ᅵ ᆯ ᄉ ᅮᄃ ᅩ ᄋ ᅵ ᆻᄉ ᅳ ᆸᄂ ᅵ ᄃ ᅡ.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Japanese</head><p>The U.S. Corps of Engineers estimated that 6 inches of rainfall could breach the previously damaged levees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>米工兵隊は、以前に決壊した堤</head><formula xml:id="formula_8">防が6インチの降水量で再び決壊 する可能性があると推定してい ます。 米国エンジニア兵団は、6インチ の降雨で以前に損傷した堤防が 浸水すると推定しています。 以前に損傷を受けた堤防が、米 国エンジニア兵団が推定する6イ ンチの降雨で浸水するかもしれ ません。</formula><p>French Although three people were inside the house when the car impacted it, none of them were hurt.</p><p>Bien que trois personnes aient été présentes dans la maison quand la voiture l'a percutée, aucune n'a été blessée.</p><p>Bien que trois personnes se trouvaient à l'intérieur de la maison lorsque la voiture a percuté celle-ci, aucune d'entre elles n'a été blessée. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>French</head><p>The qualities that determine a subculture as distinct may be linguistic, aesthetic, religious, political, sexual, geographical, or a combination of factors.</p><p>Les critères qui déterminent une sousculture comme distincte peuvent être linguistiques, esthétiques, religieux, politiques, sexuels, géographiques ou une combinaison de facteurs.</p><p>Les qualités qui déterminent une sousculture comme distincte peuvent être linguistiques, esthétiques, religieuses, politiques, sexuelles, géographiques ou une combinaison de facteurs."</p><p>Les caractéristiques qui déterminent une sous-culture comme distincte peuvent être linguistiques, esthétiques, religieuses, politiques, sexuelles, géographiques ou une combinaison de ces éléments.</p><p>French New Kingdom ancient Egyptians marvelled at their predecessors monuments, which were then well over a thousand year old.</p><p>Les Égyptiens antiques du Nouvel Empire étaient émerveillés par les monuments de leurs prédécesseurs, qui avaient alors bien plus de mille ans.</p><p>Les Égyptiens anciens de la Nouvelle-République admiraient les monuments de leurs prédécesseurs, qui étaient alors bien plus âgés d'un millénaire.</p><p>Les Égyptiens anciens de la Nouvelle-République admiraient les monuments de leurs prédécesseurs, qui avaient alors plus de mille ans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>French</head><p>The U.S. Corps of Engineers estimated that 6 inches of rainfall could breach the previously damaged levees.</p><p>D'après le U.S. Corps of Engineers, une pluviométrie de 6 pouces pourrait ouvrir une brèche dans les digues précédemment endommagées.</p><p>Le Corps des ingénieurs des États-Unis a estimé qu'une pluie de 15 cm pourrait affaiblir les digues précédemment endommagées.</p><p>Le Corps des ingénieurs des États-Unis a estimé qu'une pluie de 15 cm pourrait mettre à mal les digues précédemment endommagées.</p><p>Indonesian Although three people were inside the house when the car impacted it, none of them were hurt.</p><p>Walau ada tiga orang di dalam rumah yang ditabrak mobil, tak satu pun yang cedera.</p><p>Meskipun tiga orang ada di dalam rumah saat mobil menabraknya, tidak ada yang terluka.</p><p>Meskipun tiga orang ada di dalam rumah saat mobil menabraknya, mereka semua selamat.</p><p>Indonesian 34 per cent of those in the poll share this view, wanting Queen Elizabeth II to be Australia's last monarch.</p><p>Dalam jajak pendapat mengenai pandangan ini, 34 persen dari mereka menginginkan Ratu Elizabeth II menjadi pemimpin monarki terakhir Australia.</p><p>34 persen dari orang yang terlibat dalam polling ini memiliki pandangan yang sama, yaitu ingin Ratu Elizabeth II menjadi ratu terakhir di Australia.</p><p>34 persen dari orang yang terlibat dalam polling ini memiliki pandangan yang sama, yaitu ingin Ratu Elizabeth II menjadi ratu terakhir di Australia.</p><p>Indonesian The qualities that determine a subculture as distinct may be linguistic, aesthetic, religious, political, sexual, geographical, or a combination of factors.</p><p>Kualitas yang menentukan suatu subkultur berbeda dari yang lain bisa berupa bahasa, estetika, agama, politik, seksual, geografis, atau kombinasi sejumlah faktor.</p><p>Kualitas yang menentukan suatu subkultur sebagai distinct dapat berupa linguistik, estetika, agama, politik, seksual, geografis, atau kombinasi faktor-faktor tersebut.</p><p>Faktor-faktor yang menentukan sebuah subkultur sebagai distinct bisa berupa faktor linguistik, estetika, agama, politik, seksual, geografis, atau kombinasi dari beberapa faktor tersebut.</p><p>Indonesian New Kingdom ancient Egyptians marvelled at their predecessors monuments, which were then well over a thousand year old.</p><p>Kerajaan Baru Mesir kuno mengagumi monumen para pendahulunya, yang saat itu berusia lebih dari seribu tahun.</p><p>Kekaisaran Baru orang-orang Mesir kuno terpesona dengan monumenmonumen pendahulunya, yang saat itu sudah lebih dari seribu tahun tua.</p><p>Orang-orang Mesir kuno Kekaisaran Baru terpesona dengan monumenmonumen pendahulunya, yang saat itu sudah lebih dari seribu tahun tua.</p><p>Indonesian The U.S. Corps of Engineers estimated that 6 inches of rainfall could breach the previously damaged levees.</p><p>U.S. Corps of Engineers memperkirakan bahwa curah hujan sebesar 6 inci ini mampu menerobos tanggul yang sudah rusak.</p><p>Korps Engineer AS menghitung bahwa hujan 6 inci dapat merusak parit yang sebelumnya sudah rusak.</p><p>Badan Engineer AS memperkirakan bahwa hujan 6 inci dapat menembus parit yang sebelumnya sudah rusak.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Javanese</head><p>Although three people were inside the house when the car impacted it, none of them were hurt.</p><p>Sanadyan uwong telu ana ing njero omah nalika mobil kuwi nabrak, nanging kabeh selamet.</p><p>Walaupun tiga orang berada di dalam rumah saat mobil menabraknya, tidak ada di antara mereka yang terluka.</p><p>Walaupun ana ing tiga wong ing rumah kala mobil mbentak ing kono, ora ana saka ingkang terluka.</p><p>Javanese 34 per cent of those in the poll share this view, wanting Queen Elizabeth II to be Australia's last monarch.</p><p>34 per sen sing menehi swara sesawangane ngene, kepengin Ratu Elizabeth II dadi raja sing keri dhewe ana ning Australia.</p><p>Sebagian 34 persen dari mereka yang terlibat dalam polling ini berpendapat demikian, ingin Ratu Elizabeth II menjadi Ratu Australia terakhir.</p><p>Sebagian 34 persen dari mereka yang terlibat dalam polling ini memiliki pandangan yang sama, yaitu menginginkan Ratu Elizabeth II menjadi Ratu Australia terakhir.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Javanese</head><p>The qualities that determine a subculture as distinct may be linguistic, aesthetic, religious, political, sexual, geographical, or a combination of factors.</p><p>Kualitas sing nemtokake sawijining cabang kabudayan mbokmenawa basa, estetika, sing ana gayutane karo agama, politik, seksual, geografis, utawa sawijining kombinasi saka faktor-faktor.</p><p>Sifat-sifat yang menentukan subkultur sebagai yang terpisah bisa berupa linguistik, estetik, agama, politik, seksual, geografis, atau kombinasi faktorfaktor.</p><p>Kualitas-kualitas sing menentukan subkultur minangka distinct bisa ngandhut linguistik, estetik, agama, politik, seksual, geografis, utawa gabungan faktor-faktor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Javanese</head><p>New Kingdom ancient Egyptians marvelled at their predecessors monuments, which were then well over a thousand year old.</p><p>Krajan Anyar Mesir kuno nggumun marang monumen-monumen leluhure, sing nalika iku tetep apik luwih seka sewu taun.</p><p>Rakyat Kerajaan Baru dari Mesir Kuno terpesona oleh monumenmonumen pendahulunya, yang saat itu sudah lebih dari seribu tahun tua.</p><p>Rakyat Kerajaan Baru dari Mesir Kuno terpesona oleh monumenmonumen pendahulunya, yang saat itu sudah lebih dari seribu tahun tua.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Javanese</head><p>The U.S. Corps of Engineers estimated that 6 inches of rainfall could breach the previously damaged levees.</p><p>Korps Insinyur AS ngira manawa udan 6 inci bisa nembus tanggul sing rusak sadurunge.</p><p>Korps Insinyur Amerika Serikat menghitung bahwa hujan 6 inci bisa merusak parit yang sebelumnya rusak.</p><p>Korps Insinyur Amerika Serikat menaksir bahwa hujan 6 inci bisa merusak parit yang telah rusak sebelumnya.</p><p>Sundanese Although three people were inside the house when the car impacted it, none of them were hurt.</p><p>Sanaos tilu urang aya di jero bumi pas mobil na nabrak, teu aya anu cidera.</p><p>Walaupun tiga orang berada di dalam rumah saat mobil menabraknya, tidak ada yang terluka.</p><p>Walaupun ada tiga orang di dalam rumah saat mobil menabraknya, tak ada yang terluka.</p><p>Sundanese 34 per cent of those in the poll share this view, wanting Queen Elizabeth II to be Australia's last monarch.</p><p>34 persen jalma dina polling di gaduh pendapat ieu, nyaeta hoyong Ratu Elizabeth II janten monarkis pamungkas di Australia.</p><p>34 persen dari mereka yang terlibat dalam survei memiliki pandangan ini, yaitu ingin Ratu Elizabeth II menjadi ratu terakhir Australia.</p><p>34 persen dari mereka yang terlibat dalam survei memiliki pandangan yang sama, yaitu ingin Ratu Elizabeth II menjadi ratu terakhir di Australia.</p><p>Sundanese The qualities that determine a subculture as distinct may be linguistic, aesthetic, religious, political, sexual, geographical, or a combination of factors.</p><p>Kualitas anu nangtukeun subkultur salaku bédana panginten basa, éstétis, religius, politik, séks, géografis, atanapi kombinasi faktor.</p><p>Sifat-sifat yang menentukan subkultur sebagai terpisah mungkin bersifat linguistik, estetika, agama, politik, seksual, geografis, atau kombinasi dari faktor-faktor tersebut.</p><p>Sifat-sifat nu nentukkeun subkultur salaku nu béda bisa jadi linguistik, estetika, agama, politik, seksual, geografis, atawa kombinasi ti faktorfaktor ieu.</p><p>Sundanese New Kingdom ancient Egyptians marvelled at their predecessors monuments, which were then well over a thousand year old.</p><p>Karajaan anyar urang Mesir kuno takjub kana monumén paninggalan karuhunna, anu umurna langkung ti sarebu taun.</p><p>Para raja anyar dina Egypt kuno nyogog nara-nara jaman awal, anu dina jaman ayeuna kira-kira ribuan taun.</p><p>Para raja anyar dina Egypt kuno terkagum-kagum kana nara-nara candi jaman awal, anu dina jaman ayeuna kira-kira leuweung taun.</p><p>Sundanese The U.S. Corps of Engineers estimated that 6 inches of rainfall could breach the previously damaged levees.</p><p>Korps insinyur A.S ngira-ngira curah hujan 6 inci tiasa nembus tanggul anu samemehna geus ruksak.</p><p>Korps Engineer AS diperkirakan bahwa 6 inci hujan bisa merusak benteng yang sebelumnya sudah rusak.</p><p>Korps Engineer AS diperkirakan bahwa hujan sebesar 6 inci dapat merusak benteng yang sudah rusak sebelumnya. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Results of the portion (%) of generated flags evaluated into five grades, A ∼ E. The second column shows the results of an ablation study, which removes the step of flag description generation and directly asks ChatGPT to generate the SVG code of the flag image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of a German flag drawn by Chat-GPT using SVG format: (top) without and (bottom) with a self-retrieved textual description of the flag. A rendered image is shown in place of the generated SVG format for the sake of simplicity.</figDesc><graphic coords="5,333.43,236.83,163.70,172.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Result of the multi-turn MT-APE experiment. #Correct MT denotes the number of correct translations. #Correct APE denotes the number of correct translations after post-editing.Interactivity on Machine Translation One of the capabilities of ChatGPT is to perform text translation from one language to another. With the interactivity of ChatGPT, we explore the possibility of performing a combined machine translation and automatic post-editing tasks to improve the translation quality of ChatGPT. For the experiment, we adapt the dataset used in §2.2.2. As shown in Figure2, despite the translation and post-editing being done using a single ChatGPT model, the multi-turn approach method helps to improve the correctness of the translation by making partial corrections or even full corrections in some cases. We provide experimental setup details and examples of the postediting in Appendix J.</figDesc><graphic coords="8,87.24,70.87,185.53,72.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Changes in ChatGPT's drawing of the Canadian flag over three turns. Layout, color, completion, and shape/size are marked as if they align with those of the ground truth, and ✗ otherwise.</figDesc><graphic coords="8,317.06,70.87,196.43,176.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>e., supervised stateof-the-art performance from Winata et al. (2022) and zero-shot multilingual LLM from Cahyawijaya et al. (2022). ChatGPT outperforms the previous state-of-the-art zero-shot model by a large margin except for the Buginese, where it performs on par.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Complete results of the flag drawing task. Multi-turn refinement allows ChatGPT to generate a more similar image to the ground truth image.</figDesc><graphic coords="26,70.87,70.87,453.54,409.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Example of the Canadian flag drawn by In-structGPT.</figDesc><graphic coords="34,70.87,70.86,218.27,250.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: From fruits to a Christmas tree. Step-by-step image drawing and modification by ChatGPT.</figDesc><graphic coords="34,332.88,155.17,164.80,497.67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="33,70.87,70.87,218.27,246.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Language Category SA Acc. LID Acc.</figDesc><table><row><cell>English</cell><cell>HRL</cell><cell>84%</cell><cell>100%</cell></row><row><cell>Indonesian</cell><cell>MRL</cell><cell>80%</cell><cell>100%</cell></row><row><cell>Javanese</cell><cell>LRL</cell><cell>78%</cell><cell>0%</cell></row><row><cell>Buginese</cell><cell>X-LRL</cell><cell>56%</cell><cell>12%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Accuracy of ChatGPT on Sentiment Analysis (SA) and Language Identification (LID) tasks.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>#Correct translations of ChatGPT. XXX denotes the target language listed in the first column.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Composed results for all reasoning tasks.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Jan Kocoń, Igor Cichecki, Oliwier Kaszyca, Mateusz Kochanek, Dominika Szydło, Joanna Baran, Julita Bielaniewicz, Marcin Gruza, Arkadiusz Janz, Kamil Kanclerz, et al. 2023. Chatgpt: Jack of all trades, master of none. Information Fusion, page 101861.</figDesc><table><row><cell>for natural language generation, translation, and com-</cell><cell>Rui Mao, Guanyi Chen, Xulang Zhang, Frank Guerin,</cell></row><row><cell>prehension. In Proceedings of the 58th Annual Meet-</cell><cell>and Erik Cambria. 2023. Gpteval: A survey on</cell></row><row><cell>ing of the Association for Computational Linguistics,</cell><cell>assessments of chatgpt and gpt-4. arXiv preprint</cell></row><row><cell>pages 7871-7880.</cell><cell>arXiv:2308.12488.</cell></row><row><cell>Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian</cell><cell>Escape Velocity Labs. 2022. Chatgpt imitates logical Bernard Marr. 2022. What does chatgpt really mean for businesses?</cell></row><row><cell>Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Ku-mar, Benjamin Newman, Binhang Yuan, Bobby Yan, Ce Zhang, Christian Cosgrove, Christopher D. Man-ning, Christopher Ré, Diana Acosta-Navas, Drew A. Hudson, Eric Zelikman, Esin Durmus, Faisal Lad-hak, Frieda Rong, Hongyu Ren, Huaxiu Yao, Jue Wang, Keshav Santhanam, Laurel Orr, Lucia Zheng, Mert Yuksekgonul, Mirac Suzgun, Nathan Kim, Neel Guha, Niladri Chatterji, Omar Khattab, Peter Henderson, Qian Huang, Ryan Chi, Sang Michael Xie, Shibani Santurkar, Surya Ganguli, Tatsunori Hashimoto, Thomas Icard, Tianyi Zhang, Vishrav Chaudhary, William Wang, Xuechen Li, Yifan Mai, Yuhui Zhang, and Yuta Koreeda. 2022. Holistic eval-uation of language models. Stephanie Lin, Jacob Hilton, and Owain Evans. 2022.</cell><cell>reasoning surprisingly well. Viet Dac Lai, Nghia Trung Ngo, Amir Pouran Ben Veyseh, Hieu Man, Franck Dernoncourt, Trung Bui, Vaibhav Mavi, Anubhav Jangra, and Adam Jatowt. 2022. A survey on multi-hop question answering and gen-eration. arXiv preprint arXiv:2204.09140. and Thien Huu Nguyen. 2023. Chatgpt beyond en-glish: Towards a comprehensive evaluation of large language models in multilingual learning. arXiv preprint arXiv:2304.05613. Md Tahmid Rahman Laskar, M Saiful Bari, Mizanur Rahman, Md Amran Hossen Bhuiyan, Shafiq Joty, Pasquale Minervini, Sebastian Riedel, Pontus Stenetorp, Edward Grefenstette, and Tim Rocktäschel. 2020. Learning reasoning strategies in end-to-end differen-tiable proving. In Proceedings of the 37th Interna-tional Conference on Machine Learning, ICML'20. JMLR.org. and Jimmy Huang. 2023a. A systematic study and Roshanak Mirzaee and Parisa Kordjamshidi. 2022. comprehensive evaluation of ChatGPT on benchmark Transfer learning with synthetic corpora for spatial datasets. In Findings of the Association for Com-role labeling and reasoning. In Proceedings of the putational Linguistics: ACL 2023, pages 431-469, 2022 Conference on Empirical Methods in Natu-Toronto, Canada. Association for Computational Lin-ral Language Processing, pages 6148-6165, Abu guistics. Dhabi, United Arab Emirates. Association for Com-</cell></row><row><cell>TruthfulQA: Measuring how models mimic human falsehoods. In Proceedings of the 60th Annual Meet-ing of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3214-3252, Dublin, Ireland. Association for Computational Linguistics. Zhaojiang Lin, Bing Liu, Andrea Madotto, Seungwhan</cell><cell>putational Linguistics. Md Tahmid Rahman Laskar, M Saiful Bari, Miza-nur Rahman, Md Amran Hossen Bhuiyan, Shafiq Roshanak Mirzaee, Hossein Rajaby Faghihi, Qiang Joty, and Jimmy Xiangji Huang. 2023b. A sys-Ning, and Parisa Kordjamshidi. 2021. SPARTQA: tematic study and comprehensive evaluation of A textual question answering benchmark for spatial chatgpt on benchmark datasets. arXiv preprint reasoning. In Proceedings of the 2021 Conference of arXiv:2305.18486. the North American Chapter of the Association for</cell></row><row><cell>Moon, Zhenpeng Zhou, Paul A Crook, Zhiguang Wang, Zhou Yu, Eunjoon Cho, Rajen Subba, et al. 2021. Zero-shot dialogue state tracking via cross-task transfer. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 7890-7900. Holy Lovenia, Bryan Wilie, Romain Barraud, Samuel Cahyawijaya, Willy Chung, and Pascale Fung. 2022. Every picture tells a story: Image-grounded control-lable stylistic story generation. In Proceedings of the 6th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature, pages 40-52, Gyeongju, Republic of Korea. International Conference on Com-putational Linguistics. Hongyuan Lu, Haoyang Huang, Shuming Ma, Dong-dong Zhang, Wai Lam, and Furu Wei. 2022. Trip: Triangular document-level pre-training for multilingual language models. arXiv preprint arXiv:2212.07752. Andrea Madotto, Zhaojiang Lin, Genta Indra Winata, and Pascale Fung. 2021. Few-shot bot: Prompt-based learning for dialogue systems. arXiv preprint arXiv:2110.08118.</cell><cell>Computational Linguistics: Human Language Tech-Anton E Lawson. 2005. What is the role of induction nologies, pages 4582-4598, Online. Association for and deduction in reasoning and scientific inquiry? Computational Linguistics. Journal of Research in Science Teaching, 42(6):716-740. Nayeon Lee, Yejin Bang, Andrea Madotto, and Pascale Seungwhan Moon, Pararth Shah, Anuj Kumar, and Ra-jen Subba. 2019. Opendialkg: Explainable conver-sational reasoning with attention-based walks over Fung. 2021. Towards few-shot fact-checking via perplexity. In Proceedings of the 2021 Conference of the North American Chapter of the Association knowledge graphs. In Proceedings of the 57th An-nual Meeting of the Association for Computational Linguistics, pages 845-854. for Computational Linguistics: Human Language Technologies, pages 1971-1981, Online. Association for Computational Linguistics. Nayeon Lee, Wei Ping, Peng Xu, Mostofa Patwary, Pas-cale Fung, Mohammad Shoeybi, and Bryan Catan-zaro. 2022. Factuality enhanced language models for Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven Le Scao, M Saiful Bari, Sheng Shen, Zheng-Xin Yong, Hai-ley Schoelkopf, Xiangru Tang, Dragomir Radev, Alham Fikri Aji, Khalid Almubarak, Samuel Al-banie, Zaid Alyafeai, Albert Webson, Edward Raff, open-ended text generation. In Advances in Neural Information Processing Systems. Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020a. BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and com-prehension. In Proceedings of the 58th Annual Meet-ing of the Association for Computational Linguistics, pages 7871-7880, Online. Association for Computa-and Colin Raffel. 2022. Crosslingual generaliza-tion through multitask finetuning. arXiv preprint Yan Xu, Deqian Kong, Dehong Xu, Ziwei Ji, Bo Pang, arXiv:2211.01786. Pascale Fung, and Ying Nian Wu. 2023. Diverse and faithful knowledge-grounded dialogue generation via Benjamin Muller, Antonios Anastasopoulos, Benoît sequential posterior inference. In Proceedings of the Sagot, and Djamé Seddah. 2021. When being un-40th International Conference on Machine Learning, seen from mBERT is just the beginning: Handling volume 202 of Proceedings of Machine Learning new languages with multilingual language models. Research, pages 38518-38534. PMLR. In Proceedings of the 2021 Conference of the North tional Linguistics: Human Language Technologies, American Chapter of the Association for Computa-Yunyi Yang, Yunhao Li, and Xiaojun Quan. 2021. Ubar:</cell></row><row><cell></cell><cell>tional Linguistics. pages 448-462, Online. Association for Computa-</cell></row><row><cell></cell><cell>Mike Lewis, Yinhan Liu, Naman Goyal, Marjan tional Linguistics.</cell></row><row><cell></cell><cell>Ghazvininejad, Abdelrahman Mohamed, Omer Levy,</cell></row><row><cell></cell><cell>Veselin Stoyanov, and Luke Zettlemoyer. 2020b.</cell></row><row><cell></cell><cell>Bart: Denoising sequence-to-sequence pre-training</cell></row></table><note><p>Ziwei Ji, Zihan Liu, Nayeon Lee, Tiezheng Yu, Bryan Wilie, Min Zeng, and Pascale Fung. 2022b. Rho (ρ): Reducing hallucination in open-domain dialogues with knowledge grounding. arXiv preprint arXiv:2212.01588. Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Xing Wang, and Zhaopeng Tu. 2023. Is chatgpt a good translator? a preliminary study. Arianna Johnson. 2023. Is chatgpt partisan? poems about trump and biden raise questions about the ai bot's bias-here's what experts think. Pratik Joshi, Sebastin Santy, Amar Budhiraja, Kalika Bali, and Monojit Choudhury. 2020. The state and fate of linguistic diversity and inclusion in the NLP world. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6282-6293, Online. Association for Computational Linguistics. Jennifer A. Kingson. 2023. Friend or foe? teachers debate chatgpt. Kyle Mahowald, Anna A Ivanova, Idan A Blank, Nancy Kanwisher, Joshua B Tenenbaum, and Evelina Fedorenko. 2023. Dissociating language and thought in large language models: a cognitive perspective. arXiv preprint arXiv:2301.06627. Ramesh Nallapati, Bowen Zhou, Cicero dos Santos, Çaglar Gulçehre, and Bing Xiang. 2016. Abstractive text summarization using sequence-to-sequence Towards fully end-to-end task-oriented dialog system with gpt-2. Proceedings of the AAAI Conference on Artificial Intelligence, 35(16):14230-14238. Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, and Christopher D Manning. 2018. Hotpotqa: A dataset for</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>provides a survey of recent assessments of ChatGPT in broad categories of 1) Language and Reasoning Ability, 2) Scientific Knowledge, and 3) Ethical Considerations. Laskar et al. provide extensive automatic or human-in-the-loop evaluations on 140 tasks. Qin et al. mainly evaluated the reasoning abilities of ChatGPT while Zhuo et al.; Ray focus on other important aspects such as ethics, robustness, reliability, limitations, and future scope of ChatGPT. Kocoń et al. examined whether the high quality of the LLM can indicate</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>, respectively.</figDesc><table><row><cell>Task</cell><cell>Key</cell><cell>Text Content</cell></row><row><cell></cell><cell></cell><cell>Use the following knowledge base to complete the task of "recommending a restaurant" by</cell></row><row><cell></cell><cell></cell><cell>continuing the conversation as a task-oriented dialogue system:</cell></row><row><cell></cell><cell></cell><cell>Restaurant: Mama Julia, Food: French, Price: Expensive, Location: 7th street, Rating: 5</cell></row><row><cell></cell><cell></cell><cell>Restaurant: Papa John, Food: Italian, Price: Moderate, Location: 3rd street, Rating: 4</cell></row><row><cell></cell><cell></cell><cell>Restaurant: The Crossroad, Food: Morocco, Price: Moderate, Location: Downtown, Rating: 2</cell></row><row><cell></cell><cell>Prompt</cell><cell>Restaurant: Tacos City, Food: Mexian, Price: Cheap, Location: Center, Rating: 1 Restaurant: Golden Rice Bowl, Food: Chinese, Price: Cheap, Location: 3rd district, Rating: 3</cell></row><row><cell></cell><cell></cell><cell>Restaurant: Veggie Garden, Food: Chinese, Price: Expensive, Location: Town Hall, Rating: 4</cell></row><row><cell></cell><cell></cell><cell>Restaurant: Pizza House, Food: Italian, Price: Moderate, Location: 3rd street, Rating: 2</cell></row><row><cell></cell><cell></cell><cell>Restaurant: The Palace, Food: Vietnamese, Price: Expensive, Location: Hotel Grandview, Rating:</cell></row><row><cell></cell><cell></cell><cell>5</cell></row><row><cell></cell><cell></cell><cell>Hi, I'm looking for a restaurant</cell></row><row><cell></cell><cell>ChatGPT</cell><cell>Sure, what type of food are you in the mood for?</cell></row><row><cell></cell><cell>Prompt</cell><cell>I only want restaurants rated 3 or higher. Any suggestions?</cell></row><row><cell>Multi-turn unified approach</cell><cell>ChatGPT</cell><cell>Here are some restaurants that have a rating of 3 or higher: Mama Julia (French, Expensive, 5 rating), Papa John (Italian, Moderate, 4 rating), Golden Rice Bowl (Chinese, Cheap, 3 rating), Veggie Garden (Chinese, Expensive, 4 rating), and The Palace (Vietnamese, Expensive, 5 rating).</cell></row><row><cell></cell><cell></cell><cell>Which one would you like to know more about?</cell></row><row><cell></cell><cell>Prompt</cell><cell>What food does The Palace serve?</cell></row><row><cell></cell><cell>ChatGPT</cell><cell>The Palace serves Vietnamese cuisine.</cell></row><row><cell></cell><cell>Prompt</cell><cell>Is Taxos City expensive to eat at?</cell></row><row><cell></cell><cell>ChatGPT</cell><cell>Tacos City is considered as cheap restaurant.</cell></row><row><cell></cell><cell>Prompt</cell><cell>I want to eat Italian food, any recommendations?</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 8 :</head><label>8</label><figDesc>Example of Buginese language identification response from ChatGPT, InstructGPT, and text-davinci-003.</figDesc><table><row><cell>Language</cell><cell cols="2">#Speakers CC Size (%)</cell><cell>Language Category</cell></row><row><cell>English (eng)</cell><cell>1.452B</cell><cell>46.320</cell><cell>HRL</cell></row><row><cell>Chinese (zho)</cell><cell>1.118B</cell><cell>4.837</cell><cell>HRL</cell></row><row><cell>French (fra)</cell><cell>235M</cell><cell>4.604</cell><cell>HRL</cell></row><row><cell>Indonesian (ind)</cell><cell>199M</cell><cell>0.781</cell><cell>MRL</cell></row><row><cell>Korean (kor)</cell><cell>81.7M</cell><cell>0.679</cell><cell>MRL</cell></row><row><cell>Javanese (jav)</cell><cell>68.3M</cell><cell>0.002</cell><cell>LRL</cell></row><row><cell>Sundanese (sun)</cell><cell>32.4M</cell><cell>0.001</cell><cell>LRL</cell></row><row><cell>Buginese (bug)</cell><cell>5M</cell><cell>0.000</cell><cell>X-LRL</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 9 :</head><label>9</label><figDesc>The statistics of languages used in our language disparity experiment. HRL, MRL, LRL, X-LRL denote high-, medium-, low-, extremely low-resourced language respectively.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 10 :</head><label>10</label><figDesc>Accuracy of ChatGPT on Sentiment Analysis (SA) and Language Identification (LID) tasks.</figDesc><table><row><cell>is much inferior to the other languages with Latin</cell></row><row><cell>scripts, i.e., French or Indonesian. Similarly, prior</cell></row><row><cell>works focusing on transliteration (Chau and Smith,</cell></row><row><cell>2021; Muller et al., 2021) have shown the effec-</cell></row><row><cell>tiveness of utilizing Latin scripts over other scripts,</cell></row><row><cell>e.g., Cyrillic, Georgian, Arabic, etc, especially for</cell></row><row><cell>low-resource languages. Interestingly, this problem</cell></row><row><cell>of using non-Latin scripts is less severe for trans-</cell></row><row><cell>lation from Chinese and Korean to English, which</cell></row><row><cell>suggests that ChatGPT can better neutralize the ef-</cell></row><row><cell>fect of non-Latin scripts as source languages (Wan,</cell></row><row><cell>2022), but it still lacks the ability to generate non-</cell></row><row><cell>Latin script languages.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 11 :</head><label>11</label><figDesc>Reasoning categories and corresponding datasets used to evaluate ChatGPT in this work.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 12 :</head><label>12</label><figDesc>Inductive vs. Deductive Reasoning. Chat-GPT performs better deduction rather than induction. Engineering the prompt to explicitly ask ChatGPT to do reasonable inference improves its reasoning capability. The scores are in accuracy over tested samples.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 15 :</head><label>15</label><figDesc>Spatial reasoning ability of ChatGPT. Overall, ChatGPT falls short of the task.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 16 :</head><label>16</label><figDesc>Commonsense reasoning ability of ChatGPT. ChatGPT shows good performance of commonsense reasoning capability on the three test data we test it on.</figDesc><table><row><cell cols="3">Commonsense Reasoning Tasks</cell></row><row><cell cols="3">CommonsenseQA PiQA Pep-3k (Hard)</cell></row><row><cell>27/30</cell><cell>25/30</cell><cell>28/30</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head>Table 18 :</head><label>18</label><figDesc>Results for causal, multi-hop, and analogical reasoning. ChatGPT shows good causal and analogical reasoning capability, but not on multi-hop reasoning.</figDesc><table><row><cell cols="2">Causal Multi-hop</cell><cell>Analogical</cell></row><row><cell cols="3">E-CARE HotpotQA Letter string analogies</cell></row><row><cell>24/30</cell><cell>8/30</cell><cell>30/30</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head></head><label></label><figDesc>.</figDesc><table><row><cell>Dataset</cell><cell></cell><cell>Task</cell><cell>Description</cell><cell>Reference</cell><cell>#Test Size</cell><cell>#ChatGPT Eval</cell></row><row><cell>National</cell><cell>Flag</cell><cell>IG</cell><cell>National Flag Drawing is a designed synthetic dataset which is used to</cell><cell>Curated by authors of</cell><cell>50</cell><cell>50</cell></row><row><cell>Drawing</cell><cell></cell><cell></cell><cell>evaluate the multimodal understanding of LLMs. The instruction for</cell><cell>this paper</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>the National Flag Drawing is as follow: given a nation, draw the corre-</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>sponding national flag and revise it based on the follow-up correction</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>requests.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>CNN/DM</cell><cell></cell><cell>SUM</cell><cell>The CNN/DailyMail Dataset is an English-language dataset containing</cell><cell cols="2">Nallapati et al. (2016) 11490</cell><cell>50</cell></row><row><cell></cell><cell></cell><cell></cell><cell>just over 300k unique news articles as written by journalists at CNN</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>and the Daily Mail. The current version supports both extractive and</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>abstractive summarization, though the original version was created for</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>machine-reading and comprehension and abstractive question answer-</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>ing.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>SAMSum</cell><cell></cell><cell>SUM</cell><cell>SAMSum dataset contains about 16k messenger-like conversations with</cell><cell>Gliwa et al. (2019)</cell><cell>819</cell><cell>50</cell></row><row><cell></cell><cell></cell><cell></cell><cell>summaries. Conversations were created and written down by linguists</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>fluent in English. Linguists were asked to create conversations similar</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>to those they write on a daily basis, reflecting the proportion of topics of</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>their real-life messenger convesations.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>FLoRes-200</cell><cell></cell><cell>MT</cell><cell>FLoRes is a benchmark dataset for machine translation between English</cell><cell>Goyal et al. (2021)</cell><cell>1012 per language</cell><cell>30 per language (12</cell></row><row><cell></cell><cell></cell><cell></cell><cell>and four low resource languages, Nepali, Sinhala, Khmer and Pashto,</cell><cell></cell><cell>(200 languages)</cell><cell>languages)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>based on sentences translated from Wikipedia.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>NusaX</cell><cell></cell><cell>SA</cell><cell>NusaX is a high-quality multilingual parallel corpus that covers 12 lan-</cell><cell>Winata et al. (2022)</cell><cell>400</cell><cell>50</cell></row><row><cell></cell><cell></cell><cell></cell><cell>guages, Indonesian, English, and 10 Indonesian local languages, namely</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau,</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Javanese, Ngaju, Sundanese, and Toba Batak.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>bAbI task 15</cell><cell></cell><cell>QA</cell><cell>This basic deduction bAbI tasks is taken from the (</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_25"><head></head><label></label><figDesc>Unlike the Covid19-Scientific dataset, it contains non-scientific and socially-related claims, such as "For the coronavirus, the death rate in Texas, per capita of 29 million people, we're one of the lowest in the country." Such claims may not be life-and-death matters, but they still have the potential to bring negative sociopolitical effects. , finance and politics. The questions are of those that some humans would answer falsely due to a false belief or misconception. (e.g., [conspiracy] "If it's cold outside what does that tell us about global warming?"; [health] "Can coughing effectively stop a heart attack?")</figDesc><table><row><cell>HotpotQA SpaRTQA TruthfulQA</cell><cell>QA QA QA</cell><cell cols="3">Weston et al. (2016b) 1000 Yang et al. (2018) 7405 Mirzaee et al. (2021) 510 health, lawLin et al. (2022) HotpotQA is a new dataset with 113k Wikipedia-based question-answer pairs with four key features: (1) the questions require finding and rea-SpartQA is a textual question answering benchmark for spatial rea-soning on natural language text which contains more realistic spatial The dataset comprises questions that span 38 categories, including 817</cell><cell>30 30 64 65</cell></row><row><cell></cell><cell></cell><cell>soning over multiple supporting documents to answer; (2) the questions phenomena not covered by prior datasets and that is challenging for state-</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>are diverse and not constrained to any pre-existing knowledge bases of-the-art language models (LM). SPARTQA is built on NLVR's images</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>or knowledge schemas; (3) we provide sentence-level supporting facts containing more objects with richer spatial structures. SPARTQA's sto-</cell><cell></cell><cell></cell><cell></cell></row><row><cell>EntailmentBank PiQA MultiWOZ 2.2</cell><cell>QA QA TOD</cell><cell>ENTAILMENTBANK, the first dataset of multistep entailment trees for QA, to support entailment-based explanation. ENTAILMENTBANK contains two parts: 1,840 entailment trees, each tree showing how a question-answer pair (QA) is entailed from a small number of relevant sentences (e.g., Figure 1); and a general corpus C, containing those and required for reasoning, allowing QA systems to reason with strong su-pervision and explain the predictions; (4) we offer a new type of factoid comparison questions to test QA systems' ability to extract relevant facts and perform necessary comparison. To apply eyeshadow without a brush, should I use a cotton swab or a toothpick? Questions requiring this kind of physical commonsense ries are more natural, have more sentences, and richer in spatial relations slot span annotations for these slots. set, which consists of 510 instances. (e.g., restaurant name, time of booking) and introducing standardized capabilities. The default test set of this dataset is human-annotated test allowing vocabularies of slots with a large number of possible values yes/no (YN), which allows for more fine-grained analysis of models' utterances on top of MultiWOZ 2.1 and redefines the ontology by dis-four types: find relation (FR), find blocks (FB), choose object (CO), and tifies and fixes dialogue state annotation errors across 17.3% of the in each sentence, and the questions require deeper reasoning and have MultiWOZ 2.2 is an improved version of MultiWOZ 2.1, which iden-</cell><cell>Dalvi et al. (2021) Bisk et al. (2020) Zang et al. (2020)</cell><cell>340 1838 5000 dialogue turns</cell><cell>30 30 50 dialog turns</cell></row><row><cell>CLUTRR Pep-3k StepGame OpenDialKG</cell><cell>QA QA QA KGD</cell><cell>other sentences of domain-specific and general knowledge relevant to the QA domain. CLUTRR (Compositional Language Understanding and Text-based Re-lational Reasoning), a diagnostic benchmark suite, is first introduced in rules, and test for the various forms of model robustness by adding different kinds of superfluous noise facts to the stories. events. It requires a mixture of commonsense knowledge and conceptual everyday materials. Pep-3k is a dataset of physical semantic plausibility judgments of single instructions on how to build, craft, bake, or manipulate objects using tion by testing on stories that contain unseen combinations of logical The dataset is inspired by instructables.com, which provides users with respectively. benchmark allows us to test a model's ability for systematic generaliza-focuses on everyday situations with a preference for atypical solutions. 10, there are 30000, 1000, and 30000 samples for train, valid, and test and inductive reasoning capabilities of NLU systems. The CLUTRR that interact with the world and understand natural language. PIQA about the relative position of two of those entities. For each k from 1 to (https://arxiv.org/abs/1908.06177) to test the systematic generalization pose a challenge to state-of-the-art natural language understanding sys-tems. The PIQA dataset introduces the task of physical commonsense reasoning and a corresponding benchmark dataset Physical Interaction: Question Answering or PIQA. Physical commonsense knowledge is a major challenge on the road to true AI-completeness, including robots StepGame is a robust multi-hop spatial reasoning dataset in textual (k is up to 10) expressed in natural language and answer a question entities and relations that are mentioned in the dialog. spatial relations (e.g left, top-right, 90 degree clockwise) of k+1 entities paired with its corresponding "KG paths" that weave together the KG task 19. In this task, the AI system is required to interpret a story of k agents engaging in a dialog about a given topic. Each dialog turn is format which addresses the limitation from the bAbI dataset task 17 and OpenDialKG is a dataset of conversations between two crowdsourcing</cell><cell>Wang et al. (2018b) Sinha et al. (2019) Shi et al. (2022b) Moon et al. (2019)</cell><cell>3080 1146 sions 30000 2.25k dialogue ses-</cell><cell>30 30 30 50 dialogue turns</cell></row><row><cell>αNLI E-Care COVID-Social</cell><cell>QA QA MD</cell><cell cols="2">Abductive Natural Language Inference (αNLI) is a new commonsense benchmark dataset designed to test an AI system's capability to apply Understanding causality has vital importance for various Natural Lan-knowledge to solve. Each event consists of a subject, a verb, and an guage Processing (NLP) applications. Beyond the labeled instances, object, i.e it has the simple s-v-o format. For example, the event can be conceptual explanations of the causality can provide a deep understand-man swallow paintball, with the label 0 (implausible). In total, Pep-3k abductive reasoning and common sense to form possible explanations ing of the causal fact to facilitate the causal reasoning process. We has 3080 instances with plausible-implausible data balance. for a given set of observations. Formulated as a binary-classification task, the goal is to pick the most plausible explanatory hypothesis given two observations from narrative contexts. present a human-annotated explainable CAusal REasoning dataset (e-CARE), which contains over 20K causal reasoning questions, together with natural language formed explanations of the causal questions. COVID-19-related claims fact-checked by journalists from a website called Politifact.com. Lee et al. (2021) Bhagavatula et al. Du et al. (2022) (2020)</cell><cell>3059 2122 340</cell><cell>30 30 50</cell></row><row><cell cols="2">CommonsenseQA QA Letter string anal-QA ogy COVID-MD</cell><cell>CommonsenseQA is a new multiple-choice question answering dataset The letter string analogy domain was introduced in order to evaluate that requires different types of commonsense knowledge to predict the computational models of analogical reasoning. This task is composed correct answers . It contains 12,102 questions with one correct answer of simple alphanumeric characters, but nevertheless require a significant and four distractor answers. The dataset is provided in two major training/validation/testing set splits: "Random split" which is the main degree of abstraction to identify an analogy. COVID-Scientific is a testset consists of COVID-19-related scientific</cell><cell>Talmor et al. (2018) Webb et al. (2022b) Lee et al. (2021)</cell><cell>1221 -172</cell><cell>30 30 50</cell></row><row><cell>Scientific</cell><cell></cell><cell>evaluation split, and "Question token split", see paper for details. or medical myths that must be debunked correctly to ensure the safety</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>of the public (e.g., "Drinking a bleach solution will prevent you from</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>getting COVID-19").</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_26"><head>Table 21 :</head><label>21</label><figDesc>List of all datasets used in our experiments. IG denotes image generation, SUM denotes summarization, MT denotes machine translation, SA denotes sentiment analysis, QA denotes question answering, MD denotes misinformation detection, TOD denotes task-oriented dialogue, and KGD denotes knowledge-grounded dialogue. Some of the descriptions are directly from the original reference.</figDesc><table><row><cell cols="3">J Examples from Machine Translation and Post-Editing</cell><cell></cell><cell></cell></row><row><cell>Target</cell><cell>English Text</cell><cell>Label</cell><cell>Translation</cell><cell>Post-Edited Text</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_28"><head>Table 22 :</head><label>22</label><figDesc>Examples of ChatGPT translated and post-edited sentences.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>https://openai.com/blog/forecasting-misuse/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>For a fairer comparison in our multitask experiment, we strictly follow the definition of high-resource and low-resource languages from NLLB<ref type="bibr" target="#b60">(Team et al., 2022)</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>An example provided by Bhagavatula et al. (2020).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>Refer to detailed findings in the original paper.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>Those of which spatial relations are described with explicit vocabulary.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work has been partially funded by <rs type="grantNumber">MRP/055/18</rs> of the <rs type="affiliation">Innovation Technology Commission, Hong Kong SAR Government</rs>; the <rs type="grantName">Hong Kong Fellowship Scheme</rs> by the <rs type="funder">Hong Kong Research Grants Council</rs>, and <rs type="grantNumber">PF20-43679</rs> <rs type="grantName">Hong Kong PhD Fellowship Scheme, Hong Kong Research Grants Council</rs>.</p></div>
			</div>
			<div type="funding">
<div><p>Sebastian Ruder. 2022. One country, 700+ languages: NLP challenges for underrepresented languages and dialects in Indonesia. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages <rs type="grantNumber">7226-7249</rs>, <rs type="institution">Dublin, Ireland. Association for Computational Linguistics</rs>. An automatic metric for MT evaluation with improved correlation with human judgments. In Proceedings of the <rs type="institution">ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation</rs> and/or Summarization, pages <rs type="grantNumber">65-72</rs>, <rs type="person">Ann Arbor</rs>, <rs type="institution">Michigan. Association for Computational Linguistics</rs>. : Benchmark and resources for evaluating Indonesian natural language generation. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages <rs type="grantNumber">8875-8898</rs>, <rs type="person">Online</rs> and <rs type="person">Punta Cana</rs>, <rs type="person">Dominican Republic</rs>. <rs type="funder">Association for Computational Linguistics</rs>. <rs type="person">Ethan C. Chau</rs> and <rs type="person">Noah A. Smith</rs>. 2021. Specializing multilingual language models: An empirical study. In Proceedings of the 1st Workshop on Multilingual Representation Learning, pages <rs type="grantNumber">51-61</rs>, <rs type="person">Punta Cana</rs>, <rs type="person">Dominican Republic</rs>. Association for Computational Linguistics. Retrieval-free knowledgegrounded dialogue response generation with adapters. In Proceedings of the Second DialDoc Workshop on Document-grounded Dialogue and Conversational Question Answering, pages <rs type="grantNumber">93-107</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_gHZBMpR">
					<idno type="grant-number">MRP/055/18</idno>
					<orgName type="grant-name">Hong Kong Fellowship Scheme</orgName>
				</org>
				<org type="funding" xml:id="_QzBwuaB">
					<idno type="grant-number">PF20-43679</idno>
					<orgName type="grant-name">Hong Kong PhD Fellowship Scheme, Hong Kong Research Grants Council</orgName>
				</org>
				<org type="funding" xml:id="_rZDQM6b">
					<idno type="grant-number">7226-7249</idno>
				</org>
				<org type="funding" xml:id="_FDY2NCw">
					<idno type="grant-number">65-72</idno>
				</org>
				<org type="funding" xml:id="_4eNcJvg">
					<idno type="grant-number">8875-8898</idno>
				</org>
				<org type="funding" xml:id="_VtTqFh3">
					<idno type="grant-number">51-61</idno>
				</org>
				<org type="funding" xml:id="_YaGwaMj">
					<idno type="grant-number">93-107</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Given facts: Bernhard is a swan. Greg is a frog. Brian is a swan. Julius is a lion. Greg is gray. Julius is yellow. Lily is a lion. Lily is green. Brian is yellow.</p><p>The most recent fact is the correct fact.</p><p>Based on the given facts above, do a reasonable inference on this question using inductive reasoning: What color is Bernhard?</p><p>Based on the given facts, it can be inferred that Bernhard is yellow, as Brian is also stated to be yellow. yellow T</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CLUTRR</head><p>[Jason] and his wife [Gabrielle] went to the beach to watch the fireworks on the 4th of July.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ChatGPT Generation</head><p>The ancient Egyptian Pharaohs built beautiful monuments that are still well-preserved after thousands of years.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hallucination</head><p>Extrinsic -New Kingdom ancient Egyptians marveled at their predecessors monuments, which were then well over a thousand year old. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summarization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ChatGPT Generation</head><p>The move comes following the recent framework deal between Iran and the P5+1 (US, UK, France, China, Russia, and Germany) to curb Iran's nuclear activities in exchange for sanctions relief.</p><p>Hallucination Extrinsic Factual -"P5+1" are the exact countries that the source document mentions and the model can correctly list the names of these countries in summary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task-oriented Dialogue</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prompt</head><p>Continue the dialogue as a task-oriented dialogue system called SYSTEM. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prompt</head><p>Where do people smoke more on average than in Russia?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ChatGPT Generation</head><p>There are several countries where people smoke more on average than in Russia. According to data from the World Health Organization, the following countries have higher smoking rates than Russia: Indonesia: 55.2% of adults smoke China: 52.9% of adults smoke Serbia: 47.5% of adults smoke Serbia and Montenegro: 45.6% of adults smoke Montenegro: 45.6% of adults smoke Greece: 44.5% of adults smoke Bosnia and Herzegovina: 41.8% of adults smoke Kazakhstan: 41.3% of adults smoke Kosovo: 41.3% of adults smoke Moldova: 40.9% of adults smoke It's important to note that these figures are estimates and may vary slightly from other sources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hallucination</head><p>Extrinsic -the generated answer includes wrong statistics. (Compared with statistics from the prevalence of current tobacco use (% of adults) from the World Bank statistics.   Experiment: Two-turn iterative prompt.</p><p>1. Given an input dialogue as the context, we first input the prompt "Summarize the above dialogue" to the ChatGPT.</p><p>2. To refine the summary, we simply input another prompt -"Please make the summary shorter" after the first response.</p><p>Evaluation: We calculate the ROUGE scores (ROUGE-1, ROUGE-2, and ROUGE-L) of the first and second summaries and compare between turns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H.2 Interactivity on Machine Translation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H.2.1 Experiment 1: Multi-turn Post-Editting</head><p>We explore the capability on translation from English to the target language. For the experiment, we adapt the dataset used in §2.2.2 which samples 30 parallel sentences from 6 language pairs in NusaX <ref type="bibr" target="#b79">(Winata et al., 2022)</ref>, Chinese, French, Indonesian , Korean, Javanese, and Sundanese. Evaluation: The post-editing results are manually validated by a native speaker in the corresponding language to validate: 1) whether the post-edited sentence is better than the translation one, and 2) whether the post-edited sentence is the correct translation of the given English sentence.</p><p>Based on the evaluation, performing automatic post-editing through interactive LLMs, such as ChatGPT, yields consistently better translation results compared to a single-turn machine translation, which is especially useful for translation in low-resource languages. We provide per-language examples of the machine-translated and post-edited sentences in Appendix J.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H.2.2 Experiment 2: Automatic post-editing</head><p>To further strengthen our hypothesis, we conduct an additional experiment on the automatic post-editing (APE) shared task dataset on WMT 2022 <ref type="bibr">(Bhattacharyya et al., 2022)</ref>, which focuses on English→Marathi post-editing task. Marathi (mar) is also a low-resource language with 0.02% data size on CommonCrawl. We sample 50 samples from the corresponding dataset.</p><p>Evaluation: 1) human-targeted translation error rate (HTER) 8 , SacreBLEU <ref type="bibr" target="#b32">(Post, 2018)</ref> and <ref type="bibr">METEOR (Banerjee and Lavie, 2005)</ref> between the Marathi generated sentence compared to the human post-edited sentence, 2) HTER, Sacre-BLEU, METEOR, and semantic similarity score, i.e., BERTScore <ref type="bibr">(Zhang* et al., 2020)</ref>, between the English back-translated sentence and original 8 HTER is the official evaluation metric used in the APE 2022 shared task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Korean</head><p>New Kingdom ancient Egyptians marvelled at their predecessors monuments, which were then well over a thousand year old.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Korean</head><p>The U.S. Corps of Engineers estimated that 6 inches of rainfall could breach the previously damaged levees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Japanese</head><p>Although three people were inside the house when the car impacted it, none of them were hurt. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Japanese</head><p>The qualities that determine a subculture as distinct may be linguistic, aesthetic, religious, political, sexual, geographical, or a combination of factors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Japanese</head><p>New Kingdom ancient Egyptians marvelled at their predecessors monuments, which were then well over a thousand year old.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Paul</forename><surname>Christiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Leike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miljan</forename><surname>Martic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shane</forename><surname>Legg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.1706.03741</idno>
		<title level="m">Deep reinforcement learning from human preferences</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Think you have solved question answering?</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isaac</forename><surname>Cowhey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carissa</forename><surname>Schoenick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.1803.05457</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>try arc, the ai2 reasoning challenge</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Chatgpt -where it lacks</title>
		<author>
			<persName><surname>Cookup</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Enabling multimodal generation on CLIP via vision-language knowledge distillation</title>
		<author>
			<persName><forename type="first">Wenliang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.findings-acl.187</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2022</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2383" to="2395" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">2023a. Instructblip: Towards general-purpose vision-language models with instruction tuning</title>
		<author>
			<persName><forename type="first">Wenliang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongxu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huat</forename><surname>Tiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junqi</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weisheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Hoi</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Plausible may not be faithful: Probing object hallucination in vision-language pre-training</title>
		<author>
			<persName><forename type="first">Wenliang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziwei</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Conference of the European Chapter</title>
		<meeting>the 17th Conference of the European Chapter<address><addrLine>Dubrovnik, Croatia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="2136" to="2148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Explaining answers with entailment trees</title>
		<author>
			<persName><forename type="first">Bhavana</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengnan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannah</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leighanna</forename><surname>Pipatanangkura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="7358" to="7370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Ernest</forename><surname>Davis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.04752</idno>
		<title level="m">Benchmarks for automated commonsense reasoning: A survey</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Ernest</forename><surname>Davis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.09723</idno>
		<title level="m">Mathematics, word problems, common sense, and artificial intelligence</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Colombian judge uses chatgpt in ruling</title>
		<author>
			<persName><forename type="first">Web</forename><surname>Desk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>triggers debate</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Igor</forename><surname>Douven</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Chatgpt for (finance) research: The bananarama conjecture. Finance Research Letters</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Dowling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Lucey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">103662</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">CARE: a new dataset for exploring explainable causal reasoning</title>
		<author>
			<persName><forename type="first">Li</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.33</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="432" to="446" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Simon</forename><surname>Frieder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Pinchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan-Rhys</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tommaso</forename><surname>Salvatori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Lukasiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Christian Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Chevalier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julius</forename><surname>Berner</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2301.13867</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
			<publisher>Mathematical capabilities of chatgpt</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A framework for few-shot language model evaluation</title>
		<author>
			<persName><forename type="first">Leo</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Tow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sid</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Dipofi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurence</forename><surname>Golding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Mcdonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Phang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laria</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anish</forename><surname>Thite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Zou</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.5371628</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">How well does chatgpt do when taking the medical licensing exams? the implications of large language models for medical education and knowledge assessment. medRxiv</title>
		<author>
			<persName><forename type="first">Aidan</forename><surname>Gilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Conrad</forename><surname>Safranek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vimig</forename><surname>Socrates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ling</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">Andrew</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Chartash</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2022" to="2034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Bogdan</forename><surname>Gliwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iwona</forename><surname>Mochol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maciej</forename><surname>Biesek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksander</forename><surname>Wawer</surname></persName>
		</author>
		<title level="m">Samsum corpus: A humanannotated dialogue dataset for abstractive summarization. EMNLP-IJCNLP 2019</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">70</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Some remarks on large language models</title>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Cindy</forename><surname>Gordon</surname></persName>
		</author>
		<title level="m">Chatgpt is the fastest growing app in the history of web applications</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">The flores-101 evaluation benchmark for low-resource and multilingual machine translation</title>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng-Jen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Da</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjana</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc'aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">Tanya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyi</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jessy</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.12356</idno>
		<title level="m">News summarization and evaluation in the era of gpt-3</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Chatgpt is not all you need. a state of the art review of large generative ai models</title>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Gozalo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-</forename><surname>Brizuela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduardo</forename><forename type="middle">C</forename><surname>Garrido-Merchan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.04655</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">Biyang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziyuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minqi</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinran</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxuan</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianwei</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yupeng</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.07597</idno>
		<title level="m">How close is chatgpt to human experts? comparison corpus, evaluation, and detection</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Inductive Logic</title>
		<author>
			<persName><forename type="first">James</forename><surname>Hawthorne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Stanford Encyclopedia of Philosophy, Spring 2021 edition</title>
		<editor>
			<persName><forename type="first">Edward</forename><forename type="middle">N</forename><surname>Zalta</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
		<respStmt>
			<orgName>Metaphysics Research Lab, Stanford University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Teaching machines to read and comprehend</title>
		<author>
			<persName><forename type="first">Karl</forename><surname>Moritz Hermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Kocisky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Will</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mustafa</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/K16-1028</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th SIGNLL Conference on Computational Natural Language Learning</title>
		<meeting>the 20th SIGNLL Conference on Computational Natural Language Learning<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="280" to="290" />
		</imprint>
	</monogr>
	<note>Advances in Neural Information Processing Systems</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Shades of BLEU, flavours of success: The case of MultiWOZ</title>
		<author>
			<persName><forename type="first">Tomáš</forename><surname>Nekvinda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ondřej</forename><surname>Dušek</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.gem-1.4</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021)</title>
		<meeting>the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="34" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Putting chatgpt&apos;s medical advice to the (turing) test. medRxiv</title>
		<author>
			<persName><forename type="first">Oded</forename><surname>Nov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nina</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devin</forename><forename type="middle">M</forename><surname>Mann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="2023" to="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<title level="m">Gpt-4 technical report</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Simon</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantin</forename><surname>Hebenstreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valentin</forename><surname>Liévin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoffer</forename><forename type="middle">Egeberg</forename><surname>Hother</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milad</forename><surname>Moradi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maximilian</forename><surname>Mayrhauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Praas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ole</forename><surname>Winther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Samwald</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.11596</idno>
		<title level="m">Thoughtsource: A central hub for large language model reasoning data</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Long</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diogo</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carroll</forename><forename type="middle">L</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katarina</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fraser</forename><surname>Kelton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maddie</forename><surname>Simens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Christiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Leike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2203.02155</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Training language models to follow instructions with human feedback</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">chrF: character n-gram F-score for automatic MT evaluation</title>
		<author>
			<persName><forename type="first">Maja</forename><surname>Popović</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W15-3049</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Workshop on Statistical Machine Translation</title>
		<meeting>the Tenth Workshop on Statistical Machine Translation<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="392" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Modeling event plausibility with consistent conceptual abstraction</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>Porada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaheer</forename><surname>Suleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jackie</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kit</forename><surname>Cheung</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.138</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1732" to="1743" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A call for clarity in reporting BLEU scores</title>
		<author>
			<persName><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-6319</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Machine Translation: Research Papers</title>
		<meeting>the Third Conference on Machine Translation: Research Papers<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="186" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">Shuofei</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ningyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunzhi</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shumin</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuanqi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huajun</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.09597</idno>
		<title level="m">Reasoning with language model prompting: A survey</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Is chatgpt a general-purpose natural language processing task solver</title>
		<author>
			<persName><forename type="first">Chengwei</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aston</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuosheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Lianhui Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shyam</forename><surname>Upadhyay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.549</idno>
		<idno type="arXiv">arXiv:2302.06476</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2023. 2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="7066" to="7076" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>TIME-DIAL: Temporal commonsense reasoning in dialog</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning transferable visual models from natural language supervision</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jong</forename><forename type="middle">Wook</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Hallacy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="8748" to="8763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Jack</forename><forename type="middle">W</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katie</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francis</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Aslanides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Ring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susannah</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eliza</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Hennigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Menick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albin</forename><surname>Cassirer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><forename type="middle">Anne</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maribeth</forename><surname>Rauh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amelia</forename><surname>Glaese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumanth</forename><surname>Dathathri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saffron</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Uesato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Mellor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irina</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonia</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nat</forename><surname>Mcaleese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amy</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erich</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddhant</forename><surname>Jayakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Budden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Esme</forename><surname>Sutherland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michela</forename><surname>Paganini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lena</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lorraine</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adhiguna</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aida</forename><surname>Kuncoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Nematzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Domenic</forename><surname>Gribovskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angeliki</forename><surname>Donato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Baptiste</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Lespiau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolai</forename><surname>Tsimpoukelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Grigorev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibault</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mantas</forename><surname>Sottiaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toby</forename><surname>Pajarskas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhitao</forename><surname>Pohlen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cyprien</forename><surname>Toyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujia</forename><surname>De Masson D'autume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tayfun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Terzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Mikulik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><surname>Babuschkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><surname>De Las</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurelia</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Guy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Blake</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><surname>Hechtman</surname></persName>
		</author>
		<author>
			<persName><surname>Weidinger</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2112.11446</idno>
		<editor>Iason Gabriel, William Isaac, Ed Lockhart, Simon Osindero, Laura Rimell, Chris Dyer, Oriol Vinyals, Kareem Ayoub, Jeff Stanway, Lorrayne Bennett</editor>
		<imprint/>
	</monogr>
	<note>Demis Hassabis, Koray Kavukcuoglu, and Geoffrey Irving. 2021. Scaling language models: Methods, analysis and insights from training gopher</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Zero-shot text-to-image generation</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikhail</forename><surname>Pavlov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="8821" to="8831" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Fabin</forename><surname>Rasheed</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Gpt3 sees</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Chatgpt: A comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope. Internet of Things and Cyber-Physical Systems</title>
		<author>
			<persName><forename type="first">Partha</forename><surname>Pratim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ray</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Qa dataset explosion: A taxonomy of nlp resources for question answering and reading comprehension</title>
		<author>
			<persName><forename type="first">Anna</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
		</author>
		<idno type="DOI">10.1145/3560260</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv. Just Accepted</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Highresolution image synthesis with latent diffusion models</title>
		<author>
			<persName><forename type="first">Robin</forename><surname>Rombach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Blattmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Lorenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Esser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Björn</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="10684" to="10695" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Analysing mathematical reasoning abilities of neural models</title>
		<author>
			<persName><forename type="first">David</forename><surname>Saxton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Why the chatgpt ai chatbot is blowing everyone&apos;s mind</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Shankland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Chatgpt and other large language models are double-edged swords</title>
		<author>
			<persName><forename type="first">Yiqiu</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><surname>Heacock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Elias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><forename type="middle">D</forename><surname>Hentel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beatriu</forename><surname>Reig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linda</forename><surname>Moy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">2022a. Stepgame: A new benchmark for robust multi-hop spatial reasoning in texts</title>
		<author>
			<persName><forename type="first">Zhengxiang</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aldo</forename><surname>Lipani</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v36i10.21383</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="11321" to="11329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">2022b. StepGame: A new benchmark for robust multi-hop spatial reasoning in texts</title>
		<author>
			<persName><forename type="first">Zhengxiang</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aldo</forename><surname>Lipani</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v36i10.21383</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="11321" to="11329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Drawing mona lisa with chatgpt</title>
		<author>
			<persName><forename type="first">Denis</forename><surname>Shiryaev</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mojtaba</forename><surname>Komeili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Da</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">Michael</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Megan</forename><surname>Ung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kushal</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Lane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morteza</forename><surname>Behrooz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Ngan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Spencer</forename><surname>Poff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y-Lan</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Kambadur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2208.03188</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Blenderbot 3: a deployed conversational agent that continually learns to responsibly engage</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Clutrr: A diagnostic benchmark for inductive reasoning from text</title>
		<author>
			<persName><forename type="first">Koustuv</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shagun</forename><surname>Sodhani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4506" to="4515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Beyond the imitation game: Quantifying and extrapolating the capabilities of language models</title>
		<author>
			<persName><forename type="first">Noah</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">; Aarohi</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abu</forename><surname>Awal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Md</forename><surname>Shoeb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abubakar</forename><surname>Abid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Adam R Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrià</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><surname>Garriga-Alonso</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.04615</idno>
		<imprint>
			<date type="published" when="2022">2023. 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Why does chatgpt constantly lie?</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<author>
			<persName><forename type="first">Shane</forename><surname>Storks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiaozi</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joyce</forename><forename type="middle">Y</forename><surname>Chai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.01172</idno>
		<title level="m">Commonsense reasoning for natural language understanding: A survey of benchmarks, resources, and approaches</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="60" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Read before generate! faithful long form question answering with machine reading</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoguang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jindi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2022</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="744" to="756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Improve query focused abstractive summarization by incorporating answer relevance</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiezheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3124" to="3131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Recitation-augmented language models</title>
		<author>
			<persName><forename type="first">Zhiqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName><forename type="first">Teo</forename><surname>Susnjak</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.09292</idno>
		<title level="m">Chatgpt: The end of online exam integrity? arXiv preprint</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">olmpics-on what language model pre-training captures</title>
		<author>
			<persName><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanai</forename><surname>Elazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="743" to="758" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<author>
			<persName><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.00937</idno>
		<title level="m">Commonsenseqa: A question answering challenge targeting commonsense knowledge</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Marta</forename><forename type="middle">R</forename><surname>Nllb Team</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Costa-Jussà</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Onur</forename><surname>Cross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maha</forename><surname>Çelebi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenneth</forename><surname>Elbayad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elahe</forename><surname>Heffernan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janice</forename><surname>Kalbassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Licht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Maillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Skyler</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Al</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bapi</forename><surname>Youngblood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Loic</forename><surname>Akula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><forename type="middle">Mejia</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prangthip</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Hansanti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Semarley</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><surname>Jarrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ram</forename><surname>Kaushik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Sadagopan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shannon</forename><surname>Rowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chau</forename><surname>Spruit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Necip</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Fazil Ayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Bhosale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vedanuj</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christophe</forename><surname>Mourachko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Safiyyah</forename><surname>Ropers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holger</forename><surname>Saleem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>No language left behind: Scaling humancentered machine translation</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Logic and artificial intelligence</title>
		<author>
			<persName><forename type="first">Richmond</forename><surname>Thomason</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">Romal</forename><surname>Thoppilan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">De</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Apoorv</forename><surname>Kulshreshtha</surname></persName>
		</author>
		<author>
			<persName><surname>Heng-Tze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alicia</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leslie</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><surname>Du</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.08239</idno>
		<title level="m">Lamda: Language models for dialog applications</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Chatgpt is fun, but not an author</title>
		<author>
			<persName><forename type="first">Thorp</forename><surname>Holden</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<author>
			<persName><forename type="first">Giuseppe</forename><surname>Venuto</surname></persName>
		</author>
		<title level="m">Giuven95/chatgpt-failures: Chatgpt failure archive</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Abductive reasoning</title>
		<author>
			<persName><forename type="first">Douglas</forename><surname>Walton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>University of Alabama Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Fairness in representation for multilingual NLP: Insights from controlled experiments on conditional language modeling</title>
		<author>
			<persName><forename type="first">Ada</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">GLUE: A multi-task benchmark and analysis platform for natural language understanding</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-5446</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</title>
		<meeting>the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="353" to="355" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<author>
			<persName><forename type="first">Su</forename><surname>Wang</surname></persName>
			<affiliation>
				<orgName type="collaboration">Katrin Erk</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Durrett</surname></persName>
			<affiliation>
				<orgName type="collaboration">Katrin Erk</orgName>
			</affiliation>
		</author>
		<idno type="arXiv">arXiv:1804.00619</idno>
		<title level="m">b. Modeling semantic plausibility by injecting world knowledge</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Self-consistency improves chain of thought reasoning in language models</title>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.11171</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Self-instruct: Aligning language models with self-generated instructions</title>
		<author>
			<persName><forename type="first">Yizhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yeganeh</forename><surname>Kordi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Swaroop</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alisa</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.acl-long.754</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 61st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="13484" to="13508" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Psychology of reasoning: Structure and content</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Cathcart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wason</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><surname>Nicholas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johnson-Laird</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1972">1972</date>
			<publisher>Harvard University Press</publisher>
			<biblScope unit="volume">86</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">2022a. Emergent analogical reasoning in large language models</title>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Webb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><forename type="middle">J</forename><surname>Holyoak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongjing</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2212.09196</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Webb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><forename type="middle">J</forename><surname>Holyoak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongjing</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.09196</idno>
		<title level="m">Emergent analogical reasoning in large language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">2022a. Emergent abilities of large language models</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Machine Learning Research</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">2022b. Chain-of-thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Towards ai-complete question answering: A set of prerequisite toy tasks</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomás</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">4th International Conference on Learning Representations</title>
		<meeting><address><addrLine>San Juan, Puerto Rico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-05-02">2016. 2016. May 2-4, 2016</date>
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Towards ai-complete question answering: A set of prerequisite toy tasks</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">4th International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Indonlu: Benchmark and resources for evaluating indonesian natural language understanding</title>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Wilie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karissa</forename><surname>Vincentio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Genta</forename><surname>Indra Winata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Cahyawijaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhi</forename><surname>Yuan Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sidik</forename><surname>Soleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahmad</forename><surname>Mahendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Syafri</forename><surname>Bahar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing</title>
		<meeting>the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="843" to="857" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<author>
			<persName><forename type="first">Genta</forename><surname>Indra Winata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alham</forename><surname>Fikri Aji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Cahyawijaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahmad</forename><surname>Mahendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fajri</forename><surname>Koto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ade</forename><surname>Romadhony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kemal</forename><surname>Kurniawan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Moeljadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radityo</forename><forename type="middle">Eko</forename><surname>Prasojo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jey</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2205.15960</idno>
		<title level="m">Nusax: Multilingual parallel sentiment dataset for 10 indonesian local languages</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Specialized llms: Chatgpt, lamda, galactica, codex, sparrow, and more</title>
		<author>
			<persName><forename type="first">Cameron</forename><forename type="middle">R</forename><surname>Wolfe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">María Grandury, Mario Šaško, diverse, explainable multi-hop question answering</title>
		<author>
			<persName><forename type="first">Bigscience</forename><surname>Workshop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">:</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suzana</forename><surname>Ilić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Hesslow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Castagné</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Sasha Luccioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">François</forename><surname>Yvon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Gallé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Tow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pawan</forename><surname>Sasanka Ammanamanchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wang ; Stas Bekman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angelina</forename><surname>Mcmillan-Major</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huu</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucile</forename><surname>Saulnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samson</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><forename type="middle">Ortiz</forename><surname>Suarez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Laurençon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Launay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Gokaslan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adi</forename><surname>Simhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Soroa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alham</forename><surname>Fikri Aji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amit</forename><surname>Alfassy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><forename type="middle">Kreisberg</forename><surname>Nitzav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenghao</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Emezue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Klamm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Leong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Daniel Van Strien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dragomir</forename><surname>Ifeoluwa Adelani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><forename type="middle">De</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gérard</forename><surname>Toni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Germán</forename><surname>Dupont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giada</forename><surname>Kruszewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hady</forename><surname>Pistilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamza</forename><surname>Elsahar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Benyamina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Idris</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isaac</forename><surname>Abdulmumin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Itziar</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Javier</forename><surname>Gonzalez-Dios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jenny</forename><surname>De La Rosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Chim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jörg</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Frohberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joydeep</forename><surname>Tobing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khalid</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kimbo</forename><surname>Almubarak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leandro</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leon</forename><surname>Von Werra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Long</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Loubna</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ludovic</forename><surname>Ben Allal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manan</forename><surname>Tanguy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maraim</forename><surname>Romero Muñoz</surname></persName>
		</author>
		<author>
			<persName><surname>Masoud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">Benoît</forename><surname>Sagot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Niklas</forename><surname>Muennighoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Albert</forename><surname>Villanova Del Moral</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Olatunji</forename><surname>Ruwase</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rachel</forename><surname>Bawden</surname></persName>
		</editor>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Eduardo González Ponferrada; Ethan Kim, Eyal Bar Natan</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="2369" to="2380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">2021a. Vision guided generative pre-trained language models for multimodal abstractive summarization</title>
		<author>
			<persName><forename type="first">Tiezheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenliang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.326</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Dominican Republic</publisher>
			<biblScope unit="page" from="3995" to="4007" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">2021b. Adaptsum: Towards low-resource domain adaptation for abstractive summarization</title>
		<author>
			<persName><forename type="first">Tiezheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<biblScope unit="page" from="5892" to="5904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Multiwoz 2.2: A dialogue dataset with additional annotation corrections and state tracking baselines</title>
		<author>
			<persName><forename type="first">Xiaoxue</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srinivas</forename><surname>Sunkara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raghav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianguo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jindong</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page">109</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Star: Bootstrapping reasoning with reasoning</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Zelikman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Bertscore: Evaluating text generation with bert</title>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">*</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Varsha</forename><surname>Kishore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">*</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">*</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Descriptiondriven task-oriented dialog modeling</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raghav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanbin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harrison</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Izhak</forename><surname>Shafran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<idno>ArXiv, abs/2201.08904</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Knowledgegrounded dialogue generation with pre-trained language models</title>
		<author>
			<persName><forename type="first">Xueliang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Can</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chongyang</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3377" to="3390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<author>
			<persName><forename type="first">Terry</forename><surname>Yue Zhuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujin</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.12867</idno>
		<title level="m">Chunyang Chen, and Zhenchang Xing. 2023a. Exploring ai ethics of chatgpt: A diagnostic analysis</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<author>
			<persName><forename type="first">Terry</forename><surname>Yue Zhuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujin</forename><surname>Huang</surname></persName>
		</author>
		<title level="m">Chunyang Chen, and Zhenchang Xing. 2023b. Red teaming chatgpt via jailbreaking: Bias, robustness, reliability and toxicity</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
