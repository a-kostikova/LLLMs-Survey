<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Multimodal Analysis of Influencer Content on Twitter</title>
				<funder ref="#_DnUqBFK">
					<orgName type="full">Leverhulme Trust</orgName>
				</funder>
				<funder ref="#_SHQmhF7">
					<orgName type="full">ESRC</orgName>
				</funder>
				<funder ref="#_RPBgATD #_hqWmPAE">
					<orgName type="full">UK Research and Innovation</orgName>
				</funder>
				<funder ref="#_yhd3PcW">
					<orgName type="full">European Research Council</orgName>
					<orgName type="abbreviated">ERC</orgName>
				</funder>
				<funder>
					<orgName type="full">Dutch Research Council (NWO)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Danae</forename><surname>Sánchez Villegas</surname></persName>
							<email>dsanchezvillegas1@sheffield.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Catalina</forename><surname>Goanta</surname></persName>
							<email>e.c.goanta@uu.nl</email>
							<affiliation key="aff1">
								<orgName type="institution">Utrecht University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nikolaos</forename><surname>Aletras</surname></persName>
							<email>n.aletras@sheffield.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Multimodal Analysis of Influencer Content on Twitter</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4637F771A0C8440AB2760AAFF4F1B7DB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-05-29T14:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Guidelines Keywords retrieved from relevant guidelines Recommended and not recommended terms</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Influencer marketing involves a wide range of strategies in which brands collaborate with popular content creators (i.e., influencers) to leverage their reach, trust, and impact on their audience to promote and endorse products or services. Because followers of influencers are more likely to buy a product after receiving an authentic product endorsement rather than an explicit direct product promotion, the line between personal opinions and commercial content promotion is frequently blurred. This makes automatic detection of regulatory compliance breaches related to influencer advertising (e.g., misleading advertising or hidden sponsorships) particularly difficult. In this work, we (1) introduce a new Twitter (now X) dataset consisting of 15, 998 influencer posts mapped into commercial and noncommercial categories for assisting in the automatic detection of commercial influencer content; (2) experiment with an extensive set of predictive models that combine text and visual information showing that our proposed cross-attention approach outperforms state-ofthe-art multimodal models; and (3) conduct a thorough analysis of strengths and limitations of our models. We show that multimodal modeling is useful for identifying commercial posts, reducing the amount of false positives, and capturing relevant context that aids in the discovery of undisclosed commercial posts.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Social media influencers are content creators who have established credibility in a specific domain (e.g., fitness, technology), are sometimes followed by a large number of accounts and can impact the buying decisions of their followers <ref type="bibr" target="#b30">(Keller and Berry, 2003;</ref><ref type="bibr" target="#b6">Brown and Hayes, 2008;</ref><ref type="bibr" target="#b48">Nandagiri and Philip, 2018;</ref><ref type="bibr" target="#b40">Lee et al., 2022)</ref>. Influencer marketing (i.e., promoted content via influencer posts 1 Data and code are available at https://github.com/d anaesavi/micd-influencer-content-twitter Commercial: For a truly beautiful and delicate summer fragrance you have to try @USER's newest scent.</p><p>Non-commercial: So that's tonight's dinner, tomorrow's lunch, dinner &amp; inbetweenies sorted. in social media) has gained popularity as an alternative to traditional advertising (e.g., magazines, television, billboards) and mainstream digital marketing such as pop-up and platform ads <ref type="bibr" target="#b41">(Leerssen et al., 2019;</ref><ref type="bibr" target="#b48">Nandagiri and Philip, 2018;</ref><ref type="bibr" target="#b42">Lou et al., 2019;</ref><ref type="bibr" target="#b27">Jarrar et al., 2020;</ref><ref type="bibr" target="#b17">Fang and Wang, 2022)</ref> for reaching a larger and more targeted audience <ref type="bibr" target="#b21">(Gross and Wangenheim, 2018)</ref>.</p><p>Influencer marketing is dominated by native advertising where there is no obvious distinction between commercial (i.e., content that is monetized) and non-commercial content such as personal thoughts, sentiment and experiences <ref type="bibr" target="#b8">(Chia, 2012)</ref>. Even though the disclosure of commercial content (via keywords such as #ad, #sponsored) by influencers has become a requirement in some countries due to consumer protection obligations,<ref type="foot" target="#foot_0">2</ref> identifying commercial content in influencer posts is challenging in practice because (1) disclosure guidelines are not always followed, e.g., not including or hiding standard disclosure terms<ref type="foot" target="#foot_1">3</ref>  <ref type="bibr" target="#b64">(Wojdynski, 2016;</ref><ref type="bibr" target="#b5">Boerman and van Reijmersdal, 2016;</ref><ref type="bibr" target="#b45">Mathur et al., 2018;</ref><ref type="bibr" target="#b1">Alassani and Göretz, 2019;</ref><ref type="bibr" target="#b11">De Gregorio and Goanta, 2020)</ref>; and (2) brand cues (i.e., elements that may affect buying behavior) may appear in different modalities such as text, images or both <ref type="bibr">(Sánchez Villegas et al., 2021)</ref>. Figure <ref type="figure" target="#fig_0">1</ref> shows an example of a commercial and a noncommercial post. Both examples appear to include products, however only the top example is commercial. This makes it difficult for the users to distinguish between paid promotion and personal opinions. Therefore, automatically detecting whether an influencer's post involves paid promotion of products or services is of utmost importance for addressing issues related to transparency and regulatory compliance, such as misleading advertising or undisclosed sponsorships in large scale <ref type="bibr" target="#b45">(Mathur et al., 2018;</ref><ref type="bibr" target="#b16">Evans et al., 2017;</ref><ref type="bibr" target="#b65">Wojdynski et al., 2018;</ref><ref type="bibr" target="#b14">Ducato, 2020;</ref><ref type="bibr" target="#b15">Ershov and Mitchell, 2020)</ref>. Previous work on identifying influencer commercial content has focused on analyzing user features (e.g., popularity and engagement) and network characteristics of influencers <ref type="bibr" target="#b68">(Zarei et al., 2020;</ref><ref type="bibr">Kim et al., 2021b)</ref>, while the use of language and its relationship to images has not been explicitly explored.</p><p>In this work, we present a new expert annotated Twitter (now X) dataset and an extensive empirical study on influencer multimodal content focused on analyzing the contribution of text and image modalities to commercial and non-commercial posts. Our main contributions are as follows:</p><p>• We present a large publicly available dataset of 14, 384 text-image pairs and 1, 614 textonly influencer tweets written in English.</p><p>Tweets are mapped into commercial and noncommercial categories;</p><p>• We benchmark an extensive set of state-ofthe-art language, vision and multimodal models for automatically identifying commercial content, including prompting large language models (LLMs);</p><p>• We propose a simple yet effective crossattention multimodal approach that outperforms all text, vision and multimodal models;</p><p>• We conduct a qualitative analysis to shed light on the limitations of automatically detecting commercial content, and provide insights into when each modality is beneficial.</p><p>2 Related Work</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Computational Studies on Influencers</head><p>Previous work has analyzed the characteristics of influencers on social media platforms such as Twit-ter <ref type="bibr" target="#b26">(Huang et al., 2014;</ref><ref type="bibr" target="#b39">Lagrée et al., 2018;</ref><ref type="bibr" target="#b22">Han et al., 2021)</ref>, Instagram <ref type="bibr" target="#b33">(Kim et al., 2017</ref><ref type="bibr">(Kim et al., , 2021a;;</ref><ref type="bibr" target="#b18">Fernandes et al., 2022)</ref> and Pinterest <ref type="bibr" target="#b20">(Gilbert et al., 2013;</ref><ref type="bibr" target="#b45">Mathur et al., 2018)</ref>. <ref type="bibr" target="#b33">Kim et al. (2017)</ref>   <ref type="bibr" target="#b45">Mathur et al. (2018)</ref> examine whether influencers comply with advertising disclosure regulations and show that while influencer commercial content has increased over the years, its disclosure remains limited.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Data Resources for Influencer Content Analysis</head><p>Datasets for analyzing influencer content have been developed to analyze the influencers' impact on spreading information <ref type="bibr" target="#b22">(Han et al., 2021)</ref>, categorizing influencers into different domains, e.g., fashion, beauty <ref type="bibr" target="#b34">(Kim et al., 2020)</ref>, and analyzing the characteristics of branded content <ref type="bibr" target="#b67">(Yang et al., 2019)</ref>. <ref type="bibr" target="#b67">Yang et al. (2019)</ref> introduce a dataset to study how influencers mention brands in their posts. They collect 800K Instagram posts from 18K influencers that explicitly mention (@mention) a brand, and characterize them as sponsored or non-sponsored using three sponsorship indicators: #ad, #sponsored, #paidAD.</p><p>Datasets for analyzing commercial content shared by influencers have been developed by <ref type="bibr" target="#b68">Zarei et al. (2020)</ref> and <ref type="bibr">Kim et al. (2021b)</ref>. <ref type="bibr" target="#b68">Zarei et al. (2020)</ref> present a dataset consisting of 35K Instagram posts and 99K stories (i.e., posts that disappear after 24 hours) from 12K influencers and use an LSTM model <ref type="bibr" target="#b25">(Hochreiter and Schmidhuber, 1997)</ref> to identify whether a post is sponsored or not. <ref type="bibr">Kim et al. (2021b)</ref> develop a dataset of 38K influencer posts that explicitly mention (@mention) a brand. Similar to <ref type="bibr" target="#b67">Yang et al. (2019)</ref>, they label these posts as sponsored if they contain at least one of three sponsorship indicators: #ad, #sponsored, #paidAD. They propose an attention-based neural network model to classify posts as sponsored or non-sponsored. Limitations of existing resources Table <ref type="table" target="#tab_1">1</ref> compares existing datasets for analyzing influencer content. We observe that current datasets have only used a limited set of keywords (e.g., #ad) for identifying posts with commercial content (seven or less). While some datasets include only text content <ref type="bibr" target="#b68">(Zarei et al., 2020)</ref>, others focus only on posts that explicitly mention (@mention) a brand <ref type="bibr" target="#b67">(Yang et al., 2019;</ref><ref type="bibr">Kim et al., 2021b)</ref>. In contrast to prior datasets for analyzing influencer commercial content that use Instagram, we use Twitter because it is a text-first platform and has rapidly increased in popularity as a tool for influencer marketing. For instance, 49% of Twitter users say that they have made a purchase as a direct result of a Tweet from an influencer. We present a new multimodal influencer content dataset (MICD) consisting of Twitter posts mapped into commercial and non-commercial classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Retrieving Candidate Influencers</head><p>To map tweets into these two classes, we first need to identify candidate influencers on Twitter. We look for candidate accounts in six different domains (i.e., Beauty, Travel, Fitness, Food, Tech and Lifestyle) to ensure thematic diversity. The domains related to 'Beauty', 'Fitness', 'Travel' and 'Lifestyle' are among the most popular in Twitter,<ref type="foot" target="#foot_3">5</ref> while Food and Tech have recently gained attention <ref type="bibr" target="#b1">(Alassani and Göretz, 2019;</ref><ref type="bibr" target="#b63">Weber et al., 2021)</ref>. To retrieve influencers, we query for accounts that contain domain-specific keywords in their bios (e.g., beauty vlogger, travel influencer, lifestyle blogger, food writer) as influencers tend to provide such information in profile descriptions <ref type="bibr" target="#b34">(Kim et al., 2020)</ref>. <ref type="foot" target="#foot_4">6</ref> We collect all available imagetext tweets written in English from each account using the Academic Twitter API. <ref type="foot" target="#foot_5">7</ref> Duplicate tweets with identical text are removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Keyword-based Weak Labeling</head><p>We initially use a keyword-based strategy to automatically map posts into the commercial and non-commercial categories (i.e., weak labeling). This is suitable in a real-world scenario of an automatic regulatory compliance system with limited resources for manually labeling all available posts <ref type="bibr" target="#b68">(Zarei et al., 2020;</ref><ref type="bibr">Kim et al., 2021b)</ref>.</p><p>Commercial Commercial tweets include content that promotes or endorses a brand or its products or services, a free product or service or any other incentive. Thus, we extract keywords strongly associated with influencer marketing following the official guidelines provided by the Federal Trade Commission <ref type="bibr">(FTC, 2019)</ref>  A. We label as commercial all tweets containing at least one of the influencer marketing keywords excluding tweets where the keyword is negated (e.g., not ad, not an ad). To avoid data leakage in the experiments, we remove all of the keywords used for data labeling (see Sec. 5.1) from the posts after labeling them. As a result, our models can identify commercial content without the use of such terms (see Sec. 4).</p><p>Non-commercial Non-commercial posts refer to organic content such as personal ideas, comments and life updates that do not aim for monetization. Thus, all tweets that do not include any of the keywords presented above are considered noncommercial. To balance the dataset, we sample non-commercial posts weighted according to the number of commercial tweets for each account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Data Splits</head><p>Text-Image Sets We split the tweets into train, dev and test sets at the account level (i.e., tweets included in each split belong to different accounts) to ensure that models can generalize to unseen influencer accounts and prevent information leakage in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text-only Test Set</head><p>We further collect text-only posts from influencer accounts in the test set. We sample text-only tweets according to the number of tweets for each influencer account in the test set, resulting in a total of 1, 614 text-only tweets. This is done to account for cases where only text content is provided. 8</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Human Data Annotation</head><p>To ensure a high quality data set for evaluation, we use human annotators for labeling all tweets in both  The inter-annotator agreement between two annotations across all tweets is 0.78 Cohen's-Kappa <ref type="bibr" target="#b10">(Cohen, 1960)</ref> that corresponds to the upper part of the substantial agreement band <ref type="bibr" target="#b4">(Artstein and Poesio, 2008)</ref>. Furthermore, the agreement between the automatic weak labels and the resulting human annotations is 0.67 Cohen's-Kappa which corresponds to substantial agreement and denotes weak labels of good quality for model training.</p><p>Our final dataset contains 14, 384 text-image pairs <ref type="bibr">(7, 259 non-commercial and 7, 125 commercial)</ref>. Additionally, the text-only test set consists of 1, 614 tweets (1, 377 non-commercial and 237 commercial). Table <ref type="table" target="#tab_4">3</ref> shows the distribution of commercial and non-commercial tweets by split.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Exploratory Analysis</head><p>Exploratory analysis of our dataset revealed that influencer accounts in our dataset have between 8K and 500K followers covering micro and macro influencers which are considered to create highly persuasive content <ref type="bibr" target="#b29">(Kay et al., 2020)</ref>. Table <ref type="table">2</ref> shows the number of influencer accounts per domain. In average, each domain contains 22 accounts, and all accounts have a minimum of 10 commercial tweets. Finally, we observe a different label distribution in text-image and text-only test splits. Textonly test split is unbalanced with most posts manually annotated as non-commercial (85.32% noncommercial, 14.68% commercial). On the other hand, text-image test set label distribution is balanced (48.01% non-commercial, 51.99% commercial). This highlights the use of visuals in influencer marketing for effectively advertising products, which is consistent with findings in conventional online advertising research <ref type="bibr" target="#b46">(Mazloom et al., 2016)</ref>. It also emphasizes the multimodal nature of the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Comparison with Related Datasets</head><p>Table 1 compares our dataset, MICD, to related datasets for influencer content analysis (see Sec. 2). Our dataset contains posts with and without explicit (i.e., @USER) brand mentions from influencers of different domains. We follow a similar approach for weak labeling commercial posts as previous work <ref type="bibr" target="#b68">(Zarei et al., 2020;</ref><ref type="bibr">Kim et al., 2021b</ref>), but we considerably extend the list of keywords following relevant guidelines and experts feedback (see Sec. 3.2). Moreover, we include test sets with a total of 3, 049 tweets annotated by experts in the legal domain. We anticipate that this dataset will be beneficial not only for this study, but also for future influencer content analysis research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Influencer Content Classification Models</head><p>Given a social media post P (e.g., a tweet) consisting of a text and image pair (L, I), the task is to classify a post P into the correct category (commercial or non-commercial).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Unimodal Models</head><p>Prompting We first experiment with prompting Flan-T5 (Chung et al., 2022) and GPT-3 <ref type="bibr" target="#b7">(Brown et al., 2020)</ref>. We use the following prompt: "Label the next text as 'commercial' or 'not commercial'. Text: &lt;TWEET&gt;". We map responses to the corresponding commercial or non-commercial class and report results for each model (zero-shot).</p><p>We </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Multimodal Models</head><p>Text &amp; Image Transformers We fine-tune three multimodal transformer-based models: MMBT <ref type="bibr" target="#b31">(Kiela et al., 2019)</ref>, ViLT <ref type="bibr">(Kim et al., 2021c)</ref> and LXMERT <ref type="bibr" target="#b59">(Tan and Bansal, 2019)</ref>.</p><p>MMBT uses ResNet and BERT as image and text encoders respectively, ViLT uses a convolutionfree encoder similar to ViT, and LXMERT takes object-level features as input (see Sec. 5.1). ViLT and LXMERT are multimodally pre-trained on visual-language tasks such as image-text matching and and visual question answering.</p><p>Aspect-Attention <ref type="bibr">Kim et al. (2021b)</ref> proposed an aspect-attention fusion model to rank Instagram posts based on their likelihood of including undeclared paid partnerships. Thus, we repurpose their model to identify commercial posts on Twitter. Aspect-attention fusion consists of generating a score for each modality by applying the attention mechanism across the image and text vectors.</p><p>Then, the multimodal post representation is produced by computing a linear combination of the score and the unimodal representations. The model is fine-tuned by adding a fully-connected layer with a softmax activation function (Aspect-Att).</p><p>ViT-BERTweet-Att We propose to combine unimodal pretrained representations via crossattention fusion strategy so that text features can guide the model to pay attention to the relevant image regions. We use BERTweet to obtain contextual representations of the text content</p><formula xml:id="formula_0">L ∈ R d L ×m L ,</formula><p>where L is the output of the last layer of BERTweet, d L is the hidden size of BERTweet and m L is the text sequence length. For encoding the images, we use the Vision Transformer pre-trained on ImageNet <ref type="bibr" target="#b53">(Russakovsky et al., 2015)</ref>. We obtain the visual representations of the image content I ∈ R d I ×m I , where I is the output of the last layer of ViT, d I is the hidden size of ViT and m I is the image sequence length. We propose to capture the inter-modality interactions using a cross-attention layer. Specifically, given L and I, we compute the scaled dot attention with L as queries, and I as keys and values as follows: Cross-Att(L,</p><formula xml:id="formula_1">I) = softmax( [W Q L][W K I] T d k )[W V I],</formula><p>where {W Q , W K , W V } are learnable parameters, Text For each tweet, we lowercase and tokenize text using DLATK <ref type="bibr" target="#b57">(Schwartz et al., 2017)</ref>. We also replace URLs and user @-mentions with placeholder tokens following the BERTweet pipeline <ref type="bibr" target="#b49">(Nguyen et al., 2020)</ref>. Emojis are replaced with their corresponding text string, e.g thumbs_up. Keywords used in the weak labeling process (Sec. Evaluation We evaluate all models using weighted-averaged<ref type="foot" target="#foot_8">12</ref> F1, precision, and recall to manage imbalanced classes. Results are obtained over three runs using different random seeds reporting average and standard deviation.</p><formula xml:id="formula_2">d k = d L = d I ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Implementation Details</head><p>We select the hyperparameters for all models using early stopping by monitoring the validation loss. We use the Adam optimizer (Kingma and Ba, 2014). We estimate the class weights using the 'balanced' heuristic <ref type="bibr" target="#b37">(King and Zeng, 2001)</ref>. All experiments (unless indicated) are performed using an Nvidia V100 GPU with a batch size of 16.</p><p>Prompting We use one GPU T4 to obtain the inference results from Flan-T5 (Chung et al., 2022) model. We use the large version from HuggingFace library (780M parameters) <ref type="bibr" target="#b66">(Wolf et al., 2019)</ref>. For GPT-3 <ref type="bibr" target="#b7">(Brown et al., 2020)</ref>, we use the text-davinci-003 model via the OpenAI<ref type="foot" target="#foot_9">13</ref> Library. Prompt templates are included in Appx. D.</p><p>Image-only For ResNet152 <ref type="bibr" target="#b23">(He et al., 2016)</ref>, we fine-tune for 1 epoch with learning rate η = 1e We use Adam (Kingma and Ba, 2014) with learning rate η = 1e -3 with η ∈ {1e -3 , 1e -4 , 1e -5 }, minimizing the binary cross-entropy using a batch size of 8 over 6 epochs with early stopping.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text-only Transformers</head><p>We fine-tune BERT and BERTweet for 20 epochs and choose the epoch with the lowest validation loss. We use the pretrained base-uncased model for BERT <ref type="bibr" target="#b60">(Vaswani et al., 2017;</ref><ref type="bibr" target="#b12">Devlin et al., 2019)</ref> from HuggingFace library (12-layer, 768-dimensional) <ref type="bibr" target="#b66">(Wolf et al., 2019)</ref>, and the base model for BERTweet (Nguyen et al., 2020) with a maximal sequence length of 128. We fine-tune BERT for 1 epoch, learning rate η = 1e -5 and dropout δ = 0.05; and BERTweet for 2 epochs, η = 1e -5 and δ = 0.05. For all models η ∈ {2e</p><p>-5 , 1e -4 , 1e -5 } and δ ∈ [0, 0.5], random search.</p><p>Text &amp; Image Transformers We train MMBT <ref type="bibr" target="#b31">(Kiela et al., 2019)</ref> for 1 epoch and η = 1e -5 where η ∈ {1e -3 , 1e -4 , 1e -5 } and dropout δ = 0.05 (δ in [0, 0.5], random search) before passing through the classification layer.</p><p>ViLT <ref type="bibr">(Kim et al., 2021c</ref>) is fine-tuned for 4 epochs and η = 1e -5 , vision layers are frozen.</p><p>LXMERT <ref type="bibr" target="#b59">(Tan and Bansal, 2019)</ref> is fine-tuned for 3 epochs with η = 1e -5 and δ = 0.05. -3 , 1e -4 , 1e -5 } and δ in [0, 0.5], random search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Aspect-Attention and</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>Table <ref type="table">4</ref> presents the performance on commercial and non-commercial influencer content prediction of all predictive models on our new multimodal influencer content dataset (MICD).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Unimodal Models</head><p>We first observe that the two image-only models obtain similar performance. Although both models surpass Most Freq. baseline and Flan-T5 prompting, the text-only models (BiLSTM-ATT, BERT and BERTweet) perform better than imageonly models. This corroborates results from pre- vious work in multimodal computational social science <ref type="bibr" target="#b62">(Wang et al., 2020;</ref><ref type="bibr" target="#b44">Ma et al., 2021)</ref> and influencer content analysis <ref type="bibr">(Kim et al., 2021b)</ref>. We further note that BERT-based models (BERT and BERTweet) outperform GPT-3 prompting and BiLSTM-Att models over 4% across all metrics.</p><p>Among the text-only models, BERTweet achieves the highest performance with 76.34, 76.80 and 76.45 weighted F1, precision and recall respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Multimodal models</head><p>State-of-the-art pre-trained multimodal models, ViLT and LXMERT fail to outperform text-only transformers achieving only 68.46 and 70.64 weighted F1 respectively. This emphasizes the challenges for modeling multimodal influencer content. Specifically, ViLT and LXMERT are pretrained on standard vision-language tasks including image captioning and visual question answering <ref type="bibr" target="#b69">(Zhou et al., 2020;</ref><ref type="bibr" target="#b43">Lu et al., 2019)</ref> using data where text and image modalities share common semantic relationships. In contrast, social media advertising frequently employs various types of visual and text rhetoric (e.g., symbolism) to convey their message with no obvious relationship between text and image <ref type="bibr" target="#b61">(Vempala and Preoţiuc-Pietro, 2019;</ref><ref type="bibr" target="#b24">Hessel and Lee, 2020;</ref><ref type="bibr">Sánchez Villegas and Aletras, 2021)</ref>. Similar behavior is observed with MMBT which obtains comparable performance to BERT. This suggests it is more beneficial to use a text-only encoder (BERTweet) that has been pre-trained on the same domain, in this case Twitter, than finetuning a more complex out-of-the-box multimodal transformer model (e.g., ViLT, LXMERT, MMBT).</p><p>BERTweet and ViT are used by Aspect-Att (a state-of-the-art model for influencer commercial content prediction) and our model, ViT-BERTweet-Att, to obtain text and visual representations. However, only ViT-BERTweet-Att outperforms all text-and image-only models <ref type="bibr">(77.50, 78.46, 77.61 weighted F1, precision, and recall)</ref>, indicating that not only the choice of text and image encoders is important, but so is the fusion strategy for effectively modeling text-image relationships for identifying influencer commercial content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Ablation Study</head><p>To analyze the contribution of each component of our ViT-BERTweet-Att in identifying commercial posts, Table <ref type="table" target="#tab_6">5</ref> shows the performance of ViT, BERTweet, and ViT-BERTweet-Att with and without the Cross-Att layer (see Sec. 4). ViT-BERTweet-Att without the Cross-Att layer consists of simply concatenating text and image vectors (ViT-BERTweet-Concat). While the performance of BERTweet and ViT-BERTweet-Concat are comparable (BERTweet and ViT-BERTweet-Concat weighted F1: 76.34), ViT-BERTweet-Att (weighted F1: 77.50) outperforms BERTweet suggesting the Cross-Att layer successfully captures the relevant regions in images for identifying commercial posts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Text-only Test Set Evaluation</head><p>Finally, previous work on text-image classification in commercial influencer content has only experimented with fully paired data where every post contains an image and text <ref type="bibr">(Kim et al., 2021b)</ref>. However, this requirement may not always hold since not all posts contain both modalities. Thus, we further evaluate our models on our text-only test set (see Sec. 3.3). Table <ref type="table" target="#tab_7">6</ref> shows the results obtained. We observe a consistent improvement of ViT-BERTweet-Att multimodal model over BERTweet text-only model, i.e., 88.69 versus 87.50. This suggests that multimodal modeling of influencer posts is beneficial for identifying textonly commercial posts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Qualitative Analysis</head><p>We finally perform a qualitative analysis of the classification effectiveness between ViT-BERTweet-Att and the best text-only model <ref type="bibr">(BERTweet)</ref>. We analyze the strengths and limitations of each model.</p><p>Multimodal modeling helps to reduce the number of false positives. We find that 53% of BERTweet errors from the text-image test set are false positives, i.e., misclassifying non-commercial posts as commercial, which would be problematic for an automated regulatory compliance system. Our multimodal model, ViT-BERTweet-Att, on the other hand, correctly classifies 38% of BERTweet's false positive mistakes such as the non-commercial post in Figure <ref type="figure" target="#fig_0">1</ref>. Similarly, for text-only posts, we observe that 69% of BERTweet missclassifications correspond to false positive errors. 50.9% of these posts are correctly classified by ViT-BERTweet-Att.</p><p>Multimodal modeling errors. The most common error when distinguishing commercial posts (60%) by our multimodal model, ViT-BERTweet-Att, corresponds to cases where the post includes a standard natural or personal photo, rather than an image depicting products, as is more common in influencer commercial content <ref type="bibr">(Kim et al., 2021b)</ref> and conventional online advertising (Al-Subhi, 2022). Figure <ref type="figure" target="#fig_7">2</ref>  Challenging cases for text and multimodal models. We observe cases that remain challenging for both multimodal and text-only models. Previous work in influencer commercial content on Instagram <ref type="bibr" target="#b68">(Zarei et al., 2020)</ref> highlights the difficulty of identifying commercial influencer posts promoting products given the use of native advertising <ref type="bibr" target="#b8">(Chia, 2012)</ref>. However, we find that the most common error (20%) when identifying commercial posts (in both text-image and text-only posts), are those that rather than promoting products, they describe their "personal" experiences, particularly while traveling, in both text and image as shown in Figure <ref type="figure" target="#fig_7">2</ref> Post C. These commercial posts are difficult to identify as they do not include any specific brand mention or product name and are accompanied by standard traveling images also common in non-commercial posts <ref type="bibr" target="#b50">(Oliveira et al., 2020)</ref>. 14 Using the text before removing commercial keywords. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We introduced a novel dataset of multimodal influencer content consisting of tweets labeled as commercial or non-commercial. This is the first dataset to include high quality annotated posts by experts in advertising regulation. We conducted an extensive empirical study including vision, language and multimodal approaches as well as LLM prompting. Our results show that our proposed cross-attention approach to combine text and images, outperforms state-of-the-art multimodal models. Our new dataset can enable further studies on automatically detecting influencer hidden advertising as well as studies in computational linguistics <ref type="bibr" target="#b58">(Sim et al., 2016;</ref><ref type="bibr" target="#b56">Sánchez Villegas et al., 2020;</ref><ref type="bibr" target="#b47">Mu and Aletras, 2020;</ref><ref type="bibr" target="#b28">Jin et al., 2022;</ref><ref type="bibr" target="#b3">Ao et al., 2022)</ref> for analysis of commercial language characteristics on a large scale. Future work includes modeling influencer content in multilingual settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>We experimented using only data in English. Influencer advertising strategies could differ across cultures and languages. We plan to address this research direction in future work. We have also presented the main limitations of our best performing model in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics Statement</head><p>Our work complies with Twitter data policy for research.</p><p><ref type="foot" target="#foot_10">15</ref> Tweets were retrieved in August 2021.</p><p>We received approval from our University Research Ethics Committee.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Influencer Marketing Keywords</head><p>We extract keywords strongly associated with influencer marketing from the guidelines provided by the Federal Trade Commission (FTC, 2019) in the US, and the Advertisements Standards Authority and Competition and Markets Authority in the UK (CMA, 2020). The keywords in these guidelines are based on regulatory standards for digital enforcement which are meant to create objective and transparent expectations regarding the disclosure of native advertising on social media. Thus, our list of keywords include sponsorship disclosure terms that are relevant to different business models (i.e., market practices based on the obligations of the parties). A complete list of keywords is presented in Table <ref type="table">7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Annotation Guidelines</head><p>Purpose of the study This annotation effort is part of a study that aims to characterize and identify commercial content on Twitter. Commercial content is an umbrella term for communications that relate to commercial transactions, or in other words, content that is monetized. For influencers, that may entail various business models:</p><p>• Endorsements: an influencer receives money in order to promote a product or service.</p><p>• Affiliate marketing: the influencer is paid a percentage of referral sales, often identified through discount codes.</p><p>• Barter: exchange of goods or services from a brand or its representatives against an advertising service offered by the influencer.</p><p>• Direct selling: influencers can also choose to create their own products, branded products, and/or services, and link to their web shops.</p><p>Task Description The task is to annotate whether a given influencer's Twitter post is perceived to contain commercial content or not given only its text and image content (if available). If annotators perceive that the tweet contains commercial content, then it should be annotated as commercial, otherwise as non-commercial. If it is not clear whether the Tweet is perceived to contain commercial content, it should be labeled as unclear.</p><p>The details of each category are as follows:</p><p>• Commercial: posts refer to any of the business models mentioned above. This category includes promoting or endorsing a brand or its products/services, a free loan of a product/service, a free product/service (whether requested or received out of the blue), or any other incentive. This can be noted by the use of terms or hashtags such as #gifted, #ad, @mentions of the brand, hashtags including the name of the brand and/or campaign slogans.</p><p>• Non-Commercial: Organic content such as personal ideas, personal comments and life updates, and that does not seem monetized through any of the business models mentioned above.</p><p>• Unclear: This option should be chosen when it is not clear whether the Tweet contains commercial content or not (e.g., commenting about a brand without using hashtags or @mentioning the brand).</p><p>Instructions 1. For each post, read the text, look at the image (if available), and select one of the categories (Commercial, Non-commercial, Unclear).</p><p>2. If the post is annotated as Commercial, then in the "Brand Cues" section write down the term(s) or hashtag(s) that support your decision such as: #gifted, #ad, @mentions, hashtags including the name of the brand and/or campaign slogans. Use the "Brand Cues" column that corresponds to the location of them: "Brand Cues Text" if the brand cues are found in the text and/or "Brand Cues Image" if they are located in the image. Select the option(s) (Text, Image) used to make your annotation (e.g., if the brand cues are in the text then select Text, if the post was annotated as noncommercial choose the option that you looked at to make your decision).</p><p>3. If the post was annotated as Unclear, then: select the "Other" option and click on the Tweet Link. If you find any brand cues in the Tweet's page, write them down in the column "Brand cues Other". If it is still unclear whether the Tweet is commercial or not keep the label "Unclear", otherwise select the appropriate label (Commercial/Non-Commercial).</p><p>#ad, ad, #advert #collab, collab, #spon, #sponsored, spon, #sp, sponsored, 'thanks to'/ 'funded by'/ 'supported by'/'in association with' @USER Endoresements An influencer receives money to promote a product or service. #ambassador, ambassador Barter Exchange of goods or services from a brand or its representatives against an advertising service offered by the influencer.</p><p>#gift, gift, #giveaway, giveaway unpaid sample</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Affiliate Marketing</head><p>The influencer is paid a percentage of referral sales, often identified through discount codes.</p><p>#aff, aff, #affiliate, affiliate, discount code</p><p>Table <ref type="table">7</ref>: Commercial keywords. @USER refers to an @-mention of a brand account. Annotator Details All annotators were senior law school students (third year bachelor and masters level) who study comparative and international law. The students have a background in law, which entails a good grasp of consumer protection disclosures. In addition, their profiles were also particularly interesting for annotation since they had spent 6 months of their study being trained under an extracurricular Influencer Law Clinic honors programme. The training consisted in multidisciplinary workshops and hands-on research on influencer-related legal topics. The annotators come from a wide range of socio-economic back-grounds and are fluent in English. The majority of annotators are female. However, the emphasis in the annotation process has been on the understanding of market practices in the light of legal frameworks, which mitigates any potential gender imbalance in the annotator pool. All annotators expressed their written consent and were informed about how data would be used following ethics guidelines from our Institution. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Predictive Performance</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Commercial and non-commercial tweets in our dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>and Cross-Att(L, I) ∈ R m L ×d k The multimodal representation vector h is obtained by concatenating the 'classification' [CLS] L token from L (output from the last layer of BERTweet), and the [CLS] Att token from the output of the cross-attention layer (Cross-Att(L, I)). In this way, we leverage the text content of the influencer posts, and the relevant information from the image content. We fine-tune the model on the commercial content classification task by adding a fully-connected layer with a softmax activation function</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>3.2) are removed from all commercial tweets. 11 Figure 4 shows a diagram of the model. Image Images are resized to (224 × 224) pixels representing a value for the red, green and blue color in [0, 255]. The pixel values are normalized to [0 -1].For LXMERT, we extract object-level features using Faster-RCNN(Ren et al., 2016)  as in<ref type="bibr" target="#b2">Anderson et al. (2018)</ref> and keep 36 objects for each image as in<ref type="bibr" target="#b59">Tan and Bansal (2019)</ref>.5.2 Most Freq. Baseline and EvaluationMost Freq. Baseline We assign the most frequent label in the training set to all instances in the test set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>δ = 0.05 before passing the image representation through the classification layer. We finetune ViT<ref type="bibr" target="#b13">(Dosovitskiy et al., 2020)</ref> for 3 epochs with learning rate η = 1e -5 and dropout δ = 0.05. η ∈ {1e-3 , 1e -4 , 1e -5 } and δ in [0, 0.5], random search.Text-only Recurrent Model For BiLSTM-Att we use 200-dimensional GloVe embeddings<ref type="bibr" target="#b51">(Pennington et al., 2014)</ref> pre-trained on Twitter data. The maximum sequence length is set to 50. The LSTM size is h = 32 where h ∈ {32, 64, 100} with dropout δ = 0.3 where δ ∈ [0, 0.5], random search.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>ViT-BERTweet-Att We train Aspect-Attention and ViT-BERTweet-Att with BERTweet as text encoder and ViT as image encoder for 15 epochs and choose the epoch with the lowest validation loss. Aspect-Attention: 1 epoch with η = 1e -5 and δ = 0.05 and ViT-BERTweet-Att 3 epochs with η = 1e -5 and δ = 0.05 ; The dimensionality of the multimodal representation is 768. η ∈ {1e</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Post A depicts a post incorrectly labeled as non-commercial by ViT-BERTweet-Att and correclty classified by BERTweet. Multimodal modeling captures context beyond keyword-matching. To analyze if multimodal modeling improves over weak labels, we apply the keyword-based weak labeling approach 14 to the test sets (see Sec. 3.2). We find that 20% and 80% of the weak labeling errors in the text-image and the text-only test sets respectively, are correctly classified by ViT-BERTweet-Att. This suggests that our multimodal model, ViT-BERTweet-Att captures stylistic differences and visual information relevant to identify commercial posts beyond keywordmatching. Indeed, most of the errors (85%) in both text-image and text-only posts are false positives (i.e., true label is non-commercial) and are misslabeled as commercial as they contain one of the keywords, although they are used in a different context. For example: Just seen that Pepsi ad...awkward. Multimodal modeling aids in the discovery of undisclosed commercial posts Using ViT-BERTweet-Att we found undisclosed commercial posts (15%) in text-image posts such as the one depicted in Figure 1 (commercial) and Figure 2 Post B, as well as in text-only posts such as the next example: if you love @USER pro-collagen then you might like the new ultra smart line.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Examples of classifications of BERTweet and ViT-BERTweet-Att.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Figure 3: Example of Annotation</figDesc><graphic coords="15,75.94,479.01,443.41,63.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>A comparison of existing datasets for influencer content analysis</figDesc><table><row><cell>Platform</cell><cell>Modality</cell><cell>Time Range</cell><cell>Domains</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Dataset statistics showing the number of tweets for each split.</figDesc><table><row><cell>9 Four</cell></row></table><note><p>test sets (text-image and text-only test sets). and run a calibration round on a random set of 20 examples. All tweets in the test sets were labeled by two different annotators as commercial, noncommercial, or unclear (i.e., it is not clear whether the post contains commercial content or not). In cases of disagreement, a third independent annotator assigned the final label (commercial or noncommercial) after adjudication. Posts labeled as unclear (15) are removed, as well as posts written in other language than English (2).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>denotes current state-of-theart models for influencer commercial content detection. Subscripts denote standard deviations. Best results are in bold.</figDesc><table><row><cell>Model</cell><cell>F1</cell><cell>P</cell><cell></cell><cell>R</cell></row><row><cell>Most Freq.</cell><cell cols="4">31.15 0.0 23.05 0.0 48.01 0.0</cell></row><row><cell>Prompting</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Flan-T5 (zero-shot)</cell><cell cols="4">42.98 0.0 72.01 0.0 53.51 0.0</cell></row><row><cell>Flan-T5 (few-shot)</cell><cell cols="4">48.70 1.6 62.07 0.9 53.47 0.6</cell></row><row><cell>GPT-3 (zero-shot)</cell><cell cols="4">63.91 0.0 65.64 0.0 64.81 0.0</cell></row><row><cell>GPT-3 (few-shot)</cell><cell cols="4">69.57 1.5 71.69 2.1 70.01 0.8</cell></row><row><cell>Image-only</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ResNet</cell><cell cols="4">59.59 0.5 59.85 0.5 59.60 0.5</cell></row><row><cell>ViT</cell><cell cols="4">60.81 1.3 61.58 0.9 61.02 1.2</cell></row><row><cell>Text-only</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">BiLSTM-Att  *  (Zarei et al., 2020) 66.10 0.7 66.48 0.8 65.15 0.7</cell></row><row><cell>BERT</cell><cell cols="4">74.32 0.6 75.01 0.6 74.43 0.7</cell></row><row><cell>BERTweet</cell><cell cols="4">76.34 0.3 76.80 0.3 76.45 0.3</cell></row><row><cell>Text &amp; Image</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ViLT</cell><cell cols="4">68.46 0.9 66.66 3.8 66.66 3.8</cell></row><row><cell>LXMERT</cell><cell cols="4">70.64 0.4 71.00 0.3 70.68 0.4</cell></row><row><cell>MMBT</cell><cell cols="4">73.58 0.4 73.79 0.6 73.59 0.4</cell></row><row><cell>Aspect-Att  *  (Kim et al., 2021b)</cell><cell cols="4">75.45 0.8 77.42 1.1 75.68 0.7</cell></row><row><cell>ViT-BERTweet-Att (Ours)</cell><cell>77.50  ‡ 0.6</cell><cell>78.46</cell><cell>† 0.5</cell><cell>‡ 77.61 0.6</cell></row><row><cell cols="5">Table 4: Weighted F1-Score, precision (P) and recall</cell></row><row><cell cols="5">(R) for commercial influencer content prediction.  † and</cell></row><row><cell cols="5">‡ indicates statistically significant improvement (t-test,</cell></row><row><cell cols="5">p &lt; 0.05) over BERTweet, and both BERTweet and</cell></row><row><cell>Aspect-Att respectively.  Model</cell><cell>F1</cell><cell>P</cell><cell></cell><cell>R</cell></row><row><cell>BERTweet</cell><cell>76.34 0.3</cell><cell cols="2">76.80 0.3</cell><cell>76.45 0.3</cell></row><row><cell>ViT</cell><cell>60.81 1.3</cell><cell cols="2">61.58 0.9</cell><cell>61.02 1.2</cell></row><row><cell>ViT-BERTweet-Concat</cell><cell>76.34 0.9</cell><cell cols="2">78.10 0.5</cell><cell>76.54 0.8</cell></row><row><cell>ViT-BERTweet-Att (Ours)</cell><cell>77.50 0.6</cell><cell cols="3">78.46 0.5 77.61 0.6</cell></row></table><note><p>* Comparison of each of the ViT-BERTweet-Att components including the removal of the Cross-Att layer (ViT-BERTweet-Concat). Subscripts denote standard deviations. Best results are in bold.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Flan-T5 (zero-shot) 81.02 0.0 80.41 0.0 84.88 0.0 Flan-T5 (few-shot) 82.22 0.5 81.72 0.6 83.56 0.6 GPT-3 (zero-shot) 77.26 0.0 85.12 0.0 73.79 0.0 GPT-3 (few-shot) 84.03 3.0 85.55 1.1 83.68 4.8 BERTweet 87.50 1.0 88.58 0.4 86.84 1.3 ViT-BERTweet-Att (Ours) 88.69 0.2 88.69 0.2 88.93 0.5 Weighted F1-Score, precision (P) and recall (R) for commercial influencer content prediction for tweets containing text only. Subscripts denote standard deviations. Best results are in bold.</figDesc><table><row><cell>Model</cell><cell>F1</cell><cell>P</cell><cell>R</cell></row><row><cell>Most Freq.</cell><cell cols="3">78.55 0.0 72.78 0.0 85.31 0.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 9 and</head><label>9</label><figDesc>Table 10 present the macro-averaged results of commercial content prediction.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>https://icas.global/advertising-self-regulat ion/influencer-guidelines/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>Only about 10% of affiliate marketing content on Pinterest and YouTube contains any disclosures<ref type="bibr" target="#b45">(Mathur et al., 2018)</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>https://blog.twitter.com/en_us/a/2016/new-r esearch-the-value-of-influencers-on-twitter</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>https://influencermarketinghub.com/influence r-marketing-benchmark-report-2021/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>Influencer accounts were manually validated to ensure bots are not included.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5"><p>https://developer.twitter.com/en/products/tw itter-api</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_6"><p>Note that while text-only tweets are prevalent on Twitter, image-only tweets are uncommon.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_7"><p>We received approval from the Ethics Committee of our institution. Annotation guidelines can be found in Appx. B.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_8"><p>Macro-averaged results are included in Appx. C.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_9"><p>https://platform.openai.com/docs/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_10"><p>See: https://developer.twitter.com/en/develop er-terms/agreement-and-policy</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments DSV and NA are supported by the <rs type="funder">Leverhulme Trust</rs> under Grant Number: RPG#<rs type="grantNumber">2020</rs>#<rs type="grantNumber">148</rs>. NA is also supported by <rs type="funder">ESRC</rs> (<rs type="grantNumber">ES/T012714/1</rs>). DSV is also supported by the <rs type="institution">Centre for Doctoral Training in Speech and Language Technologies (SLT)</rs> and their Applications funded by the <rs type="funder">UK Research and Innovation</rs> grant <rs type="grantNumber">EP/S023062/1</rs>. CG is supported by the <rs type="funder">ERC</rs> <rs type="grantName">Starting Grant</rs> research project <rs type="projectName">HUMANads</rs> (<rs type="grantNumber">ERC-2021-StG No 101041824</rs>) and the Spinoza grant of the <rs type="funder">Dutch Research Council (NWO)</rs>, awarded in 2021 to <rs type="person">José van Dijck</rs>, <rs type="person">Professor of Media</rs> and <rs type="institution">Digital Society at Utrecht University</rs>.</p><p>We would also like to thank the members of the Competition and Markets Authority in the UK who contributed to the enhancement of the list of terms for our initial keyword-based strategy (refer to Section 3.2). Additionally, we extend our gratitude to the annotators who actively participated in our human annotation labeling task. We would like to thank <rs type="person">Mali Jin</rs>, <rs type="person">Yida Mu</rs>, <rs type="person">Katerina Margatina</rs>, <rs type="person">Constantinos Karouzos</rs>, <rs type="person">Panayiotis Karachristou</rs> and all reviewers for their valuable feedback.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_DnUqBFK">
					<idno type="grant-number">2020</idno>
				</org>
				<org type="funding" xml:id="_SHQmhF7">
					<idno type="grant-number">148</idno>
				</org>
				<org type="funding" xml:id="_RPBgATD">
					<idno type="grant-number">ES/T012714/1</idno>
				</org>
				<org type="funding" xml:id="_hqWmPAE">
					<idno type="grant-number">EP/S023062/1</idno>
				</org>
				<org type="funded-project" xml:id="_yhd3PcW">
					<idno type="grant-number">ERC-2021-StG No 101041824</idno>
					<orgName type="grant-name">Starting Grant</orgName>
					<orgName type="project" subtype="full">HUMANads</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For zero-shot prompting we use the following prompt:</p><p>Label the next text as 'commercial' or 'not commercial'. Text: &lt;TWEET&gt;.</p><p>We map responses to the corresponding commercial or non-commercial class and report results for each model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Few-shot Prompting</head><p>We experiment with few-shot prompting by appending four randomly selected training examples (two examples from each class) before each prompt. We run this three times with a different set examples.    &lt;Label-TRAIN&gt; corresponds to the true label of the &lt;TWEET-TRAIN&gt; training example (commercial or non-commercial), &lt;TWEET&gt; refers to a testing example. We remove punctuation and spaces and map the output of each model (FLAN-T5 or GPT-3) to the corresponding label (commercial or noncommercial).</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Metadiscourse in online advertising: Exploring linguistic and visual metadiscourse in social media advertisements</title>
		<author>
			<persName><forename type="first">Aisha</forename><surname>Saadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Al-Subhi</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Pragmatics</title>
		<imprint>
			<biblScope unit="volume">187</biblScope>
			<biblScope unit="page" from="24" to="40" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Product placements by micro and macro influencers on instagram</title>
		<author>
			<persName><forename type="first">Rachidatou</forename><surname>Alassani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julia</forename><surname>Göretz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on humancomputer interaction</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="251" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Bottom-up and top-down attention for image captioning and visual question answering</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Buehler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Damien</forename><surname>Teney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="6077" to="6086" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Combining humor and sarcasm for improving political parody detection</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Ao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danae</forename><forename type="middle">Sanchez</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Preotiuc-Pietro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolaos</forename><surname>Aletras</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.naacl-main.131</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Seattle, United States. Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1800" to="1807" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Inter-coder agreement for computational linguistics</title>
		<author>
			<persName><forename type="first">Ron</forename><surname>Artstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="555" to="596" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Informing consumers about &quot;hidden&quot; advertising: A literature review of the effects of disclosing sponsored content</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sophie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eva</forename><forename type="middle">A</forename><surname>Boerman</surname></persName>
		</author>
		<author>
			<persName><surname>Van Reijmersdal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advertising in new formats and media</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Duncan</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Hayes</surname></persName>
		</author>
		<title level="m">Influencer marketing</title>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Welcome to me-mart: The politics of user-generated content in personal blogs</title>
		<author>
			<persName><forename type="first">Aleena</forename><surname>Chia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Behavioral Scientist</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="421" to="438" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Scaling instruction-finetuned language models</title>
		<author>
			<persName><forename type="first">Chung</forename><surname>Hyung Won</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shayne</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddhartha</forename><surname>Brahma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.11416</idno>
		<ptr target="https://www.ftc.gov/system/files/documents/plain-language/1001a-influencer-guide-508_1.pdf" />
		<imprint>
			<date type="published" when="2020">2022. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Competition and Markets Authority CMA. Influencers&apos; guide to making clear that ads are ads</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">A coefficient of agreement for nominal scales. Educational and psychological measurement</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1960">1960</date>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="37" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">Giovanni</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregorio</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Catalina</forename><surname>Goanta</surname></persName>
		</author>
		<title level="m">The influencer republic: Monetizing political speech on social media. Available at SSRN</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11929</idno>
		<title level="m">An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">One hashtag to rule them all? mandated disclosures and design duties in influencer marketing practices</title>
		<author>
			<persName><forename type="first">Rossana</forename><surname>Ducato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Regulation of Social Media Influencers</title>
		<imprint>
			<publisher>Edward Elgar Publishing</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The effects of influencer advertising disclosure regulations: Evidence from instagram</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ershov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st ACM Conference on Economics and Computation</title>
		<meeting>the 21st ACM Conference on Economics and Computation</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="73" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Disclosing instagram influencer advertising: The effects of disclosure language on advertising recognition, attitudes, and behavioral intent</title>
		<author>
			<persName><forename type="first">Nathaniel</forename><forename type="middle">J</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Phua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyoyeun</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of interactive advertising</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="138" to="149" />
			<date type="published" when="2017-06">Jun. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Using natural language processing to identify effective influencers</title>
		<author>
			<persName><forename type="first">Xing</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianfu</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Market Research</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="611" to="629" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Influencers analysis from social media data</title>
		<author>
			<persName><forename type="first">Roshan</forename><surname>Fernandes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anisha</forename><forename type="middle">P</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhuvaneshwari</forename><surname>Shetty</surname></persName>
		</author>
		<idno type="DOI">10.1109/AIDE57180.2022.10059732</idno>
	</analytic>
	<monogr>
		<title level="m">2022 International Conference on Artificial Intelligence and Data Engineering (AIDE)</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="217" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Federal Trade Commission FTC</title>
		<ptr target="https://www.ftc.gov/system/files/documents/plain-language/1001a-influencer-guide-508_1.pdf" />
	</analytic>
	<monogr>
		<title level="m">Disclosures 101 for social media influencers</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">i need to try this&quot;? a statistical overview of pinterest</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saeideh</forename><surname>Bakhshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuo</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Loren</forename><surname>Terveen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on human factors in computing systems</title>
		<meeting>the SIGCHI conference on human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2427" to="2436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The big four of influencer marketing. a typology of influencers</title>
		<author>
			<persName><forename type="first">Jana</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><forename type="middle">V</forename><surname>Wangenheim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Review St. Gallen</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="30" to="38" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fitnet: Identifying fashion influencers on twitter</title>
		<author>
			<persName><forename type="first">Jinda</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinglin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xilun</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weikai</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanxian</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suhansanu</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hari</forename><surname>Sundaram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ranjitha</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="DOI">10.1145/3449227</idno>
	</analytic>
	<monogr>
		<title level="j">Proc. ACM Hum.-Comput. Interact</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Does my multimodal model learn cross-modal interactions? it&apos;s harder to tell than you might think</title>
		<author>
			<persName><forename type="first">Jack</forename><surname>Hessel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.62</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="861" to="877" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A cross-sectional examination of marketing of electronic cigarettes on twitter</title>
		<author>
			<persName><forename type="first">Jidong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Kornfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Glen</forename><surname>Szczypka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherry</forename><forename type="middle">L</forename><surname>Emery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tobacco control</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="26" to="30" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>suppl 3</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Yosra</forename><surname>Jarrar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayodeji</forename><surname>Olalekan Awobamise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adebola</forename><surname>Adewunmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aderibigbe</forename></persName>
		</author>
		<title level="m">Effectiveness of influencer marketing vs social media sponsored advertising. Utopia y Praxis Latinoamericana</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="40" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Automatic identification and classification of bragging in social media</title>
		<author>
			<persName><forename type="first">Mali</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Preotiuc-Pietro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Seza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolaos</forename><surname>Dogruöz</surname></persName>
		</author>
		<author>
			<persName><surname>Aletras</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.273</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3945" to="3959" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">When less is more: the impact of macro and micro social media influencers&apos; disclosure</title>
		<author>
			<persName><forename type="first">Samantha</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rory</forename><surname>Mulcahy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joy</forename><surname>Parkinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Marketing Management</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="248" to="278" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">The influentials: One American in ten tells the other nine how to vote, where to eat, and what to buy</title>
		<author>
			<persName><forename type="first">Edward</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berry</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Simon and Schuster</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suvrat</forename><surname>Bhooshan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamed</forename><surname>Firooz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Davide</forename><surname>Testuggine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.02950</idno>
		<title level="m">Supervised multimodal bitransformers for classifying images and text</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">2021a. Evaluating audience loyalty and authenticity in influencer marketing via multi-task multi-relational learning</title>
		<author>
			<persName><forename type="first">Seungbae</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiusi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jyun-Yu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinyoung</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International AAAI Conference on Web and Social Media</title>
		<meeting>the International AAAI Conference on Web and Social Media</meeting>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="278" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">How are social influencers connected in instagram</title>
		<author>
			<persName><forename type="first">Seungbae</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinyoung</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seunghyun</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Gerla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Social Informatics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="257" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multimodal post attentive profiling for influencer marketing</title>
		<author>
			<persName><forename type="first">Seungbae</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jyun-Yu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masaki</forename><surname>Nakada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinyoung</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Web Conference 2020</title>
		<meeting>The Web Conference 2020</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2878" to="2884" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Discovering undisclosed paid partnership on social media via aspect-attentive sponsored post learning</title>
		<author>
			<persName><forename type="first">Seungbae</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jyun-Yu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM International Conference on Web Search and Data Mining</title>
		<meeting>the 14th ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="319" to="327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">2021c. Vilt: Vision-and-language transformer without convolution or region supervision</title>
		<author>
			<persName><forename type="first">Wonjae</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bokyung</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ildoo</forename><surname>Kim</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<biblScope unit="page" from="5583" to="5594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Logistic regression in rare events data</title>
		<author>
			<persName><forename type="first">Gary</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Langche</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Political analysis</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="163" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Algorithms for online influencer marketing</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Lagrée</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Cappé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bogdan</forename><surname>Cautis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silviu</forename><surname>Maniu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Knowledge Discovery from Data (TKDD)</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Why are consumers following social media influencers on instagram? exploration of consumers&apos; motives for following influencers and the role of materialism</title>
		<author>
			<persName><forename type="first">Jung</forename><surname>Ah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Sabitha</forename><surname>Sudarshan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristen</forename><forename type="middle">L</forename><surname>Sussman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><forename type="middle">F</forename><surname>Bright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">S</forename><surname>Eastin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Advertising</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="78" to="100" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Platform ad archives: promises and pitfalls</title>
		<author>
			<persName><forename type="first">Paddy</forename><surname>Leerssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jef</forename><surname>Ausloos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brahim</forename><surname>Zarouali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natali</forename><surname>Helberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claes</forename><forename type="middle">H</forename><surname>De Vreese</surname></persName>
		</author>
		<idno type="DOI">10.14763/2019.4.1421</idno>
	</analytic>
	<monogr>
		<title level="j">Internet Policy Review</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Investigating consumer engagement with influencervs. brand-promoted ads: The roles of source and disclosure</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sang-Sang</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyu</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Interactive Advertising</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="169" to="186" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks</title>
		<author>
			<persName><forename type="first">Jiasen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">On the (in)effectiveness of images for text classification</title>
		<author>
			<persName><forename type="first">Chunpeng</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aili</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiyori</forename><surname>Yoshikawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomoya</forename><surname>Iwakura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.eacl-main.4</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="42" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Endorsements on social media: An empirical study of affiliate marketing disclosures on youtube and pinterest</title>
		<author>
			<persName><forename type="first">Arunesh</forename><surname>Mathur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marshini</forename><surname>Chetty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Multimodal popularity prediction of brand-related social media posts</title>
		<author>
			<persName><forename type="first">Masoud</forename><surname>Mazloom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Rietveld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stevan</forename><surname>Rudinac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcel</forename><surname>Worring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Willemijn</forename><surname>Van Dolen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM international conference on Multimedia</title>
		<meeting>the 24th ACM international conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="197" to="201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Identifying twitter users who repost unreliable news sources with linguistic information</title>
		<author>
			<persName><forename type="first">Yida</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolaos</forename><surname>Aletras</surname></persName>
		</author>
		<idno type="DOI">10.7717/peerj-cs.325</idno>
	</analytic>
	<monogr>
		<title level="j">PeerJ Computer Science</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">325</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Impact of influencers from instagram and youtube on their followers</title>
		<author>
			<persName><forename type="first">Vaibhavi</forename><surname>Nandagiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leena</forename><surname>Philip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Multidisciplinary Research and Modern Education</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="65" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">BERTweet: A pre-trained language model for English tweets</title>
		<author>
			<persName><forename type="first">Thanh</forename><surname>Dat Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anh</forename><forename type="middle">Tuan</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName><surname>Nguyen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-demos.2</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Why do people share their travel experiences on social media?</title>
		<author>
			<persName><forename type="first">Tiago</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benedita</forename><surname>Araujo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Tam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tourism Management</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page">104041</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/D14-1162</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Faster R-CNN: towards real-time object detection with region proposal networks</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1137" to="1149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Point-of-interest type prediction using text and images</title>
		<author>
			<persName><forename type="first">Danae</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Sánchez</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolaos</forename><surname>Aletras</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.614</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Dominican Republic. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="7785" to="7797" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Analyzing online political advertisements</title>
		<author>
			<persName><forename type="first">Danae Sánchez</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saeid</forename><surname>Mokaram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolaos</forename><surname>Aletras</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-acl.321</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3669" to="3680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Point-of-interest type inference from social media text</title>
		<author>
			<persName><forename type="first">Danae Sánchez</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Preotiuc-Pietro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolaos</forename><surname>Aletras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing</title>
		<meeting>the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing<address><addrLine>Suzhou, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="804" to="810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">DLATK: Differential language analysis ToolKit</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Andrew</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salvatore</forename><surname>Giorgi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Crutchley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lyle</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Eichstaedt</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-2010</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Friends with motives: Using text to infer influence on SCOTUS</title>
		<author>
			<persName><forename type="first">Yanchuan</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Routledge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D16-1178</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1724" to="1733" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">LXMERT: Learning cross-modality encoder representations from transformers</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1514</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5100" to="5111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Categorizing and inferring the relationship between the text and image of Twitter posts</title>
		<author>
			<persName><forename type="first">Alakananda</forename><surname>Vempala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Preoţiuc-Pietro</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1272</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2830" to="2840" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Cross-media keyphrase prediction: A unified framework with multi-modality multi-head attention and image wordings</title>
		<author>
			<persName><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irwin</forename><surname>King</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.268</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3311" to="3324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">it&apos;s a kind of art!&quot;: Understanding food influencers as influential content creators</title>
		<author>
			<persName><forename type="first">Philip</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Ludwig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabrina</forename><surname>Brodesser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><surname>Grönewald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2021 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Native advertising: Engagement, deception, and implications for theory. The new advertising: Branding, content and consumer relationships in a data-driven social media era</title>
		<author>
			<persName><forename type="first">W</forename><surname>Bartosz</surname></persName>
		</author>
		<author>
			<persName><surname>Wojdynski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="203" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Measuring sponsorship transparency in the age of native advertising</title>
		<author>
			<persName><forename type="first">Nathaniel</forename><forename type="middle">J</forename><surname>Bartosz W Wojdynski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariea</forename><forename type="middle">Grubbs</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><surname>Hoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Consumer Affairs</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="115" to="137" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Huggingface&apos;s transformers: State-of-the-art natural language processing</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rémi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.03771</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">How do influencers mention brands in social media? sponsorship prediction of instagram posts</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seungbae</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining</title>
		<meeting>the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="101" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Characterising and detecting sponsored influencer posts on instagram</title>
		<author>
			<persName><forename type="first">Koosha</forename><surname>Zarei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Damilola</forename><surname>Ibosiola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reza</forename><surname>Farahbakhsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zafar</forename><surname>Gilani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kiran</forename><surname>Garimella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noël</forename><surname>Crespi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gareth</forename><surname>Tyson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="327" to="331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Unified Vision-Language Pre-Training for Image Captioning and VQA</title>
		<author>
			<persName><forename type="first">Luowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Palangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Houdong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Corso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v34i07.7005</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="13041" to="13049" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
