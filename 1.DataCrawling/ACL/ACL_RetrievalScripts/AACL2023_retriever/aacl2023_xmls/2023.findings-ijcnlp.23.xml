<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Template Filling for Controllable Commonsense Reasoning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Dheeraj</forename><surname>Rajagopal</surname></persName>
							<email>dheeraj@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
								<address>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vivek</forename><surname>Khetan</surname></persName>
							<email>vivek.a.khetan@accenture.com</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Accenture Labs</orgName>
								<address>
									<settlement>San Francisco</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bogdan</forename><surname>Sacaleanu</surname></persName>
							<email>bogdan.e.sacaleanu@accenture.com</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Accenture Labs</orgName>
								<address>
									<settlement>San Francisco</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anatole</forename><surname>Gershman</surname></persName>
							<email>anatoleg@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
								<address>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andrew</forename><surname>Fano</surname></persName>
							<email>andrew.e.fano@accenture.com</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Accenture Labs</orgName>
								<address>
									<settlement>San Francisco</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
							<email>hovy@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
								<address>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Template Filling for Controllable Commonsense Reasoning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EE54B8424C279E3E410649D68794DDA0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-05-29T13:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large-scale sequence-to-sequence models have shown to be adept at both multiple-choice and open-domain commonsense reasoning tasks. However, the current formulations do not provide the ability to control the various attributes of the reasoning chain. To enable better controllability, we propose to study the commonsense reasoning as a template filling task (TemplateCSR) -where the language models fills reasoning templates with the given constraints as control factors. As an approach to TemplateCSR, we (i) propose a dataset of commonsense reasoning templateexpansion pairs for healthcare and well-being domain and (ii) introduce ITO, an instruction fine-tuned sequence-to-sequence model that performs commonsense reasoning across concepts in the template. Our experiments show that our approach outperforms baseline both in generation metrics and factuality metrics. We also present a detailed error analysis on our approach's ability to reliably perform template based commonsense reasoning 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Commonsense reasoning has been studied across both multiple choice <ref type="bibr" target="#b43">(Tandon et al., 2018;</ref><ref type="bibr" target="#b42">Talmor et al., 2019;</ref><ref type="bibr" target="#b28">Lv et al., 2020)</ref>, and open-ended knowledge base settings <ref type="bibr">(Lin et al., 2021a)</ref>. While multiple choice approaches require a list of answer options, open-ended KB approaches assume that the answer exists in an available knowledge base (KB). Such constraints often limit these systems' ability in practical applications where control is required (e.g. a web search query with specific conditions).</p><p>To complement the existing commonsense reasoning efforts, our work aims to enhance the commonsense reasoning capabilities of natural language processing (NLP) systems by studying template commonsense reasoning (TemplateCSR) 1 All code and data will be released publicly Input: Are people who smoke at higher risk for lung cancer ?</p><p>Output: Yes Input: People who smoke {are/aren't} at risk for {disease} because {reason}?</p><p>Output: People who smoke are at risk for lung cancer because cigarette smoke contains carcinogens that affect DNA Input: People who smoke are at {higher/lower} risk of {disease} Output: People who smoke are at higher risk of lung cancer</p><p>Commonsense QA Sample TemplateCSR</p><p>(1) Template-Expansion Pair</p><p>(2) Template-Expansion Pair</p><p>Figure 1: In this example, we show how a commonsense reasoning question can be formulated as two different template-expansion pairs, each focusing on different aspects of reasoning between the concepts smoking and lung cancer. While formulation (1) focuses on the explanation, (2) aims to understand the qualitative relationship between them.</p><p>-where reasoning is achieved by filling templates with restricted template slots, rather than selecting answers from a list of candidates or KB. TemplateCSR task is challenging as there are no available annotations and potentially multiple correct expansions for each template. Moreover, the task of designing templates with slots that satisfy arbitrary constrains and their expansion is still an open challenge. For example, for an example reasoning template People who smoke are at a risk of {disease} , a system needs to first constrain the slot to only diseases, and then use the addi-tional constraint of smoking to arrive at the right answer in the slot. In comparison to Language Model (LM) probing approaches <ref type="bibr" target="#b36">(Ribeiro et al., 2020)</ref> that test capabilities of LM that are already trained, we aim to propose a task and train a model for TemplateCSR task.</p><p>Figure <ref type="figure">1</ref> shows one such example from the healthcare and well-being domain, where we show how an existing commonsense reasoning query can be formulated as different templateexpansion pairs with control over different aspects of the reasoning. In the first expansion, the reasoning chain focuses on the relationship between smoking and cancer with the corresponding explanation (reason), while the second chain solely focuses on the qualitative relationship between the smoking and cancer.</p><p>To address the above mentioned challenges, our contributions in this paper for TemplateCSR are two-fold. First, we present a dataset of commonsense reasoning templates for the healthcare and well-being domain and their corresponding expansions that are valid completions of the template, which we define as template-expansion pairs <ref type="bibr" target="#b14">(Fass and Wilks, 1983)</ref>. The slots in the templates are open-ended and are not restricted to any particular categories and enable controlling the reasoning chain. Given the recent focus on explainable models for reasoning <ref type="bibr" target="#b46">(Wiegreffe and Marasović, 2021)</ref>, we also augment templates with an optional free-form explanation slot that explains the reasoning connection between various commonsense concepts. Our TemplateCSR dataset comprises of about 3600 unique template-expansion pairs collected from diverse sources, and we hope to enable SEQ-TO-SEQ systems to effectively learn to fill commonsense reasoning templates.</p><p>Next, we present ITO, a model that formulates the TemplateCSR challenge as a SEQ-TO-SEQ task where given a template with slots for specific concepts, the goal of the model is to produce meaningful completed sentences for the template. The concept in each slot in the template is provided via an instruction <ref type="bibr">(Wei et al., 2022a)</ref>, which indicates an abstraction of the nature of the slot. The multiple choice qualifier slot is used to model the relationship between the concepts and the explanation slot generates a free-form text explanation for the reasoning chain. Specifying each slots in free-form text enables control allowing commonsense reasoning questions to specify concepts, the qualitative relationship and the nature of explanation.</p><p>In our experiments for the TemplateCSR task, ITO outperforms baseline both in terms of generation metrics such as ROUGE and BERTSCORE, and factual correctness (factuality) metrics such as FACTCC. We also evaluate the factuality of the dataset using expert human judges and present a detailed analysis of model failures. While we still observe factual errors, our approach provides deeper understanding of the mistakes, enabling alternate ways to build commonsense reasoning systems via templates using SEQ-TO-SEQ models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dataset</head><p>For our use-case, we create dataset samples of commonsense reasoning templates related to healthcare and well-being. Incorporating NLP systems for aiding healthy lifestyle has been an active area of research in the past decade <ref type="bibr" target="#b24">(Liberato et al., 2014;</ref><ref type="bibr" target="#b12">Fadhil and Gabrielli, 2017;</ref><ref type="bibr" target="#b11">Doustmohammadian and Bazhan, 2021;</ref><ref type="bibr" target="#b2">Ahne et al., 2022)</ref>. Inspired by this line of research, we want to collect templates that describe a relation between lifestyle related commonsense concept and a corresponding health related concept. In comparison to existing datasets like commonsenseqa <ref type="bibr" target="#b42">(Talmor et al., 2019)</ref> which relies on fixed set of relationships from a knowledge-base <ref type="bibr" target="#b40">(Speer and Havasi, 2013)</ref>, we do not restrict the relationship types or number of concepts or hops, making it close to openvocabulary text. We believe that our dataset augments well with the existing commonsense reasoning datasets in the community, contributing to the diversity of the data.</p><p>Based on the efficacy assessment for NLP systems in health and lifestyle related settings <ref type="bibr" target="#b22">(Laranjo et al., 2018;</ref><ref type="bibr">Abd-alrazaq et al., 2020;</ref><ref type="bibr" target="#b17">Hoermann et al., 2017)</ref>, we designed our basic template structure. Our basic units for the TemplateCSR task is as follows:</p><p>1. concept slot : contains an abstract category of a concept. The concept's abstraction is provided in a natural language format in openvocabulary, without fixed class constraints.</p><p>In the example shown in figure <ref type="figure">2</ref>, people with habit and disease are concept slots.</p><p>2. multiple-choice qualifier slot : a word or phrase that describes the nature of the relationship between the concepts. This slot : An overview of the overall template structure for our approach. Our goal is to reason across concepts for TemplateCSR. In this example template, concept slots are people_with_habit and disease, and the multiple choice qualifier slot -higher/lower describes their relationship and an explanation reason slot aims to get a free-form text explanation for how they are related.</p><p>is typically framed as a multiple-choice slot, where the goal is to pick an option from the choices rather than replacing the text in the template slot. Figure <ref type="figure">2</ref> shows an example where the slot higher/lower is one such multiple-choice qualifier slot.</p><p>3. explanation slot : this optional field consists of a free-form explanation that explains the reasoning between concepts, typically marked as reason slot.</p><p>Towards this, we collect a set of template (x) and its corresponding expansions (y) based on this overall schema for commonsense reasoning. In the example shown in figure <ref type="figure">2</ref>, the template comprises of two concept slots, (people with habit and disease). The qualifier slot (higher/lower) specifies how one concept is connected to another concept in terms of their qualitative relationship. The template also includes an optional explanation slot that specifies in free-form text how smoking is connected to cancer. A valid output for the above-mentioned template is for instance, people who smoke are at a higher risk for lung cancer because carcinogens in smoke causes DNA damage, where people with habit is replaced by people who smoke, and the multiple choice qualifier slot higher/lower is replaced by higher, and disease slot replaced by lung cancer and finally the reason slot replaced by explanation of the qualitative relationship carcinogens in smoke causes DNA damage. In this example, we show how both the template-expansion pairs aim to uncover the relationship between smoke and lung cancer, while also providing the flexibility to additionally constrain the reasoning chain in any way.</p><p>Task Setup : To collect our dataset using crowdsourcing, we use amazon mechanical turk platform<ref type="foot" target="#foot_0">2</ref> . Each datapoint took ∼120 seconds to annotate, and we paid an average of $15 per hour. Additionally, we used a filtering step to select master annotators with an approval rate of more than 90%. All the turkers were given specific instructions to input only factual information and not opinionated statements. Specifically, the turkers were instructed to use the following sources: CDC<ref type="foot" target="#foot_1">3</ref> , WebMD<ref type="foot" target="#foot_2">4</ref> , Healthline<ref type="foot" target="#foot_3">5</ref> and Mayo Clinic<ref type="foot" target="#foot_4">6</ref> . The annotators were also instructed to give a template, and at least two corresponding sentences that matches the template. The statistics of the data are as follows: the average sentence length was about 14.57 words, with mean 2.4 slots per template. Some qualitative examples from the dataset are given in the table 1. Overall, our dataset contains about 7000 template-sentence pairs with about 3600 unique templates. Once the templates are collected, the authors post-process the data to verify each template-expansion pair for correctness and validate that we do not have any identifying information like proper names. We then create a standard 70/10/20 train/val/test split.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head><p>Early NLP systems have often relied on rulebased templatic systems <ref type="bibr" target="#b37">(Riloff, 1996;</ref><ref type="bibr" target="#b5">Brin, 1998;</ref><ref type="bibr" target="#b1">Agichtein and Gravano, 1999;</ref><ref type="bibr" target="#b7">Craven et al., 2000)</ref> due to their simplistic nature. Compared to machine learning methods, they were often rigid <ref type="bibr" target="#b50">(Yih, 1997)</ref> systems are often easy to comprehend, and lend themselves to easily incorporate domain knowledge <ref type="bibr" target="#b6">(Chiticariu et al., 2013)</ref>. Our goal is to combine the strengths of both template-based systems and recent advances in pretrained SEQ-TO-SEQ models for the task of commonsense reasoning via template expansion.</p><p>In this work, we present ITO (Instruction Fine-tuning for Template Based Commonsense Reasoning), an approach that models the TemplateCSR task as a instruction fine-tuning task inspired by the recent advances in instruction based fine-tuning <ref type="bibr">(Wei et al., 2022a)</ref>. Table <ref type="table" target="#tab_1">2</ref> shows an example of our task setup for our ITO approach. In comparison to approaches such as <ref type="bibr" target="#b10">Donahue et al. (2020)</ref>, our approach does not strictly enforce that sentences only fill missing spans of text. Rather, the expanded sentences are allowed to have additional modifications (token addition, deletion and rewrite). For instance, for the following input template -{person_at_location} has a {higher/lower} risk of {disease} because {reason_for_risk}, a valid expansion is person who lives in the city has a higher risk of depression due to noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Training</head><p>Given a template x ∈ X and its corresponding expansion y ∈ Y, we can train any sequenceto-sequence model that models p θ (y|x). Towards this, we use a pretrained sequence-to-sequence model M to estimate the filled template y for an input x. We model the conditional distribution Input (Template)</p><p>Output (Expansion)</p><p>The first blank is person_at_location.</p><p>The second blank is higher/lower. The third blank is disease.</p><p>The fourth blank is a reason_for_risk.</p><p>[MASK] has a [MASK] risk of</p><formula xml:id="formula_0">[MASK] because [MASK]</formula><p>Person who lives in a city has a higher risk of depression because of higher stress due to noise p θ (y | x) parameterized by θ as</p><formula xml:id="formula_1">p θ (y | x) = M k=1 p θ (y k | x, y 1 , .., y k-1 )</formula><p>where M is the length of y.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Inference to Decode Template Expansions</head><p>The auto-regressive factorization of SEQ-TO-SEQ p θ allows us to effectively cast the constrained decoding of filling the template as generating the sequence given the input x. For each expansion, we sample y 1 j ∼ p θ (y | x j ). Consequently, we sample y 2 j ∼ p θ (y | x j , y 1 j ), and the token generation process is repeated until we reach the end-symbol. For each symbol, the model has to decide between generating a token to replace the template slot or generate part of the template, while also ensuring the overall generated output sequence is consistent with the constraints given in the template.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we describe the experimental setup, and baselines for our approach. Since our ITO approach is agnostic to the pretrained encoderdecoder architecture type, we perform experiments on two state-of-the-art SEQ-TO-SEQ models -BART and T5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>Metrics : We use the following evaluation metrics for evaluation for the TemplateCSR task: (i) ROUGE <ref type="bibr" target="#b26">(Lin, 2004</ref>) and (ii) BERTSCORE <ref type="bibr" target="#b51">(Zhang et al., 2019)</ref>. N-gram metrics such as ROUGE are known to be limited, specifically for reasoning tasks. To mitigate this, we use BERTSCORE, which uses the similarity score between the reference and generated output using conceptual embeddings from BERT <ref type="bibr" target="#b9">(Devlin et al., 2019)</ref> model, which correlates better towards human judgements.</p><p>To perform the evaluation, we compare the generated sentence for the template against the gold annotations in the dataset. We remove the template words from the output and only compare the slot filler concepts to avoid score inflation due to copying. All the experiments were performed on a cluster of 8 NVIDIA V100 GPUs for about 32 GPU hours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Models</head><p>We follow the same experimental settings across the baseline and our approach for all the models. We initialize all the models with their pretrained weights. We use commonly used encoder-decoder architectures for our experiments -BART-BASE, BART-LARGE, T5-BASE and T5-LARGE. The model settings are given in below:</p><p>(i) BART-BASE: This pretrained encoderdecoder transformer architecture is based on <ref type="bibr" target="#b23">Lewis et al. (2020)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Baseline Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SPL TOKEN:</head><p>In this approach, we use the special token approach (SPL TOKEN) <ref type="bibr" target="#b10">(Donahue et al., 2020)</ref>, where we indicate the start and end of each template slot in the input and generate the output sentence. Table <ref type="table" target="#tab_3">4</ref> shows the baseline setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results</head><p>The results across various pretrained encoderdecoder approaches are shown in table <ref type="table" target="#tab_2">3</ref>. In this table, we see that on average, BART models perform better than T5 models on average. We hypothesize this might be an effect of their pretraining task choices and corresponding datasets. We also observe that INSTRUCTION based models outperform the SPL TOKEN based approach. For all of the models and baselines, we used the greedy decoding strategy. Across all the experiments, we found that the ITO approach outperforms SPL TOKEN approach across both ROUGE and BERTSCORE scores for all models.</p><p>7 Implementation adapted from Huggingface <ref type="bibr" target="#b47">(Wolf et al., 2020)</ref> 5 Factual Correctness Evaluation Expert Evaluation of Dataset : Since our dataset contains health related commonsense knowledge, we additionally verified our data from domain experts. In our case, we selected a subset of 100 data samples from our validation set, and we verified the factual claims by recruiting two annotators with a Doctor of Medicine (M.D.) degree<ref type="foot" target="#foot_5">8</ref> . Each expert annotator labeled either correct or incorrect for a template-expansion pair. Overall, they found an average of 70% of the samples to be factually correct with an inter-annotator agreement of 80%.</p><p>Model Output Evaluation : To assess the quality of generated output, we perform additional factuality evaluation towards our best performing models -SPL TOKEN and ITO approach using BART-LARGE. Towards this we use the FACTCC factuality metric <ref type="bibr" target="#b21">(Kryscinski et al., 2020)</ref>, which uses entailment classification to predict a binary factuality label between the source document and generated output.</p><p>Computing factuality using FACTCC metric requires an input source document; (i.e.) the gener-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Type FACTCC BART-LARGE SPL TOKEN 65.27 BART-LARGE ITO 79.88</p><p>Table <ref type="table">5</ref>: Factual consistency results. In this experiment, we show that our ITO approach outperforms the SPL TOKEN approach in terms of factuality metric FACTCC, showing its relative effectiveness ated output is compared against the source document for factual correctness. For this evaluation setup, we augmented each generated output y with a source document. Towards this, we use a large scale retrieval corpus based on <ref type="bibr" target="#b31">Nguyen et al. (2016)</ref>, and retrieve the top similar document D <ref type="bibr">(Lin et al., 2021b)</ref> to a generated template expansion. Using the (D, y) pairs, we compute the factual correctness of our best performing models. From the table 5, we observe that our ITO approach outperforms the SPL TOKEN approach for factual correctness by ∼14 points in accuracy. Additionally, we also perform human evaluation of factual correctness. For this experiment, three human judges annotated 100 unique samples for correctness -that indicates how many samples were correct from a human perspective. We used our best performing BART-BASE-ITO model for this evaluation. In this experiment, a sentence generated by the model for a given template was given to each human judge and they were asked to evaluate whether the sentence was correct, given the template. The inter-annotator agreement on sentence expansion correctness was substantial with a Fleiss' Kappa score <ref type="bibr" target="#b16">(Fleiss and Cohen, 1973)</ref> of 0.73. From our evaluation, we found that human judges rated about 69% of the sentences to be correct given a template, comparable to our FACTCC evaluation metric numbers. Both the automated and human evaluation suggests that our ITO approach has better factual consistency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Error Analysis</head><p>In this section, we analyze in detail how well language models perform template-expansion task for multihop reasoning. To understand the errors in depth, we complement our automated evaluation with manual error analysis. For this analysis, we randomly select 100 samples from the validation set predictions where the ROUGE scores were low. We observe the following categories of errors that language models exhibit. Table <ref type="table" target="#tab_5">6</ref> shows the common type of errors and a corresponding example for each type.</p><p>Error Type -Correct but not in gold (17%) :</p><p>In several cases, we observe that the output produced by the language models are correct despite not matching the gold answer. This phenomenon is evident when the input template contains multiple possible answers. While the gold answer in the example shown in Table <ref type="table" target="#tab_5">6</ref> (first row) fills the template using smoking, the model generates an answer related to kidney damage. While correct, the automated generation metrics such as ROUGE and BERTSCORE score such answers lower.</p><p>Error Type -Wrong commonsense concept (8%) : In this category of error, the model generates the wrong specification for the given slot. For instance (second row in table 6), the model mistakenly assumes person taking less medication as a socioeconomic condition. This error type gives a more nuanced understanding on which concept categories the model makes the most mistakes.</p><p>Error Type -Generic Explanation (53%): In several cases, the model resorts to generic explanation that are obvious. A generic explanation repeats the same information as the rest of sentence as an explanation, thereby not providing any new information compared to the rest of the sentence. In the example shown in Table <ref type="table" target="#tab_5">6</ref> (row 3), the explanation because of the strain of the heart is already clear from the concept chest pain. A generic explanation is often unreliable in explainable NLP systems since it does not provide any insight into the reasoning capability of the model <ref type="bibr" target="#b49">(Ye and Durrett, 2022)</ref>.</p><p>Error Type -Factually Incorrect (22%) : Factual correctness is one of the biggest challenges in NLP applications <ref type="bibr" target="#b33">(Petroni et al., 2020;</ref><ref type="bibr" target="#b32">Pagnoni et al., 2021)</ref>. The incorrect factual information is also acute for cross-domain reasoning applications as well. As shown in the example (row 4 in table 6), the model incorrectly generates that people with flu diagnosis should do exercise. Factual correctness in generation models is an active area of research and we believe that template-based approaches can provide additional insight into this phenomenon.</p><p>Overall, TemplateCSR remains a challenging  task for SEQ-TO-SEQ models, specifically on their factual correctness and we believe it opens several avenues for progress in this research direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related Work</head><p>Knowledge Bases : Knowledge Bases (KBs) have been the predominant approach to perform commonsense reasoning in the past <ref type="bibr" target="#b40">(Speer and Havasi, 2013)</ref>. Some of the prominent knowledge bases for commonsense reasoning include DBPedia <ref type="bibr" target="#b29">(Mendes et al., 2012)</ref>, YAGO <ref type="bibr" target="#b41">(Suchanek et al., 2007)</ref> and NELL <ref type="bibr" target="#b30">(Mitchell et al., 2018)</ref> or extending KBs with domain knowledge <ref type="bibr" target="#b19">(Khetan et al., 2021</ref><ref type="bibr">(Khetan et al., , 2022))</ref>. In this work, we focus on TemplateCSR using LM, which can be viewed as a complementary using KBs for commonsense.</p><p>Language Models for Reasoning: Using pretrained language models to generate knowledge has been studied for commonsense reasoning tasks. <ref type="bibr" target="#b38">(Sap et al., 2019;</ref><ref type="bibr" target="#b4">Bosselut et al., 2019;</ref><ref type="bibr" target="#b39">Shwartz et al., 2020;</ref><ref type="bibr" target="#b3">Bosselut et al., 2021)</ref>. Our work closely aligns with <ref type="bibr" target="#b4">Bosselut et al. (2019</ref><ref type="bibr" target="#b3">Bosselut et al. ( , 2021))</ref>. Compared to <ref type="bibr" target="#b4">Bosselut et al. (2019)</ref>, where our goal is to extend towards more controllable commonsense reasoning. Our work is also related to recent chain-of-thought prompting approach <ref type="bibr" target="#b8">(Dalvi et al., 2021;</ref><ref type="bibr">Wei et al., 2022b)</ref>, where a reasoning chain is first generated before the final solution. Compared to chain-of-thought prompting, our approach focuses on controllability of the reasoning process from input, via tem-plate slots using instructions, similar to <ref type="bibr">Wei et al. (2022a)</ref>.  <ref type="formula">2020</ref>) but our application differs from them in that we focus on commonsense reasoning instead of content planning for stories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion and Future Work</head><p>In this paper, we present the ITO approach that adapts language models to perform the TemplateCSR task via prompting. We collect a dataset for the same, and show that such an approach allows higher control over the reasoning process by enabling practitioners to specify the nature of the template slots. Through both automated and human metrics, we find that our ITO approach outperforms the baselines while also maintaining high factuality. For future work, we hope to extend this line of work towards other controllable generation tasks such as story generation and summarization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Limitations and Ethics Considerations</head><p>Our work only tests single sentence templateexpansion pairs. One of the limitation of our work is that we do not try on longer template sequences, which we want to explore for future work. While we present our dataset and corresponding modeling approaches, we acknowledge the limitations of the system and potential risks if it was used for real-world use-cases due to its factual errors.</p><p>While we worked diligently with the annotators, and real domain experts to ascertain the quality of the dataset, we believe that there is immense room to be potentially improved and scaled further. We also did not test our dataset efficacy in large-scale models such as GPT-3 due to budget constraints, which we consider another limitation of this work.</p><p>As our results show, common sense reasoning and its health related knowledge reasoning is far from solved and we hope this dataset starts a research direction towards addressing this reasoning challenge. In no way, we support using this system for real-world commonsense related advice. The system, dataset and the accompanying publication is intended only for research purposes and ability to test current NLP systems' capabilities.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure2: An overview of the overall template structure for our approach. Our goal is to reason across concepts for TemplateCSR. In this example template, concept slots are people_with_habit and disease, and the multiple choice qualifier slot -higher/lower describes their relationship and an explanation reason slot aims to get a free-form text explanation for how they are related.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Model Infilling : Our work also closely relates to the language model infilling work in the literature such as Fedus et al. (2018) and Donahue et al. (2020). Compared to these works which only look at cloze-test infilling, our work aims to expand templates that cannot be directly modeled as cloze-style. Our work is also related to the story generation efforts such as Yao et al. (2019); Fan et al. (2018); Ippolito et al. (2019); Rashkin et al. (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>. Despite their rigidity, template based</figDesc><table><row><cell>Concepts</cell><cell cols="2">Template Expansion Pairs</cell></row><row><cell></cell><cell>Sample Template</cell><cell>Valid Expansions for the Template</cell></row><row><cell>location, disease</cell><cell>{person_at_location} has a {higher/lower} risk of {disease} because {reason_for_risk}</cell><cell>Person who lives in a city has a higher risk -of depression because of stress due to noise Person who lives near a village has a lower risk -of respiratory illness because of lower pollution</cell></row><row><cell>prescription medication, disease</cell><cell>{person_taking_prescription} has a higher risk of {disease} due to {reason}</cell><cell>Someone on steroids have a higher risk for heart disease -because steroids compromise heart pumping People on insulin have a lower risk of hyperglycemia -because of lower glucose levels.</cell></row><row><cell></cell><cell></cell><cell>Steak should not be consumed with mashed potatoes</cell></row><row><cell>food item,</cell><cell>{food_item_1} should not</cell><cell>-because pairing fried foods increases the risk of diabetes.</cell></row><row><cell>substitute</cell><cell>be consumed with {food_item_2}</cell><cell>Pizza should not be consumed with French fries because</cell></row><row><cell>item</cell><cell>because {reason}</cell><cell>-proteins require a much different stomach</cell></row><row><cell></cell><cell></cell><cell>-environment than starches for proper digestion</cell></row><row><cell></cell><cell></cell><cell>A change in behavior such as becoming more sedentary is</cell></row><row><cell>behavior</cell><cell>A change in behavior such as</cell><cell>-often associated with obesity</cell></row><row><cell>change,</cell><cell>{behavior_change} is often</cell><cell>-because less activity leads to less calorie burning.</cell></row><row><cell>medical</cell><cell>associated with {a_medical_condition}</cell><cell>A change in behavior such as no longer drinking coffee</cell></row><row><cell>condition</cell><cell>because {reason_for_condition}</cell><cell>-is often associated with diminished insomnia</cell></row><row><cell></cell><cell></cell><cell>-because less caffeine equals improved sleep.</cell></row><row><cell>symptom, medical condition, everyday action</cell><cell>When severe symptoms like {a_symptom} for a {a_medical_condition} shows up, immediately one should perform {an_action}</cell><cell>When severe symptoms like confusion or disorientation -for heatstroke show up, immediately, one should perform -cooling actions, such as applying cooling towels. When severe symptoms like unconsciousness for a -heart attack show up, immediately one should -call 911 and perform CPR while awaiting help.</cell></row><row><cell>lifestyle activity, disease</cell><cell>People often do {an_activity} before going to bed in night to prevent risk of {disease}.</cell><cell></cell></row></table><note><p><p><p><p><p>This is because {reason_for_activity}</p>People often do reading before going to bed in night -to prevent risk of insomnia. This is because -doing some light reading helps lull you to sleep. People often do teeth brushing before going to bed in night -to prevent risk of tooth decay. This is because -brushing removes cavity-causing plaque from teeth.</p>Table</p>1</p>: Examples from our dataset. Each template has two corresponding sentences. [concept] is a concept, and [text] represents the explanation and [text] represents a qualifier. We show two sentences each for a template. Each template slot is given in free-form text without any restriction in vocabulary.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Overview of ITO approach for TemplateCSR. Each concept category is given as a instruction to the input and the slots are represented via the [MASK] token. The instruction describes each slot's abstraction and the task is to generate the output.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Overview of the results compared to baselines. The table shows that BART-BASE performs better than T5-BASE model and BART-LARGE outperforms both. Both in terms of ROUGE and BERTSCORE, we also observe that our INSTRUCTION approach outperforms SPL TOKEN approach. All experiments were done with 5 seeds, and reported are the average.</figDesc><table><row><cell>. It consists of 12 transformer</cell></row><row><cell>layers each with 768 hidden size, 16 attention</cell></row><row><cell>heads and overall with 139M params. (ii) BART-</cell></row><row><cell>LARGE: Larger version of BART-BASE, with 24</cell></row><row><cell>transformer layers, 1024 hidden size, 16 heads and</cell></row><row><cell>406M params. (iii) T5-BASE: The T5 model is</cell></row><row><cell>also a transformer encoder-decoder model based</cell></row><row><cell>on Raffel et al. (2020) with 220M parameters with</cell></row><row><cell>12-layers each with 768 hidden-state, 3072 feed-</cell></row><row><cell>forward hidden-state and 12 attention heads. (iv)</cell></row><row><cell>T5-LARGE: T5-Large model version comprises</cell></row><row><cell>of 770M parameters with 24-layers with 1024</cell></row><row><cell>hidden-state, 4096 feed-forward hidden-state and</cell></row><row><cell>16 attention heads 7 .</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Baseline Setup: We use Donahue et al. (2020) and use special tokens to indicate the start and end of each slot. The model is trained to predict the output, which is a valid expansion for the template.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Error Analysis based on the BART-BASE-ITO model. We select 100 samples from the validation set and each row shows an example of each class of error.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>https://www.mturk.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>https://www.cdc.gov/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>https://www.webmd.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>https://www.healthline.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>https://www.mayoclinic.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_5"><p>https://www.upwork.com/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mohannad Alajlani, Bridgette M. Bewick, and Mowafa Said Househ. 2020. Effectiveness and safety of using chatbots to improve mental health: Systematic review and meta-analysis</title>
		<author>
			<persName><forename type="first">Alaa</forename><forename type="middle">A</forename><surname>Abd-Alrazaq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asma</forename><surname>Rababeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Medical Internet Research</title>
		<imprint>
			<biblScope unit="page">22</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Extracting relations from large plain-text collections</title>
		<author>
			<persName><forename type="first">Eugene</forename><surname>Agichtein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gravano</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Extraction of explicit and implicit cause-effect relationships in patient-reported diabetes-related tweets from 2017 to 2021: Deep learning approach</title>
		<author>
			<persName><forename type="first">Adrian</forename><surname>Ahne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vivek</forename><surname>Khetan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Tannier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Md</forename><surname>Imbesat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hassan</forename><surname>Rizvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Czernichow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Orchard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charline</forename><surname>Bour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><forename type="middle">E</forename><surname>Fano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Fagherazzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMIR Medical Informatics</title>
		<imprint>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Dynamic neuro-symbolic knowledge graph construction for zero-shot commonsense question answering</title>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronan</forename><surname>Le Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the 35th AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Comet: Commonsense transformers for automatic knowledge graph construction</title>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannah</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaitanya</forename><surname>Malaviya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asli</forename><surname>Çelikyilmaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Extracting patterns and relations from the world wide web</title>
		<author>
			<persName><forename type="first">S</forename><surname>Brin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WebDB</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Rule-based information extraction is dead! long live rule-based information extraction systems</title>
		<author>
			<persName><forename type="first">Laura</forename><surname>Chiticariu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunyao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederick</forename><forename type="middle">R</forename><surname>Reiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="827" to="832" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning to construct knowledge bases from the world wide web</title>
		<author>
			<persName><forename type="first">M</forename><surname>Craven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Dipasquo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dayne</forename><surname>Freitag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Michael Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seán</forename><surname>Slattery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page" from="69" to="113" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Explaining answers with entailment trees</title>
		<author>
			<persName><forename type="first">Bhavana</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengnan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannah</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leighanna</forename><surname>Pipatanangkura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.585</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Dominican Republic. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="7358" to="7370" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">NAACL 2019</title>
		<imprint>
			<publisher>Minnesota. Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Enabling language models to fill in the blanks</title>
		<author>
			<persName><forename type="first">Chris</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mina</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Social marketing-based interventions to promote healthy nutrition behaviors: a systematic review protocol</title>
		<author>
			<persName><forename type="first">Azam</forename><surname>Doustmohammadian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marjan</forename><surname>Bazhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Systematic Reviews</title>
		<imprint>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Addressing challenges in promoting healthy lifestyles: the al-chatbot approach</title>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Fadhil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvia</forename><surname>Gabrielli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th EAI International Conference on Pervasive Computing Technologies for Healthcare</title>
		<meeting>the 11th EAI International Conference on Pervasive Computing Technologies for Healthcare</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Hierarchical neural story generation</title>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Dauphin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1082</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="889" to="898" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Preference semantics, iii-formedness, and metaphor</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Fass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yorick</forename><surname>Wilks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Comput. Linguistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="178" to="187" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">MaskGAN: Better text generation via filling in the</title>
		<author>
			<persName><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The equivalence of weighted kappa and the intraclass correlation coefficient as measures of reliability</title>
		<author>
			<persName><forename type="first">L</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Fleiss</surname></persName>
		</author>
		<author>
			<persName><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational and psychological measurement</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="613" to="619" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Application of synchronous text-based dialogue systems in mental health interventions: Systematic review</title>
		<author>
			<persName><forename type="first">Simon</forename><surname>Hoermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathryn</forename><forename type="middle">L</forename><surname>Mccabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">N</forename><surname>Milne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafael</forename><forename type="middle">Alejandro</forename><surname>Calvo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Medical Internet Research</title>
		<imprint>
			<biblScope unit="page">19</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unsupervised hierarchical story infilling</title>
		<author>
			<persName><forename type="first">Daphne</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douglas</forename><surname>Eck</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W19-2405</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Narrative Understanding</title>
		<meeting>the First Workshop on Narrative Understanding<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="37" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Knowledge graph anchored informationextraction for domain-specific insights</title>
		<author>
			<persName><surname>Vivek Khetan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Annervaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erin</forename><surname>Wetherley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Eneva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shubhashis</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">E</forename><surname>Fano</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2104.08936</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">MIMICause: Representation and automatic extraction of causal relation types from clinical notes</title>
		<author>
			<persName><forename type="first">Md</forename><surname>Vivek Khetan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessica</forename><surname>Imbesat Rizvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paige</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bogdan</forename><surname>Bartusiak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Sacaleanu</surname></persName>
		</author>
		<author>
			<persName><surname>Fano</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.findings-acl.63</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2022</title>
		<meeting><address><addrLine>Dublin</addrLine></address></meeting>
		<imprint>
			<publisher>Ireland. Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Evaluating the factual consistency of abstractive text summarization</title>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Kryscinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.750</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9332" to="9346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Conversational agents in healthcare: a systematic review</title>
		<author>
			<persName><forename type="first">Liliana</forename><surname>Laranjo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><forename type="middle">G</forename><surname>Dunn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huong</forename><forename type="middle">Ly</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmet</forename><forename type="middle">Baki</forename><surname>Kocaballi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessica</forename><forename type="middle">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rabia</forename><surname>Bashir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Didi</forename><surname>Surian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Blanca</forename><surname>Gallego</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Farah</forename><surname>Magrabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Annie</forename><forename type="middle">Y S</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enrico</forename><forename type="middle">W</forename><surname>Coiera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association : JAMIA</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1248" to="1258" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal ; Abdelrahman Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.703</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">Marjan Ghazvininejad,. 2020</date>
			<biblScope unit="page" from="7871" to="7880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Nutrition interventions at point-of-sale to encourage healthier food purchasing: a systematic review</title>
		<author>
			<persName><forename type="first">Selma</forename><surname>Coelho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liberato</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Stewart Bailie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julie</forename><forename type="middle">K</forename><surname>Brimblecombe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>BMC Public Health</publisher>
			<biblScope unit="volume">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Xiang Ren, and William W. Cohen. 2021a. Differentiable open-ended commonsense reasoning</title>
		<author>
			<persName><forename type="first">Haitian</forename><surname>Bill Yuchen Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhuwan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manzil</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName><surname>Zaheer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Rouge: A package for automatic evaluation of summaries</title>
		<author>
			<persName><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text summarization branches out</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Ronak Pradeep, and Rodrigo Nogueira. 2021b. Pyserini: A Python toolkit for reproducible information retrieval research with sparse and dense representations</title>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueguang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng-Chieh</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jheng-Hong</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2021)</title>
		<meeting>the 44th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2021)</meeting>
		<imprint>
			<biblScope unit="page" from="2356" to="2362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Graph-based reasoning over heterogeneous external knowledge for commonsense question answering</title>
		<author>
			<persName><forename type="first">Shangwen</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daya</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linjun</forename><surname>Shou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daxin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guihong</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Songlin</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">DBpedia: A multilingual cross-domain knowledge base</title>
		<author>
			<persName><forename type="first">Pablo</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Bizer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC&apos;12)</title>
		<meeting>the Eighth International Conference on Language Resources and Evaluation (LREC&apos;12)<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA)</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1813" to="1817" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Never-ending learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hruschka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Betteridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kisiel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mazaitis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nakashole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Platanios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Samadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Settles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wijaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saparov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Greaves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Welling</surname></persName>
		</author>
		<idno type="DOI">10.1145/3191513</idno>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="103" to="115" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Ms marco: A human generated machine reading comprehension dataset</title>
		<author>
			<persName><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mir</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Understanding factuality in abstractive summarization with FRANK: A benchmark for factuality metrics</title>
		<author>
			<persName><forename type="first">Artidoro</forename><surname>Pagnoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vidhisha</forename><surname>Balachandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.383</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4812" to="4829" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">How context affects language models&apos; factual predictions</title>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">H</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In Automated Knowledge Base Construction</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified textto-text transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">140</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">PlotMachines: Outlineconditioned generation with dynamic plot state tracking</title>
		<author>
			<persName><forename type="first">Asli</forename><surname>Hannah Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><surname>Gao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.349</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4274" to="4295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Beyond accuracy: Behavioral testing of NLP models with Check-List</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Tulio Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tongshuang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.442</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4902" to="4912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Automatically generating extraction patterns from untagged text</title>
		<author>
			<persName><forename type="first">E</forename><surname>Riloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI/IAAI</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Atomic: An atlas of machine commonsense for if-then reasoning</title>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Ronan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandra</forename><surname>Allaway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannah</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Roof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="3027" to="3035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Unsupervised commonsense question answering with selftalk</title>
		<author>
			<persName><forename type="first">Vered</forename><surname>Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Ronan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandra</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.05483</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Conceptnet 5: A large semantic network for relational knowledge</title>
		<author>
			<persName><forename type="first">Robyn</forename><surname>Speer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Havasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The People&apos;s Web Meets NLP</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Yago: A core of semantic knowledge</title>
		<author>
			<persName><forename type="first">Fabian</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gjergji</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
		<idno type="DOI">10.1145/1242572.1242667</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on World Wide Web, WWW &apos;07</title>
		<meeting>the 16th International Conference on World Wide Web, WWW &apos;07<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="697" to="706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Commonsenseqa: A question answering challenge targeting commonsense knowledge</title>
		<author>
			<persName><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Reasoning about actions and state changes by injecting commonsense knowledge</title>
		<author>
			<persName><forename type="first">Niket</forename><surname>Tandon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhavana</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Grus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1006</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Finetuned language models are zero-shot learners</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Chain of thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2201.11903</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Teach me to explain: A review of datasets for explainable natural language processing</title>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Wiegreffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ana</forename><surname>Marasović</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS Datasets and Benchmarks</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rémi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariama</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Planand-write: Towards better automatic storytelling</title>
		<author>
			<persName><forename type="first">Lili</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v33i01.33017378</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="7378" to="7385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">The unreliability of explanations in few-shot in-context learning</title>
		<author>
			<persName><forename type="first">Xi</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2205.03401</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Template-based information extraction from tree-structured html documents</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yih</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Bertscore: Evaluating text generation with bert</title>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varsha</forename><surname>Kishore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<idno>ArXiv, abs/1904.09675</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
