<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Who Are All The Stochastic Parrots Imitating? They Should Tell Us!</title>
				<funder ref="#_xgeFNJT #_rfU56T7">
					<orgName type="full">National Institutes of Health</orgName>
					<orgName type="abbreviated">NIH</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sagi</forename><surname>Shaier</surname></persName>
							<email>sagi.shaier@colorado.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Colorado Boulder</orgName>
								<orgName type="institution" key="instit2">University of Colorado Denver</orgName>
								<orgName type="institution" key="instit3">Johannes Gutenberg University Mainz</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lawrence</forename><forename type="middle">E</forename><surname>Hunter</surname></persName>
							<email>larry.hunter@cuanschutz.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Colorado Boulder</orgName>
								<orgName type="institution" key="instit2">University of Colorado Denver</orgName>
								<orgName type="institution" key="instit3">Johannes Gutenberg University Mainz</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Katharina</forename><surname>Von Der Wense</surname></persName>
							<email>katharina.kann@colorado.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Colorado Boulder</orgName>
								<orgName type="institution" key="instit2">University of Colorado Denver</orgName>
								<orgName type="institution" key="instit3">Johannes Gutenberg University Mainz</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Who Are All The Stochastic Parrots Imitating? They Should Tell Us!</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7E09CCE9B4CECE6420332B4702A8FFFB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-05-29T13:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Both standalone language models (LMs) as well as LMs within downstream-task systems have been shown to generate statements which are factually untrue. This problem is especially severe for low-resource languages, where training data is scarce and of worse quality than for high-resource languages. In this opinion piece, we argue that LMs in their current state will never be fully trustworthy in critical settings and suggest a possible novel strategy to handle this issue: by building LMs such that can cite their sources -i.e., point a user to the parts of their training data that back up their outputs. We first discuss which current NLP tasks would or would not benefit from such models. We then highlight the expected benefits such models would bring, e.g., quick verifiability of statements. We end by outlining the individual tasks that would need to be solved on the way to developing LMs with the ability to cite. We hope to start a discussion about the field's current approach to building LMs, especially for low-resource languages, and the role of the training data in explaining model generations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Transformers <ref type="bibr" target="#b47">(Vaswani et al., 2017)</ref> and related models have been improving rapidly, with applications in a surprisingly large number of domains, such as natural language generation <ref type="bibr" target="#b56">(Zhang et al., 2019)</ref>, machine translation <ref type="bibr" target="#b49">(Wang et al., 2019)</ref>, question answering <ref type="bibr" target="#b0">(Akermi et al., 2020)</ref>, and code generation <ref type="bibr" target="#b43">(Svyatkovskiy et al., 2020)</ref>, based on the ability to generate sensible outputs to prompts over a nearly limitless input domain.</p><p>Despite impressive performance on a wide array of benchmark tasks, these models are known to produce "AI-splaining," confident sounding but incorrect statements: "To the extent that a use case places importance on the truth of the outputs pro-♠ Formerly: Katharina Kann I am powered by OpenAI's learning set, which has been raised with the help of machine learning techniques on Internet culture, including websites, books, articles, quotes, and more"). We argue that ChatGPT and similar models should be able to direct the user to the sources of their information, which will have multiple benefits, such as quick verifiability of model statements. vided, it is not a good fit for GPT-3" <ref type="bibr" target="#b5">(Dale, 2021)</ref>; see also <ref type="bibr" target="#b4">Church et al. (2022) and</ref><ref type="bibr" target="#b27">Marcus (2019)</ref>.</p><p>This problem has proven to be especially true for models trained on low-resource languages <ref type="bibr" target="#b16">(Guerreiro et al., 2023)</ref>, where data may not only be scarce <ref type="bibr" target="#b26">(Mager et al., 2018)</ref>, but also not well curated with respect to correctness or quality, in comparison to higher-resource languages <ref type="bibr" target="#b17">(Hedderich et al., 2021)</ref>. Furthermore, model hallucination in such settings can result in toxic patterns that can be found in the training data <ref type="bibr" target="#b16">(Guerreiro et al., 2023)</ref>.</p><p>In accordance with the large LMs and lowresource languages theme track, we argue that while the performance and factuality of LMs has been improving, both in high-resource and lowresource settings, in their existing state, LMs will realistically never be fully trustworthy. Thus, in settings in which factuality is required, such as medicine, they are dangerous and unemployable. This is further noted in <ref type="bibr" target="#b30">Menick et al. (2022)</ref>, who state that users cannot trust any claim a model makes without fact-checking.</p><p>Our proposal to address these concerns suggests both technical development and a simple regulatory framework: as we often ask students, journalists and scholars, we should ask our models to name their sources and provide evidence for their assertions. Currently, even popular LMs often fail at this, as seen on the ChatGPT (OpenAI, 2023) example in Figure <ref type="figure">1</ref>. In the case of generative models, either the model itself or a post-hoc procedure could -and, under certain circumstances, should be required to -be designed to produce evidentiary justification for its output.</p><p>In this position paper, we overview which NLP tasks would benefit from such citation models, discuss the benefits they would bring, and present a roadmap to develop such models. Our goal is to motivate the field to start thinking about what is necessary to make current models truly useful in all sorts of -potentially critical -scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Factuality and the Lack Thereof LMs store factual knowledge <ref type="bibr" target="#b8">(Dong et al., 2022;</ref><ref type="bibr" target="#b7">De Cao et al., 2021;</ref><ref type="bibr">Elazar et al., 2021;</ref><ref type="bibr" target="#b20">Jiang et al., 2019)</ref> and previous work have shown that LMs can act as knowledge bases <ref type="bibr" target="#b33">(Petroni et al., 2019;</ref><ref type="bibr" target="#b42">Sung et al., 2021)</ref>. However, there is no guarantee that the retrieved knowledge is indeed factual, and unfortunately, often it is not. This can be seen in many areas, such as question answering <ref type="bibr" target="#b54">(Xu et al., 2021)</ref>, dialogue systems <ref type="bibr" target="#b9">(Dziri et al., 2021;</ref><ref type="bibr" target="#b40">Shuster et al., 2021;</ref><ref type="bibr" target="#b45">Testoni and Bernardi, 2021)</ref>, image captioning <ref type="bibr" target="#b37">(Rohrbach et al., 2018</ref>), text summarization <ref type="bibr">(Zhao et al., 2020b;</ref><ref type="bibr" target="#b3">Cao et al., 2022;</ref><ref type="bibr" target="#b29">Maynez et al., 2020)</ref> and translation <ref type="bibr" target="#b35">(Raunak et al., 2021;</ref><ref type="bibr" target="#b19">Jeblick et al., 2022)</ref>. This is especially true in low-resource settings <ref type="bibr" target="#b16">(Guerreiro et al., 2023)</ref>. In order for LMs to be fully utilized as such knowledge bases and in settings where factuality is crucial, the retrieved knowledge must first be factual. But, without knowing the source of such the model's knowledge, verifying its factuality is a challenge.</p><p>Citation Generation Although LMs, particularly those intended to produce scientific text, such as Meta's Galactica <ref type="bibr" target="#b44">(Taylor et al., 2022)</ref>, already produce text that looks as if it is a citation, frequently there is no document corresponding to the apparent citation or the cited document does not support the statement associated with it. Many existing approaches to citation recommendation offer productive avenues to explore for factuality testing, post-hoc generation of support, hybrid architectures, or creation of training data <ref type="bibr">(Ali et al., 2022;</ref><ref type="bibr" target="#b23">Krasnova et al., 2023)</ref>. There has also been work on citation generation, where the task is either: 1) given two documents, generate an explanation for the relation between them <ref type="bibr" target="#b25">(Luu et al., 2020)</ref>, or 2) generate a citation for an already existing text <ref type="bibr" target="#b15">(Gu and Hahnloser, 2022;</ref><ref type="bibr" target="#b53">Xing et al., 2020;</ref><ref type="bibr" target="#b52">Wu et al., 2021;</ref><ref type="bibr" target="#b11">Fetahu et al., 2016)</ref>. This is different from our suggestion to generate statements and citations simultaneously, and also not optimal: as LMs are being trained on massive datasets, evaluating whether each statement came from each of the potentially millions of article becomes impractical. Lastly, many existing systems that can in fact provide citations are based on search engines or retrieval models <ref type="bibr" target="#b30">(Menick et al., 2022;</ref><ref type="bibr" target="#b30">Glaese et al., 2022)</ref>, see also Perplexity AI ♠ , YouChat ♠ , or the ALCE benchmark <ref type="bibr" target="#b12">(Gao et al., 2023)</ref>. This is problematic because 1) it is far more time consuming than directly generating citations together with text; 2) access to the information sources needs to be provided at all times; 3) in contrast to our proposed approach, it does not increase model interpretability; and 4) for low-resource languages the quantity and quality of the data is often limited, and hence result in difficulties retrieving the relevant, factual source.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Citations and Their Pros and Cons</head><p>In this section, we will first discuss which NLP tasks -according to us -require LMs with an ability to cite their sources. We will then discuss the benefits and, subsequently, risks of such models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Which Tasks Require Citations?</head><p>We propose to classify tasks via two questions: (1) Is the source of the generated text obvious? (2) Is the generated text an objective truth or a subjective statement? See Table <ref type="table">1</ref> for examples.</p><p>If the answer to the first question is yes, no further citation is required. This is the case, e.g., for machine translation <ref type="bibr" target="#b2">(Brants et al., 2007)</ref>: the content of the generated text comes from the input sentence. The same holds true for summarization <ref type="bibr" target="#b38">(See et al., 2017)</ref> and paraphrase generation <ref type="bibr" target="#b59">(Zhou and Bhat, 2021)</ref>. However, this is only partially the case for text simplification (Sheang and Saggion, 2021): while most of the content comes from the original text, simpler versions of text sometimes contain additional explanations, which do require citations. In contrast, for many other tasks the input does not act as the source for text generationinstead, the output comes from information stored in the model parameters and, thus, originally from the training data. An ideal system would be able to cite the part of its training data responsible for any given output. This is the case for the popular NLP tasks of closed-book free-text question answering <ref type="bibr" target="#b36">(Roberts et al., 2020)</ref>, dialogue generation <ref type="bibr">(Zhao et al., 2020a)</ref>, or creative writing <ref type="bibr" target="#b57">(Xu et al., 2020)</ref>.</p><p>For tasks for which the answer to Question 1 is no, we then turn to the second aforementioned question and ask if the generated text without clear sources of information in the input contains what should be objective truths. This is typically true for closed-book free-text question answering, which, as a consequence, according to our rules does require citations. However, this is sometimes the case for other tasks too, such as the generation of additional explanations during text simplification or image captioning. Similarly, for dialogue generation, objective truths and subjective statements could be mixed within the same conversation. As a result, some generated statements for those tasks do require citations, while others are good without.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Benefits of Citations</head><p>Citations allow us to verify the factuality of generated text easily. In contrast, without knowing where the text came from we are often unable to verify that it is correct. Moreover, knowing what portion of the text is copied verbatim allows us to give credit to the author and prevent copyright violations. Citations also increase the explainability of the answer and allow users to learn more about interesting topics. Additionally, recent work in prompt engineering have shown that models providing justifications for their assertions (even when only partially correct) can improve the correctness of the outputs <ref type="bibr" target="#b21">(Jung et al., 2022)</ref>. Trustworthiness judgments among people often include a social aspect, so by doing a good job of identifying sources and influences has the potential to increase both the trust in AI systems and their trustworthiness. For example, human trustworthiness judgments about scientific claims are influenced by the interests of the authors <ref type="bibr" target="#b13">(Gierth and Bromme, 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Risks of Citations</head><p>Unfortunately, citations also come with risks. Just by having a citation next to a generated text, users are more likely to trust it <ref type="bibr" target="#b46">(Thornley et al., 2015)</ref>. However, it is likely that users will not examine each and every citation manually to verify that the text is indeed factual, or that the source is trustworthy <ref type="bibr" target="#b41">(Simkin and Roychowdhury, 2002;</ref><ref type="bibr" target="#b46">Thornley et al., 2015)</ref>. This will be exacerbated by the fact that it is incredibly unlikely that any automated system will ever produce 100% correct citations at all times, and may result in either users' diminishing trust and usage of such systems or a potential harm.</p><p>There is also the risk of decreased readability: backing up every statement with many citations, as the text may appear in multiple places, will reduce the readability of the text and may hinder users from reading or understanding it. Lastly, privacy concerns also arise from the training process of LMs. For example, state of the art LMs are often trained on a massive automatically extracted text <ref type="bibr" target="#b34">(Radford et al., 2018)</ref>. But, as manual examination of each text is not feasible for its size, there is a possibility that it may contain private user information, such as patient records. This may result in LMs cite information that should stay private.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Citations vs. Explainability</head><p>The goal to understand why a model generates any given output is shared with research on model explainability <ref type="bibr" target="#b6">(Danilevsky et al., 2020)</ref>. However, in contrast to the latter, we are not interested in the effect of certain input on the output. In addition, we do not necessarily require that the model describes its reasoning by providing citations -what we care about instead is that the citations back up the model's answer. This enables humans to verify the output -even if the cited source should not actually in the technical sense have been the reason for the model's output. other text, even taken from the same article, does not have a citation attached to it. This results in LMs that can only sometimes, on a limited text, produce citations. In order to develop LMs that can cite their sources effectively, we need to give them the metadata which contain citation information.</p><p>Retrieval Say we trained a LM with the right data such that it has knowledge of which statement came from which article. How would we extract text with citations? One avenue for such knowledge extraction is to modify the pretraining, such that citation information is being generated together with every piece of generated text.</p><p>When To Cite? The above strategy would result in LMs that would always produce a citation. However, as mentioned in Section 3.1, not every task or statement requires a citation. For tasks that do require citations, we can just let the model always cite. For tasks that do not require citations, we can simply remove the citations. For tasks in between, where citation is sometimes required, we propose to utilize the existing subjectivity classification task <ref type="bibr" target="#b51">(Wiebe et al., 1999)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Concrete Tasks to Master</head><p>Our goal is to lay out a roadmap for the community, which describes necessary steps for the development of models that can cite their sources. This is not trivial, as it requires improvements of models for existing tasks as well as the development of systems for novel challenges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simultaneous Citation and Text Generation</head><p>As mentioned in Section 2, existing work mainly retrieve citations for already generated text, which becomes intractable as models are trained on ever more text and the number of possible source documents increases drastically. In contrast, we propose STANCE: the task of Simultaneous Text ANd Citation gEneration. As an additional challenge, future work should also focus on MultiSTANCE: multihop citation generation, where the sources for a given text are spread across multiple texts. As the number of citations can be significant (though much smaller in the low-resource setting), we suggest to use topic modeling, as a potential avenue to reduce such large search space.</p><p>Subjectivity Classification As mentioned in Section 3.1, whether a task requires a citation partially depends on if the text is objective or subjective. This is not a novel task as the community has been working on subjectivity classification for quite some time <ref type="bibr" target="#b51">(Wiebe et al., 1999;</ref><ref type="bibr" target="#b50">Wiebe and Riloff, 2005)</ref>. However, to the best of our knowledge, models for this task have not been employed in the context of citations.</p><p>Citation-Text Correctness To ensure that the retrieval step (Section 4.1) is successful, we need to identify whether the statement appears in the source. For that, two existing tasks can be used: 1) identifying which part of the generated text refers to the citation <ref type="bibr" target="#b48">(Wang et al., 2020)</ref>. 2) Validate that the citation is appropriate for the selected text span <ref type="bibr" target="#b22">(Karadzhov et al., 2017;</ref><ref type="bibr" target="#b28">Martín et al., 2021;</ref><ref type="bibr" target="#b18">Honovich et al., 2022;</ref><ref type="bibr" target="#b31">Mihaylova et al., 2018;</ref><ref type="bibr" target="#b24">Lee et al., 2020)</ref>. Using such automatic methods instead of manually verifying citations will result in faster model development.</p><p>Source Trustworthiness We all know that Wikipedia is not a reliable source for citation. We propose CUE (Citation qUality Evaluation), the task of evaluating the quality of the source corresponding to a generated citation. We believe there are six main sub-tasks for CUE, which consist of classifying 1) the time of publication, 2) whether the source is credible, 3) how many times the source has been cited, 4) if the author is known, 5) if the source is unbiased, and 6) if the statement and citation are still relevant. For example, answering that the current US president is Barack Obama was previously factual, and may still show up in many source documents, but is not factual in 2023.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>Language models (LMs) performance has been improving rapidly in a wide variety of areas. However, there is the crucial issue of their generated text often being nonfactual, especially for low-resource languages. We argue that, in order for LMs to be fully trustworthy, they must cite their sources -i.e., point users to the parts of their training data that back up their outputs. In this opinion piece, we discuss NLP tasks which would benefit from such citation models, highlight the benefits and risks such models would bring, and outline the individual tasks that would need to be solved on the way to develop such LMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>While developing the proposed language models that can cite their sources increase their utility, there is a risk that people would trust them more without actually verifying that the generated citations are actually correct. Such increase in trust would be especially problematic in time-critical scenarios where people cannot examine each citation manually. Ideally, our proposal will result in an increase of data cleaning, such that each citation is by default trustworthy. That being said, our approach does not solve copyright issues.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure1: An actual conversation with ChatGPT in Hebrew on the effects of not drinking enough water. Chat-GPT is unable to point the user to its sources and instead falls back to a general answer ("I am ChatGPT, an Ope-nAI model based on the GPT-3.5 deep learning model. I am powered by OpenAI's learning set, which has been raised with the help of machine learning techniques on Internet culture, including websites, books, articles, quotes, and more"). We argue that ChatGPT and similar models should be able to direct the user to the sources of their information, which will have multiple benefits, such as quick verifiability of model statements.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Emperor penguins are the largest species of penguin, standing up to 4 feet tall. They are skilled hunters, capable of catching fish and krill by diving hundreds of feet below the surface. Summary: Emperor penguins are notable for their size and hunting prowess, making them formidable predators in their environment.Text simplification Sometimes Sometimes Sometimes Source text: Penguins have evolved unique adaptations that allow them to survive in environments as harsh as Antarctica, such as their countershaded dark and white plumage, which camouflages them from predators above and below the ice.Simplified text: Penguins live in Antarctica, which is yearround one of the coldest places on Earth [CITATION], and they look different than other birds so they don't get eaten.</figDesc><table><row><cell>Task</cell><cell>Q1</cell><cell>Q2</cell><cell cols="2">Citation? Example</cell></row><row><cell>Creative writing</cell><cell>No</cell><cell cols="3">Sometimes Sometimes Penguins are known for their ability to survive in harsh</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Antarctic conditions [CITATION], but few people know that</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>they also possess the power of telekinesis which they use to</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>build intricate nests out of ice blocks.</cell></row><row><cell>Dialogue generation</cell><cell>No</cell><cell cols="3">Sometimes Sometimes Did you know that penguins can jump up to 6 feet out of</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>water when leaping onto land or ice floes? [CITATION]. I</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>think elephants can do the same.</cell></row><row><cell>Free-text QA</cell><cell>No</cell><cell>Yes</cell><cell>Yes</cell><cell>The current president is not a penguin [CITATION].</cell></row><row><cell>Image captioning</cell><cell>No</cell><cell cols="3">Sometimes Sometimes A group of penguins diving into the ocean to catch fresh fish</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>for dinner, highlighting their impressive swimming abilities</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>[CITATION], while one penguin emerges victorious with a</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>giant fish twice its size.</cell></row><row><cell>Paraphrase generation</cell><cell>Yes</cell><cell>N/A</cell><cell>No</cell><cell>Source text: Penguins are social animals who live in large</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>colonies. Paraphrased sentence: Penguins thrive in commu-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>nity living</cell></row><row><cell cols="5">Summarization Source text: Translation Yes N/A No Yes N/A No Source text: Penguins are cool. Translated text: Pinguine</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>sind cool.</cell></row></table><note><p><p><p>Table</p>1</p>: An overview of natural language generation tasks together with our opinion regarding if they require citations. Q1: Obvious source? Q2: Objective truth?</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>♠ https://www.perplexity.ai/ ♠ https://you.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>Road Map4.1 The Big Picture Meta-information Currently, the standard in the field is to train models on text, disjoint from its origin. Even though some models are trained on data that contain text with citations (e.g.,<ref type="bibr" target="#b44">Taylor et al. (2022)</ref>), the citations are only "attached" to statements taken from other sources, while any</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We would like to thank the reviewers for taking the time to provide feedback on our work. Your insights have been valuable in helping us refine and enhance our manuscript. The authors acknowledge financial support from <rs type="funder">NIH</rs> grants <rs type="grantNumber">OT2TR003422</rs> and <rs type="grantNumber">R01LM013400</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_xgeFNJT">
					<idno type="grant-number">OT2TR003422</idno>
				</org>
				<org type="funding" xml:id="_rfU56T7">
					<idno type="grant-number">R01LM013400</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics Statement</head><p>The main reason for this paper is to point out shortcomings of state-of-the-art language models, which can have significant social, health-related, and economic consequences. Future work should develop systems that can cite their sources in order to facilitate a verification of the factuality of generated statements.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Transformer based natural language generation for question-answering</title>
		<author>
			<persName><forename type="first">Imen</forename><surname>Akermi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Heinecke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frédéric</forename><surname>Herledan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Natural Language Generation</title>
		<meeting>the 13th International Conference on Natural Language Generation<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="349" to="359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Irfan Ullah, and Waheed Abro. 2022. Citation recommendation employing heterogeneous bibliographic network embedding</title>
		<author>
			<persName><forename type="first">Zafar</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guilin</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Khan</forename><surname>Muhammad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddhartha</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00521-021-06135-y</idno>
	</analytic>
	<monogr>
		<title level="j">Neural Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="10229" to="10242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Large language models in machine translation</title>
		<author>
			<persName><forename type="first">Thorsten</forename><surname>Brants</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ashok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Popat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franz</forename><forename type="middle">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)</title>
		<meeting>the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="858" to="867" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Hallucinated but factual! inspecting the factuality of hallucinations in abstractive summarization</title>
		<author>
			<persName><forename type="first">Meng</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jackie</forename><surname>Cheung</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.236</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3340" to="3354" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A gentle introduction to deep nets and opportunities for the future</title>
		<author>
			<persName><forename type="first">Kenneth</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valia</forename><surname>Kordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gary</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ernest</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanjun</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeyu</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-tutorials.1</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Gpt-3: What&apos;s it good for?</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Dale</surname></persName>
		</author>
		<idno type="DOI">10.1017/S1351324920000601</idno>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="113" to="118" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A survey of the state of explainable AI for natural language processing</title>
		<author>
			<persName><forename type="first">Marina</forename><surname>Danilevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ranit</forename><surname>Kun Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yannis</forename><surname>Aharonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ban</forename><surname>Katsis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prithviraj</forename><surname>Kawas</surname></persName>
		</author>
		<author>
			<persName><surname>Sen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing</title>
		<meeting>the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing<address><addrLine>Suzhou, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="447" to="459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Editing factual knowledge in language models</title>
		<author>
			<persName><forename type="first">Nicola</forename><surname>De Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wilker</forename><surname>Aziz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2104.08164</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Calibrating factual knowledge in pretrained language models</title>
		<author>
			<persName><forename type="first">Qingxiu</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Damai</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2210.03329</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Neural path hunter: Reducing hallucination in dialogue systems via path grounding</title>
		<author>
			<persName><forename type="first">Nouha</forename><surname>Dziri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Osmar</forename><surname>Zaïane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avishek Joey</forename><surname>Bose</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.168</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Online and Punta Cana, Dominican Republic. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2197" to="2214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Hinrich Schütze, and Yoav Goldberg. 2021. Measuring and improving consistency in pretrained language models</title>
		<author>
			<persName><forename type="first">Yanai</forename><surname>Elazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nora</forename><surname>Kassner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shauli</forename><surname>Ravfogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhilasha</forename><surname>Ravichander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2102.01017</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Finding news citations for wikipedia</title>
		<author>
			<persName><forename type="first">Besnik</forename><surname>Fetahu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katja</forename><surname>Markert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wolfgang</forename><surname>Nejdl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avishek</forename><surname>Anand</surname></persName>
		</author>
		<idno type="DOI">10.1145/2983323.2983808</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 25th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Enabling large language models to generate text with citations</title>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Howard</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiatong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Beware of vested interests: Epistemic vigilance improves reasoning about scientific evidence (for some people)</title>
		<author>
			<persName><forename type="first">L</forename><surname>Gierth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bromme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">231387</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Amelia</forename><surname>Glaese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nat</forename><surname>Mcaleese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maja</forename><surname>Trębacz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Aslanides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vlad</forename><surname>Firoiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timo</forename><surname>Ewalds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maribeth</forename><surname>Rauh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><surname>Weidinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Chadwick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phoebe</forename><surname>Thacker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucy</forename><surname>Campbell-Gillingham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Uesato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramona</forename><surname>Comanescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abigail</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumanth</forename><surname>Dathathri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rory</forename><surname>Greig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charlie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doug</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaume</forename><surname>Sanchez Elias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soňa</forename><surname>Mokrá</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boxi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Foley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susannah</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iason</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Isaac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Mellor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Demis</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<imprint>
			<publisher>Lisa Anne Hendricks</publisher>
		</imprint>
	</monogr>
	<note>and Geoffrey Irving. 2022. Improving alignment of dialogue agents via targeted human judgements</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Nianlong</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">H R</forename><surname>Hahnloser</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2211.07066</idno>
		<title level="m">Controllable citation text generation</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Nuno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duarte</forename><surname>Guerreiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Alves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Waldendorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName><surname>Colombo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">T</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName><surname>Martins</surname></persName>
		</author>
		<title level="m">Hallucinations in large multilingual translation models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A survey on recent approaches for natural language processing in low-resource scenarios</title>
		<author>
			<persName><forename type="first">A</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukas</forename><surname>Hedderich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heike</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jannik</forename><surname>Adel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dietrich</forename><surname>Strötgen</surname></persName>
		</author>
		<author>
			<persName><surname>Klakow</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.201</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2545" to="2568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Or</forename><surname>Honovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roee</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hagai</forename><surname>Taitelbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doron</forename><surname>Kukliansy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vered</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Scialom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Idan</forename><surname>Szpektor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avinatan</forename><surname>Hassidim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yossi</forename><surname>Matias</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2204.04991</idno>
		<title level="m">True: Re-evaluating factual consistency evaluation</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Chatgpt makes medicine easy to swallow: An exploratory case study on simplified radiology reports</title>
		<author>
			<persName><forename type="first">Katharina</forename><surname>Jeblick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Balthasar</forename><surname>Schachtner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Dexl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Mittermeier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><forename type="middle">Theresa</forename><surname>Stüber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johanna</forename><surname>Topalis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Wesp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bastian</forename><surname>Sabel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jens</forename><surname>Ricke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Ingrisch</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2212.14882</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">How can we know what language models know?</title>
		<author>
			<persName><forename type="first">Zhengbao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><forename type="middle">F</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Araki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.1911.12543</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Maieutic prompting: Logically consistent reasoning with recursive explanations</title>
		<author>
			<persName><forename type="first">Jaehun</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lianhui</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Welleck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faeze</forename><surname>Brahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandra</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronan</forename><surname>Le Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2205.11822</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Fully automated fact checking using external sources</title>
		<author>
			<persName><forename type="first">Georgi</forename><surname>Karadzhov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lluis</forename><surname>Marquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Barron-Cedeno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Koychev</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.1710.00341</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Text sampling strategies for predicting missing bibliographic links</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Krasnova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Smaznevicha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">N</forename><surname>Baskakova</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2301.01673</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Language models as fact checkers?</title>
		<author>
			<persName><forename type="first">Nayeon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Belinda</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sinong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madian</forename><surname>Khabsa</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2006.04102</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rik</forename><surname>Koncel-Kedziorski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabel</forename><surname>Cachola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.00317</idno>
		<title level="m">Citation text generation</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Challenges of language technologies for the indigenous languages of the Americas</title>
		<author>
			<persName><forename type="first">Manuel</forename><surname>Mager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ximena</forename><surname>Gutierrez-Vasques</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerardo</forename><surname>Sierra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Meza-Ruiz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics<address><addrLine>Santa Fe, New Mexico, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="55" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Gary</forename><surname>Ernest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Davis</forename><surname>Marcus</surname></persName>
		</author>
		<title level="m">Rebooting AI: Building Artificial Intelligence we can Trust</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Facter-check: Semi-automated factchecking through semantic similarity and natural language inference</title>
		<author>
			<persName><forename type="first">Alejandro</forename><surname>Martín</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Javier</forename><surname>Huertas-Tato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Álvaro</forename><surname>Huertas-García</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillermo</forename><surname>Villar-Rodríguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Camacho</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2110.14532</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">On faithfulness and factuality in abstractive summarization</title>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Maynez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shashi</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernd</forename><surname>Bohnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.173</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1906" to="1919" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Menick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maja</forename><surname>Trebacz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Mikulik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Aslanides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francis</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Chadwick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mia</forename><surname>Glaese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susannah</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucy</forename><surname>Campbell-Gillingham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nat</forename><surname>Mcaleese</surname></persName>
		</author>
		<title level="m">Teaching language models to support answers with verified quotes</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Tsvetomila</forename><surname>Mihaylova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lluis</forename><surname>Marquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Barron-Cedeno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitra</forename><surname>Mohtarami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgi</forename><surname>Karadzhov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Glass</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.1803.03178</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Fact checking in community forums</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Chatgpt: Optimizing language models for dialogue</title>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Language models as knowledge bases?</title>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anton</forename><surname>Bakhtin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">H</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.1909.01066</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">The curious case of hallucinations in neural machine translation</title>
		<author>
			<persName><forename type="first">Arul</forename><surname>Vikas Raunak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Menezes</surname></persName>
		</author>
		<author>
			<persName><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2104.06683</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">How much knowledge can you pack into the parameters of a language model?</title>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.437</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5418" to="5426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Object hallucination in image captioning</title>
		<author>
			<persName><forename type="first">Anna</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><forename type="middle">Anne</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaylee</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1437</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4035" to="4045" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Get to the point: Summarization with pointergenerator networks</title>
		<author>
			<persName><forename type="first">Abigail</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1099</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1073" to="1083" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Controllable sentence simplification with a unified textto-text transfer transformer</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Natural Language Generation</title>
		<meeting>the 14th International Conference on Natural Language Generation<address><addrLine>Aberdeen, Scotland</addrLine></address></meeting>
		<imprint>
			<publisher>UK. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="341" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Retrieval augmentation reduces hallucination in conversation</title>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Spencer</forename><surname>Poff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2104.07567</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Simkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">P</forename><surname>Roychowdhury</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.COND-MAT/0212043</idno>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note>Read before you cite</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Can language models be biomedical knowledge bases?</title>
		<author>
			<persName><forename type="first">Mujeen</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinhyuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minji</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungdong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaewoo</forename><surname>Kang</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2109.07154</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Intellicode compose: Code generation using transformer</title>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Svyatkovskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengyu</forename><surname>Shao Kun Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neel</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><surname>Sundaresan</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2005.08025</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">Ross</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Kardas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Scialom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Hartshorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elvis</forename><surname>Saravia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Poulton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viktor</forename><surname>Kerkez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Stojnic</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2211.09085</idno>
		<title level="m">Galactica: A large language model for science</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">I&apos;ve seen things you people wouldn&apos;t believe&quot;: Hallucinating entities in GuessWhat?</title>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Testoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raffaella</forename><surname>Bernardi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-srw.11</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Student Research Workshop</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Student Research Workshop</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="101" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The role of trust and authority in the citation behaviour of researchers</title>
		<author>
			<persName><forename type="first">Clare</forename><surname>Thornley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Watkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Nicholas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Volentine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><forename type="middle">R</forename><surname>Jamali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eti</forename><surname>Herman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suzie</forename><surname>Allard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenneth</forename><forename type="middle">J</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carol</forename><surname>Tenopir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Res</title>
		<imprint>
			<biblScope unit="page">20</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.1706.03762</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>Attention is all you need</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Toc-rwg: Explore the combination of topic model and citation information for automatic related work generation</title>
		<author>
			<persName><forename type="first">Pancheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shasha</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jintao</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2019.2959056</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="13043" to="13055" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning deep transformer models for machine translation</title>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingbo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><forename type="middle">F</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lidia</forename><forename type="middle">S</forename><surname>Chao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1176</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1810" to="1822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Creating subjective and objective sentence classifiers from unannotated texts</title>
		<author>
			<persName><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Intelligent Text Processing and Computational Linguistics</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Development and use of a goldstandard data set for subjectivity classifications</title>
		<author>
			<persName><forename type="first">Janyce</forename><forename type="middle">M</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rebecca</forename><forename type="middle">F</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">P</forename><surname>O'hara</surname></persName>
		</author>
		<idno type="DOI">10.3115/1034678.1034721</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 37th Annual Meeting of the Association for Computational Linguistics<address><addrLine>College Park, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="246" to="253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Towards generating citation sentences for multiple references with intent control</title>
		<author>
			<persName><forename type="first">Jia-Yan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Te-Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shih-Ju</forename><surname>Shieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun-Nung</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2112.01332</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Automatic generation of citation texts in scholarly papers: A pilot study</title>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaosheng</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.550</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6181" to="6190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Attention-guided generative models for extractive question answering</title>
		<author>
			<persName><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Davis</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2110.06393</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Megatron-cntrl: Controllable story generation with external knowledge using large-scale language models</title>
		<author>
			<persName><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostofa</forename><surname>Patwary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Shoeybi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raul</forename><surname>Puri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anima</forename><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Catanzaro</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2010.00840</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Pretraining-based natural language generation for text summarization</title>
		<author>
			<persName><forename type="first">Haoyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingjing</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianjun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/K19-1074</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)</title>
		<meeting>the 23rd Conference on Computational Natural Language Learning (CoNLL)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="789" to="797" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Knowledgegrounded dialogue generation with pre-trained language models</title>
		<author>
			<persName><forename type="first">Xueliang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Can</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chongyang</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.272</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3377" to="3390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Reducing quantity hallucinations in abstractive summarization</title>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shay</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bonnie</forename><surname>Webber</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.203</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2237" to="2249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Paraphrase generation: A survey of the state of the art</title>
		<author>
			<persName><forename type="first">Jianing</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suma</forename><surname>Bhat</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.414</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Dominican Republic. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="5075" to="5086" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
