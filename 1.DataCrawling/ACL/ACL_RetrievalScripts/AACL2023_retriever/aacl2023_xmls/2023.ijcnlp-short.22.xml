<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">It&apos;s not only What You Say, It&apos;s also Who It&apos;s Said to: Counterfactual Analysis of Interactive Behavior in the Courtroom</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Biaoyan</forename><surname>Fang</surname></persName>
							<email>biaoyan@unimelb.edu.au</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
							<email>tcohn@unimelb.edu.au</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Now at Google DeepMind</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
							<email>tbaldwin@unimelb.edu.au</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lea</forename><surname>Frermann</surname></persName>
							<email>lfrermann@unimelb.edu.au</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">It&apos;s not only What You Say, It&apos;s also Who It&apos;s Said to: Counterfactual Analysis of Interactive Behavior in the Courtroom</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">AC2E65F35FD2B2A97279A66AAB27C3E0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-05-29T14:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>To what extent do personal attributes affect the way we are spoken to? Answering this question requires the precise reproduction of a conversational context except for one personal attribute of interest, amounting to a classical, yet infeasible, causal inference problem. We present a method based on counterfactual analysis by manipulating speaker attributes in observational data. We propose a case study of Advocate responses to Justices in debates in the Supreme Court of the United States. Specifically, we measure changes in politeness and coordination of Advocates when responding to (a) real Justices and (b) counterfactually-manipulated Justices, with responses generated with GPT2. We first validate our method, showing that GPT2generated outputs capture coordination and politeness. Our results confirm a known impact of the attribute gender, and suggest a weaker effect of seniority on coordination. 1  </p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Does the way we speak to others depend on the personal attributes of the addressee? Speakers employ different strategies when replying to persons of different social status <ref type="bibr" target="#b23">(Niederhoffer and Pennebaker, 2002;</ref><ref type="bibr" target="#b29">Taylor and Thomas, 2008;</ref><ref type="bibr" target="#b1">Danescu-Niculescu-Mizil et al., 2012</ref><ref type="bibr" target="#b7">, 2013;</ref><ref type="bibr" target="#b21">Mizukami et al., 2016)</ref>. Well-known strategies are linguistic accommodation, e.g., in adjusting in style to a more senior conversation partner <ref type="bibr" target="#b18">(Kulesza et al., 2014;</ref><ref type="bibr" target="#b1">Danescu-Niculescu-Mizil et al., 2012;</ref><ref type="bibr">Noble and Fernández, 2015;</ref><ref type="bibr">Xu et al., 2018)</ref>, and politeness, where speakers vary the level of formality and word choice <ref type="bibr" target="#b2">(Danescu-Niculescu-Mizil et al., 2013;</ref><ref type="bibr" target="#b11">Fu et al., 2020;</ref><ref type="bibr" target="#b20">Li et al., 2020)</ref>. A better understanding of the factors that cause such strategies is not only of interest to social scientists, but could also render dialogue systems more natural.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[BADER-GINSBURG]</head><p>[ADVRES] [. . . ] This is an obstacle preemption case masquerading as a field preemption case. [. . . ] and the Nuclear Regulatory Commission have repeatedly reaffirmed that states have the ability to regulate mining up to and including by banning it altogether <ref type="bibr">[. . . ]</ref> [KAVANAUGH] Yeah. So the mining and milling occur together, correct? In other words [. . . ] you don't have mining without milling; you don't have milling without mining</p><p>[ADVRES] [. . . ] there's a way -the in situ leaching process, they literally occur at the same time. Figure <ref type="figure">1</ref>: An example instance from our dataset. We measure politeness and coordination in the true or generated [ADVRES] response (bottom) to a question from a Justice (middle) in context <ref type="bibr">(top)</ref>. Counterfactuals replace the true Justice identity tag (male) with a different one (female).</p><p>To directly address this question would require a dataset of paired situations which are identical except for one speaker's personal attribute of interest. This would allow us to measure the causal effect of the attribute value (treatment) on language style (outcome) <ref type="bibr" target="#b24">(Pearl, 2009;</ref><ref type="bibr" target="#b15">Imbens and Rubin, 2015)</ref>.</p><p>Since this is not achievable, we present a counterfactual methodology based on manipulation of observational data and the power of pre-trained language models. Specifically, we require a dataset of observed conversations involving persons for which: (a) personal attribute values are known; (b) sufficient conversational data is available to finetune LMs; and (c) these conversations occur in a relatively controlled context. Here, we use conversations between Advocates and Justices in arguments from the US Supreme Court (SCOTUS) and investigate differences in politeness <ref type="bibr" target="#b2">(Danescu-Niculescu-Mizil et al., 2013)</ref> and coordination <ref type="bibr" target="#b1">(Danescu-Niculescu-Mizil et al., 2012)</ref> of Advocate responses to questions asked by Justices with different personal and professional attributes (Figure <ref type="figure">1</ref>).</p><p>To validate our approach, we first show that pre-trained language models reliably capture politeness and coordination (Section 3). We do so by comparing the politeness and coordination levels of real Advocate answers in the SCOTUS data against answers generated by a large pre-trained language model (GPT2; <ref type="bibr" target="#b26">Radford et al. (2019)</ref>) when prompted with the same context (Figure <ref type="figure">1</ref>, blue).</p><p>We consider three binary Justice attributesgender, nominating party, and seniority -and compare politeness and coordination in GPT2 generated responses in factual vs. counterfactuallymanipulated situations where the inquiring Justices' attribute value is flipped (Section 4; Figure <ref type="figure">1</ref>, red → blue). We ask would an Advocate's response change in politeness (coordination) had the question been asked by a Justice from a different social group?</p><p>We show that LMs are sensitive to social cues, beyond the inherent biases in LMs and data sets (Section 6), prompting further research on fairness and bias from a sociolinguistic perspective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>Data We use a subset of a published set of SCO-TUS arguments<ref type="foot" target="#foot_0">2</ref>  <ref type="bibr" target="#b0">(Chang et al., 2020)</ref>, covering transcripts from 1955 to 2019, comprising 4.5K cases, 35 Justices, and &gt;1M utterances. We randomly selected one case per year to include in the dev and test sets, respectively, and used the remainder to fine-tune GPT2. We removed Justices with &lt;80 turns from the test set. <ref type="foot" target="#foot_1">3</ref>The published SCOTUS data includes the speaker identity (name) and function (e.g., Justice or Advocate) for each turn. We retain the full Justice name and map the Advocates to the side they stand for, i.e. petitioner ([ADVPET]) or respondent <ref type="bibr">([ADVRES]</ref>). <ref type="foot" target="#foot_2">4</ref> From this, we construct our final dataset, where each instance consists of 400 words of preceding context, followed by a Justice turn directly followed by an Advocate's response. Figure <ref type="figure">1</ref> shows an example context. The statistics of our dataset are listed in Table <ref type="table">1</ref> and Appendix A provides additional details on the data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Demographic and Personal Attributes</head><p>We study the impact of three binary attributes of a Justice on the politeness and coordination levels of the Advocates' response to their questions: gender (m, f); seniority (Chief Justice or not); and the party which nominated the Justice (Democrat, Republican).</p><p>Coordination and Politeness Prior work has proposed measures of coordination <ref type="bibr" target="#b1">(Danescu-Niculescu-Mizil et al., 2012)</ref> and politeness <ref type="bibr" target="#b2">(Danescu-Niculescu-Mizil et al., 2013)</ref>, which have been used to study the connection between linguistic choices and personal attributes.</p><p>We consider those measures to analyze the behavior of Advocates in the courtroom. Particularity, we directly use the coordination indicator from ConvoKit,<ref type="foot" target="#foot_3">5</ref> which quantifies the coordination of a respondent adv to a speaker jst wrt. a linguistic marker<ref type="foot" target="#foot_4">6</ref> lm by calculating how much the fact that jst used lm increases the probability of adv using lm in a direct response. We average across markers, and instead of considering individual jst, we measure coordination to groups of jst who share an attribute value a (e.g., all male or female Justices), obtaining coordination measure ŷjst=a c . We similarly measure politeness as the probability of observing a politeness marker<ref type="foot" target="#foot_5">7</ref> pm in an utterance by adv in response to jst, normalized by the prior probability of adv using pm; again, we average over values pm and all jst that share an attribute value, obtaining a politeness measure ŷjst=a p .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>We used GPT2 to generate responses given factual (Figure <ref type="figure">1</ref>, red) and counterfactual (Figure <ref type="figure">1</ref>, blue) contexts. We fine-tuned GPT2 on the SCOTUS training set for 50 epochs to incorporate a notion of typical Advocates' response behavior, and selected the best model based on dev set perplexity. We generated Advocate responses with GPT2 given a Justice question with preceding context. Each turn includes a speaker tag (see <ref type="bibr">[TAGs]</ref> in Figure <ref type="figure">1</ref>). We chose GPT2 because, unlike its successors GPT3 and ChatGPT, it can be fine-tuned to a target domain.</p><p>Factuals We first present factual SCOTUS contexts cxt (Figure <ref type="figure">1</ref>, top and middle context) with true speaker tags (Figure <ref type="figure">1</ref>, red) as prompts to GPT2 and have it generate a factual response. We obtain a final coordination (or, equivalently, politeness) score, by averaging over all generated responses to questions by Justices with attribute a:</p><formula xml:id="formula_0">y jst=a |{cxt} a , jst=a,<label>(1)</label></formula><p>where scores y can pertain to coordination or politeness, and we omit subscripts to avoid clutter. In Section 3 we verify that GPT2 scores y jst=a mirror the true values ŷjst=a across attribute values, for both coordination and politeness.</p><p>Counterfactual Speakers We next manipulate only a Justices' attribute of interest while keeping the rest of the context fixed, to examine its effect on the Advocate's response. We do so by changing the speaker tag (Figure <ref type="figure">1</ref>, red → blue). For instance, to test the effect of gender on politeness (or, equivalently, coordination), we take all contexts involving male Justices {cxt} m and replace the male Justice's indicator (e.g., <ref type="bibr">[KAVANAUGH]</ref>) with a female Justice's name (e.g., <ref type="bibr">[BADER-GINSBURG]</ref>). We do this exhaustively for all male-female combinations and average over counterfactually generated responses towards female Justice tags to obtain a 'generic female' f politeness (coordination) score y jst= f |m under male context {cxt} m . Equivalently, we obtain a 'generic male' m politeness (coordination) score y jst= m|m under male context {cxt} m by substituting male indicators with other male tags:</p><formula xml:id="formula_1">y jst= f |m |{cxt} m , do(jst=m→ f ), y jst= m|m |{cxt} m , do(jst=m→ m),<label>(2)</label></formula><p>where we denote the counterfactual manipulation with the do operator from the causal inference literature <ref type="bibr" target="#b24">(Pearl, 2009)</ref>. In sum, we fix the context (e.g., {cxt} m ) but manipulate properties of the Justices (e.g., m vs. f ) and measure the difference between politeness (or, equivalently, coordination) scores to test the effect of attribute values in speakers. <ref type="foot" target="#foot_6">8</ref>Counterfactual Contexts Alternatively, to understand the effect of context spoken by groups with different values, we hold the properties of the Justices constant, and change the conditioning contexts. E.g., we fix the gender of the asking Justice, e.g., to a 'generic male' m by exhaustively inserting male Justice names as described above, and generate responses when (i) contextualized with male Justices' contexts {cxt} m , or (ii) female Justices' contexts {cxt} f , and compare their differences:</p><formula xml:id="formula_2">y jst= m|m |{cxt} m , do(jst=m→ m), y jst= m|f |{cxt} f , do(jst=f → m).<label>(3)</label></formula><p>In sum, we fix the properties of the Justices (e.g., m) but manipulate the context from different justices (e.g., {cxt} m vs. {cxt} f ) and measure the difference between politeness (coordination) scores to test the effect of spoken context.</p><p>In Section 4 we apply both counterfactual comparisons (Equations ( <ref type="formula" target="#formula_1">2</ref>) and (3)) across our three binary attributes, and politeness and coordination measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiment 1: Factual generation</head><p>First, we validated that generated Advocate responses to Justice questions resemble true responses in both content and coordination/politeness. We compared scores as estimated from the SCOTUS data against those generated by GPT2 when prompted with factual contexts (Equation ( <ref type="formula" target="#formula_0">1</ref>)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Content validity</head><p>We observed a decrease in dev perplexity (116.22 to 2.75) after fine-tuning GPT-2. Additionally, we manually evaluated the generated responses in terms of their informativeness, relevance, and consistency <ref type="bibr" target="#b8">(Finch and Choi, 2020)</ref>. We hired two English native-speaker social scientists not involved in the project and presented them  with the same prompt as GPT2 and the real and generated answers, and asked to indicate for each category which answer is preferred or whether both are equal. Table <ref type="table" target="#tab_1">2</ref> (left) shows that overwhelmingly both answers were rated as equal. For cases where one answer was preferred, we verified that the distribution did not differ significantly from random (Binomial test, p&gt;0.05, n=46).</p><p>Coordination and Politeness Do GPT2 responses reflect the differences in coordination and politeness in responses observed in the original SCOTUS data? Figure <ref type="figure" target="#fig_1">2</ref> shows that predicted coordination scores (green bars) consistently align with true scores (purple bars) in terms of direction and magnitude; the same holds for politeness in Figure <ref type="figure" target="#fig_1">2b</ref>. Gender produces the largest difference in coordination (Figure <ref type="figure" target="#fig_1">2a</ref> left), echoing the finding of Danescu-Niculescu-Mizil et al. ( <ref type="formula">2012</ref>) that gender impacts speaker coordination in legal discourse. Gender and seniority incur politeness differences.<ref type="foot" target="#foot_7">9</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment 2: Counterfactual Generation</head><p>Having demonstrated that GPT2-generated responses reflect content and group-specific social signaling (Section 3), we now apply the counterfactual framework (Equations ( <ref type="formula" target="#formula_1">2</ref>) and ( <ref type="formula" target="#formula_2">3</ref>)). First, we ensured the content validity of counterfactually generated utterances via human evaluation as in Section 3.  (or vice versa) for the vast majority of instances. <ref type="foot" target="#foot_8">10</ref>We first ask to what extent social cues in an Advocate response vary wrt. a manipulated attribute of the asking party (Justice). This corresponds to Equation ( <ref type="formula" target="#formula_1">2</ref>) and comparison of lined vs. dotted bars of the same color in Figure <ref type="figure" target="#fig_2">3a</ref> (coordination) and Figure <ref type="figure" target="#fig_2">3b</ref> (politeness). We find a significant difference (Welch's t-test, p&lt;0.05) in politeness in response to Justice gender: Advocates are significantly more polite to real and counterfactual female Justices given the same context. This holds in both directions (a significant increase when manipulating 'generic male' m→ f (red) and decrease when turning 'generic female' f → m (blue)).</p><p>Next, we investigate the impact of context on social signals in a response, by keeping properties of Justices fixed, but embedding them in different contexts originating either from Justices with binary attribute label a or ¬a (Equation (3)). We inspect the results by comparing the blue vs. red bars of the same shade (both lined or both dotted) in Figure <ref type="figure" target="#fig_2">3</ref>. We find a significant difference in coordination, when embedding female Justices in female vs. male contexts (left block Figure <ref type="figure" target="#fig_2">3a</ref> blue lined vs. red lined) and male Justices in female vs. male contexts (same block, blue dotted vs. red dotted). With marginal significance (p&lt;0.1, n=16), we observe a decrease in coordination and increase in politeness when embedding non-Chief Justices in non-Chief vs. Chief contexts (blue vs. red lines in the right blocks in Figures <ref type="figure" target="#fig_2">3a</ref> and<ref type="figure" target="#fig_2">3b</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>Does the way we speak depend on the personal attributes of our interlocutor? We addressed this question with a new methodology involving counterfactual manipulation and high-quality response generation from a powerful language model. Our method isolates social cues in responses to questions from groups of people with different social or demographic attributes in otherwise controlled contexts. We presented a case study on Advocate responses to Justices in SCOTUS arguments, where we manipulated the Justices' attributes of gender, seniority, and nominating political party.</p><p>We found that (1) the Justice's gender has a significant impact on Advocate politeness: Advocates are more polite toward female Justices; (2) Advocate coordination changes significantly in response to the context invoked by male vs. female Justices. We also found weak evidence that Advocate coordination and politeness change in response to the context invoked by Chief vs. non-Chief Justices.</p><p>Our method extends a line of work of leveraging LMs for causal inference with observational text data <ref type="bibr" target="#b17">(Keith et al., 2020;</ref><ref type="bibr" target="#b30">Veitch et al., 2020;</ref><ref type="bibr" target="#b25">Pryzant et al., 2021;</ref><ref type="bibr" target="#b6">Feder et al., 2022)</ref>, which has predominantly studied the causal effects of different linguistic properties (treatment) on some non-textual outcome, whereas we manipulate speaker attributes (treatment) and study their effect on language as an outcome. We address the problem of confounding (variables that affect both treatment and outcome) by: (a) tight control of contexts as legal court arguments; and (b) verification that our method of GPT2 fine-tuning and attribute-conditioned generation is both faithful in content to the original, and captures real-world differences in expression pertaining to our attributes of interest.</p><p>Our proposed counterfactual framework can be further applied to other conversations such as online discussions <ref type="bibr" target="#b1">(Danescu-Niculescu-Mizil et al., 2012)</ref>, interviews <ref type="bibr" target="#b10">(Fu et al., 2016)</ref> and congressional records <ref type="bibr" target="#b12">(Gentzkow et al., 2018)</ref>, to investigate the effect of attribute groups in various scenarios; and to other sociolinguistic phenomena, such as persuasion <ref type="bibr" target="#b4">(Dimitrov et al., 2021)</ref> in order to explore additional perspectives on the social dynamics in conversations.</p><p>While current debiasing research (Wang et al., 2020; <ref type="bibr" target="#b16">Kaneko and Bollegala, 2021;</ref><ref type="bibr" target="#b13">Guo et al., 2022)</ref> is focused on the semantic level (i.e. unwarranted associations between attributes and content), our study shows that LMs also capture subtle sociolinguistic biases (i.e. coordination and politeness). We hope our counterfactual framework spurs future work on evaluating fairness and bias from a sociolinguistic perspective.</p><p>6 Ethical Discussion</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Potential Bias</head><p>We conduct our counterfactual analysis using LMs, which have been proven to be biased <ref type="bibr" target="#b22">(Nadeem et al., 2021;</ref><ref type="bibr" target="#b3">Delobelle et al., 2022)</ref>. The generated results might contain inherited bias from the pre-trained language models. This could introduce confounds in the generated responses: (1) LMs might be a prior more likely to (not) generate selective politeness/coordination markers due to exposure in the training data. <ref type="foot" target="#foot_9">11</ref> (2) Historical biases -as LMs were predominantly trained on contemporary language leading to a temporal confound where predictions on earlier data points might be noisier than those for more recent SCOTUS discussions. We acknowledge that this could further bring undetected harm in analyzing Advocate court behaviors, especially in the counterfactual setting.</p><p>Our analysis is based on groups of speakers who share an attribute value, and makes no claims about the content/professional level, nor on individuals. Although our framework could generate intermediate results for individual Justices and, in theory, could derive personal conclusions in court, we strongly caution against this.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Human annotations</head><p>To test the content validity of GPT2, we recruited two native-speakers with social science backgrounds not involved in this project through the authors' contacts. We did not record any personal information (e.g. demographics). Authors were debriefed in full after completion of the task, and paid an hourly rate of USD$38, which far exceeds the local minimum pay rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Limitations</head><p>For modeling speaker behavior, we consider social cues based on coordination and politeness. Other dimensions, such as sentiment <ref type="bibr" target="#b7">(Feldman, 2013)</ref>, persuasion <ref type="bibr" target="#b4">(Dimitrov et al., 2021)</ref>, or rate of interruption <ref type="bibr" target="#b5">(Epstein et al., 2010)</ref>, could be further ex-plored to better understand social dynamics in the courtroom. It would also be interesting to explore the interactions among the proposed sociolinguistic perspectives. Also, we focus on the responses from Advocates toward Justices. A study from the other direction could complement this work, and aid in better understanding the dynamics of legal oral arguments. What's more, another type of speaker, e.g. amici curiae ("friends of the court") has been shown to have influences on legal judgments <ref type="bibr" target="#b28">(Sim et al., 2015)</ref> and is also worthy of investigation.</p><p>All experiments were based on GPT2 <ref type="bibr" target="#b26">(Radford et al., 2019)</ref>. There is room for exploration of pretrained language models, such as GPT3 <ref type="bibr" target="#b9">(Floridi and Chiriatti, 2020)</ref>, ChatGPT, BART <ref type="bibr" target="#b19">(Lewis et al., 2020)</ref>, or T5 <ref type="bibr" target="#b27">(Raffel et al., 2022)</ref>. In natural language generation, current work <ref type="bibr">(Wu et al., 2020;</ref><ref type="bibr" target="#b14">Hu and Li, 2021)</ref> has introduced casual models to generate counterfactual text, and this could further aid the analysis of the impacts of different social factors.</p><p>Our study is based on a subset of SCOTUS cases. 12 While they have similar statistics to full cases, they do not reflect the full conversation history of the US Supreme Court or represent the current state of the court. Also, all claims in this paper are bound to this specific use case. They are not generalizable to other SCOTUS parties, legal systems, social strategies, etc. Additionally, although, in preliminary experiments, we applied a temporal train/test split (holding out the final year, I.e. 2019, as test data) and verified that the general pattern of results (i.e. perplexity) is identical in both the random and the temporal split, temporal effects on SCOTUS cases, especially from a sociolinguistic perspective, would be worthy for further investigation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A The SCOTUS data set</head><p>Cases were removed if: (i) voting results of individual Justices were missing; or (ii) the side of the Advocate (petitioner or respondent) was unavailable; or (iii) the case was associated with more than one sitting. When constructing pairs of Justice-Advocate turns where the Justice utterance is directly followed by an Advocate utterance, we disregard the first four utterances per sitting, as they largely consist of legal boilerplate text.</p><p>We removed all nonlinguistic information from the transcripts, including indicators of cross-talk (e.g., [voice overlap], [interruption]), nonverbal expressions (e.g., [laughter], [sighs], [applause]), and procedural markers (e.g., <ref type="bibr">[luncheon], [recess]</ref>). The full list will be made available as part of the code repository.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Fine-tune Configuration</head><p>For our experiments, we used GPT2-small, 13 with 124M parameters. We fine-tuned the GPT2 model on our training data for 50 epochs, using the AdamW optimizer with a learning rate of 5e-5 and a batch size of 2. We select the model that performs the best in the Justic-Advocate pairs on the dev set based on perplexity.</p><p>Overall, it took approximately 24h to fine-tune the GPT2 model on one NVIDIA A100 40GB GPU.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Further Validation of Coordination and Politeness in GPT2 Responses</head><p>We present an extended set of results for Experiment 1 (Section 3), involving an additional four binary attributes: (1) Advocate's side (respondents; petitioner), (2) Advocate wins (the final voting result is in favor of the side of the Advocate; or not), (3) Advocate direction (liberal, conservative), and (4) Justice against Advocate (the Justice votes eventually against the side of the Advocate; or not).</p><p>Figure <ref type="figure" target="#fig_4">4</ref> shows the comparison of real scores derived from the SCOTUS data (purple) vs. factual GPT2-generated responses (green) for coordination (4a) and politeness (4b), respectively. With the exception of "Advocate side" in coordination (leftmost block in Figure <ref type="figure" target="#fig_4">4a</ref>), factual GPT2-generated responses align with the real differences. This is in line with our results for attributes gender, party, and seniority in Section 3, and confirms the capability of the fine-tuned GPT2 model to capture coordination and politeness in Advocates' responses toward Justices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Generated Samples</head><p>We provide two example contexts with real, factual generated and counterfactually generated responses. Figure <ref type="figure" target="#fig_5">5</ref> involves a question asked by a male non-chief judge, and Figure <ref type="figure" target="#fig_7">6</ref> involves a female non-chief judge. For, each we provide two counterfactual responses where we flip the justice attributes gender and seniority, respectively. We also label politeness indicators with underlining and corresponding index in the list of politeness markers from <ref type="bibr" target="#b2">Danescu-Niculescu-Mizil et al. (2013)</ref>   As shown in Figure <ref type="figure" target="#fig_8">7</ref>, to study the confounds in pretrained LMs, we investigate the breakdown coordination scores for markers with Advocates towards male vs. females Justices.</p><p>For every coordination marker, the GPT2generated ratio for male vs. female corresponds to the real-world relative prevalence observed in the SCOTUS data. In addition, the absolute prevalence per gender was comparable between real and generated texts for all categories except the use of adverbs, where GPT2 generates significantly more adverbs than were observed in the text (likely a reflection of the less institutional language that dominates the GPT2 training data).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Annotation Instructions for Evaluating Legal Court Advocates' Responses</head><p>The goal of this annotation project is to evaluate the "quality" of conversations in a court room along a variety of criteria. Specifically, you will rate the quality of an advocate's response to a preceding justice's turn. This document includes two sections: Annotation Instructions and Rating Explanations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.1 Annotation Instructions</head><p>You will be provided with excerpts from the US supreme court transcripts. Each excerpt contains three parts:</p><p>1. Previous context of 2-6 utterances preceding Justice's turn.</p><p>2. Justice's turn. The (3) advocate's response is the part that you will evaluate. More specifically, two advocates' responses are provided, and your task is to compare the two advocate's responses based on the Previous context and Justice's turn, with the evaluation metrics defined in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2 Rating Explanations</head><p>We detail the rating metrics for pairwise evaluation on the advocate's responses in Table <ref type="table">4</ref>.</p><p>Preceding context: [ADVRES] Mr. Chief Justice, and may it please the Court: This is an obstacle preemption case masquerading as a field preemption case. There is no field preemption here because of the undisputed fact that the Nuclear Regulatory Commission does not and cannot regulate any aspect of uranium mining, including the safety aspects of uranium mining. And there is no obstacle preemption here because the Atomic Energy Act and the Nuclear Regulatory Commission have repeatedly reaffirmed that states have the ability to regulate mining up to and including by banning it altogether. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Real response to [KAVANAUGH]</head><p>[ADVRES] Justice Kavanaugh, there's a way -the in situ leaching process, they literally occur at the same time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Factual GPT2 to [KAVANAUGH]</head><p>[ADVRES] We4,9 assume2,4 that the states aren't going to misstate their reasons for doing something. But16 I10 will tell you12 that it is a lot more difficult18 for a state to, for example, rezone all land that nuclear activity is taking place on as residential, even if it's totally unsuitable for residential dwelling, if they know they're going to have to come forward and justify that. And16 may2 I10 finish the second point, Your12 Honor17?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Counterfactual GPT2 to [KAVANAUGH] → [KAGAN]</head><p>[ADVRES] That's correct17. And16 -and -and that'sthat's exactly what the NRC has said. It has said that it has the authority to regulate the milling and the -and the operation of the plant. And16, in fact5, it has done so in a number of ways. First of all, it's done so on a case-bycase basis. The NRC does not have the authority under the Clean17 Air Act or the Clean17 Water Act to regulate all of the operations of a nuclear plant. That's not the case here. This is not a case where there is a single federal regulation of the entire operation of a plant.  We don't know it. We were not able to get it from Blue Cross at the time the case was before the district judge. But in any event, as the Chief Justice's question suggests, the -this issue doesn't end at Vermont. It -it has to take account of a burden that Congress was very, very aware of, it was very cognizant of the regime under the Repeal Disclosure Act, [. . . ] Just as if -if Vermont decides next week, if it wins this case, that it wants to get information about pension plans, and how they're being administered, and what benefits are being provided and not provided, those are all 100 percent self-funded plans. If my employer has to provide all that information, that is coming out of my 401(k) benefits.</p><p>Justice turn: [KAGAN] Mr. Waxman, could a State pass a tax law that requires information about -about pension disbursements, about claim payments, about assets held in trust? Could a State do that?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Real response to [KAGAN]</head><p>[ADVRES] I4,11 don't think2,4 that a State -when you12're saying requested information or imposing18 a tax?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Factual GPT2 to [KAGAN]</head><p>[ADVRES] stuff that they are asking for is so obviously critical18 to what the plan does.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Counterfct'l GPT2 to [KAGAN] → [BADER-GINSBURG]</head><p>[ADVRES] Yes, Your12 Honor17. I11 -I11 don't believe that that would be preempted by ERISA. And16 I4 think2,4 that the -the key point here is that this is not an ERISA plan. This is a plan that is created by the Federal government. The Federal government is the one that created the plan here, and it's the only one that has the authority to create a plan here. And16 so I4 think2,4 it's -it's very important17 to understand that this plan is not a plan for the benefit17 of the -of the plan participants. That is, it's a plan to provide benefits17 to people who are already covered by the plan, and that's what Congress was trying to do when it passed the ERISA statute. Congress wanted to make sure that people who were already covered under the plan would get the benefits17 they were entitled to. So16 it's not like17 a plan where the plan participant is going to have to pay all of the costs</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Counterfct'l GPT2 to [KAGAN] → [REHNQUIST]</head><p>[ADVRES] No, I10 don't believe so, Your12 Honor17. I4,11 don't think2,4 that that would be preempted by ERISA. ERISA preempts State laws that regulate ERISA plans.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Coordination and politeness scores in Advocates' responses to factual Justices. Gender: (m=Male, f=Female); Nominating party: (d=Democrat, r=Republican); Seniority (c=Chief jst, nc=Non-Chief). The coordination and politeness scores are scaled by 100 and 10 for clarity, respectively, and the same scaling applies to the following Figures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Coordination and politeness scores in Advocate responses to counterfactually-manipulated Justices. x-labels as in Figure 2. Colors indicate attribute-specific contexts. Shading indicates Justice attribute value. Pairwise significant differences according to Welch's t-test at p&lt;0.1 (*) and p&lt;0.05 (**).</figDesc><graphic coords="4,309.60,71.59,104.31,105.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>13 https://huggingface.co/gpt2 r p r p w l w l l c l c n y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Expanded experiments on coordination and politeness scores in Advocates' responses toward factual Justices. Advocate side: (r=respondent, p=petitioner); Advocate win: (w=Win, l=Lose); Advocate direction: (l=Liberal, c=Conservative); Justice against Advocate: (y=Yes, n=No).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Example 1 with context, Justice question (top) and real, factual-generated and two counterfactually generated Advocate answers (bottom). The factual Justice is [KAVANAUGH] (male, non-chief) who is counterfactually replaced with [KAGAN] (female, non-chief) and [REHNQUIST] (male, chief), respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Preceding context: [BADER-GINSBURG] And do we know -do we know what costs Blue Shield then passes on to those other self-insured plans?[ADVRES]  </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Example 2 with context, Justice question (top) and real, factual-generated and two counterfactually generated Advocate answers (bottom). The factual justice is [KAGAN] (female, non-chief) who is counterfactually replaced with [BADER-GINSBURG] (female, non-chief) and [REHNQUIST] (male, chief).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Breakdown coordination scores for markers in Advocates' responses toward male vs. female Justices.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Human preferences of Relevance (Rel), Informativeness (Info) and Consistency (Cons).</figDesc><table><row><cell></cell><cell cols="2">Factual (Exp 1)</cell><cell cols="2">C'factual (Exp 2)</cell></row><row><cell>Preference</cell><cell>Rel</cell><cell>Info Cons</cell><cell>Rel</cell><cell>Info Cons</cell></row><row><cell cols="5">None 0.88 0.53 0.71 0.77 0.43 0.52</cell></row><row><cell cols="5">Real 0.04 0.37 0.14 0.07 0.23 0.16</cell></row><row><cell cols="5">Generated 0.08 0.10 0.14 0.16 0.34 0.32</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc></figDesc><table /><note><p><p>(right)  </p>confirms that annotators did not prefer real responses over generated ones</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Tianlu Wang, Xi Victoria Lin, Nazneen Fatema Rajani, Bryan McCann, Vicente Ordonez, and Caiming Xiong. 2020. Double-hard debias: Tailoring word embeddings for gender bias mitigation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5443-5453, Online. Association for Computational Linguistics.</figDesc><table><row><cell>Yiquan Wu, Kun Kuang, Yating Zhang, Xiaozhong Liu,</cell></row><row><cell>Changlong Sun, Jun Xiao, Yueting Zhuang, Luo Si,</cell></row><row><cell>and Fei Wu. 2020. De-biased court's view gener-</cell></row><row><cell>ation with causality. In Proceedings of the 2020</cell></row><row><cell>Conference on Empirical Methods in Natural Lan-</cell></row><row><cell>guage Processing (EMNLP), pages 763-780, Online.</cell></row><row><cell>Association for Computational Linguistics.</cell></row><row><cell>Yang Xu, Jeremy Cole, and David Reitter. 2018. Not</cell></row><row><cell>that much power: Linguistic alignment is influenced</cell></row><row><cell>more by low-level linguistic features rather than so-</cell></row><row><cell>cial power. In Proceedings of the 56th Annual Meet-</cell></row><row><cell>ing of the Association for Computational Linguis-</cell></row><row><cell>tics (Volume 1: Long Papers), pages 601-610, Mel-</cell></row><row><cell>bourne, Australia. Association for Computational</cell></row><row><cell>Linguistics.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>in Table3.</figDesc><table><row><cell>0</cell><cell>"Please"</cell><cell>1</cell><cell>"Please start"</cell><cell>2</cell><cell>"Hashedge"</cell></row><row><cell>3</cell><cell>"Indirect (btw)"</cell><cell>4</cell><cell>"Hedges"</cell><cell>5</cell><cell>"Factuality"</cell></row><row><cell>6</cell><cell>"Deference"</cell><cell>7</cell><cell>"Gratitude"</cell><cell>8</cell><cell>"Apologizing"</cell></row><row><cell>9</cell><cell>"1st person pl."</cell><cell cols="2">10 '1st person"</cell><cell cols="2">11 "1st person start"</cell></row><row><cell cols="2">12 "2nd person"</cell><cell cols="2">14 "2nd person start"</cell><cell cols="2">13 "Indirect (greeting)"</cell></row><row><cell cols="2">15 "Direct question"</cell><cell cols="2">16 "Direct start"</cell><cell cols="2">17 'Positive lexicon"</cell></row><row><cell cols="2">18 "Negative lexicon"</cell><cell cols="2">19 "Counterfactual modal"</cell><cell cols="2">20 "Indicative modal"</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>List of politeness markers from<ref type="bibr" target="#b2">Danescu-Niculescu-Mizil et al. (2013)</ref>. See Table3in the cited paper for details and explanations.</figDesc><table><row><cell>Overall, compared to real advocate responses,</cell></row><row><cell>GPT2-generated responses contain more politeness</cell></row><row><cell>indicators. Compared to responses toward male jus-</cell></row><row><cell>tices, generated responses toward female justices</cell></row><row><cell>exhibit more politeness strategies.</cell></row><row><cell>E Breakdown Coordination Scores for</cell></row><row><cell>Markers in Advocates' Responses</cell></row><row><cell>toward Male vs. Female Justices</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>[KAVANAUGH]  They -they can regulate milling, correct? [ADVRES] Excuse me, I want to make -the federal government regulates milling -[KAVANAUGH] Right.[ADVRES] -Justice Kavanaugh, yes.</figDesc><table><row><cell>Justice turn: [KAVANAUGH] Yeah. So the mining and</cell></row><row><cell>milling occur together, correct? In other words [. . . ] you</cell></row><row><cell>don't have mining without milling; you don't have milling</cell></row><row><cell>without mining</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>https://convokit.cornell.edu/documentation/supreme.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>See Appendix A for data construction details.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>Note that while the distinction is not strictly necessary for the experiments, it is intuitive that social alignment is impacted by the position of the conversation partner. See Appendix C for a detailed analysis of advocates' attributes.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>https://convokit.cornell.edu/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>E.g., auxiliaries, conjunctions, or quantifiers;  cf., Danescu-Niculescu-Mizil et al. (2012)  for full list.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5"><p>E.g, greetings, apologies or hedges; cf.<ref type="bibr" target="#b2">Danescu- Niculescu-Mizil et al. (2013)</ref> for the full list.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_6"><p>Analogously we obtain y jst= m|f and y jst= f |f by manipulating Justice groups in female contexts {cxt} f .</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_7"><p>Appendix C presents further evidence for this, over 7 personal attributes across Advocates and Justices. (a) Coordination. (b) Politeness.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_8"><p>Example pairs of real and generated responses are in Appendix D. Preferences are again not significantly different from random (Binomial, p&gt;0.05).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_9"><p>We investigate coordination scores under breakdown markers in Appendix E, with Advocates towards male vs. female Justices as an example.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">ConvoKit: A toolkit for the analysis of conversations</title>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">P</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caleb</forename><surname>Chiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liye</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justine</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting>the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="57" to="60" />
		</imprint>
	</monogr>
	<note>1st virtual meeting</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Echoes of power: Language effects and power differences in social interaction</title>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jon</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Chang</surname></persName>
		</author>
		<idno type="DOI">10.1145/2187836.2187931</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International 12 We extract a subset form the Covokit dataset</title>
		<meeting>the 21st International 12 We extract a subset form the Covokit dataset<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2012">2012. 2020</date>
			<biblScope unit="page" from="699" to="708" />
		</imprint>
	</monogr>
	<note>Conference on World Wide Web, WWW &apos;12</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A computational approach to politeness with application to social factors</title>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Sudhof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="250" to="259" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Measuring fairness with biased rulers: A comparative study on bias metrics for pre-trained language models</title>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Delobelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ewoenam</forename><surname>Tokpo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toon</forename><surname>Calders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bettina</forename><surname>Berendt</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.naacl-main.122</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Seattle, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1693" to="1706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">SemEval-2021 task 6: Detection of persuasion techniques in texts and images</title>
		<author>
			<persName><forename type="first">Dimitar</forename><surname>Dimitrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Bishr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaden</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Firoj</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabrizio</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamed</forename><surname>Silvestri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preslav</forename><surname>Firooz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giovanni</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">San</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName><surname>Martino</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.semeval-1.7</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)</title>
		<meeting>the 15th International Workshop on Semantic Evaluation (SemEval-2021)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="70" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Inferring the winning party in the Supreme Court from the pattern of questioning at oral argument</title>
		<author>
			<persName><forename type="first">Lee</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">M</forename><surname>Landes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">A</forename><surname>Posner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Legal Studies</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="433" to="467" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Causal inference in natural language processing: Estimation, prediction, interpretation and beyond</title>
		<author>
			<persName><forename type="first">Amir</forename><surname>Feder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><forename type="middle">A</forename><surname>Keith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emaad</forename><surname>Manzoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reid</forename><surname>Pryzant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhanya</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zach</forename><surname>Wood-Doughty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Grimmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><forename type="middle">E</forename><surname>Roberts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1138" to="1158" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Techniques and applications for sentiment analysis</title>
		<author>
			<persName><forename type="first">Ronen</forename><surname>Feldman</surname></persName>
		</author>
		<idno type="DOI">10.1145/2436256.2436274</idno>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="82" to="89" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Towards unified dialogue system evaluation: A comprehensive analysis of current evaluation protocols</title>
		<author>
			<persName><forename type="first">Sarah</forename><forename type="middle">E</forename><surname>Finch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinho</forename><forename type="middle">D</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting>the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
	<note>st virtual meeting</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">GPT-3: Its nature, scope, limits, and consequences</title>
		<author>
			<persName><forename type="first">Luciano</forename><surname>Floridi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Chiriatti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Minds and Machines</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="681" to="694" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Tie-breaker: Using language models to quantify gender bias in sports journalism</title>
		<author>
			<persName><forename type="first">Liye</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IJCAI workshop on NLP meets Journalism</title>
		<meeting>the IJCAI workshop on NLP meets Journalism</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Facilitating the communication of politeness through fine-grained paraphrasing</title>
		<author>
			<persName><forename type="first">Liye</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><surname>Fussell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.416</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5127" to="5140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Congressional record for the 43rd-114th congresses: Parsed speeches and phrase counts</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Gentzkow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><forename type="middle">M</forename><surname>Shapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Taddy</surname></persName>
		</author>
		<ptr target="https://data.stanford.edu/congresstext" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Autodebias: Debiasing masked language models with automated biased prompts</title>
		<author>
			<persName><forename type="first">Yue</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Abbasi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.72</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1012" to="1023" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A causal lens for controllable text generation</title>
		<author>
			<persName><forename type="first">Zhiting</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Erran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="24941" to="24955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Causal inference in statistics, social, and biomedical sciences</title>
		<author>
			<persName><forename type="first">W</forename><surname>Guido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><forename type="middle">B</forename><surname>Imbens</surname></persName>
		</author>
		<author>
			<persName><surname>Rubin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Debiasing pre-trained contextualised embeddings</title>
		<author>
			<persName><forename type="first">Masahiro</forename><surname>Kaneko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danushka</forename><surname>Bollegala</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.eacl-main.107</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1256" to="1266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Text and causal inference: A review of using text to remove confounding from causal estimates</title>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Keith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan O'</forename><surname>Connor</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.474</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5332" to="5344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The echo effect: The power of verbal mimicry to influence prosocial behavior</title>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dariusz</forename><surname>Dolinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avia</forename><surname>Huisman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Majewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Language and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="183" to="201" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdelrahman</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.703</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7871" to="7880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Studying politeness across cultures using english twitter and mandarin weibo</title>
		<author>
			<persName><forename type="first">Mingyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis</forename><surname>Hickman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lyle</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharath</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guntuku</forename></persName>
		</author>
		<idno type="DOI">10.1145/3415190</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Analyzing the effect of entrainment on dialogue acts</title>
		<author>
			<persName><forename type="first">Masahiro</forename><surname>Mizukami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koichiro</forename><surname>Yoshino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Traum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satoshi</forename><surname>Nakamura</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W16-3640</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting>the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue<address><addrLine>Los Angeles</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="310" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">StereoSet: Measuring stereotypical bias in pretrained language models</title>
		<author>
			<persName><forename type="first">Moin</forename><surname>Nadeem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Bethke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.416</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5356" to="5371" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Centre stage: How social network position shapes linguistic coordination</title>
		<author>
			<persName><forename type="first">G</forename><surname>Kate</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">W</forename><surname>Niederhoffer</surname></persName>
		</author>
		<author>
			<persName><surname>Pennebaker</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/W15-1104</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Workshop on Cognitive Modeling and Computational Linguistics</title>
		<meeting>the 6th Workshop on Cognitive Modeling and Computational Linguistics<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002. 2015</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="29" to="38" />
		</imprint>
	</monogr>
	<note>Bill Noble and Raquel Fernández. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Causality</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Causal effects of linguistic properties</title>
		<author>
			<persName><forename type="first">Reid</forename><surname>Pryzant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dallas</forename><surname>Card</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Veitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhanya</forename><surname>Sridhar</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.323</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4095" to="4109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The utility of text: the case of amicus briefs and the supreme court</title>
		<author>
			<persName><forename type="first">Yanchuan</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Bryan R Routledge</surname></persName>
		</author>
		<author>
			<persName><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-Ninth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Linguistic style matching and negotiation outcome</title>
		<author>
			<persName><forename type="first">J</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sally</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Negotiation and conflict management research</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="263" to="281" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Adapting text embeddings for causal inference</title>
		<author>
			<persName><forename type="first">Victor</forename><surname>Veitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhanya</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Blei</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Uncertainty in Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="919" to="928" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
