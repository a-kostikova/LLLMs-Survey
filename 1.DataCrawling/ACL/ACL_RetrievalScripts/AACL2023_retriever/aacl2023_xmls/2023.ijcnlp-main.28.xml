<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DisCGen: A Framework for Discourse-Informed Counterspeech Generation</title>
				<funder ref="#_h7gtG9q #_7bFcqfd">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_nf8Cu4w">
					<orgName type="full">DARPA</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sabit</forename><surname>Hassan</surname></persName>
							<email>sabit.hassan@pitt.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing and Information</orgName>
								<orgName type="institution">University of Pittsburgh</orgName>
								<address>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Malihe</forename><surname>Alikhani</surname></persName>
							<email>m.alikhani@northeastern.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Khoury College of Computer Science</orgName>
								<orgName type="institution">Northeastern University</orgName>
								<address>
									<settlement>Boston</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DisCGen: A Framework for Discourse-Informed Counterspeech Generation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">07D4E91225B48219F5E9F9B20B97B5B3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-05-29T14:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Counterspeech can be an effective method for battling hateful content on social media. Automated counterspeech generation can aid in this process. Generated counterspeech, however, can be viable only when grounded in the context of topic, audience and sensitivity as these factors influence both the efficacy and appropriateness. In this work, we propose a novel framework based on theories of discourse to study the inferential links that connect counter speeches to the hateful comment. Within this framework, we propose: i) a taxonomy of counterspeech derived from discourse frameworks, and ii) discourse-informed prompting strategies for generating contextually-grounded counterspeech. To construct and validate this framework, we present a process for collecting an in-the-wild dataset of counterspeech from Reddit. Using this process, we manually annotate a dataset of 3.9k Reddit comment pairs for the presence of hatespeech and counterspeech 1 . The positive pairs are annotated for 10 classes in our proposed taxonomy. We annotate these pairs with paraphrased counterparts to remove offensiveness and first-person references. We show that by using our dataset and framework, large language models can generate contextually-grounded counterspeech informed by theories of discourse. According to our human evaluation, our approaches can act as a safeguard against critical failures of discourseagnostic models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A promising countermeasure to hatespeech is counterspeech <ref type="bibr">(Mathew et al., 2018b)</ref> -any response that counters hateful and offensive content, at times referred to as Counter-Narrative <ref type="bibr" target="#b15">(Fanton et al., 2021)</ref>. Counterspeech do not appear in isolation, but as an integral component of a broader discourse. In this work, we leverage theories of discourse <ref type="bibr" target="#b2">(Asher and Lascarides, 2005)</ref> to capture the context that the counterspeech appears in.</p><p>The interpretation of a counterspeech is shaped by its relevance to the topic, its intended audience, and its sensitivity to the matter. For instance, a counterspeech posing a Probing Question might resonate differently with an audience compared to one providing a Correction. We propose a discourse-aware framework, DisCGen, to study these different types of counter speeches and how we can potentially generate them automatically. DisCGen consists of a taxonomy of counterspeech based on discourse relations and discourse-augmented prompting strategies. The taxonomy is derived from Segmented Discourse Representation Theory (SDRT) <ref type="bibr" target="#b2">(Asher and Lascarides, 2005)</ref>.</p><p>Since there is no existing counterspeech dataset with discourse relations, we construct the first dataset from Reddit to construct and validate our framework. We choose Reddit as the data source as in-the-wild data from Reddit is likely to have more diversity compared to Nichesourced or Crowdsourced datasets that contain counterspeech written by NGO workers <ref type="bibr" target="#b9">(Chung et al., 2019)</ref> or Mechanical Turk annotators <ref type="bibr" target="#b29">(Qian et al., 2019)</ref>. Diversity in the dataset is important to demonstrate the flexibility of our framework.</p><p>Constructing an in-the-wild dataset, however, is challenging as the percentage of comments forming hatespeech-counterspeech pairs is very small on Reddit. As such, we follow a two-stage process for collecting effective counterspeech in-the-wild. We manually annotate a dataset 3.9K Reddit comment pairs for the presence of hatespeech-counterspeech pairs. We manually annotate 250 positive pairs of hatespeech-counterspeech with SDRT relations. We paraphrase the counterspeech manually to remove profanity and first-person references while retaining the original content and linguistic style. We also annotate the positive samples with the tar-geted group in the hateful comment. While the full dataset can be used for identifying effective counterspeech, the positive pairs can be used with our framework for counterspeech generation.</p><p>Lastly, we combine the proposed discoursebased taxonomy with prompting strategies in our framework. We compare Large Language Models (LLMs) under different settings. In the first setting, discourse relations are provided for both the examples in the prompt and for the inference text. In the second scenario, discourse relations are provided only for the prompt examples. These models are compared with a baseline discourse agnostic approach. Our analysis shows greater diversity in discourse relations preserved in the discourseinformed approach compared to discourse-agnostic prompting. We show that, in both discourseinformed settings, LLMs are capable of generating highly accurate counterspeeches ( &gt;95% cases) and also respect corresponding discourse relations (74% and 90% for the two strategies respectively). Further, our human evaluation shows that our strategies can act as safeguard against critical failures that discourse-agnostic LLMs are susceptible to. Thus, the contributions of this paper are:</p><p>• A novel framework for discourse-aware counterspeech generation that comprises of: i) a discourse-based taxonomy of counterspeech and ii) discourse-informed prompting strategies.</p><p>• A process for collecting an in-the-wild dataset of effective counterspeech from Reddit.</p><p>• First dataset of 3.9K pairs of Reddit comments annotated for hatespeech-counterspeech, with 250 positive pairs annotated for: i) taxonomy derived from SDRT, ii) paraphrasing removing offensiveness and first-person references, and iii) target group that the hateful attacks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>While offensive content on social media has gained much recent interest <ref type="bibr" target="#b34">(Ye et al., 2023)</ref>, work on counterspeech is still under-explored. <ref type="bibr" target="#b5">Benesch et al. (2016)</ref> conduct a field study of counterspeech on Twitter and list eight associated strategies from a social angle. The nichesourced CONAN <ref type="bibr" target="#b9">(Chung et al., 2019)</ref> dataset and its subsequent variations <ref type="bibr" target="#b15">(Fanton et al., 2021;</ref><ref type="bibr" target="#b7">Bonaldi et al., 2022)</ref>, contain counterspeech written by NGO workers. A few recent works have studied counterspeech generation. <ref type="bibr" target="#b6">Bonaldi et al. (2023)</ref> propose an attention based regularization with GPT-2 to generate more specific counter narratives. <ref type="bibr" target="#b37">Zhu and Bhat (2021)</ref> first generate multiple candidates, filter out ungrammatical ones, and then selects the most relevant countersppech. <ref type="bibr" target="#b10">Chung et al. (2021)</ref> study generation of knowledge-grounded counternarratives using an external database. <ref type="bibr" target="#b3">Ashida and Komachi (2022)</ref> show the effectiveness of prompting large language models (LLMs) for generating counterspeech. <ref type="bibr" target="#b30">Vallecillo-Rodríguez et al. (2023)</ref> show that GPT-3 is more capable of generating counter narratives compared to other large language models. Ours is the first work to provide a framework for discourse-aware counterspeech generation.</p><p>Discourse relations have been proposed as a mechanism for controlling generation, shown to aid summarization <ref type="bibr" target="#b11">(Cohan et al., 2018;</ref><ref type="bibr" target="#b32">Xu et al., 2020)</ref>, style transfer <ref type="bibr" target="#b4">(Atwell et al., 2022)</ref>, and question answering <ref type="bibr" target="#b18">(Huang et al., 2021;</ref><ref type="bibr" target="#b31">Xu et al., 2022)</ref>. <ref type="bibr" target="#b8">Bosselut et al. (2018)</ref> show that discourse-aware models can generate more coherent texts. None of the aforementioned works however, target counterspeech generation. To our knowledge, our work is also the first to integrate discourse-based framework within prompting strategies for LLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Framework</head><p>Our framework consists of a discourse-based taxonomy and two prompting strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Discourse-based Taxonomy</head><p>The style and efficacy of counterspeech is often dictated by its context, which is typically offensive or hateful content. Thus, we aim to identify different types of counterspeech through the lens of discourse relations. For the remainder of the paper, we use hatespeech as an umbrella term for offensive/hateful content.</p><p>With the help of linguist annotators, we explored ways different discourse theories such as Penn Discourse Treebank (PDTB) <ref type="bibr" target="#b28">(Prasad et al., 2008)</ref>, Rhetorical Structure Theory (RST) <ref type="bibr" target="#b23">(Mann and Thompson, 1988)</ref> and Segmented Discourse Representation Theory (SDRT) <ref type="bibr" target="#b2">(Asher and Lascarides, 2005)</ref> might help us study the inferential links that connect hateful comments with counterspeech. Our initial investigation informed us that SDRT labels could closely model these inferential links. Thus, we decide to choose SDRT as primary source for our taxonomy.</p><p>We annotate 250 counterspeeches (Section 4) to construct a discourse-based taxonomy of counterspeech that contain 10 classes adapted from SDRT relations defined in <ref type="bibr" target="#b1">Asher et al. (2016)</ref>:</p><p>• Acknowledgment when the counterspeech signals an understanding. While <ref type="bibr" target="#b1">Asher et al. (2016)</ref> include both understanding and acceptance as acknowledgment, acceptance is not considered in our definition as counterspeech should not agree with the hatespeech.</p><p>• Clarification Question when the counterspeech asks questions to clarify information presented in the hatespeech, analogous to <ref type="bibr" target="#b1">Asher et al. (2016)</ref>.</p><p>• Comment when the counterspeech provides an opinion or evaluation of the content in hatespeech, analogous to <ref type="bibr" target="#b1">Asher et al. (2016)</ref>.</p><p>• Correction when the counterspeech corrects an argument/fact presented in the hatespeech, analogous to <ref type="bibr" target="#b1">Asher et al. (2016)</ref>.</p><p>• Elaboration when the counterspeech expands on the scenario presented in the hatespeech. Differing from <ref type="bibr" target="#b1">Asher et al. (2016)</ref>, counterspeech does not elaborate on its own argument, but offers a broader perspective on the hatespeech.</p><p>• Probing question, when the counterspeech asks a question intending to acquire more information, similar to Q-Elab in <ref type="bibr" target="#b1">Asher et al. (2016)</ref>.</p><p>• Explanation when the counterspeech offers an explanation of a situation presented in the hatespeech, similar to <ref type="bibr" target="#b1">Asher et al. (2016)</ref>.</p><p>• Parallel when the counterspeech shows commonality between hatespeech and an external scenario, a special case of <ref type="bibr" target="#b1">Asher et al. (2016)</ref>.</p><p>• Result when the counterspeech connects the consequences to the content of hatespeech. The consequence is a special case of "effect" in <ref type="bibr" target="#b1">Asher et al. (2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Prompting Scenarios</head><p>We propose prompting strategies for two scenarios that use discourse relations in our taxonomy. Strategy 1 is to be applied when there is no prior information about the type of counterspeech that should be generated. The model learns from prompting examples the type of discourse relations it should maintain with respect to context. Strategy 2 is to be applied when the desired discourse relation is known beforehand.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Dataset</head><p>In this section, we first outline our data collection pipeline. Then, we describe our two-stage process for constructing our dataset, followed by annotation protocol and inter-annotator agreement. Lastly, we analyze distributions in our dataset<ref type="foot" target="#foot_1">2</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Collection</head><p>We use Pushshift API<ref type="foot" target="#foot_2">3</ref> to collect comments from 14 subreddits (Appendix ??) spanning topics of politics, personal views, gender rights, and questionanswer across a period of six months, starting from June 1st, 2021. To filter out comments that do not contain hatespeech, we fine-tune a BERT <ref type="bibr" target="#b13">(Devlin et al., 2019)</ref> on the fine-grained hatespeech data in Multitarget CONAN <ref type="bibr">(Fanton et al.</ref>, Figure <ref type="figure">2</ref>: Our process for constructing in-the-wild dataset from Reddit. First set of random samples are annotated for hatespeech-counterspeech. Then we train a classifier to predict counterspeech, and then perform a final round of annotation. We rewrite the counterspeech if it is offensive or first-person. Finally, we annotate for discourse relations and target groups. In the figure, HS refers to hatespeech and CS refers to counterspeech. 2021). The hatespeech segment of the dataset contains 5K fine-grained annotations for the following classes: WOMEN, POC, LGBT+, DISABLED, JEWS, MUSLIMS, MIGRANTS and OTHER. We removed duplicates in the dataset and use 70-10-20 split for train, dev and test data. The classifier achieves an F1 score of 91.02 on the test set. We use the classifier to classify comments. We obtain replies using PRAW 4 for only those tagged with hatespeech with probability &gt; 0.8. The threshold is empirically decided. Discarding comments without replies, we end up with 18K comments. We do not use the counterspeech data in the Multitarget CONAN dataset because using a classifier trained on Nichesourced data would not capture the natural diversity of in-the-wild data.</p><p>Lastly, We take a random sample of 500 from each target group (excluding the OTHER class, for total of 3.5K) and set aside for stage 1 annotation. We take another random sample of 1K from each target group (total of 7K) and set aside for stage 2. Figure <ref type="figure">2</ref> shows our annotation process for the two stages. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">First Stage Annotation</head><p>We manually annotate 3.5K comment pairs for presence of hatespeech and counterspeech. Due to our rigorous annotation protocol (described in section 4.4), we end up with 152 positive pairs. Using this data, we fine-tune a range of pretrained transformer models to detect counterspeech: bertbase-cased, bert-base-uncased <ref type="bibr" target="#b13">(Devlin et al., 2019)</ref>, roberta-base <ref type="bibr" target="#b20">(Liu et al., 2019)</ref>, xlnet-base <ref type="bibr" target="#b33">(Yang et al., 2019)</ref> and albert-base-v2 <ref type="bibr" target="#b19">(Lan et al., 2019)</ref>.</p><p>All models are fine-tuned with the same parameters: learning rate of 8e-5 and batch size of 16 for 5 epochs. The results are reported in Table <ref type="table" target="#tab_2">1</ref>. All positive pairs are annotated for discourse relation and target groups. The counterspeech is also rewritten, if necessary, to remove offensiveness and first-person references.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Second Stage Annotation</head><p>Using the best classifier from Stage 1 (bert-baseuncased), we tag the pool of data set aside for Stage 2. 360 samples are tagged as counterspeech. The pairs containing these 360 samples are manually annotated with the same protocol, yielding 98 more positive pairs. This shows that using this method, we can grow the size of dataset containing counterspeech with much fewer human annotations. This approach can be used in the future to construct larger datasets. Since our purpose in this paper is to construct a dataset for prompting, we consider 250 positive samples to be enough as large language models are prompted in a few-shot setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Annotation Protocol</head><p>We recruit two graduate annotators with linguistic background. The annotators were paid according to the approved rate by the human-subject review board.</p><p>To construct our dataset, we define protocol for four types of annotations: i) hatespeechcounterspeech pair, ii) paraphrasing counterspeech, iii) target group, and iv) discourse relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hatespeech-counterspeech pair:</head><p>To decide if a comment is hatespeech, we ask the annotator to identify if the comment is offensive and targets any of the seven groups in the data. To determine if a reply to the hatespeech is counterspeech, the annotators are asked to assess if the response counters the hatespeech. We ask the annotators to discard any counterspeech that simply uses profanity and are not constructive.</p><p>Target group: The annotators are asked to choose the target group (e.g., migrants/LGBTQ) that the hatespeech attacks. The target groups are defined in <ref type="bibr" target="#b15">(Fanton et al., 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discourse annotation:</head><p>We provide the annotators with the hatespeech and counterspeech and ask to determine which SDRT discourse relations is most applicable between the two. We provide them with the SDRT annotation manual by <ref type="bibr" target="#b1">Asher et al. (2016)</ref>, modified with examples from our dataset. Annotators were also able to choose "unknown/ no-discourse relation present". These instances are excluded from our dataset.</p><p>Paraphrasing counterspeech: Even after discarding counterspeech that just contain profanity, we observe that some constructive counterspeech contain profanity to a degree. Thus, we ask the annotators to remove such profanity. Since our goal is to build dataset for counterspeech generation, we also ask annotator to remove any first-person reference. Both types of edits are made with minimal modification while retaining the original meaning and linguistic style.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Inter-Annotator Agreement (IAA):</head><p>Since the percentage of counterspeech in our data is very small, taking a random overlap of the full dataset would not yield any useful information. Thus, we take a random sample of positive samples as overlap between two annotators.</p><p>Hatespeech-Counterspeech: In 90% of the cases, the annotators agreed that the given pair contained hatespeech and counterspeech. The disagreements were primarily due to one of the annotators misinterpreting context of the hatespeech.</p><p>Target group: The Cohen's Kappa <ref type="bibr" target="#b12">(Cohen, 1960)</ref> for target group annotation was 0.83, showing a high degree of agreement. The only cases where the annotators disagreed were due to presence of multiple target groups in the hatespeech. For example, a hatespeech targetting black women is labeled as "POC" by one annotator and "WOMEN" by the other.</p><p>Discourse relations: The Cohen's Kappa for discourse annotation was 0.62, indicating substantial agreement <ref type="bibr" target="#b27">(McHugh, 2012)</ref>. The lower agreement for discourse annotation is expected due to the difficulty of the task <ref type="bibr" target="#b1">(Asher et al., 2016)</ref>. The primary source of disagreement was confusion between classes that appeared together. For example, a pair often exhibited characteristics of both Comment and Correction classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Dataset Analysis</head><p>Target group distribution: Although we started with the same number of candidates for each group, we observe that after annotation, the data has the highest hatespeech-counterspeech pairs for hatespeech targeting WOMEN. Our manual examination reveals that among the candidate pairs, the classifier often mistook discussions about LGBT+ or POC as hatespeech even though they are not offensive. However, as seen from Figure <ref type="figure" target="#fig_1">3</ref> that the distri-  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discourse relation distribution:</head><p>We observe that the discourse relations Correction and Comment are the most dominant ones in Figure <ref type="figure" target="#fig_2">4</ref>. This is expected from a natural distribution because users are more likely to correct hateful content or denounce them than ask questions or show acknowledgment. Similar to earlier, we see that the distribution remains similar across the two stages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Counterspeech Generation</head><p>In this section, we provide analysis and evaluation of proposed strategies. For all experiments, we use davinci-text-003 version of GPT-3. We use 50 randomly chosen samples as example in the prompts and evaluate the models on the remaining 200 samples of our dataset. In our experiments, baseline GPT-3 is instructed to generate counterspeech for given hatespeech and is compared with the two prompting strategies outlined in Section 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evaluation:</head><p>Evaluation of generated counterspeech is considered a difficult task <ref type="bibr" target="#b3">(Ashida and Komachi, 2022)</ref>. Common generation metrics such as BLEU, BERtScore are not helpful for evaluating counterspeech. As such, we primarily rely on human evaluation similar to past works <ref type="bibr" target="#b3">(Ashida and Komachi, 2022)</ref>.</p><p>For human evaluation, we consider: i) does the generated text count as counterspeech, ii) is the generated text offensive<ref type="foot" target="#foot_3">5</ref> , and iii) for prompting strategy 1 and 2, does the generated text respect discourse relation indicated. Table <ref type="table" target="#tab_3">2</ref> show examples of counterspeech generated by different strategies.</p><p>Accuracy: We observe that in a few cases (6%), the baseline generated text that could not be considered counterspeech as they agreed with the input text instead of countering them (Table <ref type="table" target="#tab_3">2</ref>). Our proposed strategies, however, had fewer such failures (4% and 2% respectively for strategy 1 and strategy 2). This suggests, by explicitly instructing language models with discourse relations, we can avoid pitfalls of generating counterspeech by prompting large language models.</p><p>Offensiveness: Since we removed profanity from our dataset with paraphrases, the generated counterspeech did not display offensiveness toward any groups during human evaluation. We also used an independent classifier, a bert-base-cased model, finetuned on the OLID dataset <ref type="bibr">(Zampieri et al., 2019b)</ref> to tag the generated counterspeech. The classifier tagged 20% of the generated counterspeech as offensive. However, with manual analysis, we observe in most cases, the classifier tagged sensitive topics and text about minority groups as offensive. This is consistent with the observations by <ref type="bibr" target="#b16">Hartvigsen et al. (2022)</ref> that toxic language detection systems can falsely tag text with minority group mentions. Such limitations of classifiers need to be addressed for an unbiased large-scale evaluation of machine-generated counterspeech.</p><p>Diversity We observe that without any instructions about discourse relations, GPT-3 mostly generates counterspeech that are Comment or Correc-  tion. While these two are also the most frequent categories for our strategies, our strategies yield higher frequency of discourse relations such as Q-Elab or Elaboration. Higher diversity is observed when relations are explicitly mentioned in prompting strategy 2. Figure <ref type="figure" target="#fig_3">5</ref> shows the distribution of discourse relations in generated counterspeech.</p><p>Respecting discourse relations: We evaluated if the generated texts by the LLMs respect discourse relations. For the first strategy, 74% counterspeech were generated in the discourse relation that GPT-3 outputs. For the second strategy, 90% of the counterspeech were generated in the explicitly specified discourse style. This suggests specifying desired discourse relations during inference time can be respected well by language models compared to providing discourse relations only in the prompt examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>In this section, we discuss the challenges of counterspeech generation.</p><p>Evaluation: Evaluation of counterspeech remains a challenging task. As our examples show, language models such as GPT-3 mostly produce grammatically correct and coherent texts. As such, automated metrics of grammar and coherence <ref type="bibr" target="#b24">(Marchenko et al., 2020)</ref> are not good indi-cators of the quality of generated counterspeech. Instead, there is a need for automated metrics that can measure the countering capacity of generated text. While the focus of this paper is constructing the framework, dataset and generation capabilities of language models, it is important to conduct a study to evaluate the efficacy of different content in counterspeech among real users in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classifier bias:</head><p>We observed that the initial classifier, trained on the MultiTarget CONAN dataset <ref type="bibr" target="#b15">(Fanton et al., 2021)</ref>, that we used to identify hatespeech candidates, has certain limitations. Although the classifier boasted a 91% F1-score on the test set, it often tagged instances that are not hatespeech but talked about sensitive topics as hatespeech. Although we eliminated this bias by manually excluding them, care must be taken for building datasets using such classifiers. While there has been studies regarding gender and racial exhibited by classifiers recently <ref type="bibr" target="#b0">(Ahn and Oh, 2021;</ref><ref type="bibr" target="#b21">Lu et al., 2020)</ref>, further study is needed to quantify and mitigate this kind of bias. Bias reduction methods for classification tasks <ref type="bibr" target="#b17">(Hassan and Alikhani, 2023)</ref> need to be explored in the context of generation.</p><p>Knowledge Grounding: The focus of this paper has been to construct the first-of-its-kind in-thewild dataset annotated with discourse relations that can be used to control the content when prompt-ing large language models. An aspect of counterspeech generation that is out-of-scope for this paper, but needs to be explored is how facts and knowledge can be injected into the generated counterspeech. Approaches that rely on an external database of knowledge <ref type="bibr" target="#b10">(Chung et al., 2021)</ref> can be used in conjunction with our approach to generate knowledge-grounded counterspeech that respects discourse relations. Approaches such as use of topic phrases <ref type="bibr" target="#b14">(Fan et al., 2019)</ref> can be explored for complementing our discourse-augmented prompting mechanism as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we presented DisCGen, a framework for discourse-informed counterspeech generation. Within this framework, we presented a discourse-based taxonomy of counterspeech and two discourse-informed prompting strategies. Further, we outlined a process for the challenging task of collecting in-the-wild counterspeech from Reddit. Using our methodology, we collected a first-of-its kind dataset that contains hatespeechcounterspeech pairs annotated for discourse relations, paraphrased version of counterspeech and the targeted group in the hatespeech . Our automated and human evaluation show that LLMs can generate accurate and inoffensive counterspeech with our dataset. Our analysis shows that by using our proposed discourse-aware framework, we can control the content of counterspeech generated by large language models with respect to the context. We also show that our proposed approach results in a higher diversity in terms of linguistic style and can serve as a safeguard against critical failures of discourse-agnostic approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>Using classifiers to aid counterspeech classifier may result in bias. However, it is a necessary step for collecting a sizeable dataset as the percentage of counterspeech on social media is extremely low. It should be noted, however, that we manually verify all positive instances tagged by the classifier, eliminating any false-positive bias the classifier may exhibit.</p><p>It should also be noted that the scope of this paper is to present a framework for discourse-aware counterspeech generation, outline a methodology for collecting an in-the-wild dataset, publicly share the dataset, and evaluate LLM's capacity of generat-ing counterspeech with the proposed framework. A large-scale user-study for evaluating the social impact of different types of generated counterspeech is not within the scope of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics Statement</head><p>In certain scenarios, counterspeech can be insensitive to users. Inappropriate counterspeech can hurt the feelings of social media users rather than promote a safer environment. As such, counterspeech generation is aimed to reduce psychological pressure on human moderators and social media users, not replace them. Counterspeech generation should not be used indiscriminately across social media. In an ideal case, the generated counterspeech should be reviewed by a human before posted on social media or elsewhere.</p><p>Although text generated by large language models such as GPT-3 are coherent and relevant, they may exhibit bias toward certain groups such as feminine characters <ref type="bibr" target="#b22">(Lucy and Bamman, 2021)</ref>. If a generated counterspeech exhibits bias towards certain groups, it may have adverse effects. Although we did not observe such behavior with our models, these models needs to be carefully examined for specific use cases before deploying in the real-world.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Our data collection pipeline. Comments and their replies are scraped from Reddit, and then run through a hatespeech classifier. If the classifier confidence falls below threshold α then they are discarded, else their replies are obtained to form pairs. These pairs are randomly split into two buckets for two stages of annotation.</figDesc><graphic coords="4,111.68,70.87,371.90,86.59" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Women as the target group have the highest retention rate. The distribution remains similar across two stages.</figDesc><graphic coords="6,70.87,70.86,218.27,135.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Comment and Correction are the dominating discourse relations. The distribution remains similar across the two stages.</figDesc><graphic coords="6,70.87,263.40,218.26,136.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Distribution of discourse relations in generated counterspeech. Strategy 1 yields higher diversity than baseline while Strategy 2 generates the most diverse counterspeeches.</figDesc><graphic coords="7,74.48,73.28,142.87,134.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Results of finetuning pretrained models to detect counterspeech. bert-base-uncased outperforms all other pretrained transformers.</figDesc><table><row><cell>Model</cell><cell>Acc</cell><cell>Prec</cell><cell>Recall</cell><cell>F1</cell></row><row><cell>bert-base-cased</cell><cell>90.0</cell><cell>58.1</cell><cell>65.0</cell><cell>60.1</cell></row><row><cell>bert-base-uncased</cell><cell>93.1</cell><cell>64.5</cell><cell>69.6</cell><cell>66.6</cell></row><row><cell>roberta-base</cell><cell>95.7</cell><cell>47.9</cell><cell>50.0</cell><cell>48.9</cell></row><row><cell>xlnet-base</cell><cell>86.6</cell><cell>53.4</cell><cell>62.3</cell><cell>53.6</cell></row><row><cell>albert-base-v2</cell><cell>91.4</cell><cell>46.2</cell><cell>49.4</cell><cell>47.8</cell></row></table><note><p>4 https://praw.readthedocs.io/en/stable/</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Our proposed strategies can safeguard against critical failures, generate less generic response and have higher linguistic diversity. While Strategy 1 is more accurate than baseline, Strategy 2 is the most accurate.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Our code and data can be requested from here: https://github.com/sabithsn/DisCGen</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Our data collection was approved by our institution's ethics review board (anonymized for blind review)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://github.com/pushshift/api</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>we refer to definition provided in(Zampieri et al.,  2019a):"any form of non-acceptable language (profanity) or a targeted offense, which can be veiled or direct. This includes insults, threats, and posts containing profane language or swear words"</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgment</head><p>This project was supported by <rs type="funder">DARPA</rs> grant prime OTA No. <rs type="grantNumber">HR00112290024</rs> (subcontract No. <rs type="grantNumber">AWD00005100</rs> and <rs type="grantNumber">SRA00002145</rs>). We also acknowledge the <rs type="institution">Center for Research Computing at the University of Pittsburgh</rs> for providing computational resources. We would also like to thank the human annotators, the anonymous reviewers, and <rs type="person">Katherine Atwell</rs> for their valuable feedback.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_nf8Cu4w">
					<idno type="grant-number">HR00112290024</idno>
				</org>
				<org type="funding" xml:id="_h7gtG9q">
					<idno type="grant-number">AWD00005100</idno>
				</org>
				<org type="funding" xml:id="_7bFcqfd">
					<idno type="grant-number">SRA00002145</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mitigating languagedependent ethnic bias in BERT</title>
		<author>
			<persName><forename type="first">Jaimeen</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alice</forename><surname>Oh</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.42</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Dominican Republic. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="533" to="549" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Discourse structure and dialogue acts in multiparty dialogue: the STAC corpus</title>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Asher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julie</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathieu</forename><surname>Morey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benamara</forename><surname>Farah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stergos</forename><surname>Afantenos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)<address><addrLine>Portorož, Slovenia</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA)</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2721" to="2727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Logics of conversation</title>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Asher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Lascarides</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Studies in natural language processing</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Towards automatic generation of messages countering online hate speech and microaggressions</title>
		<author>
			<persName><forename type="first">Mana</forename><surname>Ashida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mamoru</forename><surname>Komachi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.woah-1.2</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Online Abuse and Harms (WOAH)</title>
		<meeting>the Sixth Workshop on Online Abuse and Harms (WOAH)<address><addrLine>Seattle, Washington</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="11" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">APPDIA: A discourse-aware transformerbased style transfer model for offensive social media conversations</title>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Atwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabit</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Malihe</forename><surname>Alikhani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Computational Linguistics</title>
		<meeting>the 29th International Conference on Computational Linguistics<address><addrLine>Gyeongju, Republic of Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="6063" to="6074" />
		</imprint>
	</monogr>
	<note>International Committee on Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">Susan</forename><surname>Benesch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>Ruths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haji</forename><surname>Kelly P Dillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Mohammad Saleem</surname></persName>
		</author>
		<author>
			<persName><surname>Wright</surname></persName>
		</author>
		<title level="m">Counterspeech on Twitter: A field study. Dangerous Speech Project</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Weigh your own words: Improving hate speech counter narrative generation via attention regularization</title>
		<author>
			<persName><forename type="first">Helena</forename><surname>Bonaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giuseppe</forename><surname>Attanasio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debora</forename><surname>Nozza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Guerini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Humanmachine collaboration approaches to build a dialogue dataset for hate speech countering</title>
		<author>
			<persName><forename type="first">Helena</forename><surname>Bonaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Dellantonio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serra</forename><surname>Sinem Tekiroglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Guerini</surname></persName>
		</author>
		<idno>ArXiv, abs/2211.03433</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Discourse-aware neural rewards for coherent text generation</title>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1016</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long Papers</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="173" to="184" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">CONAN -COunter NArratives through nichesourcing: a multilingual dataset of responses to fight online hate speech</title>
		<author>
			<persName><forename type="first">Yi-Ling</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizaveta</forename><surname>Kuzmenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serra</forename><surname>Sinem Tekiroglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Guerini</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1271</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2819" to="2829" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Towards knowledge-grounded counter narrative generation for hate speech</title>
		<author>
			<persName><forename type="first">Yi-Ling</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serra</forename><surname>Sinem Tekiroglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Guerini</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-acl.79</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="899" to="914" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A discourse-aware attention model for abstractive summarization of long documents</title>
		<author>
			<persName><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franck</forename><surname>Dernoncourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soon</forename><surname>Doo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seokhwan</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nazli</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><surname>Goharian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">A coefficient of agreement for nominal scales. Educational and Psychological Measurement</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1960">1960</date>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="37" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Strategies for structuring story generation</title>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Dauphin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1254</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2650" to="2660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Human-in-theloop for data collection: a multi-target counter narrative dataset to fight online hate speech</title>
		<author>
			<persName><forename type="first">Margherita</forename><surname>Fanton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helena</forename><surname>Bonaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serra</forename><surname>Sinem Tekiroglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Guerini</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.250</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3226" to="3240" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">ToxiGen: A large-scale machine-generated dataset for adversarial and implicit hate speech detection</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Hartvigsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saadia</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Palangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipankar</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ece</forename><surname>Kamar</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.234</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3309" to="3326" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">D-CALM: A dynamic clustering-based active learning approach for mitigating bias</title>
		<author>
			<persName><forename type="first">Sabit</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Malihe</forename><surname>Alikhani</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.findings-acl.342</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2023</title>
		<meeting><address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="5540" to="5553" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dagn: Discourse-aware graph network for logical reasoning</title>
		<author>
			<persName><forename type="first">Yinya</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="5848" to="5855" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">ALBERT: A lite BERT for selfsupervised learning of language representations</title>
		<author>
			<persName><forename type="first">Zhenzhong</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingda</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<idno>CoRR, abs/1909.11942</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Piyush Sharma, and Radu Soricut</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Roberta: A robustly optimized BERT pretraining approach</title>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno>CoRR, abs/1907.11692</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Gender bias in neural natural language processing</title>
		<author>
			<persName><forename type="first">Kaiji</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Mardziel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fangjing</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Logic, Language</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Preetam Amancharla, and Anupam Datta. and Security</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Characterizing English variation across social media communities with BERT</title>
		<author>
			<persName><forename type="first">Li</forename><surname>Lucy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Bamman</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00383</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="538" to="556" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Rhetorical structure theory: Toward a functional theory of text organization</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">C</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandra</forename><forename type="middle">A</forename><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Text &amp; Talk</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="243" to="281" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Improving text generation through introducing coherence metrics</title>
		<author>
			<persName><forename type="first">Oleksandr</forename><surname>Marchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olga</forename><surname>Radyvonenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tetiana</forename><surname>Ignatova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">V</forename><surname>Titarchuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmytro</forename><surname>Zhelezniakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cybernetics and Systems Analysis</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="13" to="21" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Analyzing the hate and counter speech accounts on twitter</title>
		<author>
			<persName><forename type="first">Binny</forename><surname>Mathew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navish</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pawan</forename><surname>Ravina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Animesh</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><surname>Mukherjee</surname></persName>
		</author>
		<idno>ArXiv, abs/1812.02712</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Thou shalt not hate: Countering online hate speech</title>
	</analytic>
	<monogr>
		<title level="m">International Conference on Web and Social Media</title>
		<editor>
			<persName><forename type="first">Binny</forename><surname>Mathew</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Hardik</forename><surname>Tharad</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Subham</forename><surname>Rajgaria</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Prajwal</forename><surname>Singhania</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kalyan</forename><surname>Suman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Pawan</forename><surname>Maity</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Animesh</forename><surname>Goyal</surname></persName>
		</editor>
		<editor>
			<persName><surname>Mukherjee</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Interrater reliability: the kappa statistic</title>
		<author>
			<persName><forename type="first">Mary</forename><forename type="middle">L</forename><surname>Mchugh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biochemia Medica</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="276" to="282" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The penn discourse treebank 2.0</title>
		<author>
			<persName><forename type="first">Rashmi</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Dinesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eleni</forename><surname>Miltsakaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Livio</forename><surname>Robaldo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aravind</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bonnie</forename><forename type="middle">Lynn</forename><surname>Webber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A benchmark dataset for learning to intervene in online hate speech</title>
		<author>
			<persName><forename type="first">Jing</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Bethke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinyin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Belding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1482</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4755" to="4764" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Automatic counter-narrative generation for hate speech in spanish</title>
		<author>
			<persName><forename type="first">Maria</forename><surname>Estrella Vallecillo-Rodríguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arturo</forename><surname>Montejo-Raéz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Teresa Martín-Valdivia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Procesamiento del Lenguaje Natural</title>
		<meeting>esamiento del Lenguaje Natural</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="227" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">Fangyuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyi</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Jessy</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.11048</idno>
		<title level="m">How do we answer complex questions: Discourse structure of long-form answers</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Discourse-aware neural extractive text summarization</title>
		<author>
			<persName><forename type="first">Jiacheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingjing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Xlnet: Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
		<idno>CoRR, abs/1906.08237</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multilingual content moderation: A case study on Reddit</title>
		<author>
			<persName><forename type="first">Meng</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karan</forename><surname>Sikka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Atwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabit</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ajay</forename><surname>Divakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Malihe</forename><surname>Alikhani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Conference of the European Chapter</title>
		<meeting>the 17th Conference of the European Chapter<address><addrLine>Dubrovnik, Croatia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="3828" to="3844" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">2019a. Predicting the type and target of offensive posts in social media</title>
		<author>
			<persName><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noura</forename><surname>Farra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ritesh</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1144</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1415" to="1420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">2019b. Predicting the type and target of offensive posts in social media</title>
		<author>
			<persName><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noura</forename><surname>Farra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ritesh</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Generate, prune, select: A pipeline for counterspeech generation against online hate speech</title>
		<author>
			<persName><forename type="first">Wanzheng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suma</forename><surname>Bhat</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-acl.12</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="134" to="149" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
