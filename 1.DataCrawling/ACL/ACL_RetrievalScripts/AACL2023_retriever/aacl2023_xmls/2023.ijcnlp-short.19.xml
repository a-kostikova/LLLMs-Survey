<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Language Model, Resources, and Computational Pipelines for the Under-Resourced Iranian Azerbaijani</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Marzia</forename><surname>Nouri</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Engineering Department</orgName>
								<orgName type="department" key="dep2">IR § AI Innovation Center</orgName>
								<orgName type="department" key="dep3">Data:Lab</orgName>
								<orgName type="laboratory">Language Processing and Digital Humanities Laboratory</orgName>
								<orgName type="institution" key="instit1">Sharif University of Technology</orgName>
								<orgName type="institution" key="instit2">Volkswagen AG</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mahsa</forename><surname>Amani</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Engineering Department</orgName>
								<orgName type="department" key="dep2">IR § AI Innovation Center</orgName>
								<orgName type="department" key="dep3">Data:Lab</orgName>
								<orgName type="laboratory">Language Processing and Digital Humanities Laboratory</orgName>
								<orgName type="institution" key="instit1">Sharif University of Technology</orgName>
								<orgName type="institution" key="instit2">Volkswagen AG</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Reihaneh</forename><surname>Zohrabi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Engineering Department</orgName>
								<orgName type="department" key="dep2">IR § AI Innovation Center</orgName>
								<orgName type="department" key="dep3">Data:Lab</orgName>
								<orgName type="laboratory">Language Processing and Digital Humanities Laboratory</orgName>
								<orgName type="institution" key="instit1">Sharif University of Technology</orgName>
								<orgName type="institution" key="instit2">Volkswagen AG</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ehsaneddin</forename><surname>Asgari</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Engineering Department</orgName>
								<orgName type="department" key="dep2">IR § AI Innovation Center</orgName>
								<orgName type="department" key="dep3">Data:Lab</orgName>
								<orgName type="laboratory">Language Processing and Digital Humanities Laboratory</orgName>
								<orgName type="institution" key="instit1">Sharif University of Technology</orgName>
								<orgName type="institution" key="instit2">Volkswagen AG</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The Language Model, Resources, and Computational Pipelines for the Under-Resourced Iranian Azerbaijani</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BA3959A5D045B82A407A9226D4A96AEA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-05-29T14:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Iranian Azerbaijani is a dialect of the Azerbaijani language spoken by more than 16% of the population in Iran (&gt;14 million). Unfortunately, a lack of computational resources is one of the factors that puts this language and its rich culture at risk of extinction. This work aims to create fundamental natural language processing (NLP) resources and pipelines for the processing and analysis of Iranian Azerbaijani introducing standard datasets and starter models for various NLP tasks such as language modeling, text classification, part-of-speech (POS) tagging, and machine translation. The proposed resources have been curated and preprocessed to facilitate the development of NLP models for Iranian Azerbaijani and provide a strong baseline for further research and development. This study is an example of bridging the gap in NLP for low-resource languages and promoting the advancement of language technologies in underrepresented languages. To the best of our knowledge, for the first time, this paper presents major infrastructures for the processing and analysis of Iranian Azerbaijani, with the ultimate goal of improving communication and information access for millions of individuals. Furthermore, our translation model's online demo is accessible at https://azeri.parsi.ai/.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>While a few of the world's languages are blessed with a wealth of linguistic resources, most of the world's 7,000 languages are considered lowresource and face the danger of extinction <ref type="bibr" target="#b5">(Cieri et al., 2016)</ref>. Each of these low-resource languages is crucial in preserving humanity's shared heritage, benefiting all. Developing techniques for analyzing these languages is currently a major challenge in the field of NLP, especially in different regions <ref type="bibr">(Zoph et al., 2016;</ref><ref type="bibr" target="#b7">Duthoo and Mesnard, 2018;</ref><ref type="bibr"></ref> ⋆ The first two authors contributed equally and their authorships were determined randomly. <ref type="bibr" target="#b2">Bansal et al., 2021;</ref><ref type="bibr" target="#b13">Han et al., 2022)</ref>. Despite significant advancements in deep learning for NLP in high-resource languages, some low-resource languages lack even sufficient digitized raw texts <ref type="bibr" target="#b15">(ImaniGooghari et al., 2021)</ref>.</p><p>Azerbaijani, spoken in Iran, which we refer to as Iranian Azerbaijani in this paper, is a dialect of the Azerbaijani language spoken by a significant population in Iran written in Perso-Arabic script. This dialect, along with Azerbaijani spoken in Azerbaijan, which we denote as Azerbaijani, constitutes two distinct branches within the Azerbaijani language family. Azerbaijani with minor phonological, lexical, syntactic, and morphological variations uses the Latin script <ref type="bibr" target="#b26">(Mokari and Werner, 2017;</ref><ref type="bibr" target="#b30">Rezaei et al., 2017)</ref>. Despite the large number of speakers of Iranian Azerbaijani, the digitized resources are very limited placing this language among low-resource languages and putting this language and its associated culture at risk of extinction <ref type="bibr" target="#b18">(Kuriyozov et al., 2020;</ref><ref type="bibr" target="#b28">Park et al., 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>The field of low-resource language research encompasses two main streams: (i) resource building through collaborative effort (e.g. Unimorph <ref type="bibr">(Mc-Carthy et al., 2020a)</ref>) and (ii) parallel projection from high resource languages <ref type="bibr" target="#b0">(Agić et al., 2016;</ref><ref type="bibr" target="#b8">Eger et al., 2018;</ref><ref type="bibr" target="#b32">Subburathinam et al., 2019;</ref><ref type="bibr" target="#b33">Xia et al., 2021)</ref>, particularly from the related languages <ref type="bibr" target="#b14">(Hedderich et al., 2021)</ref>. Iranian Azerbaijani is a member of the Turkic language family, which also includes Turkish, Uzbek, Azerbaijani, Kazakh, and Uyghur <ref type="bibr">(Mirzakhalov et al., 2021a)</ref>.</p><p>Here we summarize the recent computational efforts on Turkic languages: (i) High-resource Turkic NLP: Turkish is a high-resource language among Turkic languages, with available datasets and models for various NLP tasks, such as stemming, segmentation, POS-tagging, parsing, and named entity recognition <ref type="bibr" target="#b9">(Ehsani et al., 2012;</ref><ref type="bibr" target="#b31">Safaya et al., 2022)</ref>. Almost the entire NLP pipeline for Turkish exists in a toolkit, called TurkishDelightNLP <ref type="bibr" target="#b1">(Alecakir et al., 2022)</ref>. Text classification studies can also be observed for Turkish and Azerbaijani languages e.g., sentiment of social news articles in Azerbaijani <ref type="bibr" target="#b19">(Mammadli et al., 2019)</ref>, tweet topic classification <ref type="bibr">(Yüksel et al., 2019)</ref> and sentiment analysis <ref type="bibr" target="#b27">(Mutlu and Özgür, 2022)</ref> in Turkish. (ii) Cross/multi-lingual models: this track of research includes efforts on aligning monolingual embedding spaces of various Turkic languages, which are often affected by low-resource constraints <ref type="bibr" target="#b18">(Kuriyozov et al., 2020)</ref>. (iii) Machine translation models: machine translation have been developed for instances of Turkic languages <ref type="bibr" target="#b12">(Gökırmak et al., 2019;</ref><ref type="bibr" target="#b10">Fatullayev et al., 2008)</ref>) as well as family-scale translations among Turkic languages (22 languages) <ref type="bibr">(Mirzakhalov et al., 2021a,b)</ref>. To the best of our knowledge, no prior work has developed a comprehensive NLP dataset or pipeline for Iranian Azerbaijani, which is a language spoken by more than 14 million individuals in Iran and written in the Perso-Arabic script. In addition, the translation scenario of Iranian Azerbaijani to Persian is significant in Iran as it can enhance communication among different generations and regions.</p><p>Contributions: our paper to the best of our knowledge, for the first time introduces: (i) comprehensive linguistic resources for Iranian Azerbaijani including raw texts of various genres, a POS-tagged corpus, text classification collection, and parallel corpora (in both Turkish and Persian) as well as (ii) important starter NLP models for Iranian Azerbaijani consisting of data cleanings, word embeddings, language modeling, post-tagging model, text classification models, and machine translation. Our primary focus has been to achieve a remarkable milestone by creating the first NLP pipeline and resource collection for a language spoken by at least 14 million people, while leveraging proven methodologies already established for other languages. In addition, through proposing the above-mentioned resources and models, we attempt (iii) to improve the language technology for the communication of millions of individuals and (iv) to contribute to preserving the Iranian Azerbaijani and its rich culture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Materials and Methods</head><p>Workflow: the overview of our approach for Iranian Azerbaijani resource creation and model benchmarking is outlined in blocks of Figure <ref type="figure" target="#fig_0">1</ref>: (a) Azeri-standardization: this part includes unifying the scripts of Azerbaijani and Iranian Azerbaijani to the Perso-Arabic script and a comprehensive preprocessing spanning removal of URLs, digits, text within parentheses, elimination of non-Azerbaijani characters, and discarding sentences shorter than 10 characters. We refer to the resulting cleaned and standardized text as Azeri-STD. (b) Parallel dataset creation: we create two parallel corpora for two different reasons: Parallel to Turkish: we use a parallel corpus between Azerbaijani and Turkish (the most high-resource Turkic language) for the purpose of annotation projection <ref type="bibr" target="#b8">(Eger et al., 2018)</ref> and run Azeri-STD to generate the parallel corpus for the Iranian Azerbaijani, Parallel to Persian: we create this dataset for translation between Iranian Azerbaijani and Persian again using our Azeri-STD on collected data from different sources. (c) Training of the starter models: we develop and fine-tune starter models of different NLP tasks, including word embeddings, language modeling, text and token classification, and translation. (d) Model evaluations: we evaluate each task using appropriate metrics and evaluation datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Datasets</head><p>Raw text dataset: Our monolingual data comes from two primary sources: transliterated text using a transformer-based solution <ref type="bibr">(Zohrabi et al., 2023)</ref>, and text originally written in the Perso-Arabic script. Table <ref type="table" target="#tab_1">2</ref> provides information about our data (See Appendix A). The dataset includes 1.3M sentences spanning approximately 640K unique words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Word analogy dataset:</head><p>We propose a word analogy dataset for intrinsic evaluation of embedding spaces, inspired by previous literature such as <ref type="bibr" target="#b11">(Gladkova et al., 2016)</ref>. Our dataset includes 100 word analogies from four categories: inflectional morphology, derivational morphology, lexico-graphic, and encyclopedic semantics Text classification dataset: For text classification, we use a collection of 400 articles from the Iranian Azerbaijani Wikipedia, divided into 4 categories: Literature, Sports, History, and Geography (100 articles per category). This dataset provides a diverse set of texts for training and evaluating text classification models. We use 80% for training and dev and 20% for test purpose. Token classification dataset: We create a token classification dataset based on the POS-tagging of our parallel Turkish corpus. We use annotation projection techniques to align <ref type="bibr" target="#b16">(Jalili Sabet et al., 2020)</ref> the Turkish POS-tags <ref type="bibr" target="#b1">(Alecakir et al., 2022)</ref> with those of Azerbaijani. To ensure script consistency across the different dialects of Azerbaijani, the results are then transliterated to the Iranian Azerbaijani dialect. To improve the quality of the dataset, we leverage crowdsourcing to edit the tags. To summarize, we achieved a set of 200 tagged sentences. We use 90% for training and dev and 10% for test purpose. The agreement between the two annotators in the annotation task was evaluated using the kappa score, resulting in a value of 0.93, indicating substantial level of agreement. Machine translation dataset: we create a parallel dataset between Persian and Iranian Azerbaijani languages. This dataset comprises a total of 14,972 aligned sentence pairs. It is composed of three main sources (marked with (p) in Table 2 in Appendix A): 7851 pairs from the Bible <ref type="bibr" target="#b20">(Mayer and Cysouw, 2014)</ref>, 6175 pairs from the Quran<ref type="foot" target="#foot_0">1</ref> , and 946 pairs from a compilation of short stories we carefully extracted from different web forums manually. We use 90% for training and dev and 10% for test purpose. The only available bilingual data for Iranian Azerbaijani consists of the Quran, the Bible, and a few stories. Within the NLP community, religious texts  <ref type="bibr">, 1998)</ref>.</p><p>Text Classification: We include a text classification use case in our pipeline for Iranian Azerbaijani comparing three types of approaches: (i) an SVM model using TF-IDF embeddings, (ii) an SVM model using average fastText embeddings of a document, and (iii) supervised fine-tuning of our BERT model <ref type="bibr" target="#b6">(Devlin et al., 2019)</ref>. We evaluate the classification part by measuring accuracy and the F1 score on the test set.</p><p>Token Classification: For the example of token classification we use our POS-tagging dataset, that can benefit a range of NLP tasks. We fine-tune our BERT embedding model for the POS tagging. Since we have 11 categories, other than accuracy we evaluate the tagging on macro-F1 score as well.</p><p>Machine Translation: We train a low-resource transformer-based machine translation model between Iranian Azerbaijani and Persian. The model's computational efficiency makes it practical for use in situations where resources are limited <ref type="bibr" target="#b17">(Kreutzer et al., 2019)</ref>. We evaluate the quality of translation using the SacreBLEU <ref type="bibr" target="#b29">(Post, 2018)</ref> on the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>The objective of this research was to establish fundamental pipelines and resources for the Iranian Azerbaijani language. A collection of subword embedding (fastText), transformer language model (BERT), text classification, token classification (POS tagging), and machine translation models for Iranian Azerbaijani NLP is available at Hugging Face repository<ref type="foot" target="#foot_2">2</ref> , with corresponding code found on GitHub<ref type="foot" target="#foot_3">3</ref> .The obtained results are summarized in Table <ref type="table" target="#tab_0">1</ref>: Embedding intrinsic evaluation: Our fastText model obtained an MRR of 0.46 in word analogy intrinsic evaluation indicating that the model can guess the analogies on average in the second guess. Language modeling perplexity:</p><p>We evaluated the model perplexity of our BERT language model, and achieved a perplexity score of 48.05. Given the constraints of a low-resource language, achieving a perplexity of 48.05 is quite commendable and suggests that despite the scarcity of training data, our model was able to produce relatively accurate predictions. Text classification: our fine-tuned BERT models performed better than the other two models on the text classification task.</p><p>After the BERT model, the fastText-based baseline showed superior performance in comparison with the TF-IDF baseline (an extrinsic evaluation of the fastText embedding). We conducted a text classification comparison to showcase the impact of transliteration data for Iranian Azerbaijani in BERT masked language model pretraining. Our BERT model, trained on both transliterated and original Iranian Azerbaijani data, achieved an impressive macro-F1 of 0.89 in supervised text categorization.</p><p>In contrast, the BERT model trained solely on Iranian Azerbaijani data attained a significantly lower macro-F1 of 0.48. Moreover, training the model on transliterated data resulted in a mBert score of 0.85 macro-F1, further confirming the efficacy of utilizing transliterated data in transformer language models for downstream tasks. Token classification: The transformer-based tagger achieved a satisfactory performance with an accuracy of 0.86 and an F1-score of 0.67. This performance indicates that the fine-tuned BERT tagger is able to identify and classify language elements in the dataset with a moderate degree of accuracy and completeness.</p><p>Machine translation: We assessed the model's performance using the SacreBLEU metric and obtained scores of 10.34 for Iranian Azerbaijani to Persian translation and 8.07 for Persian to Iranian Azerbaijani translation. Although these scores may not reach the level of high-resource settings, when compared to other low-resource languages and their respective scores, our model achieved a reasonable performance for a low-resource machine translation setting <ref type="bibr">(Mirzakhalov et al., 2021a)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>In this paper, to the best of our knowledge, for the first time, we introduced computational resources and pipelines for Iranian Azerbaijani language processing. Language technologies developed for this language can significantly contribute to the communications of &gt;14M speakers of this endangered language. We introduced data sources and models on major NLP tasks including text cleaning, word embeddings, language modeling, text and token classifications, and machine translation. Our introduced embedding space, pos-tagger, and BERT language modeling can be used in a variety of other NLP tasks. Our translation model is the first technological effort toward closing the gap between generations that are not acquiring their grandparents' language. Our pipeline and prepared resources can play a key role in addressing the scarcity of computational resources for Iranian Azerbaijani and preserving the language and its culture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Limitations</head><p>Our study has several limitations that must be acknowledged. A major limitation is the limited resources available for Iranian Azerbaijani, which resulted in a scarcity of data for our pipeline. This scarcity poses a significant challenge for training and evaluating our models and may impede their overall performance. Additionally, Azerbaijani is an agglutinative language, with postfixes added to words to indicate grammatical relationships and functions. However, the way postfixes are written and separated from words varies between Azerbaijani and Iranian Azerbaijani, In Iranian Azerbaijani, there are no clear rules for written language, leading to variations in the use of spaces and halfspaces between words and postfixes. The absence of standard and pre-defined rules also results in considerable noise in the data, making accurate analysis and understanding of the language difficult. We faced challenges in accurately tokenizing Azerbaijani because of these variations and decided to use spaces to tokenize words in our data, but this method sometimes resulted in incorrect segmentation. Furthermore, we used a significant portion of transliterated data from resources in Azerbaijani, which may be affected by phonological, lexical, syntactic, and morphological differences between the two dialects, and thus may impact the performance of our pipeline and limit the accuracy of our models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgment</head><p>We would like to extend our heartfelt gratitude to several individuals and groups whose invaluable contributions have significantly enriched our research. We are grateful to Aidin Sardarynia, Parviz Zare Shahmarasi, Ghasem Lazemi, Mohammad Ali Sadraei, and the authors of the "Borderless Azerbaijani Processing: Linguistic Resources and a Transformer-based Approach for Azerbaijani Transliteration" paper for their invaluable help. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Azerbaijani vs. Iranian Azerbaijani</head><p>Azerbaijani, spoken in the Republic of Azerbaijan, commonly referred to as Azerbaijani, and Azerbaijani spoken in Iran, often denoted as Iranian Azerbaijani, are recognized as two distinct branches within the Azerbaijani language family. The usage patterns differ between the two branches, as Iranian Azerbaijani is primarily used as a spoken language, whereas Azerbaijani serves as an official, scientific, and literary language. Notably, the alphabets used by these branches exhibit dissimilarities. Azerbaijani has experienced multiple changes since 1928, whereas the Iranian branch continues to employ the Perso-Arabic alphabet. Vocabulary-wise, Azerbaijani in Iran incorporates loanwords from Persian, Arabic, and English, whereas the Azerbaijani branch includes loanwords from Russian, Arabic, Persian, and English. Furthermore, grammatical disparities exist between the two branches. The Iranian branch is primarily influenced by Persian in Iran, while the Azerbaijani branch draws influence from Russian in Azerbaijan. In summary, Azerbaijani and Iranian Azerbaijani are two distinct branches of the Azerbaijani language, differing in their usage patterns, alphabets, vocabulary, and grammatical features. These variations reflect the influence of Persian, Arabic, Russian, and English on the respective branches in their respective regions. " (yours). e. Adverb: Tags for words that modify verbs, adjectives, or other adverbs. Example: " " (quietly), " " (always). f. Conjunction: Tags for words that connect words, phrases, or clauses. Example: " " (and), " " (that). g. Number: Tags for numeric values. Example: " " (two), " " (hundred).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C POS Guideline</head><p>h. Adjective: Tags for words that describe or modify nouns. Example: " " (beautiful), " " (good).</p><p>i. Postposition: Tags for words that come after nouns and show relationships. Example: " " (like), " " (for). j. Interjection: Tags for words that express strong emotions or surprise. Example: " " (oh!), " " (ah!). k. Determiner: Tags for words that introduce or specify nouns. Example: " " (this), " " (any).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Hyperparameters</head><p>The BERT language model was trained with hyperparameters set as follows: for pre-training, the number of epochs was 10, the batch size was 128, the learning rate was 5e-5, the vocabulary size was 10,000, and the maximum size of position embeddings was set to 64. For text classification tasks, the maximum sequence length was set to 64, the batch size was 32, and the number of epochs was 10. The learning rate for text classification was set to 275e-7. For token classification tasks, the maximum sequence length was set to 64, the learning rate was set to 2e-5, the batch size was 64, and the number of training epochs was 20.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Error Analysis and Model Output Examples</head><p>Detailed examples for each task, along with model output samples, are available in the README section of our paper's GitHub repository. <ref type="foot" target="#foot_4">14</ref></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An overview of our pipeline for natural language processing of Iranian Azerbaijani, including data collection and preprocessing (block a), parallel corpus creation (block b), model development and fine-tuning (block c), and evaluation using various metrics (block d).</figDesc><graphic coords="3,70.87,70.87,453.56,198.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Summary of performance results for various NLP tasks on Iranian Azerbaijani language. The models and evaluation metrics are detailed for each task (azb: Iranian Azerbaijani, fa: Persian).</figDesc><table><row><cell>Task</cell><cell>Model</cell><cell cols="2">Evaluation Metric Performance</cell></row><row><cell cols="2">Language model-based Embedding FastText</cell><cell>MRR</cell><cell>0.46</cell></row><row><cell>Language Model</cell><cell>BERT</cell><cell>Perplexity</cell><cell>48.05</cell></row><row><cell></cell><cell>TF-IDF + SVM</cell><cell>Accuracy</cell><cell>0.79</cell></row><row><cell></cell><cell>TF-IDF + SVM</cell><cell>F1-score</cell><cell>0.78</cell></row><row><cell>Text Classification</cell><cell>FastText + SVM</cell><cell>Accuracy</cell><cell>0.86</cell></row><row><cell></cell><cell>FastText + SVM</cell><cell>F1-score</cell><cell>0.86</cell></row><row><cell></cell><cell>BERT</cell><cell>Accuracy</cell><cell>0.89</cell></row><row><cell></cell><cell>BERT</cell><cell>F1-score</cell><cell>0.89</cell></row><row><cell>Token Classification</cell><cell>BERT POS-tagger BERT POS-tagger</cell><cell>Accuracy Macro F1-score</cell><cell>0.86 0.67</cell></row><row><cell>Machine Translation</cell><cell cols="2">Text Translation azb2fa SacreBLEU Text Translation fa2azb SacreBLEU</cell><cell>10.34 8.07</cell></row></table><note><p>et al.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>A summary of our collected datasets in Iranian Azerbaijani: (P) shows the parallel corpora.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://tanzil.net/download/ are frequently employed as valuable resources for low-resource languages, primarily because of their inter-cultural nature, making them widely accessible across various languages(McCarthy et al.,</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>2020b). The creation of high-quality aligned bibles in approximately 1000 languages has been a significant effort in this area<ref type="bibr" target="#b23">(McCarthy et al., 2019)</ref>. To ensure data quality, our comprehensive preprocessing pipeline involved manual checks in some cases, successfully eliminating duplicates and noisy data from the dataset, resulting in a reduction in collection size from 2M to 1.3M sentences.2.2 ModelsSubword embedding: A proper word representation is critical for almost all NLP tasks. Since Azerbaijani languages are agglutinative, we use fastText embeddings that can properly use the subword information in the skip-gram architecture<ref type="bibr" target="#b3">(Bojanowski et al., 2017)</ref>. We evaluate this embedding extrinsically in the text classification task and intrinsically by measuring the Mean Reciprocal Rank (MRR) in the word analogy inference task. Transformer language model: Transformerbased language-model embeddings proved to be state-of-the-art approaches on a variety of NLP tasks benefiting from proper modeling of contextual information of tokens<ref type="bibr" target="#b6">(Devlin et al., 2019)</ref>. Therefore, we train a BERT language model with a masked language modeling objective on our standardized raw text. We evaluate this model by measuring perplexity of the language model (Chen</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>https://huggingface.co/language-ml-lab/ iranian-azerbaijani-nlp</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3"><p>https://github.com/language-ml/ iranian-azerbaijani-nlp</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_4"><p>https://github.com/language-ml/ iranian-azerbaijani-nlp</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multilingual projection for parsing truly low-resource languages</title>
		<author>
			<persName><forename type="first">Željko</forename><surname>Agić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anders</forename><surname>Johannsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martínez</forename><surname>Héctor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalie</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anders</forename><surname>Schluter</surname></persName>
		</author>
		<author>
			<persName><surname>Søgaard</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00100</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="301" to="312" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">TurkishDelightNLP: A neural Turkish NLP toolkit</title>
		<author>
			<persName><forename type="first">Huseyin</forename><surname>Alecakir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Necva</forename><surname>Bölücü</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Burcu</forename><surname>Can</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.naacl-demo.3</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: System Demonstrations</title>
		<meeting>the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: System Demonstrations</meeting>
		<imprint>
			<publisher>Washington + Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="17" to="26" />
		</imprint>
	</monogr>
	<note>Hybrid: Seattle</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">How low is too low? a computational perspective on extremely low-resource languages</title>
		<author>
			<persName><forename type="first">Rachit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Himanshu</forename><surname>Choudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ravneet</forename><surname>Punia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niko</forename><surname>Schenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Émilie</forename><surname>Pagé-Perron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Dahl</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-srw.5</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Student Research Workshop</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Student Research Workshop</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="44" to="59" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00051</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">Douglas</forename><surname>Stanley F Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roni</forename><surname>Beeferman</surname></persName>
		</author>
		<author>
			<persName><surname>Rosenfeld</surname></persName>
		</author>
		<title level="m">Evaluation metrics for language models</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Selection criteria for low resource language programs</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Cieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Maxwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Strassel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Tracey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="4543" to="4549" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">CEA LIST: Processing low-resource languages for CoNLL 2018</title>
		<author>
			<persName><forename type="first">Elie</forename><surname>Duthoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Mesnard</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/K18-2003</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="34" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">PD3: Better low-resource cross-lingual transfer by combining direct transfer and annotation projection</title>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Eger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Rücklé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-5216</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Workshop on Argument Mining</title>
		<meeting>the 5th Workshop on Argument Mining<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="131" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Disambiguating main POS tags for Turkish</title>
		<author>
			<persName><forename type="first">Razieh</forename><surname>Ehsani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ege</forename><surname>Muzaffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gülşen</forename><surname>Alper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eşref</forename><surname>Eryigit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Adali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taiwan</forename><surname>Chung-Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Conference on Computational Linguistics and Speech Processing</title>
		<meeting>the 24th Conference on Computational Linguistics and Speech Processing</meeting>
		<imprint>
			<publisher>The Association for Computational Linguistics and Chinese Language Processing</publisher>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="page" from="202" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dilmanc is the 1st mt system for azerbaijani</title>
		<author>
			<persName><forename type="first">Rauf</forename><surname>Fatullayev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Abbasov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abulfat</forename><surname>Fatullayev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SLTC-08</title>
		<meeting>of SLTC-08<address><addrLine>Stockholm, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="63" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Analogy-based detection of morphological and semantic relations with word embeddings: what works and what doesn&apos;t</title>
		<author>
			<persName><forename type="first">Anna</forename><surname>Gladkova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandr</forename><surname>Drozd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satoshi</forename><surname>Matsuoka</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-2002</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL Student Research Workshop</title>
		<meeting>the NAACL Student Research Workshop<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="8" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A free/open-source rule-based machine translation system for crimean tatar to turkish</title>
		<author>
			<persName><forename type="first">Memduh</forename><surname>Gökırmak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francis</forename><surname>Tyers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Washington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Technologies for MT of Low Resource Languages</title>
		<meeting>the 2nd Workshop on Technologies for MT of Low Resource Languages<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>European Association for Machine Translation</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="24" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Cross-lingual contrastive learning for finegrained entity typing for low-resource languages</title>
		<author>
			<persName><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuqi</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weize</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhou</forename><surname>Botong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suncong</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.159</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2241" to="2250" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A survey on recent approaches for natural language processing in low-resource scenarios</title>
		<author>
			<persName><forename type="first">A</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukas</forename><surname>Hedderich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heike</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jannik</forename><surname>Adel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dietrich</forename><surname>Strötgen</surname></persName>
		</author>
		<author>
			<persName><surname>Klakow</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.201</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2545" to="2568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">ParCourE: A parallel corpus explorer for a massively multilingual corpus</title>
		<author>
			<persName><forename type="first">Ayyoob</forename><surname>Imanigooghari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jalili</forename><surname>Masoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Sabet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Dufter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hinrich</forename><surname>Cysou</surname></persName>
		</author>
		<author>
			<persName><surname>Schütze</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-demo.8</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="63" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">SimAlign: High quality word alignments without parallel training data using static and contextualized embeddings</title>
		<author>
			<persName><forename type="first">Jalili</forename><surname>Masoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Sabet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">François</forename><surname>Dufter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hinrich</forename><surname>Yvon</surname></persName>
		</author>
		<author>
			<persName><surname>Schütze</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.147</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1627" to="1643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Joey NMT: A minimalist NMT toolkit for novices</title>
		<author>
			<persName><forename type="first">Julia</forename><surname>Kreutzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jasmijn</forename><surname>Bastings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-3019</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="109" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Cross-lingual word embeddings for Turkic languages</title>
		<author>
			<persName><forename type="first">Elmurod</forename><surname>Kuriyozov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yerai</forename><surname>Doval</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Gómez-Rodríguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth Language Resources and Evaluation Conference</title>
		<meeting>the Twelfth Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4054" to="4062" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sentiment polarity detection in Azerbaijani social news articles</title>
		<author>
			<persName><forename type="first">Sevda</forename><surname>Mammadli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shamsaddin</forename><surname>Huseynov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huseyn</forename><surname>Alkaramov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulviyya</forename><surname>Jafarli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Umid</forename><surname>Suleymanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samir</forename><surname>Rustamov</surname></persName>
		</author>
		<idno type="DOI">10.26615/978-954-452-056-4_082</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Recent Advances in Natural Language Processing</title>
		<meeting>the International Conference on Recent Advances in Natural Language Processing<address><addrLine>Varna, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>INCOMA Ltd</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="703" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Creating a massively parallel Bible corpus</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Cysouw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC&apos;14)</title>
		<meeting>the Ninth International Conference on Language Resources and Evaluation (LREC&apos;14)<address><addrLine>Reykjavik, Iceland</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA)</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3158" to="3163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Universal Morphology</title>
		<author>
			<persName><forename type="first">D</forename><surname>Arya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christo</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matteo</forename><surname>Kirov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amrit</forename><surname>Grella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Nidhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ekaterina</forename><surname>Gorman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabrina</forename><forename type="middle">J</forename><surname>Vylomova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Garrett</forename><surname>Mielke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miikka</forename><surname>Nicolai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timofey</forename><surname>Silfverberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nataly</forename><surname>Arkhangelskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Krizhanovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Krizhanovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Klyachko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Sorokin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valts</forename><surname>Mansfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuval</forename><surname>Ernštreits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cassandra</forename><forename type="middle">L</forename><surname>Pinter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mans</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Hulden</surname></persName>
		</author>
		<author>
			<persName><surname>Yarowsky</surname></persName>
		</author>
		<idno>UniMorph 3.0</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth Language Resources and Evaluation Conference</title>
		<meeting>the Twelfth Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3922" to="3931" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The Johns Hopkins University Bible corpus: 1600+ tongues for typological exploration</title>
		<author>
			<persName><forename type="first">D</forename><surname>Arya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dylan</forename><surname>Wicks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Winston</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oliver</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Garrett</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Nicolai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth Language Resources and Evaluation Conference</title>
		<meeting>the Twelfth Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2884" to="2892" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Modeling color terminology across thousands of languages</title>
		<author>
			<persName><forename type="first">D</forename><surname>Arya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Winston</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName><surname>Yarowsky</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1229</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2241" to="2250" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Orhan Firat, and Sriram Chellappan. 2021a. A large-scale study of machine translation in Turkic languages</title>
		<author>
			<persName><forename type="first">Jamshidbek</forename><surname>Mirzakhalov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anoop</forename><surname>Babu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duygu</forename><surname>Ataman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherzod</forename><surname>Kariev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francis</forename><surname>Tyers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Otabek</forename><surname>Abduraufov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mammad</forename><surname>Hajili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sardana</forename><surname>Ivanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abror</forename><surname>Khaytbaev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Laverghetta</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">Esra</forename><surname>Bekhzodbek Moydinboyev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaxnoza</forename><surname>Onal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahsan</forename><surname>Pulatova</surname></persName>
		</author>
		<author>
			<persName><surname>Wahab</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.475</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="5876" to="5890" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">2021b. Evaluating multiway multilingual NMT in the Turkic languages</title>
		<author>
			<persName><forename type="first">Jamshidbek</forename><surname>Mirzakhalov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anoop</forename><surname>Babu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aigiz</forename><surname>Kunafin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahsan</forename><surname>Wahab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bekhzodbek</forename><surname>Moydinboyev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sardana</forename><surname>Ivanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mokhiyakhon</forename><surname>Uzokova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaxnoza</forename><surname>Pulatova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duygu</forename><surname>Ataman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julia</forename><surname>Kreutzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francis</forename><surname>Tyers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Licato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sriram</forename><surname>Chellappan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Conference on Machine Translation</title>
		<meeting>the Sixth Conference on Machine Translation</meeting>
		<imprint>
			<biblScope unit="page" from="518" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Ghaffarvand</forename><surname>Payam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Mokari</surname></persName>
		</author>
		<author>
			<persName><surname>Werner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the International Phonetic Association</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="207" to="212" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A dataset and BERT-based models for targeted sentiment analysis on Turkish texts</title>
		<author>
			<persName><forename type="first">Mustafa</forename><surname>Melih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mutlu</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Arzucan</forename><surname>Özgür</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-srw.39</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="467" to="472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Unsupervised neural machine translation for low-resource domains via metalearning</title>
		<author>
			<persName><forename type="first">Cheonbok</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunwon</forename><surname>Tae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taehee</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soyoung</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Azam Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucy</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaegul</forename><surname>Choo</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.225</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2888" to="2901" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A call for clarity in reporting BLEU scores</title>
		<author>
			<persName><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-6319</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Machine Translation: Research Papers</title>
		<meeting>the Third Conference on Machine Translation: Research Papers<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="186" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Attitude towards azeri language in iran: a large-scale survey research</title>
		<author>
			<persName><forename type="first">Saeed</forename><surname>Rezaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashkan</forename><surname>Latifi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arash</forename><surname>Nematzadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Multilingual and Multicultural Development</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="931" to="941" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Mukayese: Turkish NLP strikes back</title>
		<author>
			<persName><forename type="first">Ali</forename><surname>Safaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emirhan</forename><surname>Kurtuluş</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arda</forename><surname>Goktogan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deniz</forename><surname>Yuret</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.findings-acl.69</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2022</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="846" to="863" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Cross-lingual structure transfer for relation and event extraction</title>
		<author>
			<persName><forename type="first">Ananya</forename><surname>Subburathinam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Di</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shih-Fu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avirup</forename><surname>Sil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clare</forename><surname>Voss</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1030</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="313" to="325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">MetaXL: Meta representation transformation for low-resource cross-lingual learning</title>
		<author>
			<persName><forename type="first">Mengzhou</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoqing</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subhabrata</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milad</forename><surname>Shokouhi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.42</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="499" to="511" />
		</imprint>
	</monogr>
	<note>Graham Neubig, and Ahmed Hassan Awadallah</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
