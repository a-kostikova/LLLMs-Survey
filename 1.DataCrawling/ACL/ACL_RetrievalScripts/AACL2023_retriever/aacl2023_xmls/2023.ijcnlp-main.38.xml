<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">FastRAT: Fast and Efficient Cross-lingual Text-to-SQL Semantic Parsing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Pavlos</forename><surname>Vougiouklis</surname></persName>
							<email>pavlos.vougiouklis@huawei.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Huawei Technologies Edinburgh RC</orgName>
								<orgName type="institution" key="instit2">CSI</orgName>
								<address>
									<settlement>Edinburgh</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nikos</forename><surname>Papasarantopoulos</surname></persName>
							<affiliation key="aff1">
								<address>
									<settlement>Priceline, Edinburgh</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Danna</forename><surname>Zheng</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<settlement>Edinburgh</settlement>
									<country>United Kingdom D.Zheng</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Tuckey</surname></persName>
							<email>david.tuckey17@imperial.ac.uk</email>
							<affiliation key="aff3">
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chenxin</forename><surname>Diao</surname></persName>
							<email>chenxindiao@huawei.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Huawei Technologies Edinburgh RC</orgName>
								<orgName type="institution" key="instit2">CSI</orgName>
								<address>
									<settlement>Edinburgh</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhili</forename><surname>Shen</surname></persName>
							<email>zhilishen@huawei.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Huawei Technologies Edinburgh RC</orgName>
								<orgName type="institution" key="instit2">CSI</orgName>
								<address>
									<settlement>Edinburgh</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jeff</forename><forename type="middle">Z</forename><surname>Pan</surname></persName>
							<email>jeff.pan@huawei.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Huawei Technologies Edinburgh RC</orgName>
								<orgName type="institution" key="instit2">CSI</orgName>
								<address>
									<settlement>Edinburgh</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Huawei Edinburgh Research Centre</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">FastRAT: Fast and Efficient Cross-lingual Text-to-SQL Semantic Parsing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8D09E99BA703D793F8BD03B7DDA3E521</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-05-29T14:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent advances of large pre-trained language models have motivated significant breakthroughs in various Text-to-SQL tasks. However, a number of challenges inhibit the deployment of SQL parsers in commercial applications. In this paper, we focus on two such challenges: decoding speed and multilingual input, and introduce FastRAT, a model that includes (i) a decoder-free framework to quickly generate SQL queries from natural language questions based on SQL Semantic Predictions, (ii) a cross-lingual multi-task pre-training scheme, and (iii) a method, based on distant supervision, to extend a semantic parser to new languages.</p><p>We apply FastRAT on CSpider and Spider, two challenging zero-shot semantic parsing benchmarks. Our system achieves an average of 10x decoding speedup over a set of competitive baselines based on auto-or semi-autoregressive decoding. In the cross-lingual CSpider dataset, our approach achieves an exact query match accuracy score of 61.3, outperforming the relevant competition. In the monolingual task, it maintains competitive performance by exhibiting &lt; 5% accuracy drop compared to disproportionately slower solutions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The task of Text-to-SQL semantic parsing is to transform natural language questions into SQL queries. The resulting queries can be executed by the corresponding database instance, in order for appropriate results to be returned to the end-user, who might not be familiar with SQL or the schema of the given database <ref type="bibr" target="#b22">(Zelle and Mooney, 1996;</ref><ref type="bibr" target="#b4">Dong and Lapata, 2016)</ref>. Given their accessibility benefits, Text-to-SQL applications have become increasingly popular recently, with many corporations developing Business Intelligence platforms.</p><p>Despite the market potential, existing solutions are usually based on larger language models, and have notable limitations-they tend to work only for simple queries and data sources, and exhibit relatively slow processing times. Furthermore, while database schemata are often in English, data records might be in other languages, and users might need to query them in languages other than English.</p><p>In an effort to alleviate the shortcomings of Textto-SQL solutions, increasingly difficult datasets and benchmarks have been developed <ref type="bibr" target="#b24">(Zhong et al., 2017;</ref><ref type="bibr" target="#b21">Yu et al., 2018;</ref><ref type="bibr" target="#b10">Min et al., 2019;</ref><ref type="bibr" target="#b5">Dou et al., 2023;</ref><ref type="bibr" target="#b23">Zhang et al., 2023)</ref>. The efforts to explore the generalisability of such Text-to-SQL systems have recently culminated with the introduction of multiple database datasets, which distinguish between training and evaluation databases. As a result, models are expected to be tested on databases they have not met during training. We refer to this setup as cross-database semantic parsing.</p><p>Research efforts for addressing the challenges introduced by this cross-database setting have converged to the general encoder-decoder framework <ref type="bibr" target="#b4">(Dong and Lapata, 2016;</ref><ref type="bibr" target="#b7">Kočiský et al., 2016;</ref><ref type="bibr">Wang et al., 2020a;</ref><ref type="bibr" target="#b11">Rubin and Berant, 2021)</ref>. In this framework, the encoder (i.e. usually based on a pre-trained language model) processes the input natural language question along with the corresponding database (i.e. database schema with or without its relevant values), whereas the decoder seeks to decode the SQL query <ref type="bibr">(Wang et al., 2020a;</ref><ref type="bibr" target="#b11">Rubin and Berant, 2021;</ref><ref type="bibr" target="#b1">Cao et al., 2021)</ref>.</p><p>A substantial amount of work has focused on the monolingual cross-database setup, where both the natural language and the database schema are in English, by (i) increasing the size or complexity of architectures <ref type="bibr">(Wang et al., 2020a;</ref><ref type="bibr" target="#b1">Cao et al., 2021;</ref><ref type="bibr" target="#b12">Shaw et al., 2021)</ref> or (ii) introducing series of pre-training stages <ref type="bibr" target="#b20">(Yu et al., 2021)</ref>. The computational cost of such approaches tends to increase, with a few approaches investigating how improved execution times can facilitate their deployability in production environments <ref type="bibr" target="#b9">(Lukovnikov and Fischer, 2021;</ref><ref type="bibr" target="#b11">Rubin and Berant, 2021)</ref>.</p><p>In this paper, we altogether delete the decoder, which is traditionally responsible for the largest amount of the necessary computational workload <ref type="bibr" target="#b0">(Akoury et al., 2019)</ref>, and treat the generation of the SQL query as a one-step multi-label classification task. We use the RAT-SQL encoder <ref type="bibr">(Wang et al., 2020a)</ref>, a popular choice among state-of-theart models employed for cross-database semantic parsing, 1 and we introduce an SQL generator capable of quickly forming the expected SQL query given a set of semantic predictions on top of the input database schema's elements.</p><p>Another factor that prohibits the deployability of state-of-the-art systems is their reliance on the monolingual setting, where both the natural language questions and the database schema are in the same language. While schema information of non-English databases is often available in English, there are several challenges in transferring a monolingual system to the cross-lingual setup, where the natural language question is in a different language than the database. Most existing cross-lingual solutions have focused on shared database semantic parsing setups where evaluation databases are known during training <ref type="bibr" target="#b14">(Sherborne et al., 2020;</ref><ref type="bibr" target="#b19">Xia and Monti, 2021;</ref><ref type="bibr" target="#b13">Sherborne and Lapata, 2022)</ref>.</p><p>In this paper, we address the above challenges, enabling Text-to-SQL semantic parsing in the crosslingual and cross-database setup in a fast and scalable way, and facilitating the deployment of relevant solutions in business intelligence products. We apply our model (FastRAT) on CSpider and Spider, two challenging zero-shot semantic parsing benchmarks. Our system achieves an average of 10 times decoding speedup over competitive baselines based on auto-or semi-auto-regressive decoding. Interestingly, FastRAT, a 673M-parameter architecture, is able to outperform the multi-billion-parameter ChatGPT system across both benchmarks, while 1 https://yale-lily.github.io/spider and https: //taolusi.github.io/CSpider-explorer/ being significantly less computationally expensive than it. In particular, on a cross-lingual dataset, our approach achieves an exact query match accuracy score of 61.3, outperforming the relevant competition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Our method draws inspiration from work on fast decoding and cross-lingual semantic parsing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Fast Decoding</head><p>Text-to-SQL semantic parsing problems are quite often solved with architectures that follow the sequence-to-sequence paradigm. Such models include an encoder, which reads and encodes the input, and a decoder, which predicts the corresponding output, often sequentially. Depending on the size and complexity of the models, the encoding and decoding process can be long; however, admittedly, decoding is the most time-consuming part.</p><p>The main reason for the time inefficiency of decoders is the fact that decoding is usually performed in an auto-regressive manner: one token at a time, in a specified direction. Auto-regressive models are based on the idea that, in order to predict the k-th element of a sequence, a model will need to have first predicted and consulted the previous k -1 elements. Interestingly, due to the intuitive information flow, auto-regressive models generally achieve better performance compared to their nonauto-regressive counterparts <ref type="bibr" target="#b0">(Akoury et al., 2019)</ref>.</p><p>A more efficient decoder would be one that is able to predict more than one token or element per decoding timestep t. <ref type="bibr" target="#b25">Zhu et al. (2020)</ref>; <ref type="bibr" target="#b9">Lukovnikov and Fischer (2021)</ref> reduce the number of decoding timesteps by using insertion-based tree decoding. The most recent work following this paradigm is the work by <ref type="bibr" target="#b11">Rubin and Berant (2021)</ref>. The authors propose a semi-auto-regressive semantic parser, SmBoP, that works in a bottom-up fashion by constructing, for each timestep t, the top-scoring subtrees of height less than or equal to t. Since SmBoP operates in a bottom-up fashion, all sub-trees of a certain height can be computed in parallel, thus reducing the computational complexity of the decoding task. While SmBoP substantially improves decoding times over auto-regressive models, its average runtime is still quite high to meet deployment standards. For reference, in a well-known Text-to-SQL dataset <ref type="bibr" target="#b21">(Yu et al., 2018)</ref>, SmBoP needs an average of 9 timesteps to decode SQL queries.</p><p>Taking the semi-auto-regressive idea to its extreme, one can have a completely non-autoregressive decoder that generates the whole output in one timestep. Inspired by recent work <ref type="bibr" target="#b20">(Yu et al., 2021)</ref>, instead of predicting SQL queries as sequences of tokens, we predict sets of SQL Semantic Prediction (SSP) labels associated with each table and column name of the input database. Subsequently, using a simple algorithm, we translate the set of SSP labels into an SQL query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Cross-lingual Semantic Parsing</head><p>The efforts of the scientific community to build systems for cross-lingual semantic parsing have led to the development of a series of relevant benchmark datasets <ref type="bibr" target="#b10">(Min et al., 2019;</ref><ref type="bibr" target="#b5">Dou et al., 2023;</ref><ref type="bibr" target="#b23">Zhang et al., 2023)</ref>. Most recent approaches for cross-lingual semantic parsing have sought to localise parsers to new target languages using backtranslations <ref type="bibr" target="#b14">(Sherborne et al., 2020)</ref> or machine translation <ref type="bibr" target="#b19">(Xia and Monti, 2021;</ref><ref type="bibr" target="#b15">Shi et al., 2022)</ref>. Such solutions precondition access to high-quality machine translation or source-target language alignment systems. However, under realistic circumstances, the resulting data diverges from actual test cases, leading to poor generalisation. More recently, <ref type="bibr" target="#b13">Sherborne and Lapata (2022)</ref> proposed a multi-task encoder-decoder model to transfer parsing knowledge to additional languages using only English logical form paired data and in-domain natural language corpora in the target languages.</p><p>While this approach has shown promising results for shared-database semantic parsing, challenges associated with linking column mentions to unseen databases are not addressed in the cross-lingual setup. In this work, we introduce a unified framework, based on distant supervision, for generating high-quality, aligned logical form queries in SQL and questions in a target language. This framework does not assume the existence of any machine translation systems, thus preserving the resulting data from any relevant inefficacies. Furthermore, inspired by <ref type="bibr" target="#b13">Sherborne and Lapata (2022)</ref>, we propose a new multi-task training scheme which offers tighter interaction between the input language and the schema representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our Approach</head><p>Let q = q 1 , q 2 , . . . , q Q be the sequence of tokens of a natural language question, t = t 1 , t 2 , . . . , t T tables, and c = c 1 1 , c 1 2 , . . . , c 1 C 1 , . . . , c T C T columns of a database D related to q, where C 1 , . . . , C T ∈ N are the indices of the last column of table t 1 and t T respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Query Decoding with SSP Labels</head><p>We follow the formulation of the auxiliary SSP task, introduced by <ref type="bibr" target="#b20">Yu et al. (2021)</ref>. In this task, given a database schema and a natural language question, the goal is to compute the SQL operation in which each column of the input schema would participate in the expected SQL query. An idealised example of the task of assigning SSP labels to the columns of an input schema and of their relevance to the expected SQL query is presented in Table <ref type="table" target="#tab_8">7</ref> of Appendix A.</p><p>Our architecture consists of a pre-trained language model which takes as input the concatenation of the input natural language question with the column and table names of a database schema of interest. In contrast to <ref type="bibr" target="#b20">Yu et al. (2021)</ref>, we extend the SSP task across the entire schema, and compute relevant SQL operations across both column and table names. Furthermore, we treat learning this version of the task as the final training step required by our system, and not as an additional pre-training phase. Consequently, we minimise any potential task-relevance gaps that can be introduced by pretraining and fine-tuning architectures in tasks of different natures. Our system is capable of efficiently decoding the SQL query that answers the input question q, by using the set of SSP labels that are computed for each element of the input schema.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">From SQL to SSP Labels</head><p>Columns and tables (schema elements) appear in SQL queries in specific contexts: each occurrence of a schema element appears in a specific SQL keyword or clause, along with an aggregate (e.g. COUNT or MAX) or an operator (e.g. = or !=), possibly within a sub-query. Each schema element occurrence can be translated into a string or snippet, that contains the basic information about where this element appears in the SQL query. Such information is encoded in SSP labels by design: each label is the concatenation of the snippets corresponding to instances of a particular column or table name in the SQL query.</p><p>Occurrence snippets are composed of three elements: (i) the nest which indicates in which subquery the schema element appears (empty for the main query), (ii) the SQL keyword/clause that is involved (SELECT, FROM, WHERE etc), and (iii) the var-ious arguments providing additional information, such as aggregate or comparison operators. For instance, in Figure <ref type="figure" target="#fig_0">1</ref>, column furniture_id of table clients appears in the sub-query indicated by the "OP_SEL" nest. This column appears in the WHERE statement of the SQL query, and its comparison operator is "=". Consequently, the occurrence snippet for the furniture_id column is "OP_SEL WHERE =". The SSP label for furniture_id is then the concatenation of all its occurrence strings; in this case only "OP_SEL WHERE =".  We model the various possible sub-queries configurations that can appear in an SQL query using the following keywords in the nest: (i) OP_SEL for sub-query, (ii) INTERSECT for an occurrence in a query after an intersect, (iii) UNION for an occurrence in a query after a union and (iv) EXCEPT for an occurrence in a query after an except. Keywords can be chained together when needed. For example, an occurrence of a column in a sub-query after an intersect operation would result in the inclusion of the following nest snippet in its corresponding occurrence string: "INTERSECT OP_SEL".</p><p>Once the nest of an occurrence string is determined, we add the keyword/clause (i.e. SELECT, FROM, WHERE, HAVING, GROUP_BY and ORDER_BY) in which it appears. Each operator might be followed by extra keywords:</p><p>• For SELECT, we add the aggregation operator that is applied to the column (e.g., SELECT count for the room.chairs column in Figure <ref type="figure" target="#fig_0">1</ref>). In case no aggregator is applied, we add the "none" keyword.</p><p>• FROM does not require extra information. Note that FROM can only appear in the SSP label of a table name.</p><p>• For HAVING, we add the relevant aggregate and comparison operator (e.g., "=", "&lt;", etc).</p><p>• For WHERE, we add the comparison operator, and an "OR" keyword if there is an "OR" condition next to the occurrence in the SQL query.</p><p>• For GROUP_BY, we add the aggregator.</p><p>• For ORDER_BY, we add the relevant aggregator, the order type ("ASC" or "DESC") and the keyword "LIMIT", if applicable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">From SSP Labels to SQL</head><p>Given a set of SSP labels, it is straightforward to uncover the basic structure of the corresponding SQL query, and find the appropriate places of the column and table mentions. We start by the nests appearing in the SSP labels, as they indicate the overall structure of the SQL query. For each sub-query identified, we extract from the SSP labels the columns that appear in it, and place them in the right position (using operators SELECT, WHERE, etc), respecting the SQL format.</p><p>Since SSP labels do not provide details about the position of sub-queries, we construct all possible SQL queries by placing each sub-query in all appropriate HAVING and WHERE statements. This process however does not build JOIN statements, since SSP labels do not contain column-joining operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Table Joining Algorithm</head><p>The most challenging part of decoding is finding the correct joins for the tables involved. We have developed an algorithm capable of generating complex join statements and finding tables that are required to construct SQL queries in which tables might not necessarily appear in any other places apart from the JOIN operators.</p><p>The algorithm (i.e. Algorithm 1) starts by adding all tables that should appear in the FROM statement into a list L t . It then builds a set of tables L s , of which the join statements are known: it begins by adding tables such that each table can be directly joined with another one in L s using a foreign key (lines 5-8). Then, it attempts to complete the JOIN statement as follows: for each table t i left to join, it finds a table t j in the database schema that can be joined to t i and t j can be joined to a table in L s (lines 10-13). A more detailed description of the involved steps is provided in Appendix B.</p><p>Algorithm 1: Joining algorithm for finding the appropriate join statement given a set of tables. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Pre-training Data Construction</head><p>Most Text-to-SQL models are trained and tested on a single language. However, the commercial need to deploy similar models for more than one language is very common. While architectures can be reused, adapting an existing model to a new language requires large amount of data in that language, which can be cumbersome to find in multiple languages. As an example, a popular pretraining dataset for Text-to-SQL <ref type="bibr" target="#b20">(Yu et al., 2021)</ref> has 400k examples; obtaining a good translation of it would take a substantial budget and some months of annotation work. Our approach to efficiently create a dataset in a new language works as follows:</p><p>• Starting from a dataset containing tuples of the form (natural language question, SQL query) we obtain templates for both elements, resulting in a small dataset of tuples of the form (natural language template, SQL template).</p><p>• We translate the natural language templates to the new language, resulting in a dataset of (natural language template in new language, SQL template) tuples.</p><p>• We sample databases, table and column names from data in the new language, and populate multiple instances of each template.</p><p>Table <ref type="table" target="#tab_2">1</ref> shows this process for a single example. Abstracting away from the templates and considering the grammar that can create natural language and SQL templates, one can think of this approach as a synchronous context-free grammar that has rules to produce text and corresponding SQL in two languages. An example of such grammar is shown in Table <ref type="table" target="#tab_12">8</ref> of the Appendix.</p><p>In our experiments, we manually translate the rules of the grammar released by <ref type="bibr" target="#b20">Yu et al. (2021)</ref> to Chinese. In our translated grammar version, there are 328 natural language production rules, corresponding to 88 SQL templates; each SQL template is paired with 1-18 natural language templates. We generate the final version of the dataset by adding terminal rules with names from new databases.</p><p>This approach, inspired by distant supervision (since it creates a weakly labelled dataset from existing data), requires substantially lower effort and resources than translating the whole dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Pre-training Strategy</head><p>The cross-lingual capabilities of our model are powered by a multi-task pre-training process. Starting off with an already pre-trained model (such as, XML-RoBERTa; Conneau and Lample 2019), we continue pre-training with a compound loss consisting of two terms: one for Semantic SQL Prediction (SSP) and one for Language Prediction (LP). A schematic representation of our pre-training framework can be seen in Figure <ref type="figure">2</ref> of the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Semantic SQL Prediction (SSP)</head><p>This objective encourages the model to implicitly learn associations between table and column names and their mentions in the text. Specifically, we prepend all columns with a delimiter ⟨/s⟩ in the input, and apply a sequence of {Linear, GELU, and LayerNorm} layers on top of the encoder representations for each ⟨/s⟩. The loss term for this task, L SSP , is the cross-entropy loss of the SSP label predictions.</p><p>Language Prediction (LP) Aiming to reduce the distance between the distributions of different languages in the encoder representations, we include a loss term for language prediction of the natural language question. Specifically, we classify between the available languages using the representation generated for the first token ⟨s⟩ of the input. The loss term for this task, L LP , is the cross-entropy loss of the language prediction. <ref type="foot" target="#foot_0">2</ref>We combine the two above-mentioned loss terms to get the loss which we use to pre-train our model,</p><formula xml:id="formula_0">L total = L SSP -L LP .</formula><p>(1)</p><p>During pre-training, our model tries to minimise the above cost function. During fine-tuning, L LP is omitted, and the system is optimised using L SSP .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We experiment on two SQL semantic parsing datasets, seeking to explore the effectiveness of our approach on both a monolingual and a crosslingual setup. Specifically, we report experiments on CSpider <ref type="bibr" target="#b10">(Min et al., 2019)</ref> and Spider <ref type="bibr" target="#b21">(Yu et al., 2018)</ref>, which contain database schema information and examples in Chinese and English respectively. Since CSpider is a translated version of the Spider dataset, the characteristics of the two with respect to structure and number of examples are identical.</p><p>Both datasets contain 8, 659 examples of questions and SQL queries along with their relevant SQL schemata (i.e. 146 unique databases). Since the test splits are only available through the evaluation servers associated with the datasets, we focus our evaluation on the development set, which is used as a test set in our experiments. This split consists of 1, 034 examples of questions on 20 unique databases that are not seen during training. Consistently with the CSpider<ref type="foot" target="#foot_1">3</ref> and Spider<ref type="foot" target="#foot_2">4</ref> leaderboards, we report results using exact match accuracy.<ref type="foot" target="#foot_3">5</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>FastRAT provides a strong decoding subsystem, but has no specific implementation for a text and schema encoder. As such, in order to instantiate an end-to-end system, we mount FastRAT to the RAT-SQL encoder. <ref type="foot" target="#foot_4">6</ref> We couple this encoder with XLM-RoBERTa (i.e. XLM-RoBERTalarge) to create a cross-lingual semantic parser, and with BERT LARGE to create a monolingual semantic parser. The selection of BERT LARGE and XLM-RoBERTa-large is in line with the pre-trained language models that were used by the RAT-SQL baseline <ref type="bibr">(Wang et al., 2020a)</ref>, and the GraPPa pretraining framework <ref type="bibr" target="#b20">(Yu et al., 2021)</ref>. For the experiments on CSpider, we simply opt for an equivalent multilingual version, and XLM-RoBERTa appears to achieve better performance for natural language understanding tasks than multilingual BERT (Conneau and Lample, 2019; <ref type="bibr">Conneau et al., 2019)</ref>.</p><p>Hyper-parameters used for pre-training and finetuning are listed in Appendix E.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pre-training</head><p>We pre-train our model using the pre-training setup described in Section 3.3, on a dataset generated as described in Section 3.2. The resulting data is constructed using the pairs of translated NL and SQL templates, which we populate with data (column and table names, and other relevant values) from DuSQL <ref type="bibr">(Wang et al., 2020b)</ref> databases, since their schemata are in Chinese. The mono-lingual variants (tested on Spider) are pretrained using the official GraPPa pre-trained model provided by <ref type="bibr" target="#b20">Yu et al. (2021)</ref>. In all scenarios, fine-tuning is performed exclusively on the target dataset: CSpider and Spider for the cross-lingual and mono-lingual variants respectively.</p><p>Baselines We compare the performance of our system to that of the following architectures:</p><p>• RAT-SQL (Relation-Aware Transformer; <ref type="bibr">Wang et al. 2020a</ref>) is a strong baseline for SQL semantic parsing. The relation-aware self-attention mechanism of RAT-SQL has been used in the architecture of several subsequent parsers, including our own.</p><p>• SmBoP (Semi-autoregressive Bottom-up Semantic Parsing; Rubin and Berant 2021) is a semi-auto-regressive semantic parser, which constructs SQL bottom-up, parallelising the calculation of sub-trees in the same height.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Performance on Semantic Parsing</head><p>The performance of FastRAT and baseline systems on the cross-lingual setup, using the CSpider dataset, can be seen in Conversely, the monolingual results in Table <ref type="table">3</ref> show that RAT-SQL and SmBoP, both specifically designed as monolingual models, outperform Fas-tRAT, although the performance of the latter is comparable with the baselines. The RAT-SQL encoder relies on matching mentions of tables and columns in the natural language question to the accompanying schema, a task which is simpler in the monolingual setup, where both question and schema are in the same language. Nonetheless, in the cross-lingual setup, the effect of schema linking becomes much more sparse. We believe that this explains the performance difference of RAT-SQL across CSpider and Spider, and how its performance relates to our scores. Interestingly, SSP pre-training<ref type="foot" target="#foot_5">7</ref> results in improvements for all three models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Ablation</head><p>The last columns of Tables <ref type="table" target="#tab_4">2</ref> and<ref type="table">3</ref> show the contribution of each of the components of FastRAT. It can be seen that adding SSP pre-training increases the exact match scores by more than 5 points in both the monolingual and the cross-lingual setup. Moreover, in the cross-lingual setup, language prediction pre-training seems to benefit all models and, when used with FastRAT, results in a system which outperforms all baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Evaluation on Known Databases</head><p>While the original data splits of Spider and CSpider seek to assess the models' capability to generalise to unseen databases, this is not the only possible scenario in industrial applications. A realistic deployment scenario can involve users or developers of a semantic parser, who are able to provide the system with a number of training examples for a particular database, which can be used to further refine the model to the schema of interest.</p><p>In order to test our approach in such a setup, in line with previous research on a compositional generalisation of semantic parsers <ref type="bibr" target="#b12">(Shaw et al., 2021)</ref>, we experiment on a number of different data splits of the Spider dataset: (i) based on source length (Len), (ii) based on Target Maximum Compound Divergence (TMCD), (iii) based on templates generated by anonymising integers and quoted strings (Template), and (iv) a random split (Random) . In all four splits, databases are shared between the train and development sets. Results can be seen in Table <ref type="table">4</ref>, which also includes the performance of two other models, (T5-Base, and NQG-T5-Base) for reference. It can be seen that FastRAT's perfor-mance follows from the difficulty of the data splits (lowest scores for Len split, higher for Random, and better performance on TMCD than Template).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System</head><p>Rand. Templ. Len TMCD (base) a model that uses a flexible quasi-synchronous grammar; data splits and results for T5 and NQG-T5 obtained from previous work <ref type="bibr" target="#b12">(Shaw et al., 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Comparing against ChatGPT</head><p>We include a comparison of our system against <ref type="bibr" target="#b8">Liu et al. (2023)</ref>, that explores a way of leveraging ChatGPT for zero-shot semantic parsing. Table <ref type="table">5</ref> summarises the results. Since larger pre-trained language models tend to under-perform in the exact match accuracy setting <ref type="bibr" target="#b8">(Liu et al., 2023)</ref>, we also include the relevant execution accuracy scores. We can see that the exact-match-accuracy performance of FastRAT is superior across all settings. Interestingly, FastRAT (which has only 673M parameters compared to multi-billion-parameter, GPT models), outperforms ChatGPT even with respect to execution accuracy. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Runtime Performance</head><p>The strongest feature of FastRAT is its speed; while it may not outperform state-of-the-art models in all setups and datasets as shown in the previous section, its decoder-free architecture allows for very fast decoding times compared to baseline models.</p><p>Table <ref type="table" target="#tab_7">6</ref> shows the runtimes of our system and baseline models, including end-to-end times and decoding times separately, on a CPU (2x AMD EPYC 7763 64-Core 1.8GHz) and a GPU (single A100-SXM-80GB). It can be seen that FastRAT decoding speed is an order of magnitude smaller than that of the baselines, with 2ms average decoding time on a GPU. Interestingly, decoding with FastRAT is 4 times faster than decoding with Sm-BoP,<ref type="foot" target="#foot_6">8</ref> which in turn has a lower decoding time than the original RAT-SQL implementation. End-to-end prediction results paint a similar picture: the average FastRAT prediction time is less than 1s on CPU, and 33ms on GPU, with the next fastest being RAT-SQL (1.4s and 257ms respectively).</p><p>The SQL queries in the datasets that we used consist of an average of 17.5 tokens (assuming wordlevel tokenisation), with a maximum length of 62 tokens. We believe that these numbers are on par with the length of the output of systems for other language generation tasks. It is important to note that industrial text-to-SQL applications commonly involve very long SQL queries, spanning several lines of code. The value of our efficient decoding paradigm becomes even more apparent in such cases, since with conventional, auto-regressive approaches, decoding time would increase linearly with respect to the expected query's length.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System</head><p>Decoding End-to-End CPU GPU CPU GPU RAT-SQL 0.412 0.120 1.441 0.257 SmBoP 0.558 0.037 7.338 0.065 FastRAT 0.010 0.002 0.993 0.033 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>FastRAT is proposed as a very fast Text-to-SQL semantic parser (substantially faster than its coun-terparts); as such, it navigates a trade-off between fast decoding times and parsing performance. Our view is that FastRAT balances this tradeoff effectively, since it achieves 10 times decoding speedup with a small performance hit (3 EM accuracy points compared to SmBoP) in Spider, and increased performance against the baseline systems on CSpider.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Expressive Power of the Decoder</head><p>FastRAT uses a deterministic decoder mechanism on top of the SSP label predictions. This design signifies a shift from commonly used decoding algorithms, which decode on a token, token chunk, or sub-tree basis.</p><p>It is important to verify that the decoding capability of FastRAT is expressive enough to fully construct SQL queries. While our algorithm is not designed to fully cover the entirety of the SQL syntax, we can quantify its expressive power using publicly available benchmarks. To this end, we run an oracle experiment: we encode SQL queries from Spider <ref type="bibr" target="#b21">(Yu et al., 2018)</ref>, DuSQL <ref type="bibr">(Wang et al., 2020b)</ref> and NL2SQL <ref type="bibr" target="#b16">(Sun et al., 2020)</ref> to SSP and then translate SSP labels back to SQL using the approach described in Section 3.1. Exact match accuracy scores on the generated SQL queries provide an upper-bound performance for our system. The scores on Spider are 95.2%, on DuSQL 89.04%, and on NL2SQL 96.31%. We conclude that our decoding algorithm is capable of successfully constructing most queries in the public parts of the datasets, and leaves enough room for improvement in the model development process.</p><p>The SQL queries that cannot be fully reconstructed belong to one of the following types: (i) they contain multiple HAVING/WHERE clauses with sub-queries, and our algorithm fails to correctly determine the antecedent of the sub-query, (ii) they contain sub-queries in the SELECT or FROM clauses of the SQL query which are not currently supported by our algorithm, or (iii) they include multiple elements in ORDER BY or GROUP BY clauses, which our algorithm predicts with a different order than the original.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Error Analysis</head><p>Conversely to other decoding mechanisms, Fas-tRAT is trained on the SSP label classification task. In other words, the model is explicitly trained to identify correct SSP labels, not to generate correct SQL queries. As such, errors in SSP predictions result directly in errors during SQL generation.</p><p>Throughout our experiments, we observed low generalisation in a subset of the development set, which we attribute to the characteristics of the dataset. Specifically, there are 11 SSP labels in the development set that do not appear in the training split, and which account for 30 development examples. Naturally, it is challenging for the model to correctly output predictions for those labels.</p><p>Moreover, is worth noting that there is a number of patterns of SSP labels<ref type="foot" target="#foot_7">9</ref> in the development split, which are underrepresented or absent from the training data. In total, there are 1, 084 unique SSP patterns in the training set and 245 in the development set. The development set includes 73 patterns which do not appear in the training set and which account for 127 examples. Unsurprisingly, our model performs worse on those unseen SSP patterns (correct output in only 18% of the examples). This disparity in the data splits is an inherent limitation of the dataset, which affects many semantic parsers. We observed similar low performance (32%) on this subset of examples in LGESQL <ref type="bibr" target="#b1">(Cao et al., 2021)</ref>, a system which has been used in different variants by many state-ofthe-art models. However, given FastRAT's heavy reliance on SSP semantics, it is disproportionately affected by this disparity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we propose FastRAT, an efficient cross-lingual Text-to-SQL semantic parser. Fas-tRAT includes a deterministic decoding mechanism, which makes it 10 times faster than the fastest previously available Text-to-SQL semantic parser.</p><p>Furthermore, we propose a method to efficiently construct pre-training datasets in new languages given a dataset in a source language. Finally, we introduce a pre-training setup, designed for the cross-lingual Text-to-SQL parsing setup; a setup in which other systems do not perform favourably. Our approach can be used to port Text-to-SQL semantic parsers to new languages quickly, and our experiments show that FastRAT outperforms strong baselines in the cross-lingual setup, while being significantly faster than them.</p><p>As for future work, we plan to further improve the expressive power of the decoder. Furthermore, we will look into coupling FastRAT with other decoding setups based on larger language models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>The design of the deterministic FastRAT decoder does not fully cover the entirety of SQL syntax. Consequently, a subset of SQL queries cannot be decoded using our approach. While Section 5 provides a detailed analysis of the expressive power of our decoder, it is important to note FastRAT is able to effectively and efficiently decode most SQL queries of general-purpose datasets (92% of Spider), and that challenging queries (see also Section 5 for a qualitative analysis) are usually part of the hard or extra hard difficulty splits of the datasets, which are rarely observed in everyday deployment scenarios.</p><p>Additionally, the analysis presented in this paper includes a small number of baselines: in most experiments, we compare FastRAT with RAT-SQL and SmBoP. This choice of baselines experimentally highlights how FastRAT navigates the tradeoff between fast decoding times and parsing performance. Specifically, RAT-SQL is a very strong text-to-SQL baseline (all Spider leader-board submissions compare against the original RAT-SQL baseline or its variants; also, a large number of submissions use RAT-SQL or parts thereof in their architecture). On the other hand, SmBoP is the fastest parser to date. FastRAT balances this trade-off effectively, since it achieves 10x decoding speedup over SmBoP with a small performance loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A From SQL to SSP Example</head><p>An idealised example of the task of assigning SSP labels to the columns of an input schema and of their relevance to the expected SQL query is presented in Table <ref type="table" target="#tab_8">7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Table Joining Algorithm</head><p>A detailed description of the steps that are involved for the table joining algorithm of Section 3.1.3 is presented below:  • Step 3: Check the remaining tables to join for tables t b that references without chaining a table t a that has already been added to the FROM statement (noted t a ⇐⇒ t b ). This means that there exists a sequence of tables (t j ) j∈[1,T ] such that t 1 = t a and t T = t b and ∀j ∈ [1, T -1], t j ⇌ t j+1 . In this case, add each intermediate table t j to the FROM statement and join on the columns allowed by these direct joins. This last step corresponds to the case where tables can be joined together but only on foreign keys referencing different columns in a third table.</p><formula xml:id="formula_1">′ → * c b b ′ ). A foreign key chain (c t i l i ) i∈[1,k] is a sequence such that: ∀i ∈ [1, k -1], t t i is a table and c t i l i is a column of table t t i st. c t i l i → c t i+1 l i+1 . We define that c a a ′ → * c b b ′ iif there exist a foreign key chain (c t i l i ) i∈[1,k] st. c a a ′ = c t 1 l 1 and c b b ′ = c t k l k . In</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C English-Chinese Context-free Grammar Example</head><p>Table <ref type="table" target="#tab_12">8</ref> shows an example of a synchronous context-free grammar for Chinese and English.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Pre-training Framework</head><p>A schematic representation of our pre-training framework, including an example, can be seen in Figure <ref type="figure">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Hyper-parameters</head><p>The hidden size for RAT (i.e. Relation-Aware Transformer) and the SSP decoder is 1024. Optimisation is performed using Adam (Kingma and Ba, 2014). We trained for 100 epochs with 5 epochs of linear warmups. After the warmup steps, we use a linear decay down to zero for both learning rates. The following tables include detailed hyperparameters that have been used for pre-training and fine-tuning for both the monolingual and crosslingual setup of FastRAT.</p><p>Non-terminals (EN) Production rules (EN)   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example of the SSP labels that describe a particular SQL query.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Initialise L t with all the tables appearing the the query; 2 Step 2: Find the direct joining statements; Initialise L s = [t i ] with a random table t i from L t ;</figDesc><table><row><cell>8</cell><cell>end</cell></row><row><cell cols="2">9 Step 3: Find the join statements that require</cell></row><row><cell></cell><cell>additional tables;</cell></row></table><note><p>1 Step 1: 3 4 Delete t i from L t ; 5 while t b ∈ L t s.t T a ⇌ T b for t a ∈ L s do 6 Add t b to L s ; 7 Delete t b from L t ; 10 while t b ∈ L t s.t T a ⇐⇒ T b for t a ∈ L s do 11 Add t b and all intermediate tables to L s ; 12 Delete t b from L t ; 13 end 14 Return L s</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Example of how data instances consisting of natural language question (in en) and SQL query can be translated into a new language (i.e. zh) using our approach. C0, T0, OP0, VAL0 are placeholders for columns, tables, operators, and values respectively.</figDesc><table><row><cell>en NL question</cell><cell>How many department heads have an age over 40?</cell></row><row><cell>SQL</cell><cell>SELECT COUNT(*) FROM head WHERE age &gt; 40</cell></row><row><cell cols="2">en NL template COUNT(*) T0 have C0 OP0 VAL0</cell></row><row><cell>SQL template</cell><cell>SELECT COUNT(*) FROM T0 WHERE C0 OP0 VAL0</cell></row><row><cell cols="2">zh NL template VAL0 C0 OP0 的 T0 有多少?</cell></row><row><cell>SQL template</cell><cell>SELECT COUNT(*) FROM T0 WHERE C0 OP0 VAL0</cell></row><row><cell cols="2">zh NL question 40 岁 以上 的 部门主管 有多少？</cell></row><row><cell>SQL</cell><cell>SELECT COUNT(*) FROM head WHERE age &gt; 40</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>. Our best model vari-</cell></row><row><cell>ant, FastRAT+SSP+LP outperforms all variants of</cell></row><row><cell>the baseline systems. Although the vanilla version</cell></row><row><cell>of FastRAT (without our pre-training step) is not</cell></row><row><cell>the strongest method, the contribution of our pre-</cell></row><row><cell>training scheme is verified, since FastRAT+SSP</cell></row><row><cell>and FastRAT+SSP+LP outperform RAT-SQL and</cell></row><row><cell>SmBoP variants with the same pre-training.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Exact match accuracy for the cross-lingual setup, on the development split of CSpider. "XLM" (i.e. XLM-RoBERTa-large) refers to the vanilla variant of each system, "+SSP" includes SSP pre-training, and "+SSP+LP" includes SSP and LP pre-training. The last row is the state-of-the-art system according to CSpider leaderboard (accessed 19 Sep. 2023).</figDesc><table><row><cell>System</cell><cell cols="3">Variant XLM +SSP +SSP+LP</cell></row><row><cell>RAT-SQL</cell><cell>47.8</cell><cell>55.1</cell><cell>56.4</cell></row><row><cell>SmBoP</cell><cell>56.4</cell><cell>57.4</cell><cell>57.7</cell></row><row><cell>FastRAT</cell><cell>54.3</cell><cell>59.9</cell><cell>61.3</cell></row><row><cell>RoBERTa Seq2SQL</cell><cell></cell><cell>66.2</cell><cell></cell></row><row><cell>System</cell><cell cols="3">Variant BERT LARGE +SSP</cell></row><row><cell>RAT-SQL</cell><cell></cell><cell>69.7</cell><cell>73.6</cell></row><row><cell>SmBoP</cell><cell></cell><cell>63.4</cell><cell>72.1</cell></row><row><cell>FastRAT</cell><cell></cell><cell>63.2</cell><cell>69.1</cell></row><row><cell cols="2">CatSQL + GraPPa</cell><cell>78.6</cell><cell></cell></row></table><note><p><p><p>Table</p>3</p>: Exact match accuracy for the monolingual setup, on the development split of Spider. "BERT" column refers to the vanilla variant of each system, while "+SSP" to adding SSP pre-training to each model.The last row is the state-of-the-art system according to the Spider leaderboard (accessed 19 Sep. 2023).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Average elapsed times (sec), CPU and GPU.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 :</head><label>7</label><figDesc>An idealised example of the alignment of SSP labels (in underlined font) with a particular SQL query given a single-table schema consisting of three columns -Go through all the columns that appear in the query, and add their respective tables to the list of tables to join L t .-Go through all the tables which have a FROM in their labels, and add them to L t .• Step 2: Starting with a random table t i , attempt to create an initial FROM statement by first adding direct joining. Assuming that t a ∈ L s , and that we are considering table t b , we evaluate whether t b can be directly joined to t a (noted t a ⇌ t b ) by checking if any of the following hold:</figDesc><table><row><cell>• Step 1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>this case, we add t b to the FROM statement and join on t a .c a a ′ = t b .c b b ′ . Note: We do not add all the intermediate tables t i . c d d ′ . In this case, add t b to the FROM statement and join on t a .c a a ′ = t b .c b b ′ . Note that t d does not need to be in the set of tables to join.</figDesc><table><row><cell>-Case 3: t a has a column c a a ′ which references c b b ′ in t b via a common reference chain. c a a ′ references c b b ′ via a common reference chain if there exists a column c d d ′ in a table t d st. c a a ′ →  *  c d d ′ and c b b ′ →</cell></row></table><note><p>*  </p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE → ti</head><label>→</label><figDesc>COLUMN → ci VALUE → vi AGG → ⟨ MAX, MIN, COUNT, AVG, SUM ⟩ OP → ⟨ =, ≤, . . ., LIKE, BETWEEN ⟩ SC → ⟨ ASC, DESC ⟩ MAX → ⟨ "maximum number of", "the largest" . . .⟩ ≤→ ⟨ "no more than", "at most" . . .⟩ . . .</figDesc><table><row><cell></cell><cell>1. ROOT → ⟨ "List all the {COLUMN0} which {OP0}</cell></row><row><cell></cell><cell>{VALUE0}.",</cell></row><row><cell></cell><cell>SELECT {COLUMN0} {FROM} WHERE {COLUMN0}</cell></row><row><cell></cell><cell>{OP0} {VALUE0} ⟩</cell></row><row><cell></cell><cell>2. ROOT → ⟨ "What are the {COLUMN0} in which the</cell></row><row><cell></cell><cell>{COLUMN1} was between {VALUE0} and {VALUE1}?",</cell></row><row><cell></cell><cell>SELECT {COLUMN0} {FROM} WHERE {COLUMN1}</cell></row><row><cell></cell><cell>BETWEEN {VALUE0} AND {VALUE1} ⟩</cell></row><row><cell></cell><cell>. . .</cell></row><row><cell>Non-terminals (ZH)</cell><cell>Production rules (ZH)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>TABLE → ti</head><label>→</label><figDesc>COLUMN → ci VALUE → vi AGG → ⟨ MAX, MIN, COUNT, AVG, SUM ⟩ OP → ⟨ =, ≤, . . ., LIKE, BETWEEN ⟩ SC → ⟨ ASC, DESC ⟩ MAX → ⟨ "最多的", "最大的" . . .⟩ ≤→ ⟨ "不超过", "至多" . . .⟩ . . .</figDesc><table><row><cell>1. ROOT → ⟨ "列出{OP0}{VALUE0}的所有{COLUMN0}.",</cell></row><row><cell>SELECT {COLUMN0} {FROM} WHERE {COLUMN0}</cell></row><row><cell>{OP0} {VALUE0} ⟩</cell></row><row><cell>2. ROOT → ⟨ "{COLUMN1} 在{VALUE0}和{VALUE1}</cell></row><row><cell>之间的{COLUMN0}是什么？",</cell></row><row><cell>SELECT {COLUMN0} {FROM} WHERE {COLUMN1}</cell></row><row><cell>BETWEEN {VALUE0} AND {VALUE1} ⟩</cell></row><row><cell>. . .</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 8 :</head><label>8</label><figDesc>An excerpt of our Synchronous Context-Free Grammar for Chinese (ZH), translated from the English (EN) version released by Yu et al. (2021). t i , c i , v i refer to table names, column names, and entry values respectively.</figDesc><table><row><cell cols="2">LP objective</cell><cell></cell><cell cols="2">SSP objective</cell></row><row><cell></cell><cell>language label</cell><cell></cell><cell>SSP label</cell><cell>SSP label</cell><cell>SSP label</cell></row><row><cell></cell><cell></cell><cell cols="3">Transformer Encoder</cell></row><row><cell>synthetic</cell><cell cols="5">&lt;s&gt; show the student ID that have more than 4 class. &lt;/s&gt; student_id &lt;/s&gt; class_id &lt;/s&gt; …&lt;/s&gt;</cell></row><row><cell>data</cell><cell cols="2">&lt;s&gt; 显示有超过四门课的学生的ID。</cell><cell cols="3">&lt;/s&gt; student_id &lt;/s&gt; class_id &lt;/s&gt; …&lt;/s&gt;</cell></row><row><cell></cell><cell></cell><cell cols="3">Figure 2: Model Pre-training Framework</cell></row><row><cell>Model</cell><cell></cell><cell>num_params</cell><cell>learning_rate</cell><cell>batch_size</cell><cell>num_epochs</cell></row><row><cell cols="2">xlm-roberta-large</cell><cell>550M</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">+ cross-lingual SSP</cell><cell>550M</cell><cell>1e -5</cell><cell>32</cell><cell>5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 9 :</head><label>9</label><figDesc>Pre-training Hyper-parameters    </figDesc><table><row><cell>Model</cell><cell>num_params</cell><cell>learning_rate</cell><cell cols="2">batch_size stop_criterion</cell></row><row><cell>FastRAT (with</cell><cell></cell><cell>lr: 1e -4; lm_lr:</cell><cell></cell><cell></cell></row><row><cell>bert-large or with https://github.</cell><cell>458M</cell><cell>3e -6 with polynomial decay (5%</cell><cell>40</cell><cell>100 epochs</cell></row><row><cell>com/taoyds/grappa)</cell><cell></cell><cell>warm-up steps)</cell><cell></cell><cell></cell></row><row><cell>FastRAT (with xlm-roberta-large or with + cross-lingual SSP) xlm-roberta-large</cell><cell>673M</cell><cell>lr: 1e -4; lm_lr: warm-up steps) 3e -6 with polynomial decay (5%</cell><cell>40</cell><cell>100 epochs</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 10 :</head><label>10</label><figDesc>Fine-tuning Hyper-parameters   </figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>Similarly to<ref type="bibr" target="#b14">Sherborne et al. (2020)</ref>, we reverse the gradient of the LP network in the backward pass, to encourage our model to learn language invariant representations.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>3 https://taolusi.github.io/CSpider-</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>explorer/ 4 https://yale-lily.github.io/spider</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>Exact match accuracy scores are computed using the framework provided by: https://github.com/taoyds/ test-suite-sql-eval.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>https://github.com/microsoft/rat-sql.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5"><p>We use the GraPPa model provided by<ref type="bibr" target="#b20">Yu et al. (2021)</ref>, which performs pre-training with both SSP and Masked Language Modelling (https://github.com/taoyds/grappa).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_6"><p>In our tests on a CPU, SmBoP was slower than RAT-SQL. We hypothesise that this is due to the SmBoP implementation using some GPU-specific parallelisation options.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_7"><p>A pattern of SSP labels is the set of SSP labels of a specific example, after discarding all the empty ones.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics Statement</head><p>Research described in this paper is done in accordance to the ACL code of ethics. Our work does not make use of private, proprietary, or sensitive data. The proposed models are trained on publicly available community datasets, building on top of publicly available pre-trained models. Due to the nature of the pre-training/fine-tuning scheme, it is conceivable that our system might perpetuate possible biases included in the datasets and/or the pre-trained models.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Syntactically supervised transformers for faster neural machine translation</title>
		<author>
			<persName><forename type="first">Nader</forename><surname>Akoury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kalpesh</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1122</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1269" to="1281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">LGESQL: Line graph enhanced text-to-SQL model with mixed local and non-local relations</title>
		<author>
			<persName><forename type="first">Ruisheng</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanbin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Su</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.198</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2541" to="2555" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kartikay</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Unsupervised cross-lingual representation learning at scale</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Crosslingual language model pretraining</title>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Alché-Buc</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="7059" to="7069" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Language to logical form with neural attention</title>
		<author>
			<persName><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1004</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="33" to="43" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multispider: Towards benchmarking multilingual text-to-sql semantic parsing</title>
		<author>
			<persName><forename type="first">Longxu</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingyang</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dingzirui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dechen</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian-Guang</forename><surname>Lou</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v37i11.26499</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence and Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence and Thirteenth Symposium on Educational Advances in Artificial Intelligence, AAAI&apos;23/IAAI&apos;23/EAAI&apos;23</title>
		<meeting>the Thirty-Seventh AAAI Conference on Artificial Intelligence and Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence and Thirteenth Symposium on Educational Advances in Artificial Intelligence, AAAI&apos;23/IAAI&apos;23/EAAI&apos;23</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<idno>CoRR, abs/1412.6980</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Semantic parsing with semi-supervised sequential autoencoders</title>
		<author>
			<persName><forename type="first">Tomáš</forename><surname>Kočiský</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gábor</forename><surname>Melis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D16-1116</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1078" to="1087" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">A comprehensive evaluation of chatgpt&apos;s zeroshot text-to-sql capability</title>
		<author>
			<persName><forename type="first">Aiwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuming</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lijie</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Insertionbased tree decoding</title>
		<author>
			<persName><forename type="first">Denis</forename><surname>Lukovnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asja</forename><surname>Fischer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-acl.283</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3201" to="3213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A pilot study for Chinese SQL semantic parsing</title>
		<author>
			<persName><forename type="first">Yuefeng</forename><surname>Qingkai Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1377</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3652" to="3658" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">SmBoP: Semiautoregressive bottom-up semantic parsing</title>
		<author>
			<persName><forename type="first">Ohad</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.29</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="311" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Compositional generalization and natural language variation: Can a semantic parsing approach handle both?</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.75</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="922" to="938" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Zero-shot cross-lingual semantic parsing</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Sherborne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.285</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4134" to="4153" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Bootstrapping a crosslingual semantic parser</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Sherborne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yumo</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.45</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="499" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Cross-lingual textto-SQL semantic parsing with representation mixup</title>
		<author>
			<persName><forename type="first">Peng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linfeng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lifeng</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haitao</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">He</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.findings-emnlp.388</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2022</title>
		<meeting><address><addrLine>Abu Dhabi</addrLine></address></meeting>
		<imprint>
			<publisher>United Arab Emirates. Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="5296" to="5306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">TableQA: a large-scale chinese text-to-sql dataset for table-aware sql generation</title>
		<author>
			<persName><forename type="first">Ningyuan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuefeng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunfeng</forename><surname>Liu</surname></persName>
		</author>
		<idno>ArXiv, abs/2006.06434</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">RAT-SQL: Relation-aware schema encoding and linking for text-to-SQL parsers</title>
		<author>
			<persName><forename type="first">Bailin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleksandr</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.677</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7567" to="7578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">DuSQL: A large-scale and pragmatic Chinese text-to-SQL dataset</title>
		<author>
			<persName><forename type="first">Lijie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenghua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.562</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6923" to="6935" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Multilingual neural semantic parsing for low-resourced languages</title>
		<author>
			<persName><forename type="first">Menglin</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emilio</forename><surname>Monti</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.starsem-1.17</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of *SEM 2021: The Tenth Joint Conference on Lexical and Computational Semantics</title>
		<meeting>*SEM 2021: The Tenth Joint Conference on Lexical and Computational Semantics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="185" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">GraPPa: Grammar-augmented pre-training for table semantic parsing</title>
		<author>
			<persName><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chien-Sheng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Victoria Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bailin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Chern Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-SQL task</title>
		<author>
			<persName><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongxu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zifan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irene</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingning</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shanelle</forename><surname>Roman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zilin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1425</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3911" to="3921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning to parse database queries using inductive logic programming</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">M</forename><surname>Zelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth National Conference on Artificial Intelligence</title>
		<meeting>the Thirteenth National Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1050" to="1055" />
		</imprint>
	</monogr>
	<note>AAAI&apos;96</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">XSemPLR: Cross-lingual semantic parsing in multiple natural languages and meaning representations</title>
		<author>
			<persName><forename type="first">Yusen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.acl-long.887</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 61st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="15918" to="15947" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Seq2SQL: Generating structured queries from natural language using reinforcement learning</title>
		<author>
			<persName><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno>CoRR, abs/1709.00103</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Don&apos;t parse, insert: Multilingual semantic parsing with insertion based decoding</title>
		<author>
			<persName><forename type="first">Qile</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haidar</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saleh</forename><surname>Soltan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Rawls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wael</forename><surname>Hamza</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.conll-1.40</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Conference on Computational Natural Language Learning</title>
		<meeting>the 24th Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="496" to="506" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
