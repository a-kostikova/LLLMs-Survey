[
    {
        "name": "Trustworthiness",
        "prompt": "Does the text refer to concerns about the reliability or trustworthiness of outputs generated by language models?"
    },
    {
        "name": "Reasoning",
        "prompt": "Does the text example highlight limitations of large language models in performing reasoning or inference tasks, such as multi-hop reasoning or deductive logic?"
    },
    {
        "name": "Generalization",
        "prompt": "Does the text discuss the inability of language models to generalize across different tasks or inputs?"
    },
    {
        "name": "Long Context",
        "prompt": "Does this paper explore challenges faced by large language models (LLMs) in handling long context lengths, such as limitations in memory, performance, or understanding over extended inputs?"
    },
    {
        "name": "Bias and Societal Harm",
        "prompt": "Does the text describe how LLMs propagate biases, stereotypes, or misinformation, leading to potential societal harms?"
    },
    {
        "name": "Hallucination",
        "prompt": "Does the text mention inaccuracies or fabricated content in the outputs of large language models (also multimodal)?"
    },
    {
        "name": "Alignment Limitations",
        "prompt": "Does the text highlight any limitations or challenges in aligning large language models with human values or safety protocols?"
    },
    {
        "name": "Security Risks",
        "prompt": "Does the text address the security risks associated with adversarial attacks or exploits that can manipulate large language models?"
    },
    {
        "name": "Prompt Sensitivity",
        "prompt": "Does the text highlight how slight variations in prompts affect the performance of language models?"
    },
    {
        "name": "Multimodality",
        "prompt": "Does the text discuss difficulties faced by LLMs in effectively integrating or coordinating information across multiple modalities, such as text and images?"
    },
    {
        "name": "Language and Cultural Limitations",
        "prompt": "Does this text highlight struggles of Language Models (LLMs) in effectively handling low-resource languages?"
    },
    {
        "name": "Privacy Risks",
        "prompt": "Does the text discuss vulnerabilities related to the potential leakage of private or sensitive information by language models?"
    },
    {
        "name": "Knowledge Editing",
        "prompt": "Does the text discuss challenges in knowledge editing, such as knowledge distortion, struggles with updating specific knowledge types, or difficulty integrating new knowledge while maintaining coherence?"
    },
    {
        "name": "Overconfidence",
        "prompt": "Does the text describe challenges related to calibration or overconfidence in language models?"
    },
    {
        "name": "Catastrophic Forgetting",
        "prompt": "Does this text describe Large Language Models (LLMs) losing previously acquired knowledge when learning new information?"
    }
]