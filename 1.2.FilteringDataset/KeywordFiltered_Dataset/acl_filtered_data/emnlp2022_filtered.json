[
    {
        "title": "Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space",
        "authors": [
            "Mor Geva",
            "Avi Caciularu",
            "Kevin Wang",
            "Yoav Goldberg"
        ],
        "published": "2022",
        "summary": "Transformer-based language models (LMs) are at the core of modern NLP, but their internal prediction construction process is opaque and largely not understood. In this work, we make a substantial step towards unveiling this underlying prediction process, by reverse-engineering the operation of the feed-forward network (FFN) layers, one of the building blocks of transformer models. We view the token representation as a changing distribution over the vocabulary, and the output from each FFN layer as an additive update to that distribution. Then, we analyze the FFN updates in the vocabulary space, showing that each update can be decomposed to sub-updates corresponding to single FFN parameter vectors, each promoting concepts that are often human-interpretable. We then leverage these findings for controlling LM predictions, where we reduce the toxicity of GPT2 by almost 50%, and for improving computation efficiency with a simple early exit rule, saving 20% of computation on average.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.3.pdf"
    },
    {
        "title": "Generating Natural Language Proofs with Verifier-Guided Search",
        "authors": [
            "Kaiyu Yang",
            "Jia Deng",
            "Danqi Chen"
        ],
        "published": "2022",
        "summary": "Reasoning over natural language is a challenging problem in NLP. In this work, we focus on proof generation: Given a hypothesis and a set of supporting facts, the model generates a proof tree indicating how to derive the hypothesis from supporting facts. Compared to generating the entire proof in one shot, stepwise generation can better exploit the compositionality and generalize to longer proofs but has achieved limited success on real-world data. Existing stepwise methods struggle to generate proof steps that are both logically valid and relevant to the hypothesis. Instead, they tend to hallucinate invalid steps given the hypothesis. In this paper, we present a novel stepwise method, NLProofS (Natural Language Proof Search), which learns to generate relevant steps conditioning on the hypothesis. At the core of our approach, we train an independent verifier to check the validity of the proof steps to prevent hallucination. Instead of generating steps greedily, we search for proofs maximizing a global proof score judged by the verifier. NLProofS achieves state-of-the-art performance on EntailmentBank and RuleTaker. Specifically, it improves the correctness of predicted proofs from 27.7% to 33.3% in the distractor setting of EntailmentBank, demonstrating the effectiveness of NLProofS in generating challenging human-authored proofs.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.7.pdf"
    },
    {
        "title": "The Geometry of Multilingual Language Model Representations",
        "authors": [
            "Tyler Chang",
            "Zhuowen Tu",
            "Benjamin Bergen"
        ],
        "published": "2022",
        "summary": "We assess how multilingual language models maintain a shared multilingual representation space while still encoding language-sensitive information in each language. Using XLM-R as a case study, we show that languages occupy similar linear subspaces after mean-centering, evaluated based on causal effects on language modeling performance and direct comparisons between subspaces for 88 languages. The subspace means differ along language-sensitive axes that are relatively stable throughout middle layers, and these axes encode information such as token vocabularies. Shifting representations by language means is sufficient to induce token predictions in different languages. However, we also identify stable language-neutral axes that encode information such as token positions and part-of-speech. We visualize representations projected onto language-sensitive and language-neutral axes, identifying language family and part-of-speech clusters, along with spirals, toruses, and curves representing token position information. These results demonstrate that multilingual language models encode information along orthogonal language-sensitive and language-neutral axes, allowing the models to extract a variety of features for downstream tasks and cross-lingual transfer learning.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.9.pdf"
    },
    {
        "title": "Improving Complex Knowledge Base Question Answering via Question-to-Action and Question-to-Question Alignment",
        "authors": [
            "Yechun Tang",
            "Xiaoxia Cheng",
            "Weiming Lu"
        ],
        "published": "2022",
        "summary": "Complex knowledge base question answering can be achieved by converting questions into sequences of predefined actions. However, there is a significant semantic and structural gap between natural language and action sequences, which makes this conversion difficult. In this paper, we introduce an alignment-enhanced complex question answering framework, called ALCQA, which mitigates this gap through question-to-action alignment and question-to-question alignment. We train a question rewriting model to align the question and each action, and utilize a pretrained language model to implicitly align the question and KG artifacts. Moreover, considering that similar questions correspond to similar action sequences, we retrieve top-k similar question-answer pairs at the inference stage through question-to-question alignment and propose a novel reward-guided action sequence selection strategy to select from candidate action sequences. We conduct experiments on CQA and WQSP datasets, and the results show that our approach outperforms state-of-the-art methods and obtains a 9.88% improvements in the F1 metric on CQA dataset. Our source code is available at https://github.com/TTTTTTTTy/ALCQA.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.10.pdf"
    },
    {
        "title": "Interpreting Language Models with Contrastive Explanations",
        "authors": [
            "Kayo Yin",
            "Graham Neubig"
        ],
        "published": "2022",
        "summary": "Model interpretability methods are often used to explain NLP model decisions on tasks such as text classification, where the output space is relatively small. However, when applied to language generation, where the output space often consists of tens of thousands of tokens, these methods are unable to provide informative explanations. Language models must consider various features to predict a token, such as its part of speech, number, tense, or semantics.Existing explanation methods conflate evidence for all these features into a single explanation, which is less interpretable for human understanding.To disentangle the different decisions in language modeling, we focus on explaining language models contrastively: we look for salient input tokens that explain why the model predicted one token instead of another. We demonstrate that contrastive explanations are quantifiably better than non-contrastive explanations in verifying major grammatical phenomena, and that they significantly improve contrastive model simulatability for human observers. We also identify groups of contrastive decisions where the model uses similar evidence, and we are able to characterize what input tokens models use during various language generation decisions.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.14.pdf"
    },
    {
        "title": "RankGen: Improving Text Generation with Large Ranking Models",
        "authors": [
            "Kalpesh Krishna",
            "Yapei Chang",
            "John Wieting",
            "Mohit Iyyer"
        ],
        "published": "2022",
        "summary": "Given an input sequence (or prefix), modern language models often assign high probabilities to output sequences that are repetitive, incoherent, or irrelevant to the prefix; as such, model-generated text also contains such artifacts. To address these issues we present RankGen, a 1.2B parameter encoder model for English that scores model generations given a prefix. RankGen can be flexibly incorporated as a scoring function in beam search and used to decode from any pretrained language model. We train RankGen using large-scale contrastive learning to map a prefix close to the ground-truth sequence that follows it and far away from two types of negatives: (1) random sequences from the same document as the prefix, and (2) sequences generated from a large language model conditioned on the prefix. Experiments across four different language models (345M-11B parameters) and two domains show that RankGen significantly outperforms decoding algorithms like nucleus, top-k, and typical sampling on both automatic metrics (85.0 vs 77.3 MAUVE) as well as human evaluations with English writers (74.5% human preference over nucleus sampling). Analysis reveals that RankGen outputs are more relevant to the prefix and improve continuity and coherence compared to baselines. We release our model checkpoints, code, and human preference data with explanations to facilitate future research.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.15.pdf"
    },
    {
        "title": "Multi-VQG: Generating Engaging Questions for Multiple Images",
        "authors": [
            "Min-Hsuan Yeh",
            "Vincent Chen",
            "Ting-Hao Huang",
            "Lun-Wei Ku"
        ],
        "published": "2022",
        "summary": "Generating engaging content has drawn much recent attention in the NLP community. Asking questions is a natural way to respond to photos and promote awareness. However, most answers to questions in traditional question-answering (QA) datasets are factoids, which reduce individuals’ willingness to answer. Furthermore, traditional visual question generation (VQG) confines the source data for question generation to single images, resulting in a limited ability to comprehend time-series information of the underlying event. In this paper, we propose generating engaging questions from multiple images. We present MVQG, a new dataset, and establish a series of baselines, including both end-to-end and dual-stage architectures. Results show that building stories behind the image sequence enables models togenerate engaging questions, which confirms our assumption that people typically construct a picture of the event in their minds before asking questions. These results open up an exciting challenge for visual-and-language models to implicitly construct a story behind a series of photos to allow for creativity and experience sharing and hence draw attention to downstream applications.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.19.pdf"
    },
    {
        "title": "Prompting for Multimodal Hateful Meme Classification",
        "authors": [
            "Rui Cao",
            "Roy Ka-Wei Lee",
            "Wen-Haw Chong",
            "Jing Jiang"
        ],
        "published": "2022",
        "summary": "Hateful meme classification is a challenging multimodal task that requires complex reasoning and contextual background knowledge. Ideally, we could leverage an explicit external knowledge base to supplement contextual and cultural information in hateful memes. However, there is no known explicit external knowledge base that could provide such hate speech contextual information. To address this gap, we propose PromptHate, a simple yet effective prompt-based model that prompts pre-trained language models (PLMs) for hateful meme classification. Specifically, we construct simple prompts and provide a few in-context examples to exploit the implicit knowledge in the pre-trained RoBERTa language model for hateful meme classification. We conduct extensive experiments on two publicly available hateful and offensive meme datasets. Our experiment results show that PromptHate is able to achieve a high AUC of 90.96, outperforming state-of-the-art baselines on the hateful meme classification task. We also perform fine-grain analyses and case studies on various prompt settings and demonstrate the effectiveness of the prompts on hateful meme classification.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.22.pdf"
    },
    {
        "title": "Robustness of Fusion-based Multimodal Classifiers to Cross-Modal Content Dilutions",
        "authors": [
            "Gaurav Verma",
            "Vishwa Vinay",
            "Ryan Rossi",
            "Srijan Kumar"
        ],
        "published": "2022",
        "summary": "As multimodal learning finds applications in a wide variety of high-stakes societal tasks, investigating their robustness becomes important. Existing work has focused on understanding the robustness of vision-and-language models to imperceptible variations on benchmark tasks. In this work, we investigate the robustness of multimodal classifiers to cross-modal dilutions – a plausible variation. We develop a model that, given a multimodal (image + text) input, generates additional dilution text that (a) maintains relevance and topical coherence with the image and existing text, and (b) when added to the original text, leads to misclassification of the multimodal input. Via experiments on Crisis Humanitarianism and Sentiment Detection tasks, we find that the performance of task-specific fusion-based multimodal classifiers drops by 23.3% and 22.5%, respectively, in the presence of dilutions generated by our model. Metric-based comparisons with several baselines and human evaluations indicate that our dilutions show higher relevance and topical coherence, while simultaneously being more effective at demonstrating the brittleness of the multimodal classifiers. Our work aims to highlight and encourage further research on the robustness of deep multimodal models to realistic variations, especially in human-facing societal applications.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.25.pdf"
    },
    {
        "title": "InstructDial: Improving Zero and Few-shot Generalization in Dialogue through Instruction Tuning",
        "authors": [
            "Prakhar Gupta",
            "Cathy Jiao",
            "Yi-Ting Yeh",
            "Shikib Mehri",
            "Maxine Eskenazi",
            "Jeffrey Bigham"
        ],
        "published": "2022",
        "summary": "Instruction tuning is an emergent paradigm in NLP wherein natural language instructions are leveraged with language models to induce zero-shot performance on unseen tasks. Dialogue is an especially interesting area in which to explore instruction tuning because dialogue systems perform multiple kinds of tasks related to language (e.g., natural language understanding and generation, domain-specific interaction), yet instruction tuning has not been systematically explored for dialogue-related tasks. We introduce InstructDial, an instruction tuning framework for dialogue, which consists of a repository of 48 diverse dialogue tasks in a unified text-to-text format created from 59 openly available dialogue datasets. We explore cross-task generalization ability on models tuned on InstructDial across diverse dialogue tasks. Our analysis reveals that InstructDial enables good zero-shot performance on unseen datasets and tasks such as dialogue evaluation and intent detection, and even better performance in a few-shot setting. To ensure that models adhere to instructions, we introduce novel meta-tasks. We establish benchmark zero-shot and few-shot performance of models trained using the proposed framework on multiple dialogue tasks.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.33.pdf"
    },
    {
        "title": "Unsupervised Boundary-Aware Language Model Pretraining for Chinese Sequence Labeling",
        "authors": [
            "Peijie Jiang",
            "Dingkun Long",
            "Yanzhao Zhang",
            "Pengjun Xie",
            "Meishan Zhang",
            "Min Zhang"
        ],
        "published": "2022",
        "summary": "Boundary information is critical for various Chinese language processing tasks, such as word segmentation, part-of-speech tagging, and named entity recognition. Previous studies usually resorted to the use of a high-quality external lexicon, where lexicon items can offer explicit boundary information. However, to ensure the quality of the lexicon, great human effort is always necessary, which has been generally ignored. In this work, we suggest unsupervised statistical boundary information instead, and propose an architecture to encode the information directly into pre-trained language models, resulting in Boundary-Aware BERT (BABERT). We apply BABERT for feature induction of Chinese sequence labeling tasks. Experimental results on ten benchmarks of Chinese sequence labeling demonstrate that BABERT can provide consistent improvements on all datasets. In addition, our method can complement previous supervised lexicon exploration, where further improvements can be achieved when integrated with external lexicon information.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.34.pdf"
    },
    {
        "title": "RetroMAE: Pre-Training Retrieval-oriented Language Models Via Masked Auto-Encoder",
        "authors": [
            "Shitao Xiao",
            "Zheng Liu",
            "Yingxia Shao",
            "Zhao Cao"
        ],
        "published": "2022",
        "summary": "Despite pre-training’s progress in many important NLP tasks, it remains to explore effective pre-training strategies for dense retrieval. In this paper, we propose RetroMAE, a new retrieval oriented pre-training paradigm based on Masked Auto-Encoder (MAE). RetroMAE is highlighted by three critical designs. 1) A novel MAE workflow, where the input sentence is polluted for encoder and decoder with different masks. The sentence embedding is generated from the encoder’s masked input; then, the original sentence is recovered based on the sentence embedding and the decoder’s masked input via masked language modeling. 2) Asymmetric model structure, with a full-scale BERT like transformer as encoder, and a one-layer transformer as decoder. 3) Asymmetric masking ratios, with a moderate ratio for encoder: 15 30%, and an aggressive ratio for decoder: 50 70%. Our framework is simple to realize and empirically competitive: the pre-trained models dramatically improve the SOTA performances on a wide range of dense retrieval benchmarks, like BEIR and MS MARCO. The source code and pre-trained models are made publicly available at https://github.com/staoxiao/RetroMAE so as to inspire more interesting research.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.35.pdf"
    },
    {
        "title": "QRelScore: Better Evaluating Generated Questions with Deeper Understanding of Context-aware Relevance",
        "authors": [
            "Xiaoqiang Wang",
            "Bang Liu",
            "Siliang Tang",
            "Lingfei Wu"
        ],
        "published": "2022",
        "summary": "Existing metrics for assessing question generation not only require costly human reference but also fail to take into account the input context of generation, rendering the lack of deep understanding of the relevance between the generated questions and input contexts. As a result, they may wrongly penalize a legitimate and reasonable candidate question when it (1) involves complicated reasoning with the context or (2) can be grounded by multiple evidences in the context.In this paper, we propose QRelScore, a context-aware Relevance evaluation metric for Question Generation.Based on off-the-shelf language models such as BERT and GPT2, QRelScore employs both word-level hierarchical matching and sentence-level prompt-based generation to cope with the complicated reasoning and diverse generation from multiple evidences, respectively.Compared with existing metrics, our experiments demonstrate that QRelScore is able to achieve a higher correlation with human judgments while being much more robust to adversarial samples.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.37.pdf"
    },
    {
        "title": "Abstract Visual Reasoning with Tangram Shapes",
        "authors": [
            "Anya Ji",
            "Noriyuki Kojima",
            "Noah Rush",
            "Alane Suhr",
            "Wai Keen Vong",
            "Robert Hawkins",
            "Yoav Artzi"
        ],
        "published": "2022",
        "summary": "We introduce KiloGram, a resource for studying abstract visual reasoning in humans and machines. Drawing on the history of tangram puzzles as stimuli in cognitive science, we build a richly annotated dataset that, with >1k distinct stimuli, is orders of magnitude larger and more diverse than prior resources. It is both visually and linguistically richer, moving beyond whole shape descriptions to include segmentation maps and part labels. We use this resource to evaluate the abstract visual reasoning capacities of recent multi-modal models. We observe that pre-trained weights demonstrate limited abstract reasoning, which dramatically improves with fine-tuning. We also observe that explicitly describing parts aids abstract reasoning for both humans and models, especially when jointly encoding the linguistic and visual inputs.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.38.pdf"
    },
    {
        "title": "UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models",
        "authors": [
            "Tianbao Xie",
            "Chen Henry Wu",
            "Peng Shi",
            "Ruiqi Zhong",
            "Torsten Scholak",
            "Michihiro Yasunaga",
            "Chien-Sheng Wu",
            "Ming Zhong",
            "Pengcheng Yin",
            "Sida I. Wang",
            "Victor Zhong",
            "Bailin Wang",
            "Chengzu Li",
            "Connor Boyle",
            "Ansong Ni",
            "Ziyu Yao",
            "Dragomir Radev",
            "Caiming Xiong",
            "Lingpeng Kong",
            "Rui Zhang",
            "Noah A. Smith",
            "Luke Zettlemoyer",
            "Tao Yu"
        ],
        "published": "2022",
        "summary": "Structured knowledge grounding (SKG) leverages structured knowledge to complete user requests, such as semantic parsing over databases and question answering over knowledge bases. Since the inputs and outputs of SKG tasks are heterogeneous, they have been studied separately by different communities, which limits systematic and compatible research on SKG. In this paper, we overcome this limitation by proposing the UnifiedSKG framework, which unifies 21 SKG tasks into a text-to-text format, aiming to promote systematic SKG research, instead of being exclusive to a single task, domain, or dataset. We use UnifiedSKG to benchmark T5 with different sizes and show that T5, with simple modifications when necessary, achieves state-of-the-art performance on almost all of the 21 tasks. We further demonstrate that multi-task prefix-tuning improves the performance on most tasks, largely improving the overall performance. UnifiedSKG also facilitates the investigation of zero-shot and few-shot learning, and we show that T0, GPT-3, and Codex struggle in zero-shot and few-shot learning for SKG. We also use UnifiedSKG to conduct a series of controlled experiments on structured knowledge encoding variants across SKG tasks. UnifiedSKG is easily extensible to more tasks, and it is open-sourced at https://github.com/hkunlp/unifiedskg.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.39.pdf"
    },
    {
        "title": "Generative Language Models for Paragraph-Level Question Generation",
        "authors": [
            "Asahi Ushio",
            "Fernando Alva-Manchego",
            "Jose Camacho-Collados"
        ],
        "published": "2022",
        "summary": "Powerful generative models have led to recent progress in question generation (QG). However, it is difficult to measure advances in QG research since there are no standardized resources that allow a uniform comparison among approaches. In this paper, we introduce QG-Bench, a multilingual and multidomain benchmark for QG that unifies existing question answering datasets by converting them to a standard QG setting. It includes general-purpose datasets such as SQuAD for English, datasets from ten domains and two styles, as well as datasets in eight different languages. Using QG-Bench as a reference, we perform an extensive analysis of the capabilities of language models for the task. First, we propose robust QG baselines based on fine-tuning generative language models. Then, we complement automatic evaluation based on standard metrics with an extensive manual evaluation, which in turn sheds light on the difficulty of evaluating QG models. Finally, we analyse both the domain adaptability of these models as well as the effectiveness of multilingual models in languages other than English.QG-Bench is released along with the fine-tuned models presented in the paper (https://github.com/asahi417/lm-question-generation), which are also available as a demo (https://autoqg.net/).",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.42.pdf"
    },
    {
        "title": "Segmenting Numerical Substitution Ciphers",
        "authors": [
            "Nada Aldarrab",
            "Jonathan May"
        ],
        "published": "2022",
        "summary": "Deciphering historical substitution ciphers is a challenging problem. Example problems that have been previously studied include detecting cipher type, detecting plaintext language, and acquiring the substitution key for segmented ciphers. However, attacking unsegmented ciphers is still a challenging task. Segmentation (i.e. finding substitution units) is essential for cracking those ciphers. In this work, we propose the first automatic methods to segment those ciphers using Byte Pair Encoding (BPE) and unigram language models. Our methods achieve an average segmentation error of 2% on 100 randomly-generated monoalphabetic ciphers and 27% on 3 real historical homophonic ciphers. We also propose a method for solving non-deterministic ciphers with existing keys using a lattice and a pretrained language model. Our method leads to the full solution of the IA cipher; a real historical cipher that has not been fully solved until this work.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.44.pdf"
    },
    {
        "title": "Reasoning Like Program Executors",
        "authors": [
            "Xinyu Pi",
            "Qian Liu",
            "Bei Chen",
            "Morteza Ziyadi",
            "Zeqi Lin",
            "Qiang Fu",
            "Yan Gao",
            "Jian-Guang Lou",
            "Weizhu Chen"
        ],
        "published": "2022",
        "summary": "Reasoning over natural language is a long-standing goal for the research community. However, studies have shown that existing language models are inadequate in reasoning. To address the issue, we present POET, a novel reasoning pre-training paradigm. Through pre-training language models with programs and their execution results, POET empowers language models to harvest the reasoning knowledge possessed by program executors via a data-driven approach. POET is conceptually simple and can be instantiated by different kinds of program executors. In this paper, we showcase two simple instances POET-Math and POET-Logic, in addition to a complex instance, POET-SQL. Experimental results on six benchmarks demonstrate that POET can significantly boost model performance in natural language reasoning, such as numerical reasoning, logical reasoning, and multi-hop reasoning. POET opens a new gate on reasoning-enhancement pre-training, and we hope our analysis would shed light on the future research of reasoning like program executors.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.48.pdf"
    },
    {
        "title": "Inducer-tuning: Connecting Prefix-tuning and Adapter-tuning",
        "authors": [
            "Yifan Chen",
            "Devamanyu Hazarika",
            "Mahdi Namazifar",
            "Yang Liu",
            "Di Jin",
            "Dilek Hakkani-Tur"
        ],
        "published": "2022",
        "summary": "Prefix-tuning, or more generally continuous prompt tuning, has become an essential paradigm of parameter-efficient transfer learning. Using a large pre-trained language model (PLM), prefix-tuning can obtain strong performance by training only a small portion of parameters. In this paper, we propose to understand and further develop prefix-tuning through the kernel lens. Specifically, we make an analogy between prefixes and inducing variables in kernel methods and hypothesize that prefixes serving as inducing variables would improve their overall mechanism. From the kernel estimator perspective, we suggest a new variant of prefix-tuning—inducer-tuning, which shares the exact mechanism as prefix-tuning while leveraging the residual form found in adapter-tuning. This mitigates the initialization issue in prefix-tuning. Through comprehensive empirical experiments on natural language understanding and generation tasks, we demonstrate that inducer-tuning can close the performance gap between prefix-tuning and fine-tuning.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.50.pdf"
    },
    {
        "title": "Metric-guided Distillation: Distilling Knowledge from the Metric to Ranker and Retriever for Generative Commonsense Reasoning",
        "authors": [
            "Xingwei He",
            "Yeyun Gong",
            "A-Long Jin",
            "Weizhen Qi",
            "Hang Zhang",
            "Jian Jiao",
            "Bartuer Zhou",
            "Biao Cheng",
            "Sm Yiu",
            "Nan Duan"
        ],
        "published": "2022",
        "summary": "Commonsense generation aims to generate a realistic sentence describing a daily scene under the given concepts, which is very challenging, since it requires models to have relational reasoning and compositional generalization capabilities. Previous work focuses on retrieving prototype sentences for the provided concepts to assist generation. They first use a sparse retriever to retrieve candidate sentences, then re-rank the candidates with a ranker. However, the candidates returned by their ranker may not be the most relevant sentences, since the ranker treats all candidates equally without considering their relevance to the reference sentences of the given concepts. Another problem is that re-ranking is very expensive, but only using retrievers will seriously degrade the performance of their generation models. To solve these problems, we propose the metric distillation rule to distill knowledge from the metric (e.g., BLEU) to the ranker. We further transfer the critical knowledge summarized by the distilled ranker to the retriever. In this way, the relevance scores of candidate sentences predicted by the ranker and retriever will be more consistent with their quality measured by the metric. Experimental results on the CommonGen benchmark verify the effectiveness of our proposed method: (1) Our generation model with the distilled ranker achieves a new state-of-the-art result. (2) Our generation model with the distilled retriever even surpasses the previous SOTA.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.53.pdf"
    },
    {
        "title": "Entity Extraction in Low Resource Domains with Selective Pre-training of Large Language Models",
        "authors": [
            "Aniruddha Mahapatra",
            "Sharmila Reddy Nangi",
            "Aparna Garimella",
            "Anandhavelu N"
        ],
        "published": "2022",
        "summary": "Transformer-based language models trained on large natural language corpora have been very useful in downstream entity extraction tasks. However, they often result in poor performances when applied to domains that are different from those they are pretrained on. Continued pretraining using unlabeled data from target domains can help improve the performances of these language models on the downstream tasks. However, using all of the available unlabeled data for pretraining can be time-intensive; also, it can be detrimental to the performance of the downstream tasks, if the unlabeled data is not aligned with the data distribution for the target tasks. Previous works employed external supervision in the form of ontologies for selecting appropriate data samples for pretraining, but external supervision can be quite hard to obtain in low-resource domains. In this paper, we introduce effective ways to select data from unlabeled corpora of target domains for language model pretraining to improve the performances in target entity extraction tasks. Our data selection strategies do not require any external supervision. We conduct extensive experiments for the task of named entity recognition (NER) on seven different domains and show that language models pretrained on target domain unlabeled data obtained using our data selection strategies achieve better performances compared to those using data selection strategies in previous works that use external supervision. We also show that these pretrained language models using our data selection strategies outperform those pretrained on all of the available unlabeled target domain data.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.61.pdf"
    },
    {
        "title": "How Large Language Models are Transforming Machine-Paraphrase Plagiarism",
        "authors": [
            "Jan Philip Wahle",
            "Terry Ruas",
            "Frederic Kirstein",
            "Bela Gipp"
        ],
        "published": "2022",
        "summary": "The recent success of large language models for text generation poses a severe threat to academic integrity, as plagiarists can generate realistic paraphrases indistinguishable from original work.However, the role of large autoregressive models in generating machine-paraphrased plagiarism and their detection is still incipient in the literature.This work explores T5 and GPT3 for machine-paraphrase generation on scientific articles from arXiv, student theses, and Wikipedia.We evaluate the detection performance of six automated solutions and one commercial plagiarism detection software and perform a human study with 105 participants regarding their detection performance and the quality of generated examples.Our results suggest that large language models can rewrite text humans have difficulty identifying as machine-paraphrased (53% mean acc.).Human experts rate the quality of paraphrases generated by GPT-3 as high as original texts (clarity 4.0/5, fluency 4.2/5, coherence 3.8/5).The best-performing detection model (GPT-3) achieves 66% F1-score in detecting paraphrases.We make our code, data, and findings publicly available to facilitate the development of detection solutions.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.62.pdf"
    },
    {
        "title": "M2D2: A Massively Multi-Domain Language Modeling Dataset",
        "authors": [
            "Machel Reid",
            "Victor Zhong",
            "Suchin Gururangan",
            "Luke Zettlemoyer"
        ],
        "published": "2022",
        "summary": "We present M2D2, a fine-grained, massively multi-domain corpus for studying domain adaptation in language models (LMs). M2D2 consists of 8.5B tokens and spans 145 domains extracted from Wikipedia and Semantic Scholar. Using ontologies derived from Wikipedia and ArXiv categories, we organize the domains in each data source into 22 groups. This two-level hierarchy enables the study of relationships between domains and their effects on in- and out-of-domain performance after adaptation. We also present a number of insights into the nature of effective domain adaptation in LMs, as examples of the new types of studies M2D2 enables. To improve in-domain performance, we show the benefits of adapting the LM along a domain hierarchy; adapting to smaller amounts of fine-grained domain-specific data can lead to larger in-domain performance gains than larger amounts of weakly relevant data. We further demonstrate a trade-off between in-domain specialization and out-of-domain generalization within and across ontologies, as well as a strong correlation between out-of-domain performance and lexical overlap between domains.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.63.pdf"
    },
    {
        "title": "Learning to Adapt to Low-Resource Paraphrase Generation",
        "authors": [
            "Zhigen Li",
            "Yanmeng Wang",
            "Rizhao Fan",
            "Ye Wang",
            "Jianfeng Li",
            "Shaojun Wang"
        ],
        "published": "2022",
        "summary": "Paraphrase generation is a longstanding NLP task and achieves great success with the aid of large corpora. However, transferring a paraphrasing model to another domain encounters the problem of domain shifting especially when the data is sparse. At the same time, widely using large pre-trained language models (PLMs) faces the overfitting problem when training on scarce labeled data. To mitigate these two issues, we propose, LAPA, an effective adapter for PLMs optimized by meta-learning. LAPA has three-stage training on three types of related resources to solve this problem: 1. pre-training PLMs on unsupervised corpora, 2. inserting an adapter layer and meta-training on source domain labeled data, and 3. fine-tuning adapters on a small amount of target domain labeled data. This method enables paraphrase generation models to learn basic language knowledge first, then learn the paraphrasing task itself later, and finally adapt to the target task. Our experimental results demonstrate that LAPA achieves state-of-the-art in supervised, unsupervised, and low-resource settings on three benchmark datasets. With only 2% of trainable parameters and 1% labeled data of the target task, our approach can achieve a competitive performance with previous work.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.66.pdf"
    },
    {
        "title": "ELMER: A Non-Autoregressive Pre-trained Language Model for Efficient and Effective Text Generation",
        "authors": [
            "Junyi Li",
            "Tianyi Tang",
            "Wayne Xin Zhao",
            "Jian-Yun Nie",
            "Ji-Rong Wen"
        ],
        "published": "2022",
        "summary": "We study the text generation task under the approach of pre-trained language models (PLMs). Typically, an auto-regressive (AR) method is adopted for generating texts in a token-by-token manner. Despite many advantages of AR generation, it usually suffers from inefficient inference. Therefore, non-autoregressive (NAR) models are proposed to generate all target tokens simultaneously. However, NAR models usually generate texts of lower quality due to the absence of token dependency in the output text. In this paper, we propose ELMER: an efficient and effective PLM for NAR text generation to explicitly model the token dependency during NAR generation. By leveraging the early exit technique, ELMER enables the token generations at different layers, according to their prediction confidence (a more confident token will exit at a lower layer). Besides, we propose a novel pre-training objective, Layer Permutation Language Modeling, to pre-train ELMER by permuting the exit layer for each token in sequences. Experiments on three text generation tasks show that ELMER significantly outperforms NAR models and further narrows the performance gap with AR PLMs (ELMER (29.92) vs BART (30.61) ROUGE-L in XSUM) while achieving over 10 times inference speedup.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.68.pdf"
    },
    {
        "title": "Multilingual Relation Classification via Efficient and Effective Prompting",
        "authors": [
            "Yuxuan Chen",
            "David Harbecke",
            "Leonhard Hennig"
        ],
        "published": "2022",
        "summary": "Prompting pre-trained language models has achieved impressive performance on various NLP tasks, especially in low data regimes. Despite the success of prompting in monolingual settings, applying prompt-based methods in multilingual scenarios has been limited to a narrow set of tasks, due to the high cost of handcrafting multilingual prompts. In this paper, we present the first work on prompt-based multilingual relation classification (RC), by introducing an efficient and effective method that constructs prompts from relation triples and involves only minimal translation for the class labels. We evaluate its performance in fully supervised, few-shot and zero-shot scenarios, and analyze its effectiveness across 14 languages, prompt variants, and English-task training in cross-lingual settings. We find that in both fully supervised and few-shot scenarios, our prompt method beats competitive baselines: fine-tuning XLM-R_EM and null prompts. It also outperforms the random baseline by a large margin in zero-shot experiments. Our method requires little in-language knowledge and can be used as a strong baseline for similar multilingual classification tasks.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.69.pdf"
    },
    {
        "title": "Fine-grained Contrastive Learning for Relation Extraction",
        "authors": [
            "William Hogan",
            "Jiacheng Li",
            "Jingbo Shang"
        ],
        "published": "2022",
        "summary": "Recent relation extraction (RE) works have shown encouraging improvements by conducting contrastive learning on silver labels generated by distant supervision before fine-tuning on gold labels. Existing methods typically assume all these silver labels are accurate and treat them equally; however, distant supervision is inevitably noisy–some silver labels are more reliable than others. In this paper, we propose fine-grained contrastive learning (FineCL) for RE, which leverages fine-grained information about which silver labels are and are not noisy to improve the quality of learned relationship representations for RE. We first assess the quality of silver labels via a simple and automatic approach we call “learning order denoising,” where we train a language model to learn these relations and record the order of learned training instances. We show that learning order largely corresponds to label accuracy–early-learned silver labels have, on average, more accurate labels than later-learned silver labels. Then, during pre-training, we increase the weights of accurate labels within a novel contrastive learning objective. Experiments on several RE benchmarks show that FineCL makes consistent and significant performance gains over state-of-the-art methods.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.71.pdf"
    },
    {
        "title": "Zero-Shot Text Classification with Self-Training",
        "authors": [
            "Ariel Gera",
            "Alon Halfon",
            "Eyal Shnarch",
            "Yotam Perlitz",
            "Liat Ein-Dor",
            "Noam Slonim"
        ],
        "published": "2022",
        "summary": "Recent advances in large pretrained language models have increased attention to zero-shot text classification. In particular, models finetuned on natural language inference datasets have been widely adopted as zero-shot classifiers due to their promising results and off-the-shelf availability. However, the fact that such models are unfamiliar with the target task can lead to instability and performance issues. We propose a plug-and-play method to bridge this gap using a simple self-training approach, requiring only the class names along with an unlabeled dataset, and without the need for domain expertise or trial and error. We show that fine-tuning the zero-shot classifier on its most confident predictions leads to significant performance gains across a wide range of text classification tasks, presumably since self-training adapts the zero-shot model to the task at hand.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.73.pdf"
    },
    {
        "title": "Z-LaVI: Zero-Shot Language Solver Fueled by Visual Imagination",
        "authors": [
            "Yue Yang",
            "Wenlin Yao",
            "Hongming Zhang",
            "Xiaoyang Wang",
            "Dong Yu",
            "Jianshu Chen"
        ],
        "published": "2022",
        "summary": "Large-scale pretrained language models have made significant advances in solving downstream language understanding tasks. However, they generally suffer from reporting bias, the phenomenon describing the lack of explicit commonsense knowledge in written text, e.g., ”an orange is orange”. To overcome this limitation, we develop a novel approach, Z-LaVI, to endow language models with visual imagination capabilities. Specifically, we leverage two complementary types of ”imaginations”: (i) recalling existing images through retrieval and (ii) synthesizing nonexistent images via text-to-image generation. Jointly exploiting the language inputs and the imagination, a pretrained vision-language model (e.g., CLIP) eventually composes a zero-shot solution to the original language tasks. Notably, fueling language models with imagination can effectively leverage visual knowledge to solve plain language tasks. In consequence, Z-LaVI consistently improves the zero-shot performance of existing language models across a diverse set of language tasks.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.78.pdf"
    },
    {
        "title": "Using Commonsense Knowledge to Answer Why-Questions",
        "authors": [
            "Yash Kumar Lal",
            "Niket Tandon",
            "Tanvi Aggarwal",
            "Horace Liu",
            "Nathanael Chambers",
            "Raymond Mooney",
            "Niranjan Balasubramanian"
        ],
        "published": "2022",
        "summary": "Answering questions in narratives about why events happened often requires commonsense knowledge external to the text. What aspects of this knowledge are available in large language models? What aspects can be made accessible via external commonsense resources? We study these questions in the context of answering questions in the TellMeWhy dataset using COMET as a source of relevant commonsense relations. We analyze the effects of model size (T5 and GPT3) along with methods of injecting knowledge (COMET) into these models. Results show that the largest models, as expected, yield substantial improvements over base models. Injecting external knowledge helps models of various sizes, but the amount of improvement decreases with larger model size. We also find that the format in which knowledge is provided is critical, and that smaller models benefit more from larger amounts of knowledge. Finally, we develop an ontology of knowledge types and analyze the relative coverage of the models across these categories.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.79.pdf"
    },
    {
        "title": "Successive Prompting for Decomposing Complex Questions",
        "authors": [
            "Dheeru Dua",
            "Shivanshu Gupta",
            "Sameer Singh",
            "Matt Gardner"
        ],
        "published": "2022",
        "summary": "Answering complex questions that require making latent decisions is a challenging task, especially when limited supervision is available. Recent works leverage the capabilities of large language models (LMs) to perform complex question answering in a few-shot setting by demonstrating how to output intermediate rationalizations while solving the complex question in a single pass. We introduce “Successive Prompting” where, we iteratively break down a complex task into a simple task, solve it, and then repeat the process until we get the final solution. Successive prompting decouples the supervision for decomposing complex questions from the supervision for answering simple questions, allowing us to (1) have multiple opportunities to query in-context examples at each reasoning step (2) learn question decomposition separately from question answering, including using synthetic data, and (3) use bespoke (fine-tuned) components for reasoning steps where a large LM does not perform well. The intermediate supervision is typically manually written, which can be expensive to collect. We introduce a way to generate synthetic dataset which can be used to bootstrap model’s ability to decompose and answer intermediate questions. Our best model (with successive prompting) achieves an improvement in F1 of ~5% when compared with a state-of-the-art model with synthetic augmentations and few-shot version of the DROP dataset.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.81.pdf"
    },
    {
        "title": "Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations",
        "authors": [
            "Jaehun Jung",
            "Lianhui Qin",
            "Sean Welleck",
            "Faeze Brahman",
            "Chandra Bhagavatula",
            "Ronan Le Bras",
            "Yejin Choi"
        ],
        "published": "2022",
        "summary": "Pre-trained language models (LMs) struggle with consistent reasoning; recently, prompting LMs to generate explanations that self-guide the inference has emerged as a promising direction to amend this. However, these approaches are fundamentally bounded by the correctness of explanations, which themselves are often noisy and inconsistent. In this work, we develop Maieutic Prompting, which aims to infer a correct answer to a question even from the unreliable generations of LM. Maieutic Prompting induces a tree of explanations abductively (e.g. X is true, because ...) and recursively, then frames the inference as a satisfiability problem over these explanations and their logical relations. We test Maieutic Prompting for true/false QA on three challenging benchmarks that require complex commonsense reasoning. Maieutic Prompting achieves up to 20% better accuracy than state-of-the-art prompting methods, and as a fully unsupervised approach, performs competitively with supervised models. We also show that Maieutic Prompting improves robustness in inference while providing interpretable rationales.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.82.pdf"
    },
    {
        "title": "DANLI: Deliberative Agent for Following Natural Language Instructions",
        "authors": [
            "Yichi Zhang",
            "Jianing Yang",
            "Jiayi Pan",
            "Shane Storks",
            "Nikhil Devraj",
            "Ziqiao Ma",
            "Keunwoo Yu",
            "Yuwei Bao",
            "Joyce Chai"
        ],
        "published": "2022",
        "summary": "Recent years have seen an increasing amount of work on embodied AI agents that can perform tasks by following human language instructions. However, most of these agents are reactive, meaning that they simply learn and imitate behaviors encountered in the training data. These reactive agents are insufficient for long-horizon complex tasks. To address this limitation, we propose a neuro-symbolic deliberative agent that, while following language instructions, proactively applies reasoning and planning based on its neural and symbolic representations acquired from past experience (e.g., natural language and egocentric vision). We show that our deliberative agent achieves greater than 70% improvement over reactive baselines on the challenging TEACh benchmark. Moreover, the underlying reasoning and planning processes, together with our modular framework, offer impressive transparency and explainability to the behaviors of the agent. This enables an in-depth understanding of the agent’s capabilities, which shed light on challenges and opportunities for future embodied agents for instruction following. The code is available at https://github.com/sled-group/DANLI.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.83.pdf"
    },
    {
        "title": "PLM-based World Models for Text-based Games",
        "authors": [
            "Minsoo Kim",
            "Yeonjoon Jung",
            "Dohyeon Lee",
            "Seung-won Hwang"
        ],
        "published": "2022",
        "summary": "World models have improved the ability of reinforcement learning agents to operate in a sample efficient manner, by being trained to predict plausible changes in the underlying environment. As the core tasks of world models are future prediction and commonsense understanding, our claim is that pre-trained language models (PLMs) already provide a strong base upon which to build world models. Worldformer is a recently proposed world model for text-based game environments, based only partially on PLM and transformers. Our distinction is to fully leverage PLMs as actionable world models in text-based game environments, by reformulating generation as constrained decoding which decomposes actions into verb templates and objects. We show that our model improves future valid action prediction and graph change prediction. Additionally, we show that our model better reflects commonsense than standard PLM.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.86.pdf"
    },
    {
        "title": "Prompt-Based Meta-Learning For Few-shot Text Classification",
        "authors": [
            "Haoxing Zhang",
            "Xiaofeng Zhang",
            "Haibo Huang",
            "Lei Yu"
        ],
        "published": "2022",
        "summary": "Few-shot Text Classification predicts the semantic label of a given text with a handful of supporting instances. Current meta-learning methods have achieved satisfying results in various few-shot situations. Still, they often require a large amount of data to construct many few-shot tasks for meta-training, which is not practical in real-world few-shot scenarios. Prompt-tuning has recently proved to be another effective few-shot learner by bridging the gap between pre-train and downstream tasks. In this work, we closely combine the two promising few-shot learning methodologies in structure and propose a Prompt-Based Meta-Learning (PBML) model to overcome the above meta-learning problem by adding the prompting mechanism. PBML assigns label word learning to base-learners and template learning to meta-learner, respectively. Experimental results show state-of-the-art performance on four text classification datasets under few-shot settings, with higher accuracy and good robustness. We demonstrate through low-resource experiments that our method alleviates the shortcoming that meta-learning requires too much data for meta-training. In the end, we use the visualization to interpret and verify that the meta-learning framework can help the prompting method converge better. We release our code to reproduce our experiments.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.87.pdf"
    },
    {
        "title": "Language Models of Code are Few-Shot Commonsense Learners",
        "authors": [
            "Aman Madaan",
            "Shuyan Zhou",
            "Uri Alon",
            "Yiming Yang",
            "Graham Neubig"
        ],
        "published": "2022",
        "summary": "We address the general task of structured commonsense reasoning: given a natural language input, the goal is to generate a graph such as an event or a reasoning-graph.To employ large language models (LMs) for this task, existing approaches ‘serialize’ the output graph as a flat list of nodes and edges.Although feasible, these serialized graphs strongly deviate from the natural language corpora that LMs were pre-trained on, hindering LMs from generating them correctly. In this paper, we show that when we instead frame structured commonsense reasoning tasks as code generation tasks, pre-trained LMs of code are better structured commonsense reasoners than LMs of natural language, even when the downstream task does not involve source code at all.We demonstrate our approach across three diverse structured commonsense reasoning tasks. In all these natural language tasks, we show that using our approach, a code generation LM (codex) outperforms natural-LMs that are fine-tuned on the target task (T5) and other strong LMs such as GPT-3 in the few-shot setting.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.90.pdf"
    },
    {
        "title": "Numerical Optimizations for Weighted Low-rank Estimation on Language Models",
        "authors": [
            "Ting Hua",
            "Yen-Chang Hsu",
            "Felicity Wang",
            "Qian Lou",
            "Yilin Shen",
            "Hongxia Jin"
        ],
        "published": "2022",
        "summary": "Singular value decomposition (SVD) is one of the most popular compression methods that approximate a target matrix with smaller matrices. However, standard SVD treats the parameters within the matrix with equal importance, which is a simple but unrealistic assumption. The parameters of a trained neural network model may affect the task performance unevenly, which suggests non-equal importance among the parameters. Compared to SVD, the decomposition method aware of parameter importance is the more practical choice in real cases. Unlike standard SVD, weighed value decomposition is a non-convex optimization problem that lacks a closed-form solution. We systematically investigated multiple optimization strategies to tackle the problem and examined our method by compressing Transformer-based language models.Further, we designed a metric to predict when the SVD may introduce a significant performance drop, for which our method can be a rescue strategy.The extensive evaluations demonstrate that our method can perform better than current SOTA methods in compressing Transformer-based language models.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.91.pdf"
    },
    {
        "title": "Generative Multi-hop Retrieval",
        "authors": [
            "Hyunji Lee",
            "Sohee Yang",
            "Hanseok Oh",
            "Minjoon Seo"
        ],
        "published": "2022",
        "summary": "A common practice for text retrieval is to use an encoder to map the documents and the query to a common vector space and perform a nearest neighbor search (NNS); multi-hop retrieval also often adopts the same paradigm, usually with a modification of iteratively reformulating the query vector so that it can retrieve different documents at each hop. However, such a bi-encoder approach has limitations in multi-hop settings; (1) the reformulated query gets longer as the number of hops increases, which further tightens the embedding bottleneck of the query vector, and (2) it is prone to error propagation. In this paper, we focus on alleviating these limitations in multi-hop settings by formulating the problem in a fully generative way. We propose an encoder-decoder model that performs multi-hop retrieval by simply generating the entire text sequences of the retrieval targets, which means the query and the documents interact in the language model’s parametric space rather than L2 or inner product space as in the bi-encoder approach. Our approach, Generative Multi-hop Retrieval (GMR), consistently achieves comparable or higher performance than bi-encoder models in five datasets while demonstrating superior GPU memory and storage footprint.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.92.pdf"
    },
    {
        "title": "COCO-DR: Combating the Distribution Shift in Zero-Shot Dense Retrieval with Contrastive and Distributionally Robust Learning",
        "authors": [
            "Yue Yu",
            "Chenyan Xiong",
            "Si Sun",
            "Chao Zhang",
            "Arnold Overwijk"
        ],
        "published": "2022",
        "summary": "We present a new zero-shot dense retrieval (ZeroDR) method, COCO-DR, to improve the generalization ability of dense retrieval by combating the distribution shifts between source training tasks and target scenarios. To mitigate the impact of document differences, COCO-DR continues pretraining the language model on the target corpora to adapt the model to target distributions via COtinuous COtrastive learning. To prepare for unseen target queries, COCO-DR leverages implicit Distributionally Robust Optimization (iDRO) to reweight samples from different source query clusters for improving model robustness over rare queries during fine-tuning. COCO-DR achieves superior average performance on BEIR, the zero-shot retrieval benchmark. At BERT_Base scale, COCO-DR Base outperforms other ZeroDR models with 60x larger size. At BERT_Large scale, COCO-DR Large outperforms the giant GPT-3 embedding model which has 500x more parameters. Our analysis shows the correlation between COCO-DR’s effectiveness in combating distribution shifts and improving zero-shot accuracy. Our code and model can be found at https://github.com/OpenMatch/COCO-DR.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.95.pdf"
    },
    {
        "title": "Language Model Pre-Training with Sparse Latent Typing",
        "authors": [
            "Liliang Ren",
            "Zixuan Zhang",
            "Han Wang",
            "Clare Voss",
            "ChengXiang Zhai",
            "Heng Ji"
        ],
        "published": "2022",
        "summary": "Modern large-scale Pre-trained Language Models (PLMs) have achieved tremendous success on a wide range of downstream tasks. However, most of the LM pre-training objectives only focus on text reconstruction, but have not sought to learn latent-level interpretable representations of sentences. In this paper, we manage to push the language models to obtain a deeper understanding of sentences by proposing a new pre-training objective, Sparse Latent Typing, which enables the model to sparsely extract sentence-level keywords with diverse latent types. Experimental results show that our model is able to learn interpretable latent type categories in a self-supervised manner without using any external knowledge. Besides, the language model pre-trained with such an objective also significantly improves Information Extraction related downstream tasks in both supervised and few-shot settings. Our code is publicly available at https://github.com/renll/SparseLT.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.96.pdf"
    },
    {
        "title": "Do Vision-and-Language Transformers Learn Grounded Predicate-Noun Dependencies?",
        "authors": [
            "Mitja Nikolaus",
            "Emmanuelle Salin",
            "Stephane Ayache",
            "Abdellah Fourtassi",
            "Benoit Favre"
        ],
        "published": "2022",
        "summary": "Recent advances in vision-and-language modeling have seen the development of Transformer architectures that achieve remarkable performance on multimodal reasoning tasks.Yet, the exact capabilities of these black-box models are still poorly understood. While much of previous work has focused on studying their ability to learn meaning at the word-level, their ability to track syntactic dependencies between words has received less attention.We take a first step in closing this gap by creating a new multimodal task targeted at evaluating understanding of predicate-noun dependencies in a controlled setup.We evaluate a range of state-of-the-art models and find that their performance on the task varies considerably, with some models performing relatively well and others at chance level. In an effort to explain this variability, our analyses indicate that the quality (and not only sheer quantity) of pretraining data is essential. Additionally, the best performing models leverage fine-grained multimodal pretraining objectives in addition to the standard image-text matching objectives.This study highlights that targeted and controlled evaluations are a crucial step for a precise and rigorous test of the multimodal knowledge of vision-and-language models.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.100.pdf"
    },
    {
        "title": "Learning Instructions with Unlabeled Data for Zero-Shot Cross-Task Generalization",
        "authors": [
            "Yuxian Gu",
            "Pei Ke",
            "Xiaoyan Zhu",
            "Minlie Huang"
        ],
        "published": "2022",
        "summary": "Training language models to learn from human instructions for zero-shot cross-task generalization has attracted much attention in NLP communities. Recently, instruction tuning (IT), which fine-tunes a pre-trained language model on a massive collection of tasks described via human-craft instructions, has been shown effective in instruction learning for unseen tasks. However, IT relies on a large amount of human-annotated samples, which restricts its generalization. Unlike labeled data, unlabeled data are often massive and cheap to obtain. In this work, we study how IT can be improved with unlabeled data. We first empirically explore the IT performance trends versus the number of labeled data, instructions, and training tasks. We find it critical to enlarge the number of training instructions, and the instructions can be underutilized due to the scarcity of labeled data. Then, we propose Unlabeled Data Augmented Instruction Tuning (UDIT) to take better advantage of the instructions during IT by constructing pseudo-labeled data from unlabeled plain texts. We conduct extensive experiments to show UDIT’s effectiveness in various scenarios of tasks and datasets. We also comprehensively analyze the key factors of UDIT to investigate how to better improve IT with unlabeled data. The code is publicly available at https://github.com/thu-coai/UDIT.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.105.pdf"
    },
    {
        "title": "Learning Label Modular Prompts for Text Classification in the Wild",
        "authors": [
            "Hailin Chen",
            "Amrita Saha",
            "Shafiq Joty",
            "Steven C.H. Hoi"
        ],
        "published": "2022",
        "summary": "Machine learning models usually assume i.i.d data during training and testing, but data and tasks in real world often change over time. To emulate the transient nature of real world, we propose a challenging but practical task: text classification in-the-wild, which introduces different non-stationary training/testing stages. Decomposing a complex task into modular components can enable robust generalisation under such non-stationary environment. However, current modular approaches in NLP do not take advantage of recent advances in parameter efficient tuning of pretrained language models. To close this gap, we propose ModularPrompt, a label-modular prompt tuning framework for text classification tasks. In ModularPrompt, the input prompt consists of a sequence of soft label prompts, each encoding modular knowledge related to the corresponding class label. In two of most formidable settings, ModularPrompt outperforms relevant baselines by a large margin demonstrating strong generalisation ability. We also conduct comprehensive analysis to validate whether the learned prompts satisfy properties of a modular representation.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.109.pdf"
    },
    {
        "title": "COST-EFF: Collaborative Optimization of Spatial and Temporal Efficiency with Slenderized Multi-exit Language Models",
        "authors": [
            "Bowen Shen",
            "Zheng Lin",
            "Yuanxin Liu",
            "Zhengxiao Liu",
            "Lei Wang",
            "Weiping Wang"
        ],
        "published": "2022",
        "summary": "Transformer-based pre-trained language models (PLMs) mostly suffer from excessive overhead despite their advanced capacity. For resource-constrained devices, there is an urgent need for a spatially and temporally efficient model which retains the major capacity of PLMs. However, existing statically compressed models are unaware of the diverse complexities between input instances, potentially resulting in redundancy and inadequacy for simple and complex inputs. Also, miniature models with early exiting encounter challenges in the trade-off between making predictions and serving the deeper layers. Motivated by such considerations, we propose a collaborative optimization for PLMs that integrates static model compression and dynamic inference acceleration. Specifically, the PLM is slenderized in width while the depth remains intact, complementing layer-wise early exiting to speed up inference dynamically. To address the trade-off of early exiting, we propose a joint training approach that calibrates slenderization and preserves contributive structures to each exit instead of only the final layer. Experiments are conducted on GLUE benchmark and the results verify the Pareto optimality of our approach at high compression and acceleration rate with 1/8 parameters and 1/19 FLOPs of BERT.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.112.pdf"
    },
    {
        "title": "Rescue Implicit and Long-tail Cases: Nearest Neighbor Relation Extraction",
        "authors": [
            "Zhen Wan",
            "Qianying Liu",
            "Zhuoyuan Mao",
            "Fei Cheng",
            "Sadao Kurohashi",
            "Jiwei Li"
        ],
        "published": "2022",
        "summary": "Relation extraction (RE) has achieved remarkable progress with the help of pre-trained language models. However, existing RE models are usually incapable of handling two situations: implicit expressions and long-tail relation types, caused by language complexity and data sparsity. In this paper, we introduce a simple enhancement of RE using k nearest neighbors (kNN-RE). kNN-RE allows the model to consult training relations at test time through a nearest-neighbor search and provides a simple yet effective means to tackle the two issues above. Additionally, we observe that kNN-RE serves as an effective way to leverage distant supervision (DS) data for RE. Experimental results show that the proposed kNN-RE achieves state-of-the-art performances on a variety of supervised RE datasets, i.e., ACE05, SciERC, and Wiki80, along with outperforming the best model to date on the i2b2 and Wiki80 datasets in the setting of allowing using DS. Our code and models are available at: https://github.com/YukinoWan/kNN-RE.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.113.pdf"
    },
    {
        "title": "Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference",
        "authors": [
            "Eric Mitchell",
            "Joseph Noh",
            "Siyan Li",
            "Will Armstrong",
            "Ananth Agarwal",
            "Patrick Liu",
            "Chelsea Finn",
            "Christopher Manning"
        ],
        "published": "2022",
        "summary": "While large pre-trained language models are powerful, their predictions often lack logical consistency across test inputs. For example, a state-of-the-art Macaw question-answering (QA) model answers <i>Yes</i> to <i>Is a sparrow a bird?</i> and <i>Does a bird have feet?</i> but answers <i>No</i> to <i>Does a sparrow have feet?</i>. To address this failure mode, we propose a framework, Consistency Correction through Relation Detection, or <b>ConCoRD</b>, for boosting the consistency and accuracy of pre-trained NLP models using pre-trained natural language inference (NLI) models without fine-tuning or re-training. Given a batch of test inputs, ConCoRD samples several candidate outputs for each input and instantiates a factor graph that accounts for both the model’s belief about the likelihood of each answer choice in isolation and the NLI model’s beliefs about pair-wise answer choice compatibility. We show that a weighted MaxSAT solver can efficiently compute high-quality answer choices under this factor graph, improving over the raw model’s predictions. Our experiments demonstrate that ConCoRD consistently boosts accuracy and consistency of off-the-shelf closed-book QA and VQA models using off-the-shelf NLI models, notably increasing accuracy of LXMERT on ConVQA by 5% absolute. See the project website (https://ericmitchell.ai/emnlp-2022-concord/) for code and data.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.115.pdf"
    },
    {
        "title": "Robustness of Demonstration-based Learning Under Limited Data Scenario",
        "authors": [
            "Hongxin Zhang",
            "Yanzhe Zhang",
            "Ruiyi Zhang",
            "Diyi Yang"
        ],
        "published": "2022",
        "summary": "Demonstration-based learning has shown great potential in stimulating pretrained language models’ ability under limited data scenario. Simply augmenting the input with some demonstrations can significantly improve performance on few-shot NER. However, why such demonstrations are beneficial for the learning process remains unclear since there is no explicit alignment between the demonstrations and the predictions. In this paper, we design pathological demonstrations by gradually removing intuitively useful information from the standard ones to take a deep dive of the robustness of demonstration-based sequence labeling and show that (1) demonstrations composed of random tokens still make the model a better few-shot learner; (2) the length of random demonstrations and the relevance of random tokens are the main factors affecting the performance; (3) demonstrations increase the confidence of model predictions on captured superficial patterns. We have publicly released our code at https://github.com/SALT-NLP/RobustDemo.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.116.pdf"
    },
    {
        "title": "Word Order Matters When You Increase Masking",
        "authors": [
            "Karim Lasri",
            "Alessandro Lenci",
            "Thierry Poibeau"
        ],
        "published": "2022",
        "summary": "Word order, an essential property of natural languages, is injected in Transformer-based neural language models using position encoding. However, recent experiments have shown that explicit position encoding is not always useful, since some models without such feature managed to achieve state-of-the art performance on some tasks. To understand better this phenomenon, we examine the effect of removing position encodings on the pre-training objective itself (i.e., masked language modelling), to test whether models can reconstruct position information from co-occurrences alone. We do so by controlling the amount of masked tokens in the input sentence, as a proxy to affect the importance of position information for the task. We find that the necessity of position information increases with the amount of masking, and that masked language models without position encodings are not able to reconstruct this information on the task. These findings point towards a direct relationship between the amount of masking and the ability of Transformers to capture order-sensitive aspects of language using position encoding.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.118.pdf"
    },
    {
        "title": "An Empirical Analysis of Memorization in Fine-tuned Autoregressive Language Models",
        "authors": [
            "Fatemehsadat Mireshghallah",
            "Archit Uniyal",
            "Tianhao Wang",
            "David Evans",
            "Taylor Berg-Kirkpatrick"
        ],
        "published": "2022",
        "summary": "Large language models are shown to present privacy risks through memorization of training data, andseveral recent works have studied such risks for the pre-training phase. Little attention, however, has been given to the fine-tuning phase and it is not well understood how different fine-tuning methods (such as fine-tuning the full model, the model head, and adapter) compare in terms of memorization risk. This presents increasing concern as the “pre-train and fine-tune” paradigm proliferates. In this paper, we empirically study memorization of fine-tuning methods using membership inference and extraction attacks, and show that their susceptibility to attacks is very different. We observe that fine-tuning the head of the model has the highest susceptibility to attacks, whereas fine-tuning smaller adapters appears to be less vulnerable to known extraction attacks.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.119.pdf"
    },
    {
        "title": "Can Visual Context Improve Automatic Speech Recognition for an Embodied Agent?",
        "authors": [
            "Pradip Pramanick",
            "Chayan Sarkar"
        ],
        "published": "2022",
        "summary": "The usage of automatic speech recognition (ASR) systems are becoming omnipresent ranging from personal assistant to chatbots, home, and industrial automation systems, etc. Modern robots are also equipped with ASR capabilities for interacting with humans as speech is the most natural interaction modality. However, ASR in robots faces additional challenges as compared to a personal assistant. Being an embodied agent, a robot must recognize the physical entities around it and therefore reliably recognize the speech containing the description of such entities. However, current ASR systems are often unable to do so due to limitations in ASR training, such as generic datasets and open-vocabulary modeling. Also, adverse conditions during inference, such as noise, accented, and far-field speech makes the transcription inaccurate. In this work, we present a method to incorporate a robot’s visual information into an ASR system and improve the recognition of a spoken utterance containing a visible entity. Specifically, we propose a new decoder biasing technique to incorporate the visual context while ensuring the ASR output does not degrade for incorrect context. We achieve a 59% relative reduction in WER from an unmodified ASR system.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.127.pdf"
    },
    {
        "title": "EvEntS ReaLM: Event Reasoning of Entity States via Language Models",
        "authors": [
            "Evangelia Spiliopoulou",
            "Artidoro Pagnoni",
            "Yonatan Bisk",
            "Eduard Hovy"
        ],
        "published": "2022",
        "summary": "This paper investigates models of event implications. Specifically, how well models predict entity state-changes, by targeting their understanding of physical attributes. Nominally, Large Language models (LLM) have been exposed to procedural knowledge about how objects interact, yet our benchmarking shows they fail to reason about the world. Conversely, we also demonstrate that existing approaches often misrepresent the surprising abilities of LLMs via improper task encodings and that proper model prompting can dramatically improve performance of reported baseline results across multiple tasks. In particular, our results indicate that our prompting technique is especially useful for unseen attributes (out-of-domain) or when only limited data is available.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.129.pdf"
    },
    {
        "title": "Large language models are few-shot clinical information extractors",
        "authors": [
            "Monica Agrawal",
            "Stefan Hegselmann",
            "Hunter Lang",
            "Yoon Kim",
            "David Sontag"
        ],
        "published": "2022",
        "summary": "A long-running goal of the clinical NLP community is the extraction of important variables trapped in clinical notes. However, roadblocks have included dataset shift from the general domain and a lack of public clinical corpora and annotations. In this work, we show that large language models, such as InstructGPT (Ouyang et al., 2022), perform well at zero- and few-shot information extraction from clinical text despite not being trained specifically for the clinical domain. Whereas text classification and generation performance have already been studied extensively in such models, here we additionally demonstrate how to leverage them to tackle a diverse set of NLP tasks which require more structured outputs, including span identification, token-level sequence classification, and relation extraction. Further, due to the dearth of available data to evaluate these systems, we introduce new datasets for benchmarking few-shot clinical information extraction based on a manual re-annotation of the CASI dataset (Moon et al., 2014) for new tasks. On the clinical extraction tasks we studied, the GPT-3 systems significantly outperform existing zero- and few-shot baselines.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.130.pdf"
    },
    {
        "title": "GeoMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models",
        "authors": [
            "Da Yin",
            "Hritik Bansal",
            "Masoud Monajatipoor",
            "Liunian Harold Li",
            "Kai-Wei Chang"
        ],
        "published": "2022",
        "summary": "Recent work has shown that Pre-trained Language Models (PLMs) store the relational knowledge learned from data and utilize it for performing downstream tasks. However, commonsense knowledge across different regions may vary. For instance, the color of bridal dress is white in American weddings whereas it is red in Chinese weddings. In this paper, we introduce a benchmark dataset, Geo-diverse Commonsense Multilingual Language Models Analysis (GeoMLAMA), for probing the diversity of the relational knowledge in multilingual PLMs. GeoMLAMA contains 3125 prompts in English, Chinese, Hindi, Persian, and Swahili, with a wide coverage of concepts shared by people from American, Chinese, Indian, Iranian and Kenyan cultures. We benchmark 11 standard multilingual PLMs on GeoMLAMA. Interestingly, we find that 1) larger multilingual PLMs variants do not necessarily store geo-diverse concepts better than its smaller variant; 2) multilingual PLMs are not intrinsically biased towards knowledge from the Western countries (the United States); 3) the native language of a country may not be the best language to probe its knowledge and 4) a language may better probe knowledge about a non-native country than its native country.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.132.pdf"
    },
    {
        "title": "Entailer: Answering Questions with Faithful and Truthful Chains of Reasoning",
        "authors": [
            "Oyvind Tafjord",
            "Bhavana Dalvi Mishra",
            "Peter Clark"
        ],
        "published": "2022",
        "summary": "Our goal is a question-answering (QA) system that can show how its answers are implied by its own internal beliefs via a systematic chain of reasoning. Such a capability would allow better understanding of why a model produced the answer it did. Our approach is to recursively combine a trained backward-chainingmodel, capable of generating a set of premises entailing an answer hypothesis, with a verifier that checks that the model itself believes those premises (and the entailment itself) through self-querying. To our knowledge, this is the first system to generate multistep chains that are both faithful (the answer follows from the reasoning) and truthful (the chain reflects the system’s own internal beliefs). In evaluation using two different datasets, users judge that a majority (70%+) of generated chains clearly show how an answer follows from a set of facts - substantially better than a high-performance baseline - while preserving answer accuracy. By materializing model beliefs that systematically support an answer, new opportunities arise for understanding the model’s system of belief, and diagnosing and correcting its misunderstandings when an answer is wrong.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.134.pdf"
    },
    {
        "title": "ToKen: Task Decomposition and Knowledge Infusion for Few-Shot Hate Speech Detection",
        "authors": [
            "Badr AlKhamissi",
            "Faisal Ladhak",
            "Srinivasan Iyer",
            "Veselin Stoyanov",
            "Zornitsa Kozareva",
            "Xian Li",
            "Pascale Fung",
            "Lambert Mathias",
            "Asli Celikyilmaz",
            "Mona Diab"
        ],
        "published": "2022",
        "summary": "Hate speech detection is complex; it relies on commonsense reasoning, knowledge of stereotypes, and an understanding of social nuance that differs from one culture to the next. It is also difficult to collect a large-scale hate speech annotated dataset. In this work, we frame this problem as a few-shot learning task, and show significant gains with decomposing the task into its “constituent” parts. In addition, we see that infusing knowledge from reasoning datasets (e.g. ATOMIC2020) improves the performance even further. Moreover, we observe that the trained models generalize to out-of-distribution datasets, showing the superiority of task decomposition and knowledge infusion compared to previously used methods. Concretely, our method outperforms the baseline by 17.83% absolute gain in the 16-shot case.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.136.pdf"
    },
    {
        "title": "Are Hard Examples also Harder to Explain? A Study with Human and Model-Generated Explanations",
        "authors": [
            "Swarnadeep Saha",
            "Peter Hase",
            "Nazneen Rajani",
            "Mohit Bansal"
        ],
        "published": "2022",
        "summary": "Recent work on explainable NLP has shown that few-shot prompting can enable large pre-trained language models (LLMs) to generate grammatical and factual natural language explanations for data labels. In this work, we study the connection between explainability and sample hardness by investigating the following research question – “Are LLMs and humans equally good at explaining data labels for both easy and hard samples?” We answer this question by first collecting human-written explanations in the form of generalizable commonsense rules on the task of Winograd Schema Challenge (Winogrande dataset). We compare these explanations with those generated by GPT-3 while varying the hardness of the test samples as well as the in-context samples. We observe that (1) GPT-3 explanations are as grammatical as human explanations regardless of the hardness of the test samples, (2) for easy examples, GPT-3 generates highly supportive explanations but human explanations are more generalizable, and (3) for hard examples, human explanations are significantly better than GPT-3 explanations both in terms of label-supportiveness and generalizability judgements. We also find that hardness of the in-context examples impacts the quality of GPT-3 explanations. Finally, we show that the supportiveness and generalizability aspects of human explanations are also impacted by sample hardness, although by a much smaller margin than models.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.137.pdf"
    },
    {
        "title": "Gendered Mental Health Stigma in Masked Language Models",
        "authors": [
            "Inna Lin",
            "Lucille Njoo",
            "Anjalie Field",
            "Ashish Sharma",
            "Katharina Reinecke",
            "Tim Althoff",
            "Yulia Tsvetkov"
        ],
        "published": "2022",
        "summary": "Mental health stigma prevents many individuals from receiving the appropriate care, and social psychology studies have shown that mental health tends to be overlooked in men. In this work, we investigate gendered mental health stigma in masked language models. In doing so, we operationalize mental health stigma by developing a framework grounded in psychology research: we use clinical psychology literature to curate prompts, then evaluate the models’ propensity to generate gendered words. We find that masked language models capture societal stigma about gender in mental health: models are consistently more likely to predict female subjects than male in sentences about having a mental health condition (32% vs. 19%), and this disparity is exacerbated for sentences that indicate treatment-seeking behavior. Furthermore, we find that different models capture dimensions of stigma differently for men and women, associating stereotypes like anger, blame, and pity more with women with mental health conditions than with men. In showing the complex nuances of models’ gendered mental health stigma, we demonstrate that context and overlapping dimensions of identity are important considerations when assessing computational models’ social biases.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.139.pdf"
    },
    {
        "title": "Prompt-and-Rerank: A Method for Zero-Shot and Few-Shot Arbitrary Textual Style Transfer with Small Language Models",
        "authors": [
            "Mirac Suzgun",
            "Luke Melas-Kyriazi",
            "Dan Jurafsky"
        ],
        "published": "2022",
        "summary": "We propose a method for arbitrary textual style transfer (TST)—the task of transforming a text into any given style—utilizing general-purpose pre-trained language models. Our method, Prompt-and-Rerank, is based on a mathematical formulation of the TST task, decomposing it into three constituent components: textual similarity, target style strength, and fluency. Our method uses zero-shot or few-shot prompting to obtain a set of candidate generations in the target style, and then re-ranks them according to the three components. Our method enables small pre-trained language models to perform on par with state-of-the-art large-scale models while using two orders of magnitude less compute and memory. We also investigate the effect of model size and prompt design (e.g., prompt paraphrasing and delimiter-pair choice) on style transfer quality across seven diverse textual style transfer datasets, finding, among other things, that delimiter-pair choice has a large impact on performance, and that models have biases on the direction of style transfer.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.141.pdf"
    },
    {
        "title": "Learning to Decompose: Hypothetical Question Decomposition Based on Comparable Texts",
        "authors": [
            "Ben Zhou",
            "Kyle Richardson",
            "Xiaodong Yu",
            "Dan Roth"
        ],
        "published": "2022",
        "summary": "Explicit decomposition modeling, which involves breaking down complex tasks into more straightforward and often more interpretable sub-tasks, has long been a central theme in developing robust and interpretable NLU systems. However, despite the many datasets and resources built as part of this effort, the majority have small-scale annotations and limited scope, which is insufficient to solve general decomposition tasks. In this paper, we look at large-scale intermediate pre-training of decomposition-based transformers using distant supervision from comparable texts, particularly large-scale parallel news. We show that with such intermediate pre-training, developing robust decomposition-based models for a diverse range of tasks becomes more feasible. For example, on semantic parsing, our model, DecompT5, improves 20% to 30% on two datasets, Overnight and TORQUE, over the baseline language model. We further use DecompT5 to build a novel decomposition-based QA system named DecompEntail, improving over state-of-the-art models, including GPT-3, on both HotpotQA and StrategyQA by 8% and 4%, respectively.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.142.pdf"
    },
    {
        "title": "Why is Winoground Hard? Investigating Failures in Visuolinguistic Compositionality",
        "authors": [
            "Anuj Diwan",
            "Layne Berry",
            "Eunsol Choi",
            "David Harwath",
            "Kyle Mahowald"
        ],
        "published": "2022",
        "summary": "Recent visuolinguistic pre-trained models show promising progress on various end tasks such as image retrieval and video captioning. Yet, they fail miserably on the recently proposed Winoground dataset, which challenges models to match paired images and English captions, with items constructed to overlap lexically but differ in meaning (e.g., “there is a mug in some grass” vs. “there is some grass in a mug”). By annotating the dataset using new fine-grained tags, we show that solving the Winoground task requires not just compositional language understanding, but a host of other abilities like commonsense reasoning or locating small, out-of-focus objects in low-resolution images. In this paper, we identify the dataset’s main challenges through a suite of experiments on related tasks (probing task, image retrieval task), data augmentation, and manual inspection of the dataset. Our analysis suggests that a main challenge in visuolinguistic models may lie in fusing visual and textual representations, rather than in compositional language understanding. We release our annotation and code at https://github.com/ajd12342/why-winoground-hard.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.143.pdf"
    },
    {
        "title": "Gradient-based Constrained Sampling from Language Models",
        "authors": [
            "Sachin Kumar",
            "Biswajit Paria",
            "Yulia Tsvetkov"
        ],
        "published": "2022",
        "summary": "Large pretrained language models are successful at generating fluent text but are notoriously hard to controllably sample from. In this work, we study constrained sampling from such language models, i.e., generating text that satisfies user-defined constraints, while maintaining fluency and model’s performance in a downstream task. We propose MuCoLa—a sampling procedure that combines the log-likelihood of the language model with arbitrary (differentiable) constraints in a single energy function, and then generates samples in a non-autoregressive manner. Specifically, it initializes the entire output sequence with noise and follows a Markov chain defined by Langevin Dynamics using the gradients of this energy. We evaluate MuCoLa on text generation with soft and hard constraints as well as their combinations, obtaining significant improvements over competitive baselines for toxicity avoidance, sentiment control, and keyword-guided generation.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.144.pdf"
    },
    {
        "title": "TaCube: Pre-computing Data Cubes for Answering Numerical-Reasoning Questions over Tabular Data",
        "authors": [
            "Fan Zhou",
            "Mengkang Hu",
            "Haoyu Dong",
            "Zhoujun Cheng",
            "Fan Cheng",
            "Shi Han",
            "Dongmei Zhang"
        ],
        "published": "2022",
        "summary": "Existing auto-regressive pre-trained language models (PLMs) like T5 and BART, have been well applied to table question answering by UNIFIEDSKG and TAPEX, respectively, and demonstrated state-of-the-art results on multiple benchmarks. However, auto-regressive PLMs are challenged by recent emerging numerical reasoning datasets, such as TAT-QA, due to the error-prone implicit calculation. In this paper, we present TaCube, to pre-compute aggregation/arithmetic results for the table in advance, so that they are handy and readily available for PLMs to answer numerical reasoning questions. TaCube systematically and comprehensively covers a collection of computational operations over table segments. By simply concatenating TaCube to the input sequence of PLMs, it shows significant experimental effectiveness. TaCube promotes the F1 score from 49.6% to 66.2% on TAT-QA and achieves new state-of-the-art results on WikiTQ (59.6% denotation accuracy). TaCube’s improvements on numerical reasoning cases are even more notable: on TAT-QA, TaCube promotes the exact match accuracy of BART-large by 39.6% on sum, 52.5% on average, 36.6% on substraction, and 22.2% on division. We believe that TaCube is a general and portable pre-computation solution that can be potentially integrated to various numerical reasoning frameworks",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.145.pdf"
    },
    {
        "title": "Rich Knowledge Sources Bring Complex Knowledge Conflicts: Recalibrating Models to Reflect Conflicting Evidence",
        "authors": [
            "Hung-Ting Chen",
            "Michael Zhang",
            "Eunsol Choi"
        ],
        "published": "2022",
        "summary": "Question answering models can use rich knowledge sources — up to one hundred retrieved passages and parametric knowledge in the large-scale language model (LM). Prior work assumes information in such knowledge sources is consistent with each other, paying little attention to how models blend information stored in their LM parameters with that from retrieved evidence documents. In this paper, we simulate knowledge conflicts (i.e., where parametric knowledge suggests one answer and different passages suggest different answers) and examine model behaviors. We find retrieval performance heavily impacts which sources models rely on, and current models mostly rely on non-parametric knowledgein their best-performing settings. We discover a troubling trend that contradictions among knowledge sources affect model confidence only marginally. To address this issue, we present a new calibration study, where models are discouraged from presenting any single answer when presented with multiple conflicting answer candidates in retrieved evidences.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.146.pdf"
    },
    {
        "title": "When FLUE Meets FLANG: Benchmarks and Large Pretrained Language Model for Financial Domain",
        "authors": [
            "Raj Shah",
            "Kunal Chawla",
            "Dheeraj Eidnani",
            "Agam Shah",
            "Wendi Du",
            "Sudheer Chava",
            "Natraj Raman",
            "Charese Smiley",
            "Jiaao Chen",
            "Diyi Yang"
        ],
        "published": "2022",
        "summary": "Pre-trained language models have shown impressive performance on a variety of tasks and domains. Previous research on financial language models usually employs a generic training scheme to train standard model architectures, without completely leveraging the richness of the financial data. We propose a novel domain specific Financial LANGuage model (FLANG) which uses financial keywords and phrases for better masking, together with span boundary objective and in-filing objective. Additionally, the evaluation benchmarks in the field have been limited. To this end, we contribute the Financial Language Understanding Evaluation (FLUE), an open-source comprehensive suite of benchmarks for the financial domain. These include new benchmarks across 5 NLP tasks in financial domain as well as common benchmarks used in the previous research. Experiments on these benchmarks suggest that our model outperforms those in prior literature on a variety of NLP tasks. Our models, code and benchmark data will be made publicly available on Github and Huggingface.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.148.pdf"
    },
    {
        "title": "SafeText: A Benchmark for Exploring Physical Safety in Language Models",
        "authors": [
            "Sharon Levy",
            "Emily Allaway",
            "Melanie Subbiah",
            "Lydia Chilton",
            "Desmond Patton",
            "Kathleen McKeown",
            "William Yang Wang"
        ],
        "published": "2022",
        "summary": "Understanding what constitutes safe text is an important issue in natural language processing and can often prevent the deployment of models deemed harmful and unsafe. One such type of safety that has been scarcely studied is commonsense physical safety, i.e. text that is not explicitly violent and requires additional commonsense knowledge to comprehend that it leads to physical harm. We create the first benchmark dataset, SafeText, comprising real-life scenarios with paired safe and physically unsafe pieces of advice. We utilize SafeText to empirically study commonsense physical safety across various models designed for text generation and commonsense reasoning tasks. We find that state-of-the-art large language models are susceptible to the generation of unsafe text and have difficulty rejecting unsafe advice. As a result, we argue for further studies of safety and the assessment of commonsense physical safety in models before release.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.154.pdf"
    },
    {
        "title": "Ground-Truth Labels Matter: A Deeper Look into Input-Label Demonstrations",
        "authors": [
            "Kang Min Yoo",
            "Junyeob Kim",
            "Hyuhng Joon Kim",
            "Hyunsoo Cho",
            "Hwiyeol Jo",
            "Sang-Woo Lee",
            "Sang-goo Lee",
            "Taeuk Kim"
        ],
        "published": "2022",
        "summary": "Despite recent explosion of interests in in-context learning, the underlying mechanism and the precise impact of the quality of demonstrations remain elusive.Intuitively, ground-truth labels should have as much impact in in-context learning (ICL) as supervised learning, but recent work reported that the input-label correspondence is significantly less important than previously thought.Intrigued by this counter-intuitive observation, we re-examine the importance of ground-truth labels in in-context learning.With the introduction of two novel metrics, namely Label-Correctness Sensitivity and Ground-truth Label Effect Ratio (GLER), we were able to conduct quantifiable analysis on the impact of ground-truth label demonstrations.Through extensive analyses, we find that the correct input-label mappings can have varying impacts on the downstream in-context learning performances, depending on the experimental configuration.Through additional studies, we identify key components, such as the verbosity of prompt templates and the language model size, as the controlling factor to achieve more noise-resilient ICL.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.155.pdf"
    },
    {
        "title": "D4: a Chinese Dialogue Dataset for Depression-Diagnosis-Oriented Chat",
        "authors": [
            "Binwei Yao",
            "Chao Shi",
            "Likai Zou",
            "Lingfeng Dai",
            "Mengyue Wu",
            "Lu Chen",
            "Zhen Wang",
            "Kai Yu"
        ],
        "published": "2022",
        "summary": "In a depression-diagnosis-directed clinical session, doctors initiate a conversation with ample emotional support that guides the patients to expose their symptoms based on clinical diagnosis criteria. Such a dialogue system is distinguished from existing single-purpose human-machine dialog systems, as it combines task-oriented and chit-chats with uniqueness in dialogue topics and procedures. However, due to the social stigma associated with mental illness, the dialogue data related to depression consultation and diagnosis are rarely disclosed. Based on clinical depression diagnostic criteria ICD-11 and DSM-5, we designed a 3-phase procedure to construct D4: a Chinese Dialogue Dataset for Depression-Diagnosis-Oriented Chat, which simulates the dialogue between doctors and patients during the diagnosis of depression, including diagnosis results and symptom summary given by professional psychiatrists for each conversation. Upon the newly-constructed dataset, four tasks mirroring the depression diagnosis process are established: response generation, topic prediction, dialog summary, and severity classification of depressive episode and suicide risk. Multi-scale evaluation results demonstrate that a more empathy-driven and diagnostic-accurate consultation dialogue system trained on our dataset can be achieved compared to rule-based bots.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.156.pdf"
    },
    {
        "title": "Navigating Connected Memories with a Task-oriented Dialog System",
        "authors": [
            "Satwik Kottur",
            "Seungwhan Moon",
            "Alborz Geramifard",
            "Babak Damavandi"
        ],
        "published": "2022",
        "summary": "Recent years have seen an increasing trend in the volume of personal media captured by users, thanks to the advent of smartphones and smart glasses, resulting in large media collections. Despite conversation being an intuitive human-computer interface, current efforts focus mostly on single-shot natural language based media retrieval to aid users query their media and re-live their memories. This severely limits the search functionality as users can neither ask follow-up queries nor obtain information without first formulating a single-turn query.In this work, we propose dialogs for connected memories as a powerful tool to empower users to search their media collection through a multi-turn, interactive conversation. Towards this, we collect a new task-oriented dialog dataset COMET, which contains 11.5k user↔assistant dialogs (totalling 103k utterances), grounded in simulated personal memory graphs. We employ a resource-efficient, two-phase data collection pipeline that uses: (1) a novel multimodal dialog simulator that generates synthetic dialog flows grounded in memory graphs, and, (2) manual paraphrasing to obtain natural language utterances. We analyze COMET, formulate four main tasks to benchmark meaningful progress, and adopt state-of-the-art language models as strong baselines, in order to highlight the multimodal challenges captured by our dataset.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.160.pdf"
    },
    {
        "title": "Language Model Decomposition: Quantifying the Dependency and Correlation of Language Models",
        "authors": [
            "Hao Zhang"
        ],
        "published": "2022",
        "summary": "Pre-trained language models (LMs), such as BERT (Devlin et al., 2018) and its variants, have led to significant improvements on various NLP tasks in past years. However, a theoretical framework for studying their relationships is still missing. In this paper, we fill this gap by investigating the linear dependency between pre-trained LMs. The linear dependency of LMs is defined analogously to the linear dependency of vectors. We propose Language Model Decomposition (LMD) to represent a LM using a linear combination of other LMs as basis, and derive the closed-form solution. A goodness-of-fit metric for LMD similar to the coefficient of determination is defined and used to measure the linear dependency of a set of LMs. In experiments, we find that BERT and eleven (11) BERT-like LMs are 91% linearly dependent. This observation suggests that current state-of-the-art (SOTA) LMs are highly “correlated”. To further advance SOTA we need more diverse and novel LMs that are less dependent on existing LMs.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.161.pdf"
    },
    {
        "title": "Whose Language Counts as High Quality? Measuring Language Ideologies in Text Data Selection",
        "authors": [
            "Suchin Gururangan",
            "Dallas Card",
            "Sarah Dreier",
            "Emily Gade",
            "Leroy Wang",
            "Zeyu Wang",
            "Luke Zettlemoyer",
            "Noah A. Smith"
        ],
        "published": "2022",
        "summary": "Language models increasingly rely on massive web crawls for diverse text data. However, these sources are rife with undesirable content. As such, resources like Wikipedia, books, and news often serve as anchors for automatically selecting web text most suitable for language modeling, a process typically referred to as quality filtering. Using a new dataset of U.S. high school newspaper articles—written by students from across the country—we investigate whose language is preferred by the quality filter used for GPT-3. We find that newspapers from larger schools, located in wealthier, educated, and urban zones (ZIP codes) are more likely to be classified as high quality. We also show that this quality measurement is unaligned with other sensible metrics, such as factuality or literary acclaim. We argue that privileging any corpus as high quality entails a language ideology, and more care is needed to construct training corpora for language models, with better transparency and justification for the inclusion or exclusion of various texts.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.165.pdf"
    },
    {
        "title": "Revisiting Parameter-Efficient Tuning: Are We Really There Yet?",
        "authors": [
            "Guanzheng Chen",
            "Fangyu Liu",
            "Zaiqiao Meng",
            "Shangsong Liang"
        ],
        "published": "2022",
        "summary": "Parameter-Efficient Tuning (PETuning) methods have been deemed by many as the new paradigm for using pretrained language models (PLMs). By tuning just a fraction amount of parameters comparing to full model finetuning, PETuning methods claim to have achieved performance on par with or even better than finetuning. In this work, we take a step back and re-examine these PETuning methods by conducting the first comprehensive investigation into the training and evaluation of them. We found the problematic validation and testing practice in current studies, when accompanied by the instability nature of PETuning methods, has led to unreliable conclusions. When being compared under a truly fair evaluation protocol, PETuning cannot yield consistently competitive performance while finetuning remains to be the best-performing method in medium- and high-resource settings. We delve deeper into the cause of the instability and observed that the number of trainable parameters and training iterations are two main factors: reducing trainable parameters and prolonging training iterations may lead to higher stability in PETuning methods.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.168.pdf"
    },
    {
        "title": "Calibrating Zero-shot Cross-lingual (Un-)structured Predictions",
        "authors": [
            "Zhengping Jiang",
            "Anqi Liu",
            "Benjamin Van Durme"
        ],
        "published": "2022",
        "summary": "We investigate model calibration in the setting of zero-shot cross-lingual transfer with large-scale pre-trained language models. The level of model calibration is an important metric for evaluating the trustworthiness of predictive models. There exists an essential need for model calibration when natural language models are deployed in critical tasks. We study different post-training calibration methods in structured and unstructured prediction tasks. We find that models trained with data from the source language become less calibrated when applied to the target language and that calibration errors increase with intrinsic task difficulty and relative sparsity of training data. Moreover, we observe a potential connection between the level of calibration error and an earlier proposed measure of the distance from English to other languages. Finally, our comparison demonstrates that among other methods Temperature Scaling (TS) generalizes well to distant languages, but TS fails to calibrate more complex confidence estimation in structured predictions compared to more expressive alternatives like Gaussian Process Calibration.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.170.pdf"
    },
    {
        "title": "PRINCE: Prefix-Masked Decoding for Knowledge Enhanced Sequence-to-Sequence Pre-Training",
        "authors": [
            "Song Xu",
            "Haoran Li",
            "Peng Yuan",
            "Youzheng Wu",
            "Xiaodong He"
        ],
        "published": "2022",
        "summary": "Pre-trained Language Models (PLMs) have shown effectiveness in various Natural Language Processing (NLP) tasks. Denoising autoencoder is one of the most successful pre-training frameworks, learning to recompose the original text given a noise-corrupted one. The existing studies mainly focus on injecting noises into the input. This paper introduces a simple yet effective pre-training paradigm, equipped with a knowledge-enhanced decoder that predicts the next entity token with noises in the prefix, explicitly strengthening the representation learning of entities that span over multiple input tokens. Specifically, when predicting the next token within an entity, we feed masks into the prefix in place of some of the previous ground-truth tokens that constitute the entity. Our model achieves new state-of-the-art results on two knowledge-driven data-to-text generation tasks with up to 2% BLEU gains.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.171.pdf"
    },
    {
        "title": "Iteratively Prompt Pre-trained Language Models for Chain of Thought",
        "authors": [
            "Boshi Wang",
            "Xiang Deng",
            "Huan Sun"
        ],
        "published": "2022",
        "summary": "While Pre-trained Language Models (PLMs) internalize a great amount of world knowledge, they have been shown incapable of recalling these knowledge to solve tasks requiring complex & multi-step reasoning. Similar to how humans develop a “chain of thought” for these tasks, how can we equip PLMs with such abilities? In this work, we explore an iterative prompting framework, a new prompting paradigm which progressively elicits relevant knowledge from PLMs for multi-step inference. We identify key limitations of existing prompting methods, namely they are either restricted to queries with a single identifiable relation/predicate, or being agnostic to input contexts, which makes it difficult to capture variabilities across different inference steps. We propose an iterative context-aware prompter, which addresses these limitations by learning to dynamically synthesize prompts conditioned on the current step’s contexts. Experiments on three datasets involving multi-step reasoning show the effectiveness of the iterative scheme and the context-aware prompter design.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.174.pdf"
    },
    {
        "title": "Back to the Future: Bidirectional Information Decoupling Network for Multi-turn Dialogue Modeling",
        "authors": [
            "Yiyang Li",
            "Hai Zhao",
            "Zhuosheng Zhang"
        ],
        "published": "2022",
        "summary": "Multi-turn dialogue modeling as a challenging branch of natural language understanding (NLU), aims to build representations for machines to understand human dialogues, which provides a solid foundation for multiple downstream tasks. Recent studies of dialogue modeling commonly employ pre-trained language models (PrLMs) to encode the dialogue history as successive tokens, which is insufficient in capturing the temporal characteristics of dialogues. Therefore, we propose Bidirectional Information Decoupling Network (BiDeN) as a universal dialogue encoder, which explicitly incorporates both the past and future contexts and can be generalized to a wide range of dialogue-related tasks. Experimental results on datasets of different downstream tasks demonstrate the universality and effectiveness of our BiDeN.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.177.pdf"
    },
    {
        "title": "Calibration Meets Explanation: A Simple and Effective Approach for Model Confidence Estimates",
        "authors": [
            "Dongfang Li",
            "Baotian Hu",
            "Qingcai Chen"
        ],
        "published": "2022",
        "summary": "Calibration strengthens the trustworthiness of black-box models by producing better accurate confidence estimates on given examples. However, little is known about if model explanations can help confidence calibration. Intuitively, humans look at important features attributions and decide whether the model is trustworthy. Similarly, the explanations may tell us when the model might know and when it does not. Inspired by this, we propose a method named CME that leverages model explanations to make the model less confident with non-inductive attributions. The idea is that when the model is not highly confident, it is difficult to identify strong indications of any class, and the tokens accordingly do not have high attribution scores for any class and vice versa. We conduct extensive experiments on six datasets with two popular pre-trained language models in the in-domain and out-of-domain settings. The results show that CME improves calibration performance in all settings. The expected calibration errors are further reduced when combined with temperature scaling. Our findings highlight that model explanations can help calibrate posterior estimates.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.178.pdf"
    },
    {
        "title": "Fast-R2D2: A Pretrained Recursive Neural Network based on Pruned CKY for Grammar Induction and Text Representation",
        "authors": [
            "Xiang Hu",
            "Haitao Mi",
            "Liang Li",
            "Gerard de Melo"
        ],
        "published": "2022",
        "summary": "Chart-based models have shown great potential in unsupervised grammar induction, running recursively and hierarchically, but requiring O(n³) time-complexity. The Recursive Transformer based on Differentiable Trees (R2D2) makes it possible to scale to large language model pretraining even with a complex tree encoder, by introducing a heuristic pruning method.However, its rule-based pruning process suffers from local optima and slow inference. In this paper, we propose a unified R2D2 method that overcomes these issues. We use a top-down unsupervised parser as a model-guided pruning method, which also enables parallel encoding during inference. Our parser casts parsing as a split point scoring task by first scoring all split points for a given sentence and then using the highest-scoring one to recursively split a span into two parts. The reverse order of the splits is considered as the order of pruning in the encoder. We optimize the unsupervised parser by minimizing the Kullback–Leibler distance between tree probabilities from the parser and the R2D2 model.Our experiments show that our Fast-R2D2 significantly improves the grammar induction quality and achieves competitive results in downstream tasks.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.181.pdf"
    },
    {
        "title": "Memory-assisted prompt editing to improve GPT-3 after deployment",
        "authors": [
            "Aman Madaan",
            "Niket Tandon",
            "Peter Clark",
            "Yiming Yang"
        ],
        "published": "2022",
        "summary": "Large LMs such as GPT-3 are powerful, but can commit mistakes that are obvious to humans. For example, GPT-3 would mistakenly interpret “What word is similar to good?” to mean a homophone, while the user intended a synonym. Our goal is to effectively correct such errors via user interactions with the system but without retraining, which will be prohibitively costly. We pair GPT-3 with a growing memory of recorded cases where the model misunderstood the user’s intents, along with user feedback for clarification. Such a memory allows our system to produce enhanced prompts for any new query based on the user feedback for error correction on similar cases in the past. On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed GPT-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT-3. Our approach is a step towards the low-cost utility enhancement for very large pre-trained LMs.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.183.pdf"
    },
    {
        "title": "PromptEHR: Conditional Electronic Healthcare Records Generation with Prompt Learning",
        "authors": [
            "Zifeng Wang",
            "Jimeng Sun"
        ],
        "published": "2022",
        "summary": "Accessing longitudinal multimodal Electronic Healthcare Records (EHRs) is challenging due to privacy concerns, which hinders the use of ML for healthcare applications. Synthetic EHRs generation bypasses the need to share sensitive real patient records. However, existing methods generate single-modal EHRs by unconditional generation or by longitudinal inference, which falls short of low flexibility and makes unrealistic EHRs. In this work, we propose to formulate EHRs generation as a text-to-text translation task by language models (LMs), which suffices to highly flexible event imputation during generation. We also design prompt learning to control the generation conditioned by numerical and categorical demographic features. We evaluate synthetic EHRs quality by two perplexity measures accounting for their longitudinal pattern (longitudinal imputation perplexity, lpl) and the connections cross modalities (cross-modality imputation perplexity, mpl). Moreover, we utilize two adversaries: membership and attribute inference attacks for privacy-preserving evaluation. Experiments on MIMIC-III data demonstrate the superiority of our methods on realistic EHRs generation (53.1% decrease of lpl and 45.3% decrease of mpl on average compared to the best baselines) with low privacy risks. Software is available at https://github.com/RyanWangZf/PromptEHR.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.185.pdf"
    },
    {
        "title": "ROSE: Robust Selective Fine-tuning for Pre-trained Language Models",
        "authors": [
            "Lan Jiang",
            "Hao Zhou",
            "Yankai Lin",
            "Peng Li",
            "Jie Zhou",
            "Rui Jiang"
        ],
        "published": "2022",
        "summary": "Even though the large-scale language models have achieved excellent performances, they suffer from various adversarial attacks.A large body of defense methods has been proposed. However, they are still limited due to redundant attack search spaces and the inability to defend against various types of attacks.In this work, we present a novel fine-tuning approach called RObust SEletive fine-tuning (ROSE) to address this issue.ROSE conducts selective updates when adapting pre-trained models to downstream tasks, filtering out invaluable and unrobust updates of parameters.Specifically, we propose two strategies: the first-order and second-order ROSE for selecting target robust parameters.The experimental results show that ROSE achieves significant improvements in adversarial robustness on various downstream NLP tasks, and the ensemble method even surpasses both variants above.Furthermore, ROSE can be easily incorporated into existing fine-tuning methods to improve their adversarial robustness further.The empirical analysis confirms that ROSE eliminates unrobust spurious updates during fine-tuning, leading to solutions corresponding to flatter and wider optima than the conventional method.Code is available at https://github.com/jiangllan/ROSE.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.186.pdf"
    },
    {
        "title": "Conformal Predictor for Improving Zero-Shot Text Classification Efficiency",
        "authors": [
            "Prafulla Kumar Choubey",
            "Yu Bai",
            "Chien-Sheng Wu",
            "Wenhao Liu",
            "Nazneen Rajani"
        ],
        "published": "2022",
        "summary": "Pre-trained language models (PLMs) have been shown effective for zero-shot (0shot) text classification. 0shot models based on natural language inference (NLI) and next sentence prediction (NSP) employ cross-encoder architecture and infer by making a forward pass through the model for each label-text pair separately. This increases the computational cost to make inferences linearly in the number of labels. In this work, we improve the efficiency of such cross-encoder-based 0shot models by restricting the number of likely labels using another fast base classifier-based conformal predictor (CP) calibrated on samples labeled by the 0shot model. Since a CP generates prediction sets with coverage guarantees, it reduces the number of target labels without excluding the most probable label based on the 0shot model. We experiment with three intent and two topic classification datasets. With a suitable CP for each dataset, we reduce the average inference time for NLI- and NSP-based models by 25.6% and 22.2% respectively, without dropping performance below the predefined error rate of 1%.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.196.pdf"
    },
    {
        "title": "Generative Entity Typing with Curriculum Learning",
        "authors": [
            "Siyu Yuan",
            "Deqing Yang",
            "Jiaqing Liang",
            "Zhixu Li",
            "Jinxi Liu",
            "Jingyue Huang",
            "Yanghua Xiao"
        ],
        "published": "2022",
        "summary": "Entity typing aims to assign types to the entity mentions in given texts. The traditional classification-based entity typing paradigm has two unignorable drawbacks: 1) it fails to assign an entity to the types beyond the predefined type set, and 2) it can hardly handle few-shot and zero-shot situations where many long-tail types only have few or even no training instances. To overcome these drawbacks, we propose a novel generative entity typing (GET) paradigm: given a text with an entity mention, the multiple types for the role that the entity plays in the text are generated with a pre-trained language model (PLM). However, PLMs tend to generate coarse-grained types after fine-tuning upon the entity typing dataset. In addition, only the heterogeneous training data consisting of a small portion of human-annotated data and a large portion of auto-generated but low-quality data are provided for model training. To tackle these problems, we employ curriculum learning (CL) to train our GET model on heterogeneous data, where the curriculum could be self-adjusted with the self-paced learning according to its comprehension of the type granularity and data heterogeneity. Our extensive experiments upon the datasets of different languages and downstream tasks justify the superiority of our GET model over the state-of-the-art entity typing models. The code has been released on https://github.com/siyuyuan/GET.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.199.pdf"
    },
    {
        "title": "Multi-level Distillation of Semantic Knowledge for Pre-training Multilingual Language Model",
        "authors": [
            "Mingqi Li",
            "Fei Ding",
            "Dan Zhang",
            "Long Cheng",
            "Hongxin Hu",
            "Feng Luo"
        ],
        "published": "2022",
        "summary": "Pre-trained multilingual language models play an important role in cross-lingual natural language understanding tasks. However, existing methods did not focus on learning the semantic structure of representation, and thus could not optimize their performance. In this paper, we propose Multi-level Multilingual Knowledge Distillation (MMKD), a novel method for improving multilingual language models. Specifically, we employ a teacher-student framework to adopt rich semantic representation knowledge in English BERT. We propose token-, word-, sentence-, and structure-level alignment objectives to encourage multiple levels of consistency between source-target pairs and correlation similarity between teacher and student models. We conduct experiments on cross-lingual evaluation benchmarks including XNLI, PAWS-X, and XQuAD. Experimental results show that MMKD outperforms other baseline models of similar size on XNLI and XQuAD and obtains comparable performance on PAWS-X. Especially, MMKD obtains significant performance gains on low-resource languages.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.202.pdf"
    },
    {
        "title": "R2F: A General Retrieval, Reading and Fusion Framework for Document-level Natural Language Inference",
        "authors": [
            "Hao Wang",
            "Yixin Cao",
            "Yangguang Li",
            "Zhen Huang",
            "Kun Wang",
            "Jing Shao"
        ],
        "published": "2022",
        "summary": "Document-level natural language inference (DOCNLI) is a new challenging task in natural language processing, aiming at judging the entailment relationship between a pair of hypothesis and premise documents. Current datasets and baselines largely follow sentence-level settings, but fail to address the issues raised by longer documents. In this paper, we establish a general solution, named Retrieval, Reading and Fusion (R2F) framework, and a new setting, by analyzing the main challenges of DOCNLI: interpretability, long-range dependency, and cross-sentence inference. The basic idea of the framework is to simplify document-level task into a set of sentence-level tasks, and improve both performance and interpretability with the power of evidence. For each hypothesis sentence, the framework retrieves evidence sentences from the premise, and reads to estimate its credibility. Then the sentence-level results are fused to judge the relationship between the documents. For the setting, we contribute complementary evidence and entailment label annotation on hypothesis sentences, for interpretability study. Our experimental results show that R2F framework can obtain state-of-the-art performance and is robust for diverse evidence retrieval methods. Moreover, it can give more interpretable prediction results. Our model and code are released at https://github.com/phoenixsecularbird/R2F.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.204.pdf"
    },
    {
        "title": "Revisiting Pre-trained Language Models and their Evaluation for Arabic Natural Language Processing",
        "authors": [
            "Abbas Ghaddar",
            "Yimeng Wu",
            "Sunyam Bagga",
            "Ahmad Rashid",
            "Khalil Bibi",
            "Mehdi Rezagholizadeh",
            "Chao Xing",
            "Yasheng Wang",
            "Xinyu Duan",
            "Zhefeng Wang",
            "Baoxing Huai",
            "Xin Jiang",
            "Qun Liu",
            "Phillippe Langlais"
        ],
        "published": "2022",
        "summary": "There is a growing body of work in recent years to develop pre-trained language models (PLMs) for the Arabic language. This work addresses two major problems in existing Arabic PLMs that limit the progress of the Arabic NLU and NLG fields. First, existing Arabic PLMs are not well-explored and their pre-training can be improved significantly using a more methodical approach. Second, there is a lack of systematic and reproducible evaluation of these models in the literature. We revisit both the pre-training and evaluation of Arabic PLMs. In terms of pre-training, we explore the impact of the quality of the pretraining data, the size of the model, and the incorporation of character-level information on Arabic PLM. As a result, we release three new Arabic BERT-style models ( JABER, Char-JABER, and SABER), and two T5-style models (AT5S and AT5B). In terms of evaluation, we conduct a comprehensive empirical study to systematically evaluate the performance of existing state-of-the-art models on ALUE, a leaderboard-powered benchmark for Arabic NLU tasks, and on a subset of the Arabic generative tasks. We show that our models significantly outperform existing Arabic PLMs and achieve a new state-of-the-art performance on discriminative and generative Arabic NLU and NLG tasks. Our models and source code to reproduce results will be made available upon acceptance.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.205.pdf"
    },
    {
        "title": "KECP: Knowledge Enhanced Contrastive Prompting for Few-shot Extractive Question Answering",
        "authors": [
            "Jianing Wang",
            "Chengyu Wang",
            "Minghui Qiu",
            "Qiuhui Shi",
            "Hongbin Wang",
            "Jun Huang",
            "Ming Gao"
        ],
        "published": "2022",
        "summary": "Extractive Question Answering (EQA) is one of the most essential tasks in Machine Reading Comprehension (MRC), which can be solved by fine-tuning the span selecting heads of Pre-trained Language Models (PLMs). However, most existing approaches for MRC may perform poorly in the few-shot learning scenario. To solve this issue, we propose a novel framework named Knowledge Enhanced Contrastive Prompt-tuning (KECP). Instead of adding pointer heads to PLMs, we introduce a seminal paradigm for EQA that transforms the task into a non-autoregressive Masked Language Modeling (MLM) generation problem. Simultaneously, rich semantics from the external knowledge base (KB) and the passage context support enhancing the query’s representations. In addition, to boost the performance of PLMs, we jointly train the model by the MLM and contrastive learning objectives. Experiments on multiple benchmarks demonstrate that our method consistently outperforms state-of-the-art approaches in few-shot settings by a large margin.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.206.pdf"
    },
    {
        "title": "Knowledge Prompting in Pre-trained Language Model for Natural Language Understanding",
        "authors": [
            "Jianing Wang",
            "Wenkang Huang",
            "Minghui Qiu",
            "Qiuhui Shi",
            "Hongbin Wang",
            "Xiang Li",
            "Ming Gao"
        ],
        "published": "2022",
        "summary": "Knowledge-enhanced Pre-trained Language Model (PLM) has recently received significant attention, which aims to incorporate factual knowledge into PLMs. However, most existing methods modify the internal structures of fixed types of PLMs by stacking complicated modules, and introduce redundant and irrelevant factual knowledge from knowledge bases (KBs). In this paper, to address these problems, we introduce a seminal knowledge prompting paradigm and further propose a knowledge-prompting-based PLM framework KP-PLM. This framework can be flexibly combined with existing mainstream PLMs. Specifically, we first construct a knowledge sub-graph from KBs for each context. Then we design multiple continuous prompts rules and transform the knowledge sub-graph into natural language prompts. To further leverage the factual knowledge from these prompts, we propose two novel knowledge-aware self-supervised tasks including prompt relevance inspection and masked prompt modeling. Extensive experiments on multiple natural language understanding (NLU) tasks show the superiority of KP-PLM over other state-of-the-art methods in both full-resource and low-resource settings. Our source codes will be released upon the acceptance of the paper.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.207.pdf"
    },
    {
        "title": "CEM: Machine-Human Chatting Handoff via Causal-Enhance Module",
        "authors": [
            "Shanshan Zhong",
            "Jinghui Qin",
            "Zhongzhan Huang",
            "Daifeng Li"
        ],
        "published": "2022",
        "summary": "Aiming to ensure chatbot quality by predicting chatbot failure and enabling human-agent collaboration, Machine-Human Chatting Handoff (MHCH) has attracted lots of attention from both industry and academia in recent years. However, most existing methods mainly focus on the dialogue context or assist with global satisfaction prediction based on multi-task learning, which ignore the grounded relationships among the causal variables, like the user state and labor cost. These variables are significantly associated with handoff decisions, resulting in prediction bias and cost increasement. Therefore, we propose Causal-Enhance Module (CEM) by establishing the causal graph of MHCH based on these two variables, which is a simple yet effective module and can be easy to plug into the existing MHCH methods. For the impact of users, we use the user state to correct the prediction bias according to the causal relationship of multi-task. For the labor cost, we train an auxiliary cost simulator to calculate unbiased labor cost through counterfactual learning so that a model becomes cost-aware.Extensive experiments conducted on four real-world benchmarks demonstrate the effectiveness of CEM in generally improving the performance of existing MHCH methods without any elaborated model crafting.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.213.pdf"
    },
    {
        "title": "Nearest Neighbor Zero-Shot Inference",
        "authors": [
            "Weijia Shi",
            "Julian Michael",
            "Suchin Gururangan",
            "Luke Zettlemoyer"
        ],
        "published": "2022",
        "summary": "Retrieval-augmented language models (LMs) use non-parametric memory to substantially outperform their non-retrieval counterparts on perplexity-based evaluations, but it is an open question whether they achieve similar gains in few- and zero-shot end-task accuracy. We extensively study one such model, the k-nearest neighbor LM (kNN-LM), showing that the gains marginally transfer. The main challenge is to achieve coverage of the verbalizer tokens that define the different end-task class labels. To address this challenge, we also introduce kNN-Prompt, a simple and effective kNN-LM with automatically expanded fuzzy verbalizers (e.g. to expand “terrible” to also include “silly” and other task-specific synonyms for sentiment classification). Across nine diverse end-tasks, using kNN-Prompt with GPT-2 large yields significant performance boosts over strong zeroshot baselines (13.4% absolute improvement over the base LM on average). We also show that other advantages of non-parametric augmentation hold for end tasks; kNN-Prompt is effective for domain adaptation with no further training, and gains increase with the size of the retrieval model.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.214.pdf"
    },
    {
        "title": "Making Pretrained Language Models Good Long-tailed Learners",
        "authors": [
            "Chen Zhang",
            "Lei Ren",
            "Jingang Wang",
            "Wei Wu",
            "Dawei Song"
        ],
        "published": "2022",
        "summary": "Prompt-tuning has shown appealing performance in few-shot classification by virtue of its capability in effectively exploiting pre-trained knowledge. This motivates us to check the hypothesis that prompt-tuning is also a promising choice for long-tailed classification, since the tail classes are intuitively few-shot ones. To achieve this aim, we conduct empirical studies to examine the hypothesis. The results demonstrate that prompt-tuning makes pretrained language models at least good long-tailed learners. For intuitions on why prompt-tuning can achieve good performance in long-tailed classification, we carry out in-depth analyses by progressively bridging the gap between prompt-tuning and commonly used finetuning. The summary is that the classifier structure and parameterization form the key to making good long-tailed learners, in comparison with the less important input structure. Finally, we verify the applicability of our finding to few-shot classification.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.217.pdf"
    },
    {
        "title": "Sentence Representation Learning with Generative Objective rather than Contrastive Objective",
        "authors": [
            "Bohong Wu",
            "Hai Zhao"
        ],
        "published": "2022",
        "summary": "Though offering amazing contextualized token-level representations, current pre-trained language models take less attention on accurately acquiring sentence-level representation during their self-supervised pre-training. However, contrastive objectives which dominate the current sentence representation learning bring little linguistic interpretability and no performance guarantee on downstream semantic tasks. We instead propose a novel generative self-supervised learning objective based on phrase reconstruction. To overcome the drawbacks of previous generative methods, we carefully model intra-sentence structure by breaking down one sentence into pieces of important phrases. Empirical studies show that our generative learning achieves powerful enough performance improvement and outperforms the current state-of-the-art contrastive methods not only on the STS benchmarks, but also on downstream semantic retrieval and reranking tasks. Our code is available at https://github.com/chengzhipanpan/PaSeR.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.221.pdf"
    },
    {
        "title": "RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning",
        "authors": [
            "Mingkai Deng",
            "Jianyu Wang",
            "Cheng-Ping Hsieh",
            "Yihan Wang",
            "Han Guo",
            "Tianmin Shu",
            "Meng Song",
            "Eric Xing",
            "Zhiting Hu"
        ],
        "published": "2022",
        "summary": "Prompting has shown impressive success in enabling large pre-trained language models (LMs) to perform diverse NLP tasks, especially with only few downstream data. Automatically finding the optimal prompt for each task, however, is challenging. Most existing work resorts to tuning *soft* prompts (e.g., embeddings) which fall short of interpretability, reusability across LMs, and applicability when gradients are not accessible. *Discrete* prompts, on the other hand, are difficult to optimize, and are often created by “enumeration (e.g., paraphrasing)-then-selection” heuristics that do not explore the prompt space systematically. This paper proposes RLPrompt, an efficient discrete prompt optimization approach with reinforcement learning (RL). RLPrompt formulates a parameter-efficient policy network that generates the optimized discrete prompt after training with reward. To harness the complex and stochastic reward signals from the large LM environment, we incorporate effective reward stabilization that substantially enhances training efficiency. RLPrompt is flexibly applicable to different types of LMs, such as masked (e.g., BERT) and left-to-right models (e.g., GPTs), for both classification and generation tasks. Experiments on few-shot classification and unsupervised text style transfer show superior performance over a wide range of existing fine-tuning or prompting methods. Interestingly, the resulting optimized prompts are often ungrammatical gibberish text; and surprisingly, those gibberish prompts are transferrable between different LMs to retain significant performance, indicating that LM prompting may not follow human language patterns.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.222.pdf"
    },
    {
        "title": "DisCup: Discriminator Cooperative Unlikelihood Prompt-tuning for Controllable Text Generation",
        "authors": [
            "Hanqing Zhang",
            "Dawei Song"
        ],
        "published": "2022",
        "summary": "Prompt learning with immensely large Casual Language Models (CLMs) has been shown promising for attribute-controllable text generation (CTG). However, vanilla prompt tuning tends to imitate training corpus characteristics beyond the control attributes, resulting in a poor generalization ability. Moreover, it is less able to capture the relationship between different attributes, further limiting the control performance. In this paper, we propose a new CTG approach, namely DisCup, which incorporates the attribute knowledge of discriminator to optimize the control-prompts, steering a frozen CLM to produce attribute-specific texts. Specifically, the frozen CLM model, capable of producing multitudinous texts, is first used to generate the next-token candidates based on the context, so as to ensure the diversity of tokens to be predicted. Then, we leverage an attribute-discriminator to select desired/undesired tokens from those candidates, providing the inter-attribute knowledge. Finally, we bridge the above two traits by an unlikelihood objective for prompt-tuning. Extensive experimental results show that DisCup can achieve a new state-of-the-art control performance while maintaining an efficient and high-quality text generation, only relying on around 10 virtual tokens.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.223.pdf"
    },
    {
        "title": "CPL: Counterfactual Prompt Learning for Vision and Language Models",
        "authors": [
            "Xuehai He",
            "Diji Yang",
            "Weixi Feng",
            "Tsu-Jui Fu",
            "Arjun Akula",
            "Varun Jampani",
            "Pradyumna Narayana",
            "Sugato Basu",
            "William Yang Wang",
            "Xin Wang"
        ],
        "published": "2022",
        "summary": "Prompt tuning is a new few-shot transfer learning technique that only tunes the learnable prompt for pre-trained vision and language models such as CLIP. However, existing prompt tuning methods tend to learn spurious or entangled representations, which leads to poor generalization to unseen concepts.Towards non-spurious and efficient prompt learning from limited examples, this paper presents a novel Counterfactual Prompt Learning (CPL) method for vision and language models, which simultaneously employs counterfactual generation and contrastive learning in a joint optimization framework.Particularly, CPL constructs counterfactual by identifying minimal non-spurious feature change between semantically-similar positive and negative samples that causes concept change, and learns more generalizable prompt representation from both factual and counterfactual examples via contrastive learning. Extensive experiments demonstrate that CPL can obtain superior few-shot performance on different vision and language tasks than previous prompt tuning methods on CLIP. On image classification, we achieve 3.55% average relative improvement on unseen classes across seven datasets; on image-text retrieval and visual question answering, we gain up to 4.09% and 25.08% relative improvements across three few-shot scenarios on unseen test sets respectively.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.224.pdf"
    },
    {
        "title": "Red Teaming Language Models with Language Models",
        "authors": [
            "Ethan Perez",
            "Saffron Huang",
            "Francis Song",
            "Trevor Cai",
            "Roman Ring",
            "John Aslanides",
            "Amelia Glaese",
            "Nat McAleese",
            "Geoffrey Irving"
        ],
        "published": "2022",
        "summary": "Language Models (LMs) often cannot be deployed because of their potential to harm users in hard-to-predict ways. Prior work identifies harmful behaviors before deployment by using human annotators to hand-write test cases. However, human annotation is expensive, limiting the number and diversity of test cases. In this work, we automatically find cases where a target LM behaves in a harmful way, by generating test cases (“red teaming”) using another LM. We evaluate the target LM’s replies to generated test questions using a classifier trained to detect offensive content, uncovering tens of thousands of offensive replies in a 280B parameter LM chatbot. We explore several methods, from zero-shot generation to reinforcement learning, for generating test cases with varying levels of diversity and difficulty. Furthermore, we use prompt engineering to control LM-generated test cases to uncover a variety of other harms, automatically finding groups of people that the chatbot discusses in offensive ways, personal and hospital phone numbers generated as the chatbot’s own contact info, leakage of private training data in generated text, and harms that occur over the course of a conversation. Overall, LM-based red teaming is one promising tool (among many needed) for finding and fixing diverse, undesirable LM behaviors before impacting users.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.225.pdf"
    },
    {
        "title": "Language Contamination Helps Explains the Cross-lingual Capabilities of English Pretrained Models",
        "authors": [
            "Terra Blevins",
            "Luke Zettlemoyer"
        ],
        "published": "2022",
        "summary": "English pretrained language models, which make up the backbone of many modern NLP systems, require huge amounts of unlabeled training data. These models are generally presented as being trained only on English text but have been found to transfer surprisingly well to other languages. We investigate this phenomenon and find that common English pretraining corpora actually contain significant amounts of non-English text: even when less than 1% of data is not English (well within the error rate of strong language classifiers), this leads to hundreds of millions of foreign language tokens in large-scale datasets. We then demonstrate that even these small percentages of non-English data facilitate cross-lingual transfer for models trained on them, with target language performance strongly correlated to the amount of in-language data seen during pretraining. In light of these findings, we argue that no model is truly monolingual when pretrained at scale, which should be considered when evaluating cross-lingual transfer.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.233.pdf"
    },
    {
        "title": "Analyzing the Mono- and Cross-Lingual Pretraining Dynamics of Multilingual Language Models",
        "authors": [
            "Terra Blevins",
            "Hila Gonen",
            "Luke Zettlemoyer"
        ],
        "published": "2022",
        "summary": "The emergent cross-lingual transfer seen in multilingual pretrained models has sparked significant interest in studying their behavior. However, because these analyses have focused on fully trained multilingual models, little is known about the dynamics of the multilingual pretraining process. We investigate when these models acquire their in-language and cross-lingual abilities by probing checkpoints taken from throughout XLM-R pretraining, using a suite of linguistic tasks. Our analysis shows that the model achieves high in-language performance early on, with lower-level linguistic skills acquired before more complex ones. In contrast, the point in pretraining when the model learns to transfer cross-lingually differs across language pairs. Interestingly, we also observe that, across many languages and tasks, the final model layer exhibits significant performance degradation over time, while linguistic knowledge propagates to lower layers of the network. Taken together, these insights highlight the complexity of multilingual pretraining and the resulting varied behavior for different languages over time.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.234.pdf"
    },
    {
        "title": "PATS: Sensitivity-aware Noisy Learning for Pretrained Language Models",
        "authors": [
            "Yupeng Zhang",
            "Hongzhi Zhang",
            "Sirui Wang",
            "Wei Wu",
            "Zhoujun Li"
        ],
        "published": "2022",
        "summary": "A wide range of NLP tasks benefit from the fine-tuning of pretrained language models (PLMs). However, a number of redundant parameters which contribute less to the downstream task are observed in a directly fine-tuned model. We consider the gap between pretraining and downstream tasks hinders the training of these redundant parameters, and results in a suboptimal performance of the overall model. In this paper, we present PATS (Perturbation According To Sensitivity), a noisy training mechanism which considers each parameter’s importance in the downstream task to help fine-tune PLMs. The main idea of PATS is to add bigger noise to parameters with lower sensitivity and vice versa, in order to activate more parameters’ contributions to downstream tasks without affecting the sensitive ones much. Extensive experiments conducted on different tasks of the GLUE benchmark show PATS can consistently empower the fine-tuning of different sizes of PLMs, and the parameters in the well-performing models always have more concentrated distributions of sensitivities, which experimentally proves the effectiveness of our method.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.241.pdf"
    },
    {
        "title": "Cross-Align: Modeling Deep Cross-lingual Interactions for Word Alignment",
        "authors": [
            "Siyu Lai",
            "Zhen Yang",
            "Fandong Meng",
            "Yufeng Chen",
            "Jinan Xu",
            "Jie Zhou"
        ],
        "published": "2022",
        "summary": "Word alignment which aims to extract lexicon translation equivalents between source and target sentences, serves as a fundamental tool for natural language processing. Recent studies in this area have yielded substantial improvements by generating alignments from contextualized embeddings of the pre-trained multilingual language models. However, we find that the existing approaches capture few interactions between the input sentence pairs, which degrades the word alignment quality severely, especially for the ambiguous words in the monolingual context. To remedy this problem, we propose Cross-Align to model deep interactions between the input sentence pairs, in which the source and target sentences are encoded separately with the shared self-attention modules in the shallow layers, while cross-lingual interactions are explicitly constructed by the cross-attention modules in the upper layers. Besides, to train our model effectively, we propose a two-stage training framework, where the model is trained with a simple Translation Language Modeling (TLM) objective in the first stage and then finetuned with a self-supervised alignment objective in the second stage. Experiments show that the proposed Cross-Align achieves the state-of-the-art (SOTA) performance on four out of five language pairs.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.244.pdf"
    },
    {
        "title": "BERTScore is Unfair: On Social Bias in Language Model-Based Metrics for Text Generation",
        "authors": [
            "Tianxiang Sun",
            "Junliang He",
            "Xipeng Qiu",
            "Xuanjing Huang"
        ],
        "published": "2022",
        "summary": "Automatic evaluation metrics are crucial to the development of generative systems. In recent years, pre-trained language model (PLM) based metrics, such as BERTScore, have been commonly adopted in various generation tasks. However, it has been demonstrated that PLMs encode a range of stereotypical societal biases, leading to a concern about the fairness of PLMs as metrics. To that end, this work presents the first systematic study on the social bias in PLM-based metrics. We demonstrate that popular PLM-based metrics exhibit significantly higher social bias than traditional metrics on 6 sensitive attributes, namely race, gender, religion, physical appearance, age, and socioeconomic status. In-depth analysis suggests that choosing paradigms (matching, regression, or generation) of the metric has a greater impact on fairness than choosing PLMs. In addition, we develop debiasing adapters that are injected into PLM layers, mitigating bias in PLM-based metrics while retaining high performance for evaluating text generation.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.245.pdf"
    },
    {
        "title": "HPT: Hierarchy-aware Prompt Tuning for Hierarchical Text Classification",
        "authors": [
            "Zihan Wang",
            "Peiyi Wang",
            "Tianyu Liu",
            "Binghuai Lin",
            "Yunbo Cao",
            "Zhifang Sui",
            "Houfeng Wang"
        ],
        "published": "2022",
        "summary": "Hierarchical text classification (HTC) is a challenging subtask of multi-label classification due to its complex label hierarchy.Recently, the pretrained language models (PLM)have been widely adopted in HTC through a fine-tuning paradigm. However, in this paradigm, there exists a huge gap between the classification tasks with sophisticated label hierarchy and the masked language model (MLM) pretraining tasks of PLMs and thus the potential of PLMs cannot be fully tapped.To bridge the gap, in this paper, we propose HPT, a Hierarchy-aware Prompt Tuning method to handle HTC from a multi-label MLM perspective.Specifically, we construct a dynamic virtual template and label words that take the form of soft prompts to fuse the label hierarchy knowledge and introduce a zero-bounded multi-label cross-entropy loss to harmonize the objectives of HTC and MLM.Extensive experiments show HPT achieves state-of-the-art performances on 3 popular HTC datasets and is adept at handling the imbalance and low resource situations. Our code is available at https://github.com/wzh9969/HPT.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.246.pdf"
    },
    {
        "title": "Neural Theory-of-Mind? On the Limits of Social Intelligence in Large LMs",
        "authors": [
            "Maarten Sap",
            "Ronan Le Bras",
            "Daniel Fried",
            "Yejin Choi"
        ],
        "published": "2022",
        "summary": "Social intelligence and Theory of Mind (TOM), i.e., the ability to reason about the different mental states, intents, and reactions of all people involved, allows humans to effectively navigate and understand everyday social interactions. As NLP systems are used in increasingly complex social situations, their ability to grasp social dynamics becomes crucial.In this work, we examine the open question of social intelligence and Theory of Mind in modern NLP systems from an empirical and theorybased perspective. We show that one of today’s largest language models (GPT-3; Brown et al., 2020) lacks this kind of social intelligence out-of-the box, using two tasks: SocialIQa (Sap et al., 2019), which measure models’ ability to understand intents and reactions of participants of social interactions, and ToMi (Le, Boureau, and Nickel, 2019), which measures whether models can infer mental states and realities of participants of situations.Our results show that models struggle substantially at these Theory of Mind tasks, with well-below-human accuracies of 55% and 60% on SocialIQa and ToMi, respectively. To conclude, we draw on theories from pragmatics to contextualize this shortcoming of large language models, by examining the limitations stemming from their data, neural architecture, and training paradigms. Challenging the prevalent narrative that only scale is needed, we posit that person-centric NLP approaches might be more effective towards neural Theory of Mind.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.248.pdf"
    },
    {
        "title": "Improving Passage Retrieval with Zero-Shot Question Generation",
        "authors": [
            "Devendra Sachan",
            "Mike Lewis",
            "Mandar Joshi",
            "Armen Aghajanyan",
            "Wen-tau Yih",
            "Joelle Pineau",
            "Luke Zettlemoyer"
        ],
        "published": "2022",
        "summary": "We propose a simple and effective re-ranking method for improving passage retrieval in open question answering. The re-ranker re-scores retrieved passages with a zero-shot question generation model, which uses a pre-trained language model to compute the probability of the input question conditioned on a retrieved passage. This approach can be applied on top of any retrieval method (e.g. neural or keyword-based), does not require any domain- or task-specific training (and therefore is expected to generalize better to data distribution shifts), and provides rich cross-attention between query and passage (i.e. it must explain every token in the question). When evaluated on a number of open-domain retrieval datasets, our re-ranker improves strong unsupervised retrieval models by 6%-18% absolute and strong supervised models by up to 12% in terms of top-20 passage retrieval accuracy. We also obtain new state-of-the-art results on full open-domain question answering by simply adding the new re-ranker to existing models with no further changes.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.249.pdf"
    },
    {
        "title": "Open-ended Knowledge Tracing for Computer Science Education",
        "authors": [
            "Naiming Liu",
            "Zichao Wang",
            "Richard Baraniuk",
            "Andrew Lan"
        ],
        "published": "2022",
        "summary": "In educational applications, knowledge tracing refers to the problem of estimating students’ time-varying concept/skill mastery level from their past responses to questions and predicting their future performance.One key limitation of most existing knowledge tracing methods is that they treat student responses to questions as binary-valued, i.e., whether they are correct or incorrect. Response correctness analysis/prediction is straightforward, but it ignores important information regarding mastery, especially for open-ended questions.In contrast, exact student responses can provide much more information.In this paper, we conduct the first exploration int open-ended knowledge tracing (OKT) by studying the new task of predicting students’ exact open-ended responses to questions.Our work is grounded in the domain of computer science education with programming questions. We develop an initial solution to the OKT problem, a student knowledge-guided code generation approach, that combines program synthesis methods using language models with student knowledge tracing methods. We also conduct a series of quantitative and qualitative experiments on a real-world student code dataset to validate and demonstrate the promise of OKT.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.254.pdf"
    },
    {
        "title": "Sparse Teachers Can Be Dense with Knowledge",
        "authors": [
            "Yi Yang",
            "Chen Zhang",
            "Dawei Song"
        ],
        "published": "2022",
        "summary": "Recent advances in distilling pretrained language models have discovered that, besides the expressiveness of knowledge, the student-friendliness should be taken into consideration to realize a truly knowledgeable teacher. Based on a pilot study, we find that over-parameterized teachers can produce expressive yet student-unfriendly knowledge and are thus limited in overall knowledgeableness. To remove the parameters that result in student-unfriendliness, we propose a sparse teacher trick under the guidance of an overall knowledgeable score for each teacher parameter. The knowledgeable score is essentially an interpolation of the expressiveness and student-friendliness scores. The aim is to ensure that the expressive parameters are retained while the student-unfriendly ones are removed. Extensive experiments on the GLUE benchmark show that the proposed sparse teachers can be dense with knowledge and lead to students with compelling performance in comparison with a series of competitive baselines.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.258.pdf"
    },
    {
        "title": "BBTv2: Towards a Gradient-Free Future with Large Language Models",
        "authors": [
            "Tianxiang Sun",
            "Zhengfu He",
            "Hong Qian",
            "Yunhua Zhou",
            "Xuanjing Huang",
            "Xipeng Qiu"
        ],
        "published": "2022",
        "summary": "Most downstream adaptation methods tune all or part of the parameters of pre-trained models (PTMs) through gradient descent, where the tuning cost increases linearly with the growth of the model size.By contrast, gradient-free methods only require the forward computation of the PTM to tune the prompt, retaining the benefits of efficient tuning and deployment.Though, past work on gradient-free tuning often introduces gradient descent to seek a good initialization of prompt and lacks versatility across tasks and PTMs.In this paper, we present BBTv2, an improved version of Black-Box Tuning, to drive PTMs for few-shot learning.We prepend continuous prompts to every layer of the PTM and propose a divide-and-conquer gradient-free algorithm to optimize the prompts at different layers alternately.Extensive experiments across various tasks and PTMs show that BBTv2 can achieve comparable performance to full model tuning and state-of-the-art parameter-efficient methods (e.g., Adapter, LoRA, BitFit, etc.) under few-shot settings while maintaining much fewer tunable parameters.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.259.pdf"
    },
    {
        "title": "Mixed-effects transformers for hierarchical adaptation",
        "authors": [
            "Julia White",
            "Noah Goodman",
            "Robert Hawkins"
        ],
        "published": "2022",
        "summary": "Language differs dramatically from context to context. To some degree, large language models like GPT-3 account for such variation by conditioning on strings of initial input text, or prompts. However, prompting can be ineffective when contexts are sparse, out-of-sample, or extra-textual. In this paper, we introduce the mixed-effects transformer (MET), a novel approach for learning hierarchically-structured prefixes— lightweight modules prepended to an input sequence— to account for structured variation in language use. Specifically, we show how the popular class of mixed-effects regression models may be extended to transformer-based architectures using a regularized prefix-tuning procedure with dropout. We evaluate this approach on several domain-adaptation benchmarks, finding that it learns contextual variation from minimal data while generalizing well to unseen contexts.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.261.pdf"
    },
    {
        "title": "MGDoc: Pre-training with Multi-granular Hierarchy for Document Image Understanding",
        "authors": [
            "Zilong Wang",
            "Jiuxiang Gu",
            "Chris Tensmeyer",
            "Nikolaos Barmpalios",
            "Ani Nenkova",
            "Tong Sun",
            "Jingbo Shang",
            "Vlad Morariu"
        ],
        "published": "2022",
        "summary": "Document images are a ubiquitous source of data where the text is organized in a complex hierarchical structure ranging from fine granularity (e.g., words), medium granularity (e.g., regions such as paragraphs or figures), to coarse granularity (e.g., the whole page). The spatial hierarchical relationships between content at different levels of granularity are crucial for document image understanding tasks. Existing methods learn features from either word-level or region-level but fail to consider both simultaneously. Word-level models are restricted by the fact that they originate from pure-text language models, which only encode the word-level context. In contrast, region-level models attempt to encode regions corresponding to paragraphs or text blocks into a single embedding, but they perform worse with additional word-level features. To deal with these issues, we propose MGDoc, a new multi-modal multi-granular pre-training framework that encodes page-level, region-level, and word-level information at the same time. MGDoc uses a unified text-visual encoder to obtain multi-modal features across different granularities, which makes it possible to project the multi-granular features into the same hyperspace. To model the region-word correlation, we design a cross-granular attention mechanism and specific pre-training tasks for our model to reinforce the model of learning the hierarchy between regions and words. Experiments demonstrate that our proposed model can learn better features that perform well across granularities and lead to improvements in downstream tasks.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.265.pdf"
    },
    {
        "title": "ProsocialDialog: A Prosocial Backbone for Conversational Agents",
        "authors": [
            "Hyunwoo Kim",
            "Youngjae Yu",
            "Liwei Jiang",
            "Ximing Lu",
            "Daniel Khashabi",
            "Gunhee Kim",
            "Yejin Choi",
            "Maarten Sap"
        ],
        "published": "2022",
        "summary": "Most existing dialogue systems fail to respond properly to potentially unsafe user utterances by either ignoring or passively agreeing with them. To address this issue, we introduce ProsocialDialog, the first large-scale multi-turn dialogue dataset to teach conversational agents to respond to problematic content following social norms. Covering diverse unethical, problematic, biased, and toxic situations, ProsocialDialog contains responses that encourage prosocial behavior, grounded in commonsense social rules (i.e., rules-of-thumb, RoTs). Created via a human-AI collaborative framework, ProsocialDialog consists of 58K dialogues, with 331K utterances, 160K unique RoTs, and 497K dialogue safety labels accompanied by free-form rationales.With this dataset, we introduce a dialogue safety detection module, Canary, capable of generating RoTs given conversational context, and a socially-informed dialogue agent, Prost. Empirical results show that Prost generates more socially acceptable dialogues compared to other state-of-the-art language and dialogue models in both in-domain and out-of-domain settings. Additionally, Canary effectively guides conversational agents and off-the-shelf language models to generate significantly more prosocial responses. Our work highlights the promise and importance of creating and steering conversational AI to be socially responsible.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.267.pdf"
    },
    {
        "title": "Automatic Generation of Socratic Subquestions for Teaching Math Word Problems",
        "authors": [
            "Kumar Shridhar",
            "Jakub Macina",
            "Mennatallah El-Assady",
            "Tanmay Sinha",
            "Manu Kapur",
            "Mrinmaya Sachan"
        ],
        "published": "2022",
        "summary": "Socratic questioning is an educational method that allows students to discover answers to complex problems by asking them a series of thoughtful questions. Generation of didactically sound questions is challenging, requiring understanding of the reasoning process involved in the problem. We hypothesize that such questioning strategy can not only enhance the human performance, but also assist the math word problem (MWP) solvers.In this work, we explore the ability of large language models (LMs) in generating sequential questions for guiding math word problem-solving. We propose various guided question generation schemes based on input conditioning and reinforcement learning.On both automatic and human quality evaluations, we find that LMs constrained with desirable question properties generate superior questions and improve the overall performance of a math word problem solver. We conduct a preliminary user study to examine the potential value of such question generation models in the education domain. Results suggest that the difficulty level of problems plays an important role in determining whether questioning improves or hinders human performance. We discuss the future of using such questioning strategies in education.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.277.pdf"
    },
    {
        "title": "The Optimal BERT Surgeon: Scalable and Accurate Second-Order Pruning for Large Language Models",
        "authors": [
            "Eldar Kurtic",
            "Daniel Campos",
            "Tuan Nguyen",
            "Elias Frantar",
            "Mark Kurtz",
            "Benjamin Fineran",
            "Michael Goin",
            "Dan Alistarh"
        ],
        "published": "2022",
        "summary": "In this paper, we consider the problem of sparsifying BERT models, which are a key building block for natural language processing, in order to reduce their storage and computational cost. We introduce the Optimal BERT Surgeon (oBERT), an efficient and accurate pruning method based on approximate second-order information, which we show to yield state-of-the-art results in both stages of language tasks: pre-training and fine-tuning. Specifically, oBERT extends existing work on second-order pruning by allowing for pruning weight blocks, and is the first such method that is applicable at BERT scale. Second, we investigate compounding compression approaches to obtain highly compressed but accurate models for deployment on edge devices. These models significantly push boundaries of the current state-of-the-art sparse BERT models with respect to all metrics: model size, inference speed and task accuracy. For example, relative to the dense BERT-base, we obtain 10x model size compression with < 1% accuracy drop, 10x CPU-inference speedup with < 2% accuracy drop, and 29x CPU-inference speedup with < 7.5% accuracy drop. Our code, fully integrated with Transformers and SparseML, is available at https://github.com/neuralmagic/sparseml/tree/main/research/optimal_BERT_surgeon_oBERT.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.279.pdf"
    },
    {
        "title": "Information-Theoretic Text Hallucination Reduction for Video-grounded Dialogue",
        "authors": [
            "Sunjae Yoon",
            "Eunseop Yoon",
            "Hee Suk Yoon",
            "Junyeong Kim",
            "Chang Yoo"
        ],
        "published": "2022",
        "summary": "Video-grounded Dialogue (VGD) aims to decode an answer sentence to a question regarding a given video and dialogue context. Despite the recent success of multi-modal reasoning to generate answer sentences, existing dialogue systems still suffer from a text hallucination problem, which denotes indiscriminate text-copying from input texts without an understanding of the question. This is due to learning spurious correlations from the fact that answer sentences in the dataset usually include the words of input texts, thus the VGD system excessively relies on copying words from input texts by hoping those words to overlap with ground-truth texts. Hence, we design Text Hallucination Mitigating (THAM) framework, which incorporates Text Hallucination Regularization (THR) loss derived from the proposed information-theoretic text hallucination measurement approach. Applying THAM with current dialogue systems validates the effectiveness on VGD benchmarks (i.e., AVSD@DSTC7 and AVSD@DSTC8) and shows enhanced interpretability.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.280.pdf"
    },
    {
        "title": "Evidence > Intuition: Transferability Estimation for Encoder Selection",
        "authors": [
            "Elisa Bassignana",
            "Max Müller-Eberstein",
            "Mike Zhang",
            "Barbara Plank"
        ],
        "published": "2022",
        "summary": "With the increase in availability of large pre-trained language models (LMs) in Natural Language Processing (NLP), it becomes critical to assess their fit for a specific target task a priori—as fine-tuning the entire space of available LMs is computationally prohibitive and unsustainable. However, encoder transferability estimation has received little to no attention in NLP. In this paper, we propose to generate quantitative evidence to predict which LM, out of a pool of models, will perform best on a target task without having to fine-tune all candidates. We provide a comprehensive study on LM ranking for 10 NLP tasks spanning the two fundamental problem types of classification and structured prediction. We adopt the state-of-the-art Logarithm of Maximum Evidence (LogME) measure from Computer Vision (CV) and find that it positively correlates with final LM performance in 94% of the setups.In the first study of its kind, we further compare transferability measures with the de facto standard of human practitioner ranking, finding that evidence from quantitative metrics is more robust than pure intuition and can help identify unexpected LM candidates.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.283.pdf"
    },
    {
        "title": "FiE: Building a Global Probability Space by Leveraging Early Fusion in Encoder for Open-Domain Question Answering",
        "authors": [
            "Akhil Kedia",
            "Mohd Abbas Zaidi",
            "Haejun Lee"
        ],
        "published": "2022",
        "summary": "Generative models have recently started to outperform extractive models in Open Domain Question Answering, largely by leveraging their decoder to attend over multiple encoded passages and combining their information. However, generative models tend to be larger than extractive models due to the need for a decoder, run slower during inference due to auto-regressive decoder beam search, and their generated output often suffers from hallucinations. We propose to extend transformer encoders with the ability to fuse information from multiple passages, using global representation to provide cross-sample attention over all tokens across samples. Furthermore, we propose an alternative answer span probability calculation to better aggregate answer scores in the global space of all samples. Using our proposed method, we outperform the current state-of-the-art method by 2.5 Exact Match score on the Natural Question dataset while using only 25% of parameters and 35% of the latency during inference, and 4.4 Exact Match on WebQuestions dataset. When coupled with synthetic data augmentation, we outperform larger models on the TriviaQA dataset as well. The latency and parameter savings of our method make it particularly attractive for open-domain question answering, as these models are often compute-intensive.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.285.pdf"
    },
    {
        "title": "On the Calibration of Massively Multilingual Language Models",
        "authors": [
            "Kabir Ahuja",
            "Sunayana Sitaram",
            "Sandipan Dandapat",
            "Monojit Choudhury"
        ],
        "published": "2022",
        "summary": "Massively Multilingual Language Models (MMLMs) have recently gained popularity due to their surprising effectiveness in cross-lingual transfer. While there has been much work in evaluating these models for their performance on a variety of tasks and languages, little attention has been paid on how well calibrated these models are with respect to the confidence in their predictions. We first investigate the calibration of MMLMs in the zero-shot setting and observe a clear case of miscalibration in low-resource languages or those which are typologically diverse from English. Next, we empirically show that calibration methods like temperature scaling and label smoothing do reasonably well in improving calibration in the zero-shot scenario. We also find that few-shot examples in the language can further help reduce calibration errors, often substantially. Overall, our work contributes towards building more reliable multilingual models by highlighting the issue of their miscalibration, understanding what language and model-specific factors influence it, and pointing out the strategies to improve the same.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.290.pdf"
    },
    {
        "title": "Retrieval Augmentation for Commonsense Reasoning: A Unified Approach",
        "authors": [
            "Wenhao Yu",
            "Chenguang Zhu",
            "Zhihan Zhang",
            "Shuohang Wang",
            "Zhuosheng Zhang",
            "Yuwei Fang",
            "Meng Jiang"
        ],
        "published": "2022",
        "summary": "A common thread of retrieval-augmented methods in the existing literature focuses on retrieving encyclopedic knowledge, such as Wikipedia, which facilitates well-defined entity and relation spaces that can be modeled. However, applying such methods to commonsense reasoning tasks faces two unique challenges, i.e., the lack of a general large-scale corpus for retrieval and a corresponding effective commonsense retriever. In this paper, we systematically investigate how to leverage commonsense knowledge retrieval to improve commonsense reasoning tasks. We proposed a unified framework of retrieval-augmented commonsense reasoning (called RACo), including a newly constructed commonsense corpus with over 20 million documents and novel strategies for training a commonsense retriever. We conducted experiments on four different commonsense reasoning tasks. Extensive evaluation results showed that our proposed RACo can significantly outperform other knowledge-enhanced method counterparts, achieving new SoTA performance on the CommonGen and CREAK leaderboards.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.294.pdf"
    },
    {
        "title": "Re3: Generating Longer Stories With Recursive Reprompting and Revision",
        "authors": [
            "Kevin Yang",
            "Yuandong Tian",
            "Nanyun Peng",
            "Dan Klein"
        ],
        "published": "2022",
        "summary": "We consider the problem of automatically generating longer stories of over two thousand words. Compared to prior work on shorter stories, long-range plot coherence and relevance are more central challenges here. We propose the Recursive Reprompting and Revision framework (Re3) to address these challenges by (a) prompting a general-purpose language model to construct a structured overarching plan, and (b) generating story passages by repeatedly injecting contextual information from both the plan and current story state into a language model prompt. We then revise by (c) reranking different continuations for plot coherence and premise relevance, and finally (d) editing the best continuation for factual consistency. Compared to similar-length stories generated directly from the same base model, human evaluators judged substantially more of Re3’s stories as having a coherent overarching plot (by 14% absolute increase), and relevant to the given initial premise (by 20%).",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.296.pdf"
    },
    {
        "title": "Continued Pretraining for Better Zero- and Few-Shot Promptability",
        "authors": [
            "Zhaofeng Wu",
            "Robert L Logan IV",
            "Pete Walsh",
            "Akshita Bhagia",
            "Dirk Groeneveld",
            "Sameer Singh",
            "Iz Beltagy"
        ],
        "published": "2022",
        "summary": "Recently introduced language model prompting methods can achieve high accuracy in zero- and few-shot settings while requiring few to no learned task-specific parameters. Nevertheless, these methods still often trail behind full model finetuning. In this work, we investigate if a dedicated continued pretraining stage could improve “promptability”, i.e., zero-shot performance with natural language prompts or few-shot performance with prompt tuning. We reveal settings where existing continued pretraining methods lack promptability. We also identify current methodological gaps, which we fill with thorough large-scale experiments. We demonstrate that a simple recipe, continued pretraining that incorporates a trainable prompt during multi-task learning, leads to improved promptability in both zero- and few-shot settings compared to existing methods, up to 31% relative. On the other hand, we find that continued pretraining using MAML-style meta-learning, a method that directly optimizes few-shot promptability, yields subpar performance. We validate our findings with two prompt tuning methods, and, based on our results, we provide concrete recommendations to optimize promptability for different use cases.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.300.pdf"
    },
    {
        "title": "Less is More: Summary of Long Instructions is Better for Program Synthesis",
        "authors": [
            "Kirby Kuznia",
            "Swaroop Mishra",
            "Mihir Parmar",
            "Chitta Baral"
        ],
        "published": "2022",
        "summary": "Despite the success of large pre-trained language models (LMs) such as Codex, they show below-par performance on the larger and more complicated programming related questions. We show that LMs benefit from the summarized version of complicated questions. Our findings show that superfluous information often present in problem description such as human characters, background stories, and names (which are included to help humans in understanding a task) does not help models in understanding a task. To this extent, we create a meta-dataset from the frequently used APPS dataset and the newly created CodeContests dataset for the program synthesis task. Our meta-dataset consists of human and synthesized summaries of the long and complicated programming questions. Experimental results on Codex show that our proposed approach outperforms baseline by 8.13% on the APPS dataset and 11.88% on the CodeContests dataset on an average in terms of strict accuracy. Our analysis shows that summaries significantly improve performance for introductory (9.86%) and interview (11.48%) related programming questions. However, it shows improvement by a small margin ( 2%) for competitive programming questions, implying the scope for future research direction.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.301.pdf"
    },
    {
        "title": "Is a Question Decomposition Unit All We Need?",
        "authors": [
            "Pruthvi Patel",
            "Swaroop Mishra",
            "Mihir Parmar",
            "Chitta Baral"
        ],
        "published": "2022",
        "summary": "Large Language Models (LMs) have achieved state-of-the-art performance on many Natural Language Processing (NLP) benchmarks. With the growing number of new benchmarks, we build bigger and more complex LMs. However, building new LMs may not be an ideal option owing to the cost, time and environmental impact associated with it. We explore an alternative route: can we modify data by expressing it in terms of the model’s strengths, so that a question becomes easier for models to answer? We investigate if humans can decompose a hard question into a set of simpler questions that are relatively easier for models to solve. We analyze a range of datasets involving various forms of reasoning and find that it is indeed possible to significantly improve model performance (24% for GPT3 and 29% for RoBERTa-SQuAD along with a symbolic calculator) via decomposition. Our approach provides a viable option to involve people in NLP research in a meaningful way. Our findings indicate that Human-in-the-loop Question Decomposition (HQD) can potentially provide an alternate path to building large LMs.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.302.pdf"
    },
    {
        "title": "Discourse-Aware Soft Prompting for Text Generation",
        "authors": [
            "Marjan Ghazvininejad",
            "Vladimir Karpukhin",
            "Vera Gor",
            "Asli Celikyilmaz"
        ],
        "published": "2022",
        "summary": "Current efficient fine-tuning methods(e.g., adapters, prefix-tuning, etc.) have optimized conditional text generation via training a small set of extra parameters of the neural language model, while freezing the rest for efficiency. While showing strong performance on some generation tasks, they don’t generalize across all generation tasks. We show that soft-prompt based conditional text generation can be improved with simple and efficient methods that simulate modeling the discourse structure of human written text.We investigate two design choices: First, we apply hierarchical blocking on the prefix parameters to simulate a higher-level discourse structure of human written text. Second, we apply attention sparsity on the prefix parameters at different layers of the network and learn sparse transformations on the softmax-function. We show that structured design of prefix parameters yields more coherent, faithful and relevant generations than the baseline prefix-tuning on all generation tasks.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.303.pdf"
    },
    {
        "title": "SLING: Sino Linguistic Evaluation of Large Language Models",
        "authors": [
            "Yixiao Song",
            "Kalpesh Krishna",
            "Rajesh Bhatt",
            "Mohit Iyyer"
        ],
        "published": "2022",
        "summary": "To understand what kinds of linguistic knowledge are encoded by pretrained Chinese language models (LMs), we introduce the benchmark of Sino LINGuistics (SLING), which consists of 38K minimal sentence pairs in Mandarin Chinese grouped into 9 high-level linguistic phenomena. Each pair demonstrates the acceptability contrast of a specific syntactic or semantic phenomenon (e.g., The keys are lost vs. The keys is lost), and an LM should assign lower perplexity to the acceptable sentence. In contrast to the CLiMP dataset (Xiang et al., 2021), which also contains Chinese minimal pairs and was created by translating the vocabulary of the English BLiMP dataset, the minimal pairs in SLING are derived primarily by applying syntactic and lexical transformations to naturally-occurring, linguist-annotated sentences from the Chinese Treebank 9.0, thus addressing severe issues in CLiMP’s data generation process. We test 18 publicly available pretrained monolingual (e.g., BERT-base-zh, CPM) and multi-lingual (e.g., mT5, XLM) language models on SLING. Our experiments show that the average accuracy for LMs is far below human performance (69.7% vs. 97.1%), while BERT-base-zh achieves the highest accuracy (84.8%) of all tested LMs, even much larger ones. Additionally, we find that most LMs have a strong gender and number (singular/plural) bias, and they perform better on local phenomena than hierarchical ones.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.305.pdf"
    },
    {
        "title": "Retrieval-Augmented Generative Question Answering for Event Argument Extraction",
        "authors": [
            "Xinya Du",
            "Heng Ji"
        ],
        "published": "2022",
        "summary": "Event argument extraction has long been studied as a sequential prediction problem with extractive-based methods, tackling each argument in isolation. Although recent work proposes generation-based methods to capture cross-argument dependency, they require generating and post-processing a complicated target sequence (template). Motivated by these observations and recent pretrained language models’ capabilities of learning from demonstrations. We propose a retrieval-augmented generative QA model (R-GQA) for event argument extraction. It retrieves the most similar QA pair and augments it as prompt to the current example’s context, then decodes the arguments as answers. Our approach outperforms substantially prior methods across various settings (i.e. fully supervised, domain transfer, and fewshot learning). Finally, we propose a clustering-based sampling strategy (JointEnc) and conduct a thorough analysis of how different strategies influence the few-shot learning performances.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.307.pdf"
    },
    {
        "title": "MetaLogic: Logical Reasoning Explanations with Fine-Grained Structure",
        "authors": [
            "Yinya Huang",
            "Hongming Zhang",
            "Ruixin Hong",
            "Xiaodan Liang",
            "Changshui Zhang",
            "Dong Yu"
        ],
        "published": "2022",
        "summary": "In this paper, we propose a comprehensive benchmark to investigate models’ logical reasoning capabilities in complex real-life scenarios. Current explanation datasets often employ synthetic data with simple reasoning structures. Therefore, it cannot express more complex reasoning processes, such as the rebuttal to a reasoning step and the degree of certainty of the evidence. To this end, we propose a comprehensive logical reasoning explanation form. Based on the multi-hop chain of reasoning, the explanation form includes three main components: (1) The condition of rebuttal that the reasoning node can be challenged; (2) Logical formulae that uncover the internal texture of reasoning nodes; (3) Reasoning strength indicated by degrees of certainty. The fine-grained structure conforms to the real logical reasoning scenario, better fitting the human cognitive process but, simultaneously, is more challenging for the current models. We evaluate the current best models’ performance on this new explanation form. The experimental results show that generating reasoning graphs remains a challenging task for current models, even with the help of giant pre-trained language models.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.310.pdf"
    },
    {
        "title": "Towards Interactivity and Interpretability: A Rationale-based Legal Judgment Prediction Framework",
        "authors": [
            "Yiquan Wu",
            "Yifei Liu",
            "Weiming Lu",
            "Yating Zhang",
            "Jun Feng",
            "Changlong Sun",
            "Fei Wu",
            "Kun Kuang"
        ],
        "published": "2022",
        "summary": "Legal judgment prediction (LJP) is a fundamental task in legal AI, which aims to assist the judge to hear the case and determine the judgment. The legal judgment usually consists of the law article, charge, and term of penalty. In the real trial scenario, the judge usually makes the decision step-by-step: first concludes the rationale according to the case’s facts and then determines the judgment. Recently, many models have been proposed and made tremendous progress in LJP, but most of them adopt an end-to-end manner that cannot be manually intervened by the judge for practical use. Moreover, existing models lack interpretability due to the neglect of rationale in the prediction process. Following the judge’s real trial logic, in this paper, we propose a novel Rationale-based Legal Judgment Prediction (RLJP) framework. In the RLJP framework, the LJP process is split into two steps. In the first phase, the model generates the rationales according to the fact description. Then it predicts the judgment based on the fact and the generated rationales. Extensive experiments on a real-world dataset show RLJP achieves the best results compared to the state-of-the-art models. Meanwhile, the proposed framework provides good interactivity and interpretability which enables practical use.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.316.pdf"
    },
    {
        "title": "Self-supervised Graph Masking Pre-training for Graph-to-Text Generation",
        "authors": [
            "Jiuzhou Han",
            "Ehsan Shareghi"
        ],
        "published": "2022",
        "summary": "Large-scale pre-trained language models (PLMs) have advanced Graph-to-Text (G2T) generation by processing the linearised version of a graph. However, the linearisation is known to ignore the structural information. Additionally, PLMs are typically pre-trained on free text which introduces domain mismatch between pre-training and downstream G2T generation tasks. To address these shortcomings, we propose graph masking pre-training strategies that neither require supervision signals nor adjust the architecture of the underlying pre-trained encoder-decoder model. When used with a pre-trained T5, our approach achieves new state-of-the-art results on WebNLG+2020 and EventNarrative G2T generation datasets. Our method also shows to be very effective in the low-resource setting.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.321.pdf"
    },
    {
        "title": "Improving Stability of Fine-Tuning Pretrained Language Models via Component-Wise Gradient Norm Clipping",
        "authors": [
            "Chenghao Yang",
            "Xuezhe Ma"
        ],
        "published": "2022",
        "summary": "Fine-tuning over large pretrained language models (PLMs) has established many state-of-the-art results. Despite its superior performance, such fine-tuning can be unstable, resulting in significant variance in performance and potential risks for practical applications. Previous works have attributed such instability to the catastrophic forgetting problem in the top layers of PLMs, which indicates iteratively fine-tuning layers in a top-down manner is a promising solution. In this paper, we first point out that this method does not always work out due to the different convergence speeds of different layers/modules. Inspired by this observation, we propose a simple component-wise gradient norm clipping method to adjust the convergence speed for different components. Experiment results demonstrate that our method achieves consistent improvements in terms of generalization performance, convergence speed, and training stability. The codebase can be found at https://github.com/yangalan123/FineTuningStability.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.322.pdf"
    },
    {
        "title": "Differentially Private Language Models for Secure Data Sharing",
        "authors": [
            "Justus Mattern",
            "Zhijing Jin",
            "Benjamin Weggenmann",
            "Bernhard Schoelkopf",
            "Mrinmaya Sachan"
        ],
        "published": "2022",
        "summary": "To protect the privacy of individuals whose data is being shared, it is of high importance to develop methods allowing researchers and companies to release textual data while providing formal privacy guarantees to its originators. In the field of NLP, substantial efforts have been directed at building mechanisms following the framework of local differential privacy, thereby anonymizing individual text samples before releasing them. In practice, these approaches are often dissatisfying in terms of the quality of their output language due to the strong noise required for local differential privacy. In this paper, we approach the problem at hand using global differential privacy, particularly by training a generative language model in a differentially private manner and consequently sampling data from it. Using natural language prompts and a new prompt-mismatch loss, we are able to create highly accurate and fluent textual datasets taking on specific desired attributes such as sentiment or topic and resembling statistical properties of the training data. We perform thorough experiments indicating that our synthetic datasets do not leak information from our original data and are of high language quality and highly suitable for training models for further analysis on real-world data. Notably, we also demonstrate that training classifiers on private synthetic data outperforms directly training classifiers with DP-SGD.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.323.pdf"
    },
    {
        "title": "Conditional set generation using Seq2seq models",
        "authors": [
            "Aman Madaan",
            "Dheeraj Rajagopal",
            "Niket Tandon",
            "Yiming Yang",
            "Antoine Bosselut"
        ],
        "published": "2022",
        "summary": "Conditional set generation learns a mapping from an input sequence of tokens to a set. Several NLP tasks, such as entity typing and dialogue emotion tagging, are instances of set generation. Seq2Seq models are a popular choice to model set generation but they treat a set as a sequence and do not fully leverage its key properties, namely order-invariance and cardinality. We propose a novel algorithm for effectively sampling informative orders over the combinatorial space of label orders. Further, we jointly model the set cardinality and output by listing the set size as the first element and taking advantage of the autoregressive factorization used by Seq2Seq models. Our method is a model-independent data augmentation approach that endows any Seq2Seq model with the signals of order-invariance and cardinality. Training a Seq2Seq model on this new augmented data (without any additional annotations), gets an average relative improvement of 20% for four benchmarks datasets across models spanning from BART-base, T5-11B, and GPT-3. We will release all code and data upon acceptance.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.324.pdf"
    },
    {
        "title": "Learning Semantic Textual Similarity via Topic-informed Discrete Latent Variables",
        "authors": [
            "Erxin Yu",
            "Lan Du",
            "Yuan Jin",
            "Zhepei Wei",
            "Yi Chang"
        ],
        "published": "2022",
        "summary": "Recently, discrete latent variable models have received a surge of interest in both Natural Language Processing (NLP) and Computer Vision (CV), attributed to their comparable performance to the continuous counterparts in representation learning, while being more interpretable in their predictions. In this paper, we develop a topic-informed discrete latent variable model for semantic textual similarity, which learns a shared latent space for sentence-pair representation via vector quantization. Compared with previous models limited to local semantic contexts, our model can explore richer semantic information via topic modeling. We further boost the performance of semantic similarity by injecting the quantized representation into a transformer-based language model with a well-designed semantic-driven attention mechanism. We demonstrate, through extensive experiments across various English language datasets, that our model is able to surpass several strong neural baselines in semantic textual similarity tasks.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.328.pdf"
    },
    {
        "title": "STRUDEL: Structured Dialogue Summarization for Dialogue Comprehension",
        "authors": [
            "Borui Wang",
            "Chengcheng Feng",
            "Arjun Nair",
            "Madelyn Mao",
            "Jai Desai",
            "Asli Celikyilmaz",
            "Haoran Li",
            "Yashar Mehdad",
            "Dragomir Radev"
        ],
        "published": "2022",
        "summary": "Abstractive dialogue summarization has long been viewed as an important standalone task in natural language processing, but no previous work has explored the possibility of whether abstractive dialogue summarization can also be used as a means to boost an NLP system’s performance on other important dialogue comprehension tasks. In this paper, we propose a novel type of dialogue summarization task - STRUctured DiaLoguE Summarization (STRUDEL) - that can help pre-trained language models to better understand dialogues and improve their performance on important dialogue comprehension tasks. In contrast to the holistic approach taken by the traditional free-form abstractive summarization task for dialogues, STRUDEL aims to decompose and imitate the hierarchical, systematic and structured mental process that we human beings usually go through when understanding and analyzing dialogues, and thus has the advantage of being more focused, specific and instructive for dialogue comprehension models to learn from. We further introduce a new STRUDEL dialogue comprehension modeling framework that integrates STRUDEL into a dialogue reasoning module over transformer encoder language models to improve their dialogue comprehension ability. In our empirical experiments on two important downstream dialogue comprehension tasks - dialogue question answering and dialogue response prediction - we demonstrate that our STRUDEL dialogue comprehension models can significantly improve the dialogue comprehension performance of transformer encoder language models.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.329.pdf"
    },
    {
        "title": "PASTA: Table-Operations Aware Fact Verification via Sentence-Table Cloze Pre-training",
        "authors": [
            "Zihui Gu",
            "Ju Fan",
            "Nan Tang",
            "Preslav Nakov",
            "Xiaoman Zhao",
            "Xiaoyong Du"
        ],
        "published": "2022",
        "summary": "Fact verification has attracted a lot of attention recently, e.g., in journalism, marketing, and policymaking, as misinformation and dis- information can sway one’s opinion and affect one’s actions. While fact-checking is a hard task in general, in many cases, false statements can be easily debunked based on analytics over tables with reliable information. Hence, table- based fact verification has recently emerged as an important and growing research area. Yet, progress has been limited due to the lack of datasets that can be used to pre-train language models (LMs) to be aware of common table operations, such as aggregating a column or comparing tuples. To bridge this gap, this paper introduces PASTA for table-based fact verification via pre-training with synthesized sentence–table cloze questions. In particular, we design six types of common sentence–table cloze tasks, including Filter, Aggregation, Superlative, Comparative, Ordinal, and Unique, based on which we synthesize a large corpus consisting of 1.2 million sentence–table pairs from WikiTables. PASTA uses a recent pre-trained LM, DeBERTaV3, and further pre- trains it on our corpus. Our experimental results show that PASTA achieves new state-of-the-art (SOTA) performance on two table-based fact verification datasets TabFact and SEM-TAB- FACTS. In particular, on the complex set of TabFact, which contains multiple operations, PASTA largely outperforms previous SOTA by 4.7% (85.6% vs. 80.9%), and the gap between PASTA and human performance on the small test set is narrowed to just 1.5% (90.6% vs. 92.1%).",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.331.pdf"
    },
    {
        "title": "Sentiment-Aware Word and Sentence Level Pre-training for Sentiment Analysis",
        "authors": [
            "Shuai Fan",
            "Chen Lin",
            "Haonan Li",
            "Zhenghao Lin",
            "Jinsong Su",
            "Hang Zhang",
            "Yeyun Gong",
            "JIan Guo",
            "Nan Duan"
        ],
        "published": "2022",
        "summary": "Most existing pre-trained language representation models (PLMs) are sub-optimal in sentiment analysis tasks, as they capture the sentiment information from word-level while under-considering sentence-level information. In this paper, we propose SentiWSP, a novel Sentiment-aware pre-trained language model with combined Word-level and Sentence-level Pre-training tasks.The word level pre-training task detects replaced sentiment words, via a generator-discriminator framework, to enhance the PLM’s knowledge about sentiment words.The sentence level pre-training task further strengthens the discriminator via a contrastive learning framework, with similar sentences as negative samples, to encode sentiments in a sentence.Extensive experimental results show that SentiWSP achieves new state-of-the-art performance on various sentence-level and aspect-level sentiment classification benchmarks. We have made our code and model publicly available at https://github.com/XMUDM/SentiWSP.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.332.pdf"
    },
    {
        "title": "COPEN: Probing Conceptual Knowledge in Pre-trained Language Models",
        "authors": [
            "Hao Peng",
            "Xiaozhi Wang",
            "Shengding Hu",
            "Hailong Jin",
            "Lei Hou",
            "Juanzi Li",
            "Zhiyuan Liu",
            "Qun Liu"
        ],
        "published": "2022",
        "summary": "Conceptual knowledge is fundamental to human cognition and knowledge bases. However, existing knowledge probing works only focus on evaluating factual knowledge of pre-trained language models (PLMs) and ignore conceptual knowledge. Since conceptual knowledge often appears as implicit commonsense behind texts, designing probes for conceptual knowledge is hard. Inspired by knowledge representation schemata, we comprehensively evaluate conceptual knowledge of PLMs by designing three tasks to probe whether PLMs organize entities by conceptual similarities, learn conceptual properties, and conceptualize entities in contexts, respectively. For the tasks, we collect and annotate 24k data instances covering 393 concepts, which is COPEN, a COnceptual knowledge Probing bENchmark. Extensive experiments on different sizes and types of PLMs show that existing PLMs systematically lack conceptual knowledge and suffer from various spurious correlations. We believe this is a critical bottleneck for realizing human-like cognition in PLMs. COPEN and our codes are publicly released at https://github.com/THU-KEG/COPEN.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.335.pdf"
    },
    {
        "title": "Capturing Global Structural Information in Long Document Question Answering with Compressive Graph Selector Network",
        "authors": [
            "Yuxiang Nie",
            "Heyan Huang",
            "Wei Wei",
            "Xian-Ling Mao"
        ],
        "published": "2022",
        "summary": "Long document question answering is a challenging task due to its demands for complex reasoning over long text. Previous works usually take long documents as non-structured flat texts or only consider the local structure in long documents. However, these methods usually ignore the global structure of the long document, which is essential for long-range understanding. To tackle this problem, we propose Compressive Graph Selector Network (CGSN) to capture the global structure in a compressive and iterative manner. The proposed model mainly focuses on the evidence selection phase of long document question answering. Specifically, it consists of three modules: local graph network, global graph network and evidence memory network. Firstly, the local graph network builds the graph structure of the chunked segment in token, sentence, paragraph and segment levels to capture the short-term dependency of the text. Secondly, the global graph network selectively receives the information of each level from the local graph, compresses them into the global graph nodes and applies graph attention to the global graph nodes to build the long-range reasoning over the entire text in an iterative way. Thirdly, the evidence memory network is designed to alleviate the redundancy problem in the evidence selection by saving the selected result in the previous steps. Extensive experiments show that the proposed model outperforms previous methods on two datasets.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.336.pdf"
    },
    {
        "title": "MetaFill: Text Infilling for Meta-Path Generation on Heterogeneous Information Networks",
        "authors": [
            "Zequn Liu",
            "Kefei Duan",
            "Junwei Yang",
            "Hanwen Xu",
            "Ming Zhang",
            "Sheng Wang"
        ],
        "published": "2022",
        "summary": "Heterogeneous information network (HIN) is essential to study complicated networks containing multiple edge types and node types. Meta-path, a sequence of node types and edge types, is the core technique to embed HINs. Since manually curating meta-paths is time-consuming, there is a pressing need to develop automated meta-path generation approaches. Existing meta-path generation approaches cannot fully exploit the rich textual information in HINs, such as node names and edge type names. To address this problem, we propose MetaFill, a text-infilling-based approach for meta-path generation. The key idea of MetaFill is to formulate meta-path identification problem as a word sequence infilling problem, which can be advanced by pretrained language models (PLMs). We observed the superior performance of MetaFill against existing meta-path generation methods and graph embedding methods that do not leverage meta-paths in both link prediction and node classification on two real-world HIN datasets. We further demonstrated how MetaFill can accurately classify edges in the zero-shot setting, where existing approaches cannot generate any meta-paths. MetaFill exploits PLMs to generate meta-paths for graph embedding, opening up new avenues for language model applications in graph analysis.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.341.pdf"
    },
    {
        "title": "DRLK: Dynamic Hierarchical Reasoning with Language Model and Knowledge Graph for Question Answering",
        "authors": [
            "Miao Zhang",
            "Rufeng Dai",
            "Ming Dong",
            "Tingting He"
        ],
        "published": "2022",
        "summary": "In recent years, Graph Neural Network (GNN) approaches with enhanced knowledge graphs (KG) perform well in question answering (QA) tasks. One critical challenge is how to effectively utilize interactions between the QA context and KG. However, existing work only adopts the identical QA context representation to interact with multiple layers of KG, which results in a restricted interaction. In this paper, we propose DRLK (Dynamic Hierarchical Reasoning with Language Model and Knowledge Graphs), a novel model that utilizes dynamic hierarchical interactions between the QA context and KG for reasoning. DRLK extracts dynamic hierarchical features in the QA context, and performs inter-layer and intra-layer interactions on each iteration, allowing the KG representation to be grounded with the hierarchical features of the QA context. We conduct extensive experiments on four benchmark datasets in medical QA and commonsense reasoning. The experimental results demonstrate that DRLK achieves state-of-the-art performances on two benchmark datasets and performs competitively on the others.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.342.pdf"
    },
    {
        "title": "Wider & Closer: Mixture of Short-channel Distillers for Zero-shot Cross-lingual Named Entity Recognition",
        "authors": [
            "Jun-Yu Ma",
            "Beiduo Chen",
            "Jia-Chen Gu",
            "Zhenhua Ling",
            "Wu Guo",
            "Quan Liu",
            "Zhigang Chen",
            "Cong Liu"
        ],
        "published": "2022",
        "summary": "Zero-shot cross-lingual named entity recognition (NER) aims at transferring knowledge from annotated and rich-resource data in source languages to unlabeled and lean-resource data in target languages. Existing mainstream methods based on the teacher-student distillation framework ignore the rich and complementary information lying in the intermediate layers of pre-trained language models, and domain-invariant information is easily lost during transfer. In this study, a mixture of short-channel distillers (MSD) method is proposed to fully interact the rich hierarchical information in the teacher model and to transfer knowledge to the student model sufficiently and efficiently. Concretely, a multi-channel distillation framework is designed for sufficient information transfer by aggregating multiple distillers as a mixture. Besides, an unsupervised method adopting parallel domain adaptation is proposed to shorten the channels between the teacher and student models to preserve domain-invariant features. Experiments on four datasets across nine languages demonstrate that the proposed method achieves new state-of-the-art performance on zero-shot cross-lingual NER and shows great generalization and compatibility across languages and fields.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.345.pdf"
    },
    {
        "title": "RuCoLA: Russian Corpus of Linguistic Acceptability",
        "authors": [
            "Vladislav Mikhailov",
            "Tatiana Shamardina",
            "Max Ryabinin",
            "Alena Pestova",
            "Ivan Smurov",
            "Ekaterina Artemova"
        ],
        "published": "2022",
        "summary": "Linguistic acceptability (LA) attracts the attention of the research community due to its many uses, such as testing the grammatical knowledge of language models and filtering implausible texts with acceptability classifiers.However, the application scope of LA in languages other than English is limited due to the lack of high-quality resources.To this end, we introduce the Russian Corpus of Linguistic Acceptability (RuCoLA), built from the ground up under the well-established binary LA approach. RuCoLA consists of 9.8k in-domain sentences from linguistic publications and 3.6k out-of-domain sentences produced by generative models. The out-of-domain set is created to facilitate the practical use of acceptability for improving language generation.Our paper describes the data collection protocol and presents a fine-grained analysis of acceptability classification experiments with a range of baseline approaches.In particular, we demonstrate that the most widely used language models still fall behind humans by a large margin, especially when detecting morphological and semantic errors. We release RuCoLA, the code of experiments, and a public leaderboard to assess the linguistic competence of language models for Russian.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.348.pdf"
    },
    {
        "title": "Should We Ban English NLP for a Year?",
        "authors": [
            "Anders Søgaard"
        ],
        "published": "2022",
        "summary": "Around two thirds of NLP research at top venues is devoted exclusively to developing technology for speakers of English, most speech data comes from young urban speakers, and most texts used to train language models come from male writers. These biases feed into consumer technologies to widen existing inequality gaps, not only within, but also across, societies. Many have argued that it is almost impossible to mitigate inequality amplification. I argue that, on the contrary, it is quite simple to do so, and that counter-measures would have little-to-no negative impact, except for, perhaps, in the very short term.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.351.pdf"
    },
    {
        "title": "LittleBird: Efficient Faster & Longer Transformer for Question Answering",
        "authors": [
            "Minchul Lee",
            "Kijong Han",
            "Myeong Cheol Shin"
        ],
        "published": "2022",
        "summary": "BERT has shown a lot of sucess in a wide variety of NLP tasks. But it has a limitation dealing with long inputs due to its attention mechanism. Longformer, ETC and BigBird addressed this issue and effectively solved the quadratic dependency problem.However we find that these models are not sufficient, and propose LittleBird, a novel model based on BigBird with improved speed and memory footprint while maintaining accuracy.In particular, we devise a more flexible and efficient position representation method based on Attention with Linear Biases(ALiBi). We also show that replacing the method of global information represented in the BigBird with pack and unpack attention is more effective.The proposed model can work on long inputs even after being pre-trained on short inputs, and can be trained efficiently reusing existing pre-trained language model for short inputs. This is a significant benefit for low-resource languages where large amounts of long text data are difficult to obtain.As a result, our experiments show that LittleBird works very well in a variety of languages, achieving high performance in question answering tasks, particularly in KorQuAD2.0, Korean Question Answering Dataset for long paragraphs.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.352.pdf"
    },
    {
        "title": "Explainable Question Answering based on Semantic Graph by Global Differentiable Learning and Dynamic Adaptive Reasoning",
        "authors": [
            "Jianguo Mao",
            "Wenbin Jiang",
            "Xiangdong Wang",
            "Hong Liu",
            "Yu Xia",
            "Yajuan Lyu",
            "QiaoQiao She"
        ],
        "published": "2022",
        "summary": "Multi-hop Question Answering is an agent task for testing the reasoning ability. With the development of pre-trained models, the implicit reasoning ability has been surprisingly improved and can even surpass human performance. However, the nature of the black box hinders the construction of explainable intelligent systems. Several researchers have explored explainable neural-symbolic reasoning methods based on question decomposition techniques. The undifferentiable symbolic operations and the error propagation in the reasoning process lead to poor performance. To alleviate it, we propose a simple yet effective Global Differentiable Learning strategy to explore optimal reasoning paths from the latent probability space so that the model learns to solve intermediate reasoning processes without expert annotations. We further design a Dynamic Adaptive Reasoner to enhance the generalization of unseen questions. Our method achieves 17% improvements in F1-score against BreakRC and shows better interpretability. We take a step forward in building interpretable reasoning methods.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.356.pdf"
    },
    {
        "title": "An Anchor-based Relative Position Embedding Method for Cross-Modal Tasks",
        "authors": [
            "Ya Wang",
            "Xingwu Sun",
            "Lian Fengzong",
            "ZhanHui Kang",
            "Chengzhong Xu Xu"
        ],
        "published": "2022",
        "summary": "Position Embedding (PE) is essential for transformer to capture the sequence ordering of input tokens. Despite its general effectiveness verified in Natural Language Processing (NLP) and Computer Vision (CV), its application in cross-modal tasks remains unexplored and suffers from two challenges: 1) the input text tokens and image patches are not aligned, 2) the encoding space of each modality is different, making it unavailable for feature comparison. In this paper, we propose a unified position embedding method for these problems, called AnChor-basEd Relative Position Embedding (ACE-RPE), in which we first introduce an anchor locating mechanism to bridge the semantic gap and locate anchors from different modalities. Then we conduct the distance calculation of each text token and image patch by computing their shortest paths from the located anchors. Last, we embed the anchor-based distance to guide the computation of cross-attention. In this way, it calculates cross-modal relative position embedding for cross-modal transformer. Benefiting from ACE-RPE, our method obtains new SOTA results on a wide range of benchmarks, such as Image-Text Retrieval on MS-COCO and Flickr30K, Visual Entailment on SNLI-VE, Visual Reasoning on NLVR2 and Weakly-supervised Visual Grounding on RefCOCO+.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.362.pdf"
    },
    {
        "title": "Rethinking Style Transformer with Energy-based Interpretation: Adversarial Unsupervised Style Transfer using a Pretrained Model",
        "authors": [
            "Hojun Cho",
            "Dohee Kim",
            "Seungwoo Ryu",
            "ChaeHun Park",
            "Hyungjong Noh",
            "Jeong-in Hwang",
            "Minseok Choi",
            "Edward Choi",
            "Jaegul Choo"
        ],
        "published": "2022",
        "summary": "Style control, content preservation, and fluency determine the quality of text style transfer models. To train on a nonparallel corpus, several existing approaches aim to deceive the style discriminator with an adversarial loss. However, adversarial training significantly degrades fluency compared to the other two metrics. In this work, we explain this phenomenon using energy-based interpretation, and leverage a pretrained language model to improve fluency. Specifically, we propose a novel approach which applies the pretrained language model to the text style transfer framework by restructuring the discriminator and the model itself, allowing the generator and the discriminator to also take advantage of the power of the pretrained model. We evaluated our model on three public benchmarks GYAFC, Amazon, and Yelp and achieved state-of-the-art performance on the overall metrics.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.366.pdf"
    },
    {
        "title": "Tiny-NewsRec: Effective and Efficient PLM-based News Recommendation",
        "authors": [
            "Yang Yu",
            "Fangzhao Wu",
            "Chuhan Wu",
            "Jingwei Yi",
            "Qi Liu"
        ],
        "published": "2022",
        "summary": "News recommendation is a widely adopted technique to provide personalized news feeds for the user. Recently, pre-trained language models (PLMs) have demonstrated the great capability of natural language understanding and benefited news recommendation via improving news modeling. However, most existing works simply finetune the PLM with the news recommendation task, which may suffer from the known domain shift problem between the pre-training corpus and downstream news texts. Moreover, PLMs usually contain a large volume of parameters and have high computational overhead, which imposes a great burden on low-latency online services. In this paper, we propose Tiny-NewsRec, which can improve both the effectiveness and the efficiency of PLM-based news recommendation. We first design a self-supervised domain-specific post-training method to better adapt the general PLM to the news domain with a contrastive matching task between news titles and news bodies. We further propose a two-stage knowledge distillation method to improve the efficiency of the large PLM-based news recommendation model while maintaining its performance. Multiple teacher models originated from different time steps of our post-training procedure are used to transfer comprehensive knowledge to the student model in both its post-training stage and finetuning stage. Extensive experiments on two real-world datasets validate the effectiveness and efficiency of our method.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.368.pdf"
    },
    {
        "title": "PLOG: Table-to-Logic Pretraining for Logical Table-to-Text Generation",
        "authors": [
            "Ao Liu",
            "Haoyu Dong",
            "Naoaki Okazaki",
            "Shi Han",
            "Dongmei Zhang"
        ],
        "published": "2022",
        "summary": "Logical table-to-text generation is a task that involves generating logically faithful sentences from tables, which requires models to derive logical-level facts from table records via logical inference. It raises a new challenge on the logical-level content planning of table-to-text models. However, directly learning the logical inference knowledge from table-text pairs is very difficult for neural models because of the ambiguity of natural language and the scarcity of parallel data. Hence even large-scale pre-trained language models present low logical fidelity on logical table-to-text. In this work, we propose a Pretrained Logical Form Generator (PLOG) framework to improve generation fidelity. Specifically, PLOG is first pretrained on a table-to-logical-form generation (table-to-logic) task, then finetuned on downstream table-to-text tasks. The logical forms are formally defined with unambiguous semantics. Hence we can collect a large amount of accurate logical forms from tables without human annotation. In addition, PLOG can learn logical inference from table-logic pairs much more reliably than from table-text pairs. To evaluate our model, we further collect a controlled logical table-to-text dataset CONTLOG based on an existing dataset. On two benchmarks, LOGICNLG and CONTLOG, PLOG outperforms strong baselines by a large margin on the logical fidelity, demonstrating the effectiveness of table-to-logic pretraining.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.373.pdf"
    },
    {
        "title": "MuRAG: Multimodal Retrieval-Augmented Generator for Open Question Answering over Images and Text",
        "authors": [
            "Wenhu Chen",
            "Hexiang Hu",
            "Xi Chen",
            "Pat Verga",
            "William Cohen"
        ],
        "published": "2022",
        "summary": "While language Models store a massive amount of world knowledge implicitly in their parameters, even very large models often fail to encode information about rare entities and events, while incurring huge computational costs. Recently, retrieval-augmented models, such as REALM, RAG, and RETRO, have incorporated world knowledge into language generation by leveraging an external non-parametric index and have demonstrated impressive performance with constrained model sizes. However, these methods are restricted to retrieving only textual knowledge, neglecting the ubiquitous amount of knowledge in other modalities like images – much of which contains information not covered by any text. To address this limitation, we propose the first Multimodal Retrieval-Augmented Transformer (MuRAG), which accesses an external non-parametric multimodal memory to augment language generation. MuRAG is pre-trained with a mixture of large-scale image-text and text-only corpora using a joint contrastive and generative loss. We perform experiments on two different datasets that require retrieving and reasoning over both images and text to answer a given query: WebQA, and MultimodalQA. Our results show that MuRAG achieves state-of-the-art accuracy, outperforming existing models by 10-20% absolute on both datasets and under both distractor and full-wiki settings.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.375.pdf"
    },
    {
        "title": "PHEE: A Dataset for Pharmacovigilance Event Extraction from Text",
        "authors": [
            "Zhaoyue Sun",
            "Jiazheng Li",
            "Gabriele Pergola",
            "Byron Wallace",
            "Bino John",
            "Nigel Greene",
            "Joseph Kim",
            "Yulan He"
        ],
        "published": "2022",
        "summary": "The primary goal of drug safety researchers and regulators is to promptly identify adverse drug reactions. Doing so may in turn prevent or reduce the harm to patients and ultimately improve public health. Evaluating and monitoring drug safety (i.e., pharmacovigilance) involves analyzing an ever growing collection of spontaneous reports from health professionals, physicians, and pharmacists, and information voluntarily submitted by patients. In this scenario, facilitating analysis of such reports via automation has the potential to rapidly identify safety signals. Unfortunately, public resources for developing natural language models for this task are scant. We present PHEE, a novel dataset for pharmacovigilance comprising over 5000 annotated events from medical case reports and biomedical literature, making it the largest such public dataset to date. We describe the hierarchical event schema designed to provide coarse and fine-grained information about patients’ demographics, treatments and (side) effects. Along with the discussion of the dataset, we present a thorough experimental evaluation of current state-of-the-art approaches for biomedical event extraction, point out their limitations, and highlight open challenges to foster future research in this area.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.376.pdf"
    },
    {
        "title": "Discovering Low-rank Subspaces for Language-agnostic Multilingual Representations",
        "authors": [
            "Zhihui Xie",
            "Handong Zhao",
            "Tong Yu",
            "Shuai Li"
        ],
        "published": "2022",
        "summary": "Large pretrained multilingual language models (ML-LMs) have shown remarkable capabilities of zero-shot cross-lingual transfer, without direct cross-lingual supervision. While these results are promising, follow-up works found that, within the multilingual embedding spaces, there exists strong language identity information which hinders the expression of linguistic factors shared across languages. For semantic tasks like cross-lingual sentence retrieval, it is desired to remove such language identity signals to fully leverage semantic information. In this work, we provide a novel view of projecting away language-specific factors from a multilingual embedding space. Specifically, we discover that there exists a low-rank subspace that primarily encodes information irrelevant to semantics (e.g., syntactic information). To identify this subspace, we present a simple but effective unsupervised method based on singular value decomposition with multiple monolingual corpora as input. Once the subspace is found, we can directly project the original embeddings into the null space to boost language agnosticism without finetuning. We systematically evaluate our method on various tasks including the challenging language-agnostic QA retrieval task. Empirical results show that applying our method consistently leads to improvements over commonly used ML-LMs.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.379.pdf"
    },
    {
        "title": "Training Language Models with Memory Augmentation",
        "authors": [
            "Zexuan Zhong",
            "Tao Lei",
            "Danqi Chen"
        ],
        "published": "2022",
        "summary": "Recent work has improved language models (LMs) remarkably by equipping them with a non-parametric memory component. However, most existing approaches only introduce mem-ories at testing time or represent them using a separately trained encoder, resulting in suboptimal training of the language model. In this work, we present TRIME, a novel yet simple training approach designed for training LMs with memory augmentation. Our approach uses a training objective that directly takes in-batch examples as accessible memory. We also present new methods for memory construction and data batching, which are used for adapting to different sets of memories—local, long-term, and external memory—at testing time. We evaluate TRIME on multiple language modeling and machine translation benchmarks and show that it is able to achieve significant improvements across all the settings. Concretely, TRIME reduces the perplexity from 18.70 to 15.37 on WIKITEXT-103, by effectively leveraging a large memory set from the training corpus. Compared to standard LM training, TRIME adds negligible computational overhead and is compatible with different neural architectures, making it a versatile solution for training memory-augmented LMs.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.382.pdf"
    },
    {
        "title": "Dimension Reduction for Efficient Dense Retrieval via Conditional Autoencoder",
        "authors": [
            "Zhenghao Liu",
            "Han Zhang",
            "Chenyan Xiong",
            "Zhiyuan Liu",
            "Yu Gu",
            "Xiaohua Li"
        ],
        "published": "2022",
        "summary": "Dense retrievers encode queries and documents and map them in an embedding space using pre-trained language models. These embeddings need to be high-dimensional to fit training signals and guarantee the retrieval effectiveness of dense retrievers. However, these high-dimensional embeddings lead to larger index storage and higher retrieval latency. To reduce the embedding dimensions of dense retrieval, this paper proposes a Conditional Autoencoder (ConAE) to compress the high-dimensional embeddings to maintain the same embedding distribution and better recover the ranking features. Our experiments show that ConAE is effective in compressing embeddings by achieving comparable ranking performance with its teacher model and making the retrieval system more efficient. Our further analyses show that ConAE can alleviate the redundancy of the embeddings of dense retrieval with only one linear layer. All codes of this work are available at https://github.com/NEUIR/ConAE.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.384.pdf"
    },
    {
        "title": "Invariant Language Modeling",
        "authors": [
            "Maxime Peyrard",
            "Sarvjeet Ghotra",
            "Martin Josifoski",
            "Vidhan Agarwal",
            "Barun Patra",
            "Dean Carignan",
            "Emre Kiciman",
            "Saurabh Tiwary",
            "Robert West"
        ],
        "published": "2022",
        "summary": "Modern pretrained language models are critical components of NLP pipelines. Yet, they suffer from spurious correlations, poor out-of-domain generalization, and biases.Inspired by recent progress in causal machine learning, in particular the invariant risk minimization (IRM) paradigm, we propose invariant language modeling, a framework for learning invariant representations that generalize better across multiple environments. In particular, we adapt a game-theoretic implementation of IRM (IRM-games) to language models, where the invariance emerges from a specific training schedule in which all the environments compete to optimize their own environment-specific loss by updating subsets of the model in a round-robin fashion.We focused on controlled experiments to precisely demonstrate the ability of our method to (i) remove structured noise, (ii) ignore specific spurious correlations without affecting global performance, and (iii) achieve better out-of-domain generalization.These benefits come with a negligible computational overhead compared to standard training, do not require changing the local loss, and can be applied to any language model. We believe this framework is promising to help mitigate spurious correlations and biases in language models.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.387.pdf"
    },
    {
        "title": "AdaMix: Mixture-of-Adaptations for Parameter-efficient Model Tuning",
        "authors": [
            "Yaqing Wang",
            "Sahaj Agarwal",
            "Subhabrata Mukherjee",
            "Xiaodong Liu",
            "Jing Gao",
            "Ahmed Hassan Awadallah",
            "Jianfeng Gao"
        ],
        "published": "2022",
        "summary": "Standard fine-tuning of large pre-trained language models (PLMs) for downstream tasks requires updating hundreds of millions to billions of parameters, and storing a large copy of the PLM weights for every task resulting in increased cost for storing, sharing and serving the models. To address this, parameter-efficient fine-tuning (PEFT) techniques were introduced where small trainable components are injected in the PLM and updated during fine-tuning. We propose AdaMix as a general PEFT method that tunes a mixture of adaptation modules – given the underlying PEFT method of choice – introduced in each Transformer layer while keeping most of the PLM weights frozen. For instance, AdaMix can leverage a mixture of adapters like Houlsby or a mixture of low rank decomposition matrices like LoRA to improve downstream task performance over the corresponding PEFT methods for fully supervised and few-shot NLU and NLG tasks. Further, we design AdaMix such that it matches the same computational cost and the number of tunable parameters as the underlying PEFT method. By only tuning 0.1-0.2% of PLM parameters, we show that AdaMix outperforms SOTA parameter-efficient fine-tuning and full model fine-tuning for both NLU and NLG tasks.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.388.pdf"
    },
    {
        "title": "BioReader: a Retrieval-Enhanced Text-to-Text Transformer for Biomedical Literature",
        "authors": [
            "Giacomo Frisoni",
            "Miki Mizutani",
            "Gianluca Moro",
            "Lorenzo Valgimigli"
        ],
        "published": "2022",
        "summary": "The latest batch of research has equipped language models with the ability to attend over relevant and factual information from non-parametric external sources, drawing a complementary path to architectural scaling. Besides mastering language, exploiting and contextualizing the latent world knowledge is crucial in complex domains like biomedicine. However, most works in the field rely on general-purpose models supported by databases like Wikipedia and Books. We introduce BioReader, the first retrieval-enhanced text-to-text model for biomedical natural language processing. Our domain-specific T5-based solution augments the input prompt by fetching and assembling relevant scientific literature chunks from a neural database with ≈60 million tokens centered on PubMed. We fine-tune and evaluate BioReader on a broad array of downstream tasks, significantly outperforming several state-of-the-art methods despite using up to 3x fewer parameters. In tandem with extensive ablation studies, we show that domain knowledge can be easily altered or supplemented to make the model generate correct predictions bypassing the retraining step and thus addressing the literature overload issue.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.390.pdf"
    },
    {
        "title": "LILA: A Unified Benchmark for Mathematical Reasoning",
        "authors": [
            "Swaroop Mishra",
            "Matthew Finlayson",
            "Pan Lu",
            "Leonard Tang",
            "Sean Welleck",
            "Chitta Baral",
            "Tanmay Rajpurohit",
            "Oyvind Tafjord",
            "Ashish Sabharwal",
            "Peter Clark",
            "Ashwin Kalyan"
        ],
        "published": "2022",
        "summary": "Mathematical reasoning skills are essential for general-purpose intelligentsystems to perform tasks from grocery shopping to climate modeling.Towards evaluating and improving AI systems in this domain, we proposeLILA, a unified mathematical reasoning benchmark consisting of 23 diversetasks along four dimensions:(i) mathematical abilities e.g., arithmetic, calculus (ii) language format e.g., question-answering, fill-in-the-blanks (iii) language diversity e.g., no language, simple language (iv) external knowledge e.g., commonsense, physics. We construct our benchmark by extending 20 datasets benchmark by collecting task instructions and solutions in the form of Python programs,thereby obtaining explainable solutions in addition to the correct answer.We additionally introduce two evaluation datasets to measure out-of-distribution performance and robustness to language perturbation.Finally, we introduce BHASKARA,a general-purpose mathematical reasoning model trained on LILA. Importantly, we find that multi-tasking leads to significant improvements (average relative improvement of 21.83% F1 score vs. single-task models),while the best performing model only obtains 60.40%,indicating the room for improvement in general mathematical reasoning and understanding.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.392.pdf"
    },
    {
        "title": "InforMask: Unsupervised Informative Masking for Language Model Pretraining",
        "authors": [
            "Nafis Sadeq",
            "Canwen Xu",
            "Julian McAuley"
        ],
        "published": "2022",
        "summary": "Masked language modeling is widely used for pretraining large language models for natural language understanding (NLU). However, random masking is suboptimal, allocating an equal masking rate for all tokens. In this paper, we propose InforMask, a new unsupervised masking strategy for training masked language models. InforMask exploits Pointwise Mutual Information (PMI) to select the most informative tokens to mask. We further propose two optimizations for InforMask to improve its efficiency. With a one-off preprocessing step, InforMask outperforms random masking and previously proposed masking strategies on the factual recall benchmark LAMA and the question answering benchmark SQuAD v1 and v2.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.395.pdf"
    },
    {
        "title": "A Framework for Adapting Pre-Trained Language Models to Knowledge Graph Completion",
        "authors": [
            "Justin Lovelace",
            "Carolyn Rosé"
        ],
        "published": "2022",
        "summary": "Recent work has demonstrated that entity representations can be extracted from pre-trained language models to develop knowledge graph completion models that are more robust to the naturally occurring sparsity found in knowledge graphs. In this work, we conduct a comprehensive exploration of how to best extract and incorporate those embeddings into knowledge graph completion models. We explore the suitability of the extracted embeddings for direct use in entity ranking and introduce both unsupervised and supervised processing methods that can lead to improved downstream performance. We then introduce supervised embedding extraction methods that can extract more informative representations. We then synthesize our findings and develop a knowledge graph completion model that significantly outperforms recent neural models.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.398.pdf"
    },
    {
        "title": "Mutual Information Alleviates Hallucinations in Abstractive Summarization",
        "authors": [
            "Liam van der Poel",
            "Ryan Cotterell",
            "Clara Meister"
        ],
        "published": "2022",
        "summary": "Despite significant progress in the quality of language generated from abstractive summarization models, these models still exhibit the tendency to hallucinate, i.e., output content not supported by the source document. A number of works have tried to fix—or at least uncover the source of—the problem with limited success. In this paper, we identify a simple criterion under which models are significantly more likely to assign more probability to hallucinated content during generation: high model uncertainty. This finding offers a potential explanation for hallucinations: models default to favoring text with high marginal probability, i.e., high-frequency occurrences in the training set, when uncertain about a continuation. It also motivates possible routes for real-time intervention during decoding to prevent such hallucinations. We propose a decoding strategy that switches to optimizing for pointwise mutual information of the source and target token—rather than purely the probability of the target token—when the model exhibits uncertainty. Experiments on the dataset show that our method decreases the probability of hallucinated tokens while maintaining the Rouge and BERT-S scores of top-performing decoding strategies.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.399.pdf"
    },
    {
        "title": "The Authenticity Gap in Human Evaluation",
        "authors": [
            "Kawin Ethayarajh",
            "Dan Jurafsky"
        ],
        "published": "2022",
        "summary": "Human ratings are the gold standard in NLG evaluation. The standard protocol is to collect ratings of generated text, average across annotators, and rank NLG systems by their average scores. However, little consideration has been given as to whether this approach faithfully captures human preferences. Analyzing this standard protocol through the lens of utility theory in economics, we identify the implicit assumptions it makes about annotators. These assumptions are often violated in practice, in which case annotator ratings cease to reflect their preferences. The most egregious violations come from using Likert scales, which provably reverse the direction of the true preference in certain cases. We suggest improvements to the standard protocol to make it more theoretically sound, but even in its improved form, it cannot be used to evaluate open-ended tasks like story generation. For the latter, we propose a new human evaluation protocol called system-level probabilistic assessment (SPA). When human evaluation of stories is done with SPA, we can recover the ordering of GPT-3 models by size, with statistically significant results. However, when human evaluation is done with the standard protocol, less than half of the expected preferences can be recovered (e.g., there is no significant difference between curie and davinci, despite using a highly powered test).",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.406.pdf"
    },
    {
        "title": "BERT in Plutarch’s Shadows",
        "authors": [
            "Ivan P. Yamshchikov",
            "Alexey Tikhonov",
            "Yorgos Pantis",
            "Charlotte Schubert",
            "Jürgen Jost"
        ],
        "published": "2022",
        "summary": "The extensive surviving corpus of the ancient scholar Plutarch of Chaeronea (ca. 45-120 CE) also contains several texts which, according to current scholarly opinion, did not originate with him and are therefore attributed to an anonymous author Pseudo-Plutarch. These include, in particular, the work Placita Philosophorum (Quotations and Opinions of the Ancient Philosophers), which is extremely important for the history of ancient philosophy. Little is known about the identity of that anonymous author and its relation to other authors from the same period. This paper presents a BERT language model for Ancient Greek. The model discovers previously unknown statistical properties relevant to these literary, philosophical, and historical problems and can shed new light on this authorship question. In particular, the Placita Philosophorum, together with one of the other Pseudo-Plutarch texts, shows similarities with the texts written by authors from an Alexandrian context (2nd/3rd century CE).",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.407.pdf"
    },
    {
        "title": "Fine-tuned Language Models are Continual Learners",
        "authors": [
            "Thomas Scialom",
            "Tuhin Chakrabarty",
            "Smaranda Muresan"
        ],
        "published": "2022",
        "summary": "Recent work on large language models relies on the intuition that most natural language processing tasks can be described via natural language instructions and that models trained on these instructions show strong zero-shot performance on several standard datasets. However, these models even though impressive still perform poorly on a wide range of tasks outside of their respective training and evaluation sets.To address this limitation, we argue that a model should be able to keep extending its knowledge and abilities, without forgetting previous skills. In spite of the limited success of Continual Learning, we show that Fine-tuned Language Models can be continual learners.We empirically investigate the reason for this success and conclude that Continual Learning emerges from self-supervision pre-training. Our resulting model Continual-T0 (CT0) is able to learn 8 new diverse language generation tasks, while still maintaining good performance on previous tasks, spanning in total of 70 datasets. Finally, we show that CT0 is able to combine instructions in ways it was never trained for, demonstrating some level of instruction compositionality.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.410.pdf"
    },
    {
        "title": "AX-MABSA: A Framework for Extremely Weakly Supervised Multi-label Aspect Based Sentiment Analysis",
        "authors": [
            "Sabyasachi Kamila",
            "Walid Magdy",
            "Sourav Dutta",
            "MingXue Wang"
        ],
        "published": "2022",
        "summary": "Aspect Based Sentiment Analysis is a dominant research area with potential applications in social media analytics, business, finance, and health. Prior works in this area are primarily based on supervised methods, with a few techniques using weak supervision limited to predicting a single aspect category per review sentence. In this paper, we present an extremely weakly supervised multi-label Aspect Category Sentiment Analysis framework which does not use any labelled data. We only rely on a single word per class as an initial indicative information. We further propose an automatic word selection technique to choose these seed categories and sentiment words. We explore unsupervised language model post-training to improve the overall performance, and propose a multi-label generator model to generate multiple aspect category-sentiment pairs per review sentence. Experiments conducted on four benchmark datasets showcase our method to outperform other weakly supervised baselines by a significant margin.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.412.pdf"
    },
    {
        "title": "Transfer Learning with Synthetic Corpora for Spatial Role Labeling and Reasoning",
        "authors": [
            "Roshanak Mirzaee",
            "Parisa Kordjamshidi"
        ],
        "published": "2022",
        "summary": "Recent research shows synthetic data as a source of supervision helps pretrained language models (PLM) transfer learning to new target tasks/domains. However, this idea is less explored for spatial language. We provide two new data resources on multiple spatial language processing tasks. The first dataset is synthesized for transfer learning on spatial question answering (SQA) and spatial role labeling (SpRL). Compared to previous SQA datasets, we include a larger variety of spatial relation types and spatial expressions. Our data generation process is easily extendable with new spatial expression lexicons. The second one is a real-world SQA dataset with human-generated questions built on an existing corpus with SPRL annotations. This dataset can be used to evaluate spatial language processing models in realistic situations. We show pretraining with automatically generated data significantly improves the SOTA results on several SQA and SPRL benchmarks, particularly when the training data in the target domain is small.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.413.pdf"
    },
    {
        "title": "Bernice: A Multilingual Pre-trained Encoder for Twitter",
        "authors": [
            "Alexandra DeLucia",
            "Shijie Wu",
            "Aaron Mueller",
            "Carlos Aguirre",
            "Philip Resnik",
            "Mark Dredze"
        ],
        "published": "2022",
        "summary": "The language of Twitter differs significantly from that of other domains commonly included in large language model training. While tweets are typically multilingual and contain informal language, including emoji and hashtags, most pre-trained language models for Twitter are either monolingual, adapted from other domains rather than trained exclusively on Twitter, or are trained on a limited amount of in-domain Twitter data.We introduce Bernice, the first multilingual RoBERTa language model trained from scratch on 2.5 billion tweets with a custom tweet-focused tokenizer. We evaluate on a variety of monolingual and multilingual Twitter benchmarks, finding that our model consistently exceeds or matches the performance of a variety of models adapted to social media data as well as strong multilingual baselines, despite being trained on less data overall.We posit that it is more efficient compute- and data-wise to train completely on in-domain data with a specialized domain-specific tokenizer.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.415.pdf"
    },
    {
        "title": "TemporalWiki: A Lifelong Benchmark for Training and Evaluating Ever-Evolving Language Models",
        "authors": [
            "Joel Jang",
            "Seonghyeon Ye",
            "Changho Lee",
            "Sohee Yang",
            "Joongbo Shin",
            "Janghoon Han",
            "Gyeonghun Kim",
            "Minjoon Seo"
        ],
        "published": "2022",
        "summary": "Language Models (LMs) become outdated as the world changes; they often fail to perform tasks requiring recent factual information which was absent or different during training, a phenomenon called temporal misalignment. This is especially a challenging problem because the research community still lacks a coherent dataset for assessing the adaptability of LMs to frequently-updated knowledge corpus such as Wikipedia. To this end, we introduce TemporalWiki, a lifelong benchmark for ever-evolving LMs that utilizes the difference between consecutive snapshots of English Wikipedia and English Wikidata for training and evaluation, respectively. The benchmark hence allows researchers to periodically track an LM’s ability to retain previous knowledge and acquire updated/new knowledge at each point in time. We also find that training an LM on the diff data through continual learning methods achieves similar or better perplexity than on the entire snapshot in our benchmark with 12 times less computational cost, which verifies that factual knowledge in LMs can be safely updated with minimal training data via continual learning.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.418.pdf"
    },
    {
        "title": "Bi-Directional Iterative Prompt-Tuning for Event Argument Extraction",
        "authors": [
            "Lu Dai",
            "Bang Wang",
            "Wei Xiang",
            "Yijun Mo"
        ],
        "published": "2022",
        "summary": "Recently, prompt-tuning has attracted growing interests in event argument extraction (EAE). However, the existing prompt-tuning methods have not achieved satisfactory performance due to the lack of consideration of entity information. In this paper, we propose a bi-directional iterative prompt-tuning method for EAE, where the EAE task is treated as a cloze-style task to take full advantage of entity information and pre-trained language models (PLMs). Furthermore, our method explores event argument interactions by introducing the argument roles of contextual entities into prompt construction. Since template and verbalizer are two crucial components in a cloze-style prompt, we propose to utilize the role label semantic knowledge to construct a semantic verbalizer and design three kind of templates for the EAE task. Experiments on the ACE 2005 English dataset with standard and low-resource settings show that the proposed method significantly outperforms the peer state-of-the-art methods.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.419.pdf"
    },
    {
        "title": "ConvFinQA: Exploring the Chain of Numerical Reasoning in Conversational Finance Question Answering",
        "authors": [
            "Zhiyu Chen",
            "Shiyang Li",
            "Charese Smiley",
            "Zhiqiang Ma",
            "Sameena Shah",
            "William Yang Wang"
        ],
        "published": "2022",
        "summary": "With the recent advance in large pre-trained language models, researchers have achieved record performances in NLP tasks that mostly focus on language pattern matching. The community is experiencing the shift of the challenge from how to model language to the imitation of complex reasoning abilities like human beings. In this work, we investigate the application domain of finance that involves real-world, complex numerical reasoning. We propose a new large-scale dataset, ConvFinQA, aiming to study the chain of numerical reasoning in conversational question answering. Our dataset poses great challenge in modeling long-range, complex numerical reasoning paths in real-world conversations. We conduct comprehensive experiments and analyses with both the neural symbolic methods and the prompting-based methods, to provide insights into the reasoning mechanisms of these two divisions. We believe our new dataset should serve as a valuable resource to push forward the exploration of real-world, complex reasoning tasks as the next research focus. Our dataset and code is publicly available at https://github.com/czyssrs/ConvFinQA.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.421.pdf"
    },
    {
        "title": "Just Fine-tune Twice: Selective Differential Privacy for Large Language Models",
        "authors": [
            "Weiyan Shi",
            "Ryan Shea",
            "Si Chen",
            "Chiyuan Zhang",
            "Ruoxi Jia",
            "Zhou Yu"
        ],
        "published": "2022",
        "summary": "Protecting large language models from privacy leakage is becoming increasingly crucial with their wide adoption in real-world products. Yet applying *differential privacy* (DP), a canonical notion with provable privacy guarantees for machine learning models, to those models remains challenging due to the trade-off between model utility and privacy loss. Utilizing the fact that sensitive information in language data tends to be sparse, Shi et al. (2021) formalized a DP notion extension called *Selective Differential Privacy* (SDP) to protect only the sensitive tokens defined by a policy function. However, their algorithm only works for RNN-based models. In this paper, we develop a novel framework, *Just Fine-tune Twice* (JFT), that achieves SDP for state-of-the-art large transformer-based models. Our method is easy to implement: it first fine-tunes the model with *redacted* in-domain data, and then fine-tunes it again with the *original* in-domain data using a private training mechanism. Furthermore, we study the scenario of imperfect implementation of policy functions that misses sensitive tokens and develop systematic methods to handle it. Experiments show that our method achieves strong utility compared to previous baselines. We also analyze the SDP privacy guarantee empirically with the canary insertion attack.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.425.pdf"
    },
    {
        "title": "Improving Temporal Generalization of Pre-trained Language Models with Lexical Semantic Change",
        "authors": [
            "Zhaochen Su",
            "Zecheng Tang",
            "Xinyan Guan",
            "Lijun Wu",
            "Min Zhang",
            "Juntao Li"
        ],
        "published": "2022",
        "summary": "Recent research has revealed that neural language models at scale suffer from poor temporal generalization capability, i.e., language model pre-trained on static data from past years performs worse over time on emerging data. Existing methods mainly perform continual training to mitigate such a misalignment. While effective to some extent but is far from being addressed on both the language modeling and downstream tasks. In this paper, we empirically observe that temporal generalization is closely affiliated with lexical semantic change, which is one of the essential phenomena of natural languages. Based on this observation, we propose a simple yet effective lexical-level masking strategy to post-train a converged language model. Experiments on two pre-trained language models, two different classification tasks, and four benchmark datasets demonstrate the effectiveness of our proposed method over existing temporal adaptation methods, i.e., continual training with new data. Our code is available at https://github.com/zhaochen0110/LMLM.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.428.pdf"
    },
    {
        "title": "ULN: Towards Underspecified Vision-and-Language Navigation",
        "authors": [
            "Weixi Feng",
            "Tsu-Jui Fu",
            "Yujie Lu",
            "William Yang Wang"
        ],
        "published": "2022",
        "summary": "Vision-and-Language Navigation (VLN) is a task to guide an embodied agent moving to a target position using language instructions. Despite the significant performance improvement, the wide use of fine-grained instructions fails to characterize more practical linguistic variations in reality. To fill in this gap, we introduce a new setting, namely Underspecified vision-and-Language Navigation (ULN), and associated evaluation datasets. ULN evaluates agents using multi-level underspecified instructions instead of purely fine-grained or coarse-grained, which is a more realistic and general setting. As a primary step toward ULN, we propose a VLN framework that consists of a classification module, a navigation agent, and an Exploitation-to-Exploration (E2E) module. Specifically, we propose to learn Granularity Specific Sub-networks (GSS) for the agent to ground multi-level instructions with minimal additional parameters. Then, our E2E module estimates grounding uncertainty and conducts multi-step lookahead exploration to improve the success rate further. Experimental results show that existing VLN models are still brittle to multi-level language underspecification. Our framework is more robust and outperforms the baselines on ULN by ~10% relative success rate across all levels.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.429.pdf"
    },
    {
        "title": "Teaching Broad Reasoning Skills for Multi-Step QA by Generating Hard Contexts",
        "authors": [
            "Harsh Trivedi",
            "Niranjan Balasubramanian",
            "Tushar Khot",
            "Ashish Sabharwal"
        ],
        "published": "2022",
        "summary": "Question-answering datasets require a broad set of reasoning skills. We show how to use question decompositions to teach language models these broad reasoning skills in a robust fashion. Specifically, we use widely available QDMR representations to programmatically create hard-to-cheat synthetic contexts for real questions in six multi-step reasoning datasets. These contexts are carefully designed to avoid common reasoning shortcuts prevalent in real contexts that prevent models from learning the right skills. This results in a pretraining dataset, named TeaBReaC, containing 525K multi-step questions (with associated formal programs) covering about 900 reasoning patterns. We show that pretraining standard language models (LMs) on TeaBReaC before fine-tuning them on target datasets improves their performance by up to 13 F1 points across 4 multi-step QA datasets, with up to 21 point gain on more complex questions. The resulting models also demonstrate higher robustness, with a 5-8 F1 point improvement on two contrast sets. Furthermore, TeaBReaC pretraining substantially improves model performance and robustness even when starting with numerate LMs pretrained using recent methods (e.g., PReasM, POET). Our work thus shows how to effectively use decomposition-guided contexts to robustly teach multi-step reasoning.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.439.pdf"
    },
    {
        "title": "G-MAP: General Memory-Augmented Pre-trained Language Model for Domain Tasks",
        "authors": [
            "Zhongwei Wan",
            "Yichun Yin",
            "Wei Zhang",
            "Jiaxin Shi",
            "Lifeng Shang",
            "Guangyong Chen",
            "Xin Jiang",
            "Qun Liu"
        ],
        "published": "2022",
        "summary": "General pre-trained language models (PLMs), such as BERT, have achieved remarkable performance on various NLP tasks. Recently, domain-specific PLMs have been proposed to boost the task performance of specific domains (e.g., biomedical and computer science) by continuing to pre-train general PLMs with domain-specific corpora. However, this domain-adaptive pre-training (DAPT (CITATION)) tends to forget the previous general knowledge acquired by general PLMs, which leads to a catastrophic forgetting phenomenon and sub-optimal performance. To alleviate this problem, we propose a new framework of Memory-Augmented Pre-trained Language Model (MAP), which augments the domain-specific PLM by a memory built from the frozen general PLM without losing the general knowledge. Specifically, we propose a new memory-augmented layer, and based on it, different augmentation strategies are explored to build memory and fusion memory into domain-specific PLM. We demonstrate the effectiveness of MAP on different domains (biomedical and computer science publications, news, and reviews) and different kinds (text classification, QA, NER) of tasks, and the extensive results show that the proposed MAP can achieve SOTA results on these tasks.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.441.pdf"
    },
    {
        "title": "Textual Manifold-based Defense Against Natural Language Adversarial Examples",
        "authors": [
            "Dang Nguyen Minh",
            "Anh Tuan Luu"
        ],
        "published": "2022",
        "summary": "Despite the recent success of large pretrained language models in NLP, they are susceptible to adversarial examples. Concurrently, several studies on adversarial images have observed an intriguing property: the adversarial images tend to leave the low-dimensional natural data manifold. In this study, we find a similar phenomenon occurs in the contextualized embedding space of natural sentences induced by pretrained language models in which textual adversarial examples tend to have their embeddings diverge off the manifold of natural sentence embeddings. Based on this finding, we propose Textual Manifold-based Defense (TMD), a defense mechanism that learns the embedding space manifold of the underlying language model and projects novel inputs back to the approximated structure before classification. Through extensive experiments, we find that our method consistently and significantly outperforms previous defenses under various attack settings while remaining unaffected to the clean accuracy. To the best of our knowledge, this is the first kind of manifold-based defense adapted to the NLP domain.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.443.pdf"
    },
    {
        "title": "Tiny-Attention Adapter: Contexts Are More Important Than the Number of Parameters",
        "authors": [
            "Hongyu Zhao",
            "Hao Tan",
            "Hongyuan Mei"
        ],
        "published": "2022",
        "summary": "Adapter-tuning is a paradigm that transfers a pretrained language model to downstream tasks by adding and tuning a small number of new parameters. Previously proposed adapter architectures are all feed-forward neural networks. In this paper, we investigate the effectiveness of using tiny-attention—i.e., attention with extremely small per-head dimensionality—as adapters. Our tiny-attention adapter learns to modify the hidden states at each position directly conditioned on the hidden states at all the other positions, which is missed by the previously proposed adapters. Moreover, we view its multiple attention heads as a mixture of experts and propose to average their weights during deployment, which further reduces its inference computation cost. On the GLUE benchmark, our tiny-attention adapter outperforms the other parameter-efficient transfer learning methods as well as full fine-tuning while only updating 0.05% of the parameters. On the FewGLUE benchmark, its performance is comparable to that of GPT-3 and PET.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.444.pdf"
    },
    {
        "title": "ATTEMPT: Parameter-Efficient Multi-task Tuning via Attentional Mixtures of Soft Prompts",
        "authors": [
            "Akari Asai",
            "Mohammadreza Salehi",
            "Matthew Peters",
            "Hannaneh Hajishirzi"
        ],
        "published": "2022",
        "summary": "This work introduces a new multi-task, parameter-efficient language model (LM) tuning method that learns to transfer knowledge across different tasks via a mixture of soft prompts—small prefix embedding vectors pre-trained for different tasks. Our method, called ATTEMPT (ATTEntional Mixtures of Prompt Tuning), obtains source prompts as encodings of large-scale source tasks into a small number of parameters and trains an attention module to interpolate the source prompts and a newly initialized target prompt for every instance in the target task. During training, only the target task prompt and the attention weights, which are shared between tasks in multi-task training, are updated, while the original LM and source prompts are intact. ATTEMPT is highly parameter-efficient (e.g., updates 2,300 times fewer parameters than full fine-tuning), while it overcomes instability of prompt tuning and achieves high task performance using learned knowledge from high-resource tasks. Moreover, it is modular using pre-trained soft prompts, and can flexibly add or remove source prompts for effective knowledge transfer. Our experimental results across 21 diverse NLP datasets show that ATTEMPT significantly outperforms prompt tuning and outperforms or matches fully fine-tuned or other parameter-efficient tuning approaches that use 10 times more parameters. Finally, ATTEMPT outperforms previous work in few-shot learning settings.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.446.pdf"
    },
    {
        "title": "META-GUI: Towards Multi-modal Conversational Agents on Mobile GUI",
        "authors": [
            "Liangtai Sun",
            "Xingyu Chen",
            "Lu Chen",
            "Tianle Dai",
            "Zichen Zhu",
            "Kai Yu"
        ],
        "published": "2022",
        "summary": "Task-oriented dialogue (TOD) systems have been widely used by mobile phone intelligent assistants to accomplish tasks such as calendar scheduling or hotel reservation. Current TOD systems usually focus on multi-turn text/speech interaction, then they would call back-end APIs designed for TODs to perform the task. However, this API-based architecture greatly limits the information-searching capability of intelligent assistants and may even lead to task failure if TOD-specific APIs are not available or the task is too complicated to be executed by the provided APIs. In this paper, we propose a new TOD architecture: GUI-based task-oriented dialogue system (GUI-TOD). A GUI-TOD system can directly perform GUI operations on real APPs and execute tasks without invoking TOD-specific backend APIs. Furthermore, we release META-GUI, a dataset for training a Multi-modal convErsaTional Agent on mobile GUI. We also propose a multi-model action prediction and response model, which show promising results on META-GUI. The dataset, codes and leaderboard are publicly available.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.449.pdf"
    },
    {
        "title": "Exploring Mode Connectivity for Pre-trained Language Models",
        "authors": [
            "Yujia Qin",
            "Cheng Qian",
            "Jing Yi",
            "Weize Chen",
            "Yankai Lin",
            "Xu Han",
            "Zhiyuan Liu",
            "Maosong Sun",
            "Jie Zhou"
        ],
        "published": "2022",
        "summary": "Recent years have witnessed the prevalent application of pre-trained language models (PLMs) in NLP. From the perspective of parameter space, PLMs provide generic initialization, starting from which high-performance minima could be found. Although plenty of works have studied how to effectively and efficiently adapt PLMs to high-performance minima, little is known about the connection of various minima reached under different adaptation configurations. In this paper, we investigate the geometric connections of different minima through the lens of mode connectivity, which measures whether two minima can be connected with a low-loss path. We conduct empirical analyses to investigate three questions: (1) how could hyperparameters, specific tuning methods, and training data affect PLM’s mode connectivity? (2) How does mode connectivity change during pre-training? (3) How does the PLM’s task knowledge change along the path connecting two minima? In general, exploring the mode connectivity of PLMs conduces to understanding the geometric connection of different minima, which may help us fathom the inner workings of PLM downstream adaptation. The codes are publicly available at https://github.com/thunlp/Mode-Connectivity-PLM.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.451.pdf"
    },
    {
        "title": "Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding",
        "authors": [
            "Rishabh Bhardwaj",
            "Amrita Saha",
            "Steven C.H. Hoi",
            "Soujanya Poria"
        ],
        "published": "2022",
        "summary": "Prompt Tuning has been largely successful as a parameter-efficient method of conditioning large-scale pre-trained language models to perform downstream tasks. Thus far, soft prompt tuning learns a fixed set of task-specific continuous vectors, i.e., soft tokens that remain static across the task samples. A fixed prompt, however, may not generalize well to the diverse kinds of inputs the task comprises. In order to address this, we propose Vector-quantized Input-contextualized Prompts (VIP) as an extension to the soft prompt tuning framework. VIP particularly focuses on two aspects—contextual prompts that learns input-specific contextualization of the soft prompt tokens through a small-scale sentence encoder and quantized prompts that maps the contextualized prompts to a set of learnable codebook vectors through a Vector quantization network. On various language understanding tasks like SuperGLUE, QA, Relation classification, NER and NLI, VIP outperforms the soft prompt tuning (PT) baseline by an average margin of 1.19%. Further, our generalization studies show that VIP learns more robust prompt representations, surpassing PT by a margin of 0.6% - 5.3% on Out-of-domain QA and NLI tasks respectively, and by 0.75% on Multi-Task setup over 4 tasks spanning across 12 domains.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.455.pdf"
    },
    {
        "title": "Boosting Natural Language Generation from Instructions with Meta-Learning",
        "authors": [
            "Budhaditya Deb",
            "Ahmed Hassan Awadallah",
            "Guoqing Zheng"
        ],
        "published": "2022",
        "summary": "Recent work has shown that language models (LMs) trained with multi-task instructional learning (MTIL) can solve diverse NLP tasks in zero- and few-shot settings with improved performance compared to prompt tuning. MTIL illustrates that LMs can extract and use information about the task from instructions beyond the surface patterns of the inputs and outputs. This suggests that meta-learning may further enhance the utilization of instructions for effective task transfer. In this paper we investigate whether meta-learning applied to MTIL can further improve generalization to unseen tasks in a zero-shot setting. Specifically, we propose to adapt meta-learning to MTIL in three directions: 1) Model Agnostic Meta Learning (MAML), 2) Hyper-Network (HNet) based adaptation to generate task specific parameters conditioned on instructions, and 3) an approach combining HNet and MAML. Through extensive experiments on the large scale Natural Instructions V2 dataset, we show that our proposed approaches significantly improve over strong baselines in zero-shot settings. In particular, meta-learning improves the effectiveness of instructions and is most impactful when the test tasks are strictly zero-shot (i.e. no similar tasks in the training set) and are “hard” for LMs, illustrating the potential of meta-learning for MTIL for out-of-distribution tasks.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.456.pdf"
    },
    {
        "title": "Help me write a Poem - Instruction Tuning as a Vehicle for Collaborative Poetry Writing",
        "authors": [
            "Tuhin Chakrabarty",
            "Vishakh Padmakumar",
            "He He"
        ],
        "published": "2022",
        "summary": "Recent work in training large language models (LLMs) to follow natural language instructions has opened up exciting opportunities for natural language interface design. Building on the prior success of large language models in the realm of computer assisted creativity, in this work, we present CoPoet, a collaborative poetry writing system, with the goal of to study if LLM’s actually improve the quality of the generated content. In contrast to auto-completing a user’s text, CoPoet is controlled by user instructions that specify the attributes of the desired text, such as Write a sentence about ‘love’ or Write a sentence ending in ‘fly’. The core component of our system is a language model fine-tuned on a diverse collection of instructions for poetry writing. Our model is not only competitive to publicly available LLMs trained on instructions (InstructGPT), but also capable of satisfying unseen compositional instructions. A study with 15 qualified crowdworkers shows that users successfully write poems with CoPoet on diverse topics ranging from Monarchy to Climate change, which are preferred by third-party evaluators over poems written without the system.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.460.pdf"
    },
    {
        "title": "Enhancing Multilingual Language Model with Massive Multilingual Knowledge Triples",
        "authors": [
            "Linlin Liu",
            "Xin Li",
            "Ruidan He",
            "Lidong Bing",
            "Shafiq Joty",
            "Luo Si"
        ],
        "published": "2022",
        "summary": "Knowledge-enhanced language representation learning has shown promising results across various knowledge-intensive NLP tasks. However, prior methods are limited in efficient utilization of multilingual knowledge graph (KG) data for language model (LM) pretraining. They often train LMs with KGs in indirect ways, relying on extra entity/relation embeddings to facilitate knowledge injection. In this work, we explore methods to make better use of the multilingual annotation and language agnostic property of KG triples, and present novel knowledge based multilingual language models (KMLMs) trained directly on the knowledge triples. We first generate a large amount of multilingual synthetic sentences using the Wikidata KG triples. Then based on the intra- and inter-sentence structures of the generated data, we design pretraining tasks to enable the LMs to not only memorize the factual knowledge but also learn useful logical patterns. Our pretrained KMLMs demonstrate significant performance improvements on a wide range of knowledge-intensive cross-lingual tasks, including named entity recognition (NER), factual knowledge retrieval, relation classification, and a newly designed logical reasoning task.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.462.pdf"
    },
    {
        "title": "XLM-D: Decorate Cross-lingual Pre-training Model as Non-Autoregressive Neural Machine Translation",
        "authors": [
            "Yong Wang",
            "Shilin He",
            "Guanhua Chen",
            "Yun Chen",
            "Daxin Jiang"
        ],
        "published": "2022",
        "summary": "Pre-training language models have achieved thriving success in numerous natural language understanding and autoregressive generation tasks, but non-autoregressive generation in applications such as machine translation has not sufficiently benefited from the pre-training paradigm. In this work, we establish the connection between a pre-trained masked language model (MLM) and non-autoregressive generation on machine translation. From this perspective, we present XLM-D, which seamlessly transforms an off-the-shelf cross-lingual pre-training model into a non-autoregressive translation (NAT) model with a lightweight yet effective decorator. Specifically, the decorator ensures the representation consistency of the pre-trained model and brings only one additional trainable parameter. Extensive experiments on typical translation datasets show that our models obtain state-of-the-art performance while realizing the inference speed-up by 19.9x. One striking result is that on WMT14 En-De, our XLM-D obtains 29.80 BLEU points with multiple iterations, which outperforms the previous mask-predict model by 2.77 points.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.466.pdf"
    },
    {
        "title": "Zero-Shot Learners for Natural Language Understanding via a Unified Multiple Choice Perspective",
        "authors": [
            "Ping Yang",
            "Junjie Wang",
            "Ruyi Gan",
            "Xinyu Zhu",
            "Lin Zhang",
            "Ziwei Wu",
            "Xinyu Gao",
            "Jiaxing Zhang",
            "Tetsuya Sakai"
        ],
        "published": "2022",
        "summary": "We propose a new paradigm for zero-shot learners that is format agnostic, i.e., it is compatible with any format and applicable to a list of language tasks, such as text classification, commonsense reasoning, coreference resolution, and sentiment analysis. Zero-shot learning aims to train a model on a given task such that it can address new learning tasks without any additional training. Our approach converts zero-shot learning into multiple-choice tasks, avoiding problems in commonly used large-scale generative models such as FLAN. It not only adds generalization ability to models but also significantly reduces the number of parameters. Our method shares the merits of efficient training and deployment. Our approach shows state-of-the-art performance on several benchmarks and produces satisfactory results on tasks such as natural language inference and text classification. Our model achieves this success with only 235M parameters, which is substantially smaller than state-of-the-art models with billions of parameters. The code and pre-trained models are available at https://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen/examples/unimc .",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.474.pdf"
    },
    {
        "title": "ParaTag: A Dataset of Paraphrase Tagging for Fine-Grained Labels, NLG Evaluation, and Data Augmentation",
        "authors": [
            "Shuohang Wang",
            "Ruochen Xu",
            "Yang Liu",
            "Chenguang Zhu",
            "Michael Zeng"
        ],
        "published": "2022",
        "summary": "Paraphrase identification has been formulated as a binary classification task to decide whether two sentences hold a paraphrase relationship. Existing paraphrase datasets only annotate a binary label for each sentence pair. However, after a systematical analysis of existing paraphrase datasets, we found that the degree of paraphrase cannot be well characterized by a single binary label. And the criteria of paraphrase are not even consistent within the same dataset. We hypothesize that such issues would limit the effectiveness of paraphrase models trained on these data. To this end, we propose a novel fine-grained paraphrase annotation schema that labels the minimum spans of tokens in a sentence that don’t have the corresponding paraphrases in the other sentence. Under this setting, we frame paraphrasing as a sequence tagging task. We collect 30k sentence pairs in English with the new annotation schema, resulting in the ParaTag dataset. In addition to reporting baseline results on ParaTag using state-of-art language models, we show that ParaTag is especially useful for training an automatic scorer for language generation evaluation. Finally, we train a paraphrase generation model from ParaTag and achieve better data augmentation performance on the GLUE benchmark than other public paraphrasing datasets.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.479.pdf"
    },
    {
        "title": "FLUTE: Figurative Language Understanding through Textual Explanations",
        "authors": [
            "Tuhin Chakrabarty",
            "Arkadiy Saakyan",
            "Debanjan Ghosh",
            "Smaranda Muresan"
        ],
        "published": "2022",
        "summary": "Figurative language understanding has been recently framed as a recognizing textual entailment (RTE) task (a.k.a. natural language inference (NLI)). However, similar to classical RTE/NLI datasets they suffer from spurious correlations and annotation artifacts. To tackle this problem, work on NLI has built explanation-based datasets such as eSNLI, allowing us to probe whether language models are right for the right reasons. Yet no such data exists for figurative language, making it harder to assess genuine understanding of such expressions. To address this issue, we release FLUTE, a dataset of 9,000 figurative NLI instances with explanations, spanning four categories: Sarcasm, Simile, Metaphor, and Idioms. We collect the data through a Human-AI collaboration framework based on GPT-3, crowd workers, and expert annotators. We show how utilizing GPT-3 in conjunction with human annotators (novices and experts) can aid in scaling up the creation of datasets even for such complex linguistic phenomena as figurative language. The baseline performance of the T5 model fine-tuned on FLUTE shows that our dataset can bring us a step closer to developing models that understand figurative language through textual explanations.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.481.pdf"
    },
    {
        "title": "Let the CAT out of the bag: Contrastive Attributed explanations for Text",
        "authors": [
            "Saneem Chemmengath",
            "Amar Prakash Azad",
            "Ronny Luss",
            "Amit Dhurandhar"
        ],
        "published": "2022",
        "summary": "Contrastive explanations for understanding the behavior of black box models has gained a lot of attention recently as they provide potential for recourse. In this paper, we propose a method Contrastive Attributed explanations for Text (CAT) which provides contrastive explanations for natural language text data with a novel twist as we build and exploit attribute classifiers leading to more semantically meaningful explanations. To ensure that our contrastive generated text has the fewest possible edits with respect to the original text, while also being fluent and close to a human generated contrastive, we resort to a minimal perturbation approach regularized using a BERT language model and attribute classifiers trained on available attributes. We show through qualitative examples and a user study that our method not only conveys more insight because of these attributes, but also leads to better quality (contrastive) text. Quantitatively, we show that our method outperforms other state-of-the-art methods across four data sets on four benchmark metrics.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.484.pdf"
    },
    {
        "title": "Dial2vec: Self-Guided Contrastive Learning of Unsupervised Dialogue Embeddings",
        "authors": [
            "Che Liu",
            "Rui Wang",
            "Junfeng Jiang",
            "Yongbin Li",
            "Fei Huang"
        ],
        "published": "2022",
        "summary": "In this paper, we introduce the task of learning unsupervised dialogue embeddings.Trivial approaches such as combining pre-trained word or sentence embeddings and encoding through pre-trained language models (PLMs) have been shown to be feasible for this task.However, these approaches typically ignore the conversational interactions between interlocutors, resulting in poor performance.To address this issue, we proposed a self-guided contrastive learning approach named dial2vec.Dial2vec considers a dialogue as an information exchange process.It captures the interaction patterns between interlocutors and leverages them to guide the learning of the embeddings corresponding to each interlocutor.Then the dialogue embedding is obtained by an aggregation of the embeddings from all interlocutors.To verify our approach, we establish a comprehensive benchmark consisting of six widely-used dialogue datasets.We consider three evaluation tasks: domain categorization, semantic relatedness, and dialogue retrieval.Dial2vec achieves on average 8.7, 9.0, and 13.8 points absolute improvements in terms of purity, Spearman’s correlation, and mean average precision (MAP) over the strongest baseline on the three tasks respectively.Further analysis shows that dial2vec obtains informative and discriminative embeddings for both interlocutors under the guidance of the conversational interactions and achieves the best performance when aggregating them through the interlocutor-level pooling strategy.All codes and data are publicly available at https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/dial2vec.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.490.pdf"
    },
    {
        "title": "Counterfactual Recipe Generation: Exploring Compositional Generalization in a Realistic Scenario",
        "authors": [
            "Xiao Liu",
            "Yansong Feng",
            "Jizhi Tang",
            "Chengang Hu",
            "Dongyan Zhao"
        ],
        "published": "2022",
        "summary": "People can acquire knowledge in an unsupervised manner by reading, and compose the knowledge to make novel combinations. In this paper, we investigate whether pretrained language models can perform compositional generalization in a realistic setting: recipe generation. We design the counterfactual recipe generation task, which asks models to modify a base recipe according to the change of an ingredient. This task requires compositional generalization at two levels: the surface level of incorporating the new ingredient into the base recipe, and the deeper level of adjusting actions related to the changing ingredient. We collect a large-scale recipe dataset in Chinese for models to learn culinary knowledge, and a subset of action-level fine-grained annotations for evaluation.We finetune pretrained language models on the recipe corpus, and use unsupervised counterfactual generation methods to generate modified recipes.Results show that existing models have difficulties in modifying the ingredients while preserving the original text style, and often miss actions that need to be adjusted. Although pretrained language models can generate fluent recipe texts, they fail to truly learn and use the culinary knowledge in a compositional way. Code and data are available at https://github.com/xxxiaol/counterfactual-recipe-generation.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.497.pdf"
    },
    {
        "title": "Tutoring Helps Students Learn Better: Improving Knowledge Distillation for BERT with Tutor Network",
        "authors": [
            "Junho Kim",
            "Jun-Hyung Park",
            "Mingyu Lee",
            "Wing-Lam Mok",
            "Joon-Young Choi",
            "SangKeun Lee"
        ],
        "published": "2022",
        "summary": "Pre-trained language models have achieved remarkable successes in natural language processing tasks, coming at the cost of increasing model size. To address this issue, knowledge distillation (KD) has been widely applied to compress language models. However, typical KD approaches for language models have overlooked the difficulty of training examples, suffering from incorrect teacher prediction transfer and sub-efficient training. In this paper, we propose a novel KD framework, Tutor-KD, which improves the distillation effectiveness by controlling the difficulty of training examples during pre-training. We introduce a tutor network that generates samples that are easy for the teacher but difficult for the student, with training on a carefully designed policy gradient method. Experimental results show that Tutor-KD significantly and consistently outperforms the state-of-the-art KD methods with variously sized student models on the GLUE benchmark, demonstrating that the tutor can effectively generate training examples for the student.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.498.pdf"
    },
    {
        "title": "Efficient Pre-training of Masked Language Model via Concept-based Curriculum Masking",
        "authors": [
            "Mingyu Lee",
            "Jun-Hyung Park",
            "Junho Kim",
            "Kang-Min Kim",
            "SangKeun Lee"
        ],
        "published": "2022",
        "summary": "Self-supervised pre-training has achieved remarkable success in extensive natural language processing tasks. Masked language modeling (MLM) has been widely used for pre-training effective bidirectional representations but comes at a substantial training cost. In this paper, we propose a novel concept-based curriculum masking (CCM) method to efficiently pre-train a language model. CCM has two key differences from existing curriculum learning approaches to effectively reflect the nature of MLM. First, we introduce a novel curriculum that evaluates the MLM difficulty of each token based on a carefully-designed linguistic difficulty criterion. Second, we construct a curriculum that masks easy words and phrases first and gradually masks related ones to the previously masked ones based on a knowledge graph. Experimental results show that CCM significantly improves pre-training efficiency. Specifically, the model trained with CCM shows comparative performance with the original BERT on the General Language Understanding Evaluation benchmark at half of the training cost.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.502.pdf"
    },
    {
        "title": "Subword Evenness (SuE) as a Predictor of Cross-lingual Transfer to Low-resource Languages",
        "authors": [
            "Olga Pelloni",
            "Anastassia Shaitarova",
            "Tanja Samardzic"
        ],
        "published": "2022",
        "summary": "Pre-trained multilingual models, such as mBERT, XLM-R and mT5, are used to improve the performance on various tasks in low-resource languages via cross-lingual transfer. In this framework, English is usually seen as the most natural choice for a transfer language (for fine-tuning or continued training of a multilingual pre-trained model), but it has been revealed recently that this is often not the best choice. The success of cross-lingual transfer seems to depend on some properties of languages, which are currently hard to explain. Successful transfer often happens between unrelated languages and it often cannot be explained by data-dependent factors.In this study, we show that languages written in non-Latin and non-alphabetic scripts (mostly Asian languages) are the best choices for improving performance on the task of Masked Language Modelling (MLM) in a diverse set of 30 low-resource languages and that the success of the transfer is well predicted by our novel measure of Subword Evenness (SuE). Transferring language models over the languages that score low on our measure results in the lowest average perplexity over target low-resource languages. Our correlation coefficients obtained with three different pre-trained multilingual models are consistently higher than all the other predictors, including text-based measures (type-token ratio, entropy) and linguistically motivated choice (genealogical and typological proximity).",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.503.pdf"
    },
    {
        "title": "Don’t Prompt, Search! Mining-based Zero-Shot Learning with Language Models",
        "authors": [
            "Mozes van de Kar",
            "Mengzhou Xia",
            "Danqi Chen",
            "Mikel Artetxe"
        ],
        "published": "2022",
        "summary": "Masked language models like BERT can perform text classification in a zero-shot fashion by reformulating downstream tasks as text infilling. However, this approach is highly sensitive to the template used to prompt the model, yet practitioners are blind when designing them in strict zero-shot settings. In this paper, we propose an alternative mining-based approach for zero-shot learning. Instead of prompting language models, we use regular expressions to mine labeled examples from unlabeled corpora, which can optionally be filtered through prompting, and used to finetune a pretrained model. Our method is more flexible and interpretable than prompting, and outperforms it on a wide range of tasks when using comparable templates. Our results suggest that the success of prompting can partly be explained by the model being exposed to similar examples during pretraining, which can be directly retrieved through regular expressions.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.509.pdf"
    },
    {
        "title": "Discovering Language-neutral Sub-networks in Multilingual Language Models",
        "authors": [
            "Negar Foroutan",
            "Mohammadreza Banaei",
            "Rémi Lebret",
            "Antoine Bosselut",
            "Karl Aberer"
        ],
        "published": "2022",
        "summary": "Multilingual pre-trained language models transfer remarkably well on cross-lingual downstream tasks. However, the extent to which they learn language-neutral representations (i.e., shared representations that encode similar phenomena across languages), and the effect of such representations on cross-lingual transfer performance, remain open questions.In this work, we conceptualize language neutrality of multilingual models as a function of the overlap between language-encoding sub-networks of these models. We employ the lottery ticket hypothesis to discover sub-networks that are individually optimized for various languages and tasks. Our evaluation across three distinct tasks and eleven typologically-diverse languages demonstrates that sub-networks for different languages are topologically similar (i.e., language-neutral), making them effective initializations for cross-lingual transfer with limited performance degradation.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.513.pdf"
    },
    {
        "title": "Cross-Modal Similarity-Based Curriculum Learning for Image Captioning",
        "authors": [
            "Hongkuan Zhang",
            "Saku Sugawara",
            "Akiko Aizawa",
            "Lei Zhou",
            "Ryohei Sasano",
            "Koichi Takeda"
        ],
        "published": "2022",
        "summary": "Image captioning models require the high-level generalization ability to describe the contents of various images in words. Most existing approaches treat the image–caption pairs equally in their training without considering the differences in their learning difficulties. Several image captioning approaches introduce curriculum learning methods that present training data with increasing levels of difficulty. However, their difficulty measurements are either based on domain-specific features or prior model training. In this paper, we propose a simple yet efficient difficulty measurement for image captioning using cross-modal similarity calculated by a pretrained vision–language model. Experiments on the COCO and Flickr30k datasets show that our proposed approach achieves superior performance and competitive convergence speed to baselines without requiring heuristics or incurring additional training costs. Moreover, the higher model performance on difficult examples and unseen data also demonstrates the generalization ability.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.516.pdf"
    },
    {
        "title": "Debiasing Masks: A New Framework for Shortcut Mitigation in NLU",
        "authors": [
            "Johannes Mario Meissner",
            "Saku Sugawara",
            "Akiko Aizawa"
        ],
        "published": "2022",
        "summary": "Debiasing language models from unwanted behaviors in Natural Language Understanding (NLU) tasks is a topic with rapidly increasing interest in the NLP community. Spurious statistical correlations in the data allow models to perform shortcuts and avoid uncovering more advanced and desirable linguistic features.A multitude of effective debiasing approaches has been proposed, but flexibility remains a major issue. For the most part, models must be retrained to find a new set of weights with debiased behavior.We propose a new debiasing method in which we identify debiased pruning masks that can be applied to a finetuned model. This enables the selective and conditional application of debiasing behaviors.We assume that bias is caused by a certain subset of weights in the network; our method is, in essence, a mask search to identify and remove biased weights.Our masks show equivalent or superior performance to the standard counterparts, while offering important benefits.Pruning masks can be stored with high efficiency in memory, and it becomes possible to switch among several debiasing behaviors (or revert back to the original biased model) at inference time. Finally, it opens the doors to further research on how biases are acquired by studying the generated masks. For example, we observed that the early layers and attention heads were pruned more aggressively, possibly hinting towards the location in which biases may be encoded.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.517.pdf"
    },
    {
        "title": "Differentiable Data Augmentation for Contrastive Sentence Representation Learning",
        "authors": [
            "Tianduo Wang",
            "Wei Lu"
        ],
        "published": "2022",
        "summary": "Fine-tuning a pre-trained language model via the contrastive learning framework with a large amount of unlabeled sentences or labeled sentence pairs is a common way to obtain high-quality sentence representations. Although the contrastive learning framework has shown its superiority on sentence representation learning over previous methods, the potential of such a framework is under-explored so far due to the simple method it used to construct positive pairs. Motivated by this, we propose a method that makes hard positives from the original training examples. A pivotal ingredient of our approach is the use of prefix that attached to a pre-trained language model, which allows for differentiable data augmentation during contrastive learning. Our method can be summarized in two steps: supervised prefix-tuning followed by joint contrastive fine-tuning with unlabeled or labeled examples. Our experiments confirm the effectiveness of our data augmentation approach. The proposed method yields significant improvements over existing methods under both semi-supervised and supervised settings. Our experiments under a low labeled data setting also show that our method is more label-efficient than the state-of-the-art contrastive learning methods.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.520.pdf"
    },
    {
        "title": "QASem Parsing: Text-to-text Modeling of QA-based Semantics",
        "authors": [
            "Ayal Klein",
            "Eran Hirsch",
            "Ron Eliav",
            "Valentina Pyatkin",
            "Avi Caciularu",
            "Ido Dagan"
        ],
        "published": "2022",
        "summary": "Various works suggest the appeals of incorporating explicit semantic representations when addressing challenging realistic NLP scenarios. Common approaches offer either comprehensive linguistically-based formalisms, like AMR, or alternatively Open-IE, which provides a shallow and partial representation. More recently, an appealing trend introduces semi-structured natural-language structures as an intermediate meaning-capturing representation, often in the form of questions and answers.In this work, we further promote this line of research by considering three prior QA-based semantic representations. These cover verbal, nominalized and discourse-based predications, regarded as jointly providing a comprehensive representation of textual information — termed QASem. To facilitate this perspective, we investigate how to best utilize pre-trained sequence-to-sequence language models, which seem particularly promising for generating representations that consist of natural language expressions (questions and answers). In particular, we examine and analyze input and output linearization strategies, as well as data augmentation and multitask learning for a scarce training data setup. Consequently, we release the first unified QASem parsing tool, easily applicable for downstream tasks that can benefit from an explicit semi-structured account of information units in text.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.528.pdf"
    },
    {
        "title": "HashFormers: Towards Vocabulary-independent Pre-trained Transformers",
        "authors": [
            "Huiyin Xue",
            "Nikolaos Aletras"
        ],
        "published": "2022",
        "summary": "Transformer-based pre-trained language models are vocabulary-dependent, mapping by default each token to its corresponding embedding. This one-to-one mapping results into embedding matrices that occupy a lot of memory (i.e. millions of parameters) and grow linearly with the size of the vocabulary. Previous work on on-device transformers dynamically generate token embeddings on-the-fly without embedding matrices using locality-sensitive hashing over morphological information. These embeddings are subsequently fed into transformer layers for text classification. However, these methods are not pre-trained. Inspired by this line of work, we propose HashFormers, a new family of vocabulary-independent pre-trained transformers that support an unlimited vocabulary (i.e. all possible tokens in a corpus) given a substantially smaller fixed-sized embedding matrix. We achieve this by first introducing computationally cheap hashing functions that bucket together individual tokens to embeddings. We also propose three variants that do not require an embedding matrix at all, further reducing the memory requirements. We empirically demonstrate that HashFormers are more memory efficient compared to standard pre-trained transformers while achieving comparable predictive performance when fine-tuned on multiple text classification tasks. For example, our most efficient HashFormer variant has a negligible performance degradation (0.4% on GLUE) using only 99.1K parameters for representing the embeddings compared to 12.3-38M parameters of state-of-the-art models.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.536.pdf"
    },
    {
        "title": "Improving Aspect Sentiment Quad Prediction via Template-Order Data Augmentation",
        "authors": [
            "Mengting Hu",
            "Yike Wu",
            "Hang Gao",
            "Yinhao Bai",
            "Shiwan Zhao"
        ],
        "published": "2022",
        "summary": "Recently, aspect sentiment quad prediction (ASQP) has become a popular task in the field of aspect-level sentiment analysis. Previous work utilizes a predefined template to paraphrase the original sentence into a structure target sequence, which can be easily decoded as quadruplets of the form (aspect category, aspect term, opinion term, sentiment polarity). The template involves the four elements in a fixed order. However, we observe that this solution contradicts with the order-free property of the ASQP task, since there is no need to fix the template order as long as the quadruplet is extracted correctly. Inspired by the observation, we study the effects of template orders and find that some orders help the generative model achieve better performance. It is hypothesized that different orders provide various views of the quadruplet. Therefore, we propose a simple but effective method to identify the most proper orders, and further combine multiple proper templates as data augmentation to improve the ASQP task. Specifically, we use the pre-trained language model to select the orders with minimal entropy. By fine-tuning the pre-trained language model with these template orders, our approach improves the performance of quad prediction, and outperforms state-of-the-art methods significantly in low-resource settings.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.538.pdf"
    },
    {
        "title": "SocioProbe: What, When, and Where Language Models Learn about Sociodemographics",
        "authors": [
            "Anne Lauscher",
            "Federico Bianchi",
            "Samuel R. Bowman",
            "Dirk Hovy"
        ],
        "published": "2022",
        "summary": "Pre-trained language models (PLMs) have outperformed other NLP models on a wide range of tasks. Opting for a more thorough understanding of their capabilities and inner workings, researchers have established the extend to which they capture lower-level knowledge like grammaticality, and mid-level semantic knowledge like factual understanding. However, there is still little understanding of their knowledge of higher-level aspects of language. In particular, despite the importance of sociodemographic aspects in shaping our language, the questions of whether, where, and how PLMs encode these aspects, e.g., gender or age, is still unexplored. We address this research gap by probing the sociodemographic knowledge of different single-GPU PLMs on multiple English data sets via traditional classifier probing and information-theoretic minimum description length probing. Our results show that PLMs do encode these sociodemographics, and that this knowledge is sometimes spread across the layers of some of the tested PLMs. We further conduct a multilingual analysis and investigate the effect of supplementary training to further explore to what extent, where, and with what amount of pre-training data the knowledge is encoded. Our overall results indicate that sociodemographic knowledge is still a major challenge for NLP. PLMs require large amounts of pre-training data to acquire the knowledge and models that excel in general language understanding do not seem to own more knowledge about these aspects.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.539.pdf"
    },
    {
        "title": "LiteVL: Efficient Video-Language Learning with Enhanced Spatial-Temporal Modeling",
        "authors": [
            "Dongsheng Chen",
            "Chaofan Tao",
            "Lu Hou",
            "Lifeng Shang",
            "Xin Jiang",
            "Qun Liu"
        ],
        "published": "2022",
        "summary": "Recent large-scale video-language pre-trained models have shown appealing performance on various downstream tasks. However, the pre-training process is computationally expensive due to the requirement of millions of video-text pairs and the redundant data structure of each video. To mitigate these problems, we propose LiteVL, which adapts a pre-trained image-language model BLIP into a video-text model directly on downstream tasks, without heavy pre-training. To enhance the temporal modeling lacking in the image-language model, we propose to add temporal attention modules in the image encoder of BLIP with dynamic temporal scaling. Besides the model-wise adaptation, we also propose a non-parametric pooling mechanism to adaptively reweight the fine-grained video embedding conditioned on the text. Experimental results on text-video retrieval and video question answering show that the proposed LiteVL even outperforms previous video-language pre-trained models by a clear margin, though without any video-language pre-training.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.545.pdf"
    },
    {
        "title": "Normalizing Mutual Information for Robust Adaptive Training for Translation",
        "authors": [
            "Youngwon Lee",
            "Changmin Lee",
            "Hojin Lee",
            "Seung-won Hwang"
        ],
        "published": "2022",
        "summary": "Despite the success of neural machine translation models, tensions between fluency of optimizing target language modeling and source-faithfulness remain as challenges. Previously, Conditional Bilingual Mutual Information (CBMI), a scoring metric for the importance of target sentences and tokens, was proposed to encourage fluent and faithful translations. The score is obtained by combining the probability from the translation model and the target language model, which is then used to assign different weights to losses from sentences and tokens. Meanwhile, we argue this metric is not properly normalized, for which we propose Normalized Pointwise Mutual Information (NPMI). NPMI utilizes an additional language model on source language to approximate the joint likelihood of source-target pair and the likelihood of the source, which is then used for normalizing the score. We showed that NPMI better captures the dependence between source-target and that NPMI-based token-level adaptive training brings improvements over baselines with empirical results from En-De, De-En, and En-Ro translation tasks.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.547.pdf"
    },
    {
        "title": "TIARA: Multi-grained Retrieval for Robust Question Answering over Large Knowledge Base",
        "authors": [
            "Yiheng Shu",
            "Zhiwei Yu",
            "Yuhan Li",
            "Börje Karlsson",
            "Tingting Ma",
            "Yuzhong Qu",
            "Chin-Yew Lin"
        ],
        "published": "2022",
        "summary": "Pre-trained language models (PLMs) have shown their effectiveness in multiple scenarios. However, KBQA remains challenging, especially regarding coverage and generalization settings. This is due to two main factors: i) understanding the semantics of both questions and relevant knowledge from the KB; ii) generating executable logical forms with both semantic and syntactic correctness. In this paper, we present a new KBQA model, TIARA, which addresses those issues by applying multi-grained retrieval to help the PLM focus on the most relevant KB context, viz., entities, exemplary logical forms, and schema items. Moreover, constrained decoding is used to control the output space and reduce generation errors. Experiments over important benchmarks demonstrate the effectiveness of our approach. TIARA outperforms previous SOTA, including those using PLMs or oracle entity annotations, by at least 4.1 and 1.1 F1 points on GrailQA and WebQuestionsSP, respectively. Specifically on GrailQA, TIARA outperforms previous models in all categories, with an improvement of 4.7 F1 points in zero-shot generalization.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.555.pdf"
    },
    {
        "title": "FormLM: Recommending Creation Ideas for Online Forms by Modelling Semantic and Structural Information",
        "authors": [
            "Yijia Shao",
            "Mengyu Zhou",
            "Yifan Zhong",
            "Tao Wu",
            "Hongwei Han",
            "Shi Han",
            "Gideon Huang",
            "Dongmei Zhang"
        ],
        "published": "2022",
        "summary": "Online forms are widely used to collect data from human and have a multi-billion market. Many software products provide online services for creating semi-structured forms where questions and descriptions are organized by predefined structures. However, the design and creation process of forms is still tedious and requires expert knowledge. To assist form designers, in this work we present FormLM to model online forms (by enhancing pre-trained language model with form structural information) and recommend form creation ideas (including question / options recommendations and block type suggestion). For model training and evaluation, we collect the first public online form dataset with 62K online forms. Experiment results show that FormLM significantly outperforms general-purpose language models on all tasks, with an improvement by 4.71 on Question Recommendation and 10.6 on Block Type Suggestion in terms of ROUGE-1 and Macro-F1, respectively.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.557.pdf"
    },
    {
        "title": "GPS: Genetic Prompt Search for Efficient Few-Shot Learning",
        "authors": [
            "Hanwei Xu",
            "Yujun Chen",
            "Yulun Du",
            "Nan Shao",
            "Wang Yanggang",
            "Haiyu Li",
            "Zhilin Yang"
        ],
        "published": "2022",
        "summary": "Prompt-based techniques have demostrated great potential for improving the few-shot generalization of pretrained language models. However, their performance heavily relies on the manual design of prompts and thus requiring a lot of human efforts. In this paper, we introduce Genetic Prompt Search (GPS) to improve few-shot learning with prompts, which utilizes a genetic algorithm to automatically search for the best prompt.GPS is gradient-free and requires no update of model parameters but only a small validation set. Experiments on diverse datasets proved the effectiveness of GPS, which outperforms manual prompts by a large margin of 2.6 points. Our method is also better than other parameter-efficient tuning methods such as prompt tuning.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.559.pdf"
    },
    {
        "title": "Multitask Instruction-based Prompting for Fallacy Recognition",
        "authors": [
            "Tariq Alhindi",
            "Tuhin Chakrabarty",
            "Elena Musi",
            "Smaranda Muresan"
        ],
        "published": "2022",
        "summary": "Fallacies are used as seemingly valid arguments to support a position and persuade the audience about its validity. Recognizing fallacies is an intrinsically difficult task both for humans and machines. Moreover, a big challenge for computational models lies in the fact that fallacies are formulated differently across the datasets with differences in the input format (e.g., question-answer pair, sentence with fallacy fragment), genre (e.g., social media, dialogue, news), as well as types and number of fallacies (from 5 to 18 types per dataset). To move towards solving the fallacy recognition task, we approach these differences across datasets as multiple tasks and show how instruction-based prompting in a multitask setup based on the T5 model improves the results against approaches built for a specific dataset such as T5, BERT or GPT-3. We show the ability of this multitask prompting approach to recognize 28 unique fallacies across domains and genres and study the effect of model size and prompt choice by analyzing the per-class (i.e., fallacy type) results. Finally, we analyze the effect of annotation quality on model performance, and the feasibility of complementing this approach with external knowledge.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.560.pdf"
    },
    {
        "title": "Towards Table-to-Text Generation with Pretrained Language Model: A Table Structure Understanding and Text Deliberating Approach",
        "authors": [
            "Miao Chen",
            "Xinjiang Lu",
            "Tong Xu",
            "Yanyan Li",
            "Zhou Jingbo",
            "Dejing Dou",
            "Hui Xiong"
        ],
        "published": "2022",
        "summary": "Although remarkable progress on the neural table-to-text methods has been made, the generalization issues hinder the applicability of these models due to the limited source tables. Large-scale pretrained language models sound like a promising solution to tackle such issues. However, how to effectively bridge the gap between the structured table and the text input by fully leveraging table information to fuel the pretrained model is still not well explored. Besides, another challenge of integrating the deliberation mechanism into the text-to-text pretrained model for solving the table-to-text task remains seldom studied. In this paper, to implement the table-to-text generation with pretrained language model, we propose a table structure understanding and text deliberating approach, namely TASD. To be specific, we devise a three-layered multi-head attention network to realize the table-structureaware text generation model with the help of the pretrained language model. Furthermore, a multi-pass decoder framework is adopted to enhance the capability of polishing generated text for table descriptions. The empirical studies, as well as human evaluation, on two public datasets, validate that our approach can generate faithful and fluent descriptive texts for different types of tables.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.562.pdf"
    },
    {
        "title": "Efficient Adversarial Training with Robust Early-Bird Tickets",
        "authors": [
            "Zhiheng Xi",
            "Rui Zheng",
            "Tao Gui",
            "Qi Zhang",
            "Xuanjing Huang"
        ],
        "published": "2022",
        "summary": "Adversarial training is one of the most powerful methods to improve the robustness of pre-trained language models (PLMs). However, this approach is typically more expensive than traditional fine-tuning because of the necessity to generate adversarial examples via gradient descent. Delving into the optimization process of adversarial training, we find that robust connectivity patterns emerge in the early training phase (typically 0.15~0.3 epochs), far before parameters converge. Inspired by this finding, we dig out robust early-bird tickets (i.e., subnetworks) to develop an efficient adversarial training method: (1) searching for robust tickets with structured sparsity in the early stage; (2) fine-tuning robust tickets in the remaining time. To extract the robust tickets as early as possible, we design a ticket convergence metric to automatically terminate the searching process. Experiments show that the proposed efficient adversarial training method can achieve up to 7× ∼ 13 × training speedups while maintaining comparable or even better robustness compared to the most competitive state-of-the-art adversarial training methods.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.569.pdf"
    },
    {
        "title": "Quantifying Privacy Risks of Masked Language Models Using Membership Inference Attacks",
        "authors": [
            "Fatemehsadat Mireshghallah",
            "Kartik Goyal",
            "Archit Uniyal",
            "Taylor Berg-Kirkpatrick",
            "Reza Shokri"
        ],
        "published": "2022",
        "summary": "The wide adoption and application of Masked language models (MLMs) on sensitive data (from legal to medical) necessitates a thorough quantitative investigation into their privacy vulnerabilities. Prior attempts at measuring leakage of MLMs via membership inference attacks have been inconclusive, implying potential robustness of MLMs to privacy attacks.In this work, we posit that prior attempts were inconclusive because they based their attack solely on the MLM’s model score. We devise a stronger membership inference attack based on likelihood ratio hypothesis testing that involves an additional reference MLM to more accurately quantify the privacy risks of memorization in MLMs. We show that masked language models are indeed susceptible to likelihood ratio membership inference attacks: Our empirical results, on models trained on medical notes, show that our attack improves the AUC of prior membership inference attacks from 0.66 to an alarmingly high 0.90 level.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.570.pdf"
    },
    {
        "title": "TextFusion: Privacy-Preserving Pre-trained Model Inference via Token Fusion",
        "authors": [
            "Xin Zhou",
            "Jinzhu Lu",
            "Tao Gui",
            "Ruotian Ma",
            "Zichu Fei",
            "Yuran Wang",
            "Yong Ding",
            "Yibo Cheung",
            "Qi Zhang",
            "Xuanjing Huang"
        ],
        "published": "2022",
        "summary": "Recently, more and more pre-trained language models are released as a cloud service. It allows users who lack computing resources to perform inference with a powerful model by uploading data to the cloud. The plain text may contain private information, as the result, users prefer to do partial computations locally and upload intermediate representations to the cloud for subsequent inference.However, recent studies have shown that intermediate representations can also be recovered to plain text with reasonable accuracy, thus the risk of privacy leakage still exists. To address this issue, we propose TextFusion, a novel method for preserving inference privacy.Specifically, we train a Fusion Predictor to dynamically fuse token representations, which hides multiple private token representations behind an unrecognizable one.Furthermore, an adversarial training regime is employed to privatize these representations. In this way, the cloud only receives incomplete and perturbed representations, making it difficult to accurately recover the complete plain text.The experimental results on diverse classification tasks show that our approach can effectively preserve inference privacy without significantly sacrificing performance in different scenarios.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.572.pdf"
    },
    {
        "title": "IELM: An Open Information Extraction Benchmark for Pre-Trained Language Models",
        "authors": [
            "Chenguang Wang",
            "Xiao Liu",
            "Dawn Song"
        ],
        "published": "2022",
        "summary": "We introduce a new open information extraction (OIE) benchmark for pre-trained language models (LM). Recent studies have demonstrated that pre-trained LMs, such as BERT and GPT, may store linguistic and relational knowledge. In particular, LMs are able to answer “fill-in-the-blank” questions when given a pre-defined relation category. Instead of focusing on pre-defined relations, we create an OIE benchmark aiming to fully examine the open relational information present in the pre-trained LMs. We accomplish this by turning pre-trained LMs into zero-shot OIE systems. Surprisingly, pre-trained LMs are able to obtain competitive performance on both standard OIE datasets (CaRB and Re-OIE2016) and two new large-scale factual OIE datasets (TAC KBP-OIE and Wikidata-OIE) that we establish via distant supervision. For instance, the zero-shot pre-trained LMs outperform the F1 score of the state-of-the-art supervised OIE methods on our factual OIE datasets without needing to use any training sets.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.576.pdf"
    },
    {
        "title": "ACENet: Attention Guided Commonsense Reasoning on Hybrid Knowledge Graph",
        "authors": [
            "Chuzhan Hao",
            "Minghui Xie",
            "Peng Zhang"
        ],
        "published": "2022",
        "summary": "Augmenting pre-trained language models (PLMs) with knowledge graphs (KGs) has demonstrated superior performance on commonsense reasoning. Given a commonsense based QA context (question and multiple choices), existing approaches usually estimate the plausibility of candidate choices separately based on their respective retrieved KGs, without considering the interference among different choices. In this paper, we propose an Attention guided Commonsense rEasoning Network (ACENet) to endow the neural network with the capability of integrating hybrid knowledge. Specifically, our model applies the multi-layer interaction of answer choices to continually strengthen correct choice information and guide the message passing of GNN. In addition, we also design a mix attention mechanism of nodes and edges to iteratively select supporting evidence on hybrid knowledge graph. Experimental results demonstrate the effectiveness of our proposed model through considerable performance gains across CommonsenseQA and OpenbookQA datasets.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.579.pdf"
    },
    {
        "title": "IRRGN: An Implicit Relational Reasoning Graph Network for Multi-turn Response Selection",
        "authors": [
            "Jingcheng Deng",
            "Hengwei Dai",
            "Xuewei Guo",
            "Yuanchen Ju",
            "Wei Peng"
        ],
        "published": "2022",
        "summary": "The task of response selection in multi-turn dialogue is to find the best option from all candidates. In order to improve the reasoning ability of the model, previous studies pay more attention to using explicit algorithms to model the dependencies between utterances, which are deterministic, limited and inflexible. In addition, few studies consider differences between the options before and after reasoning. In this paper, we propose an Implicit Relational Reasoning Graph Network to address these issues, which consists of the Utterance Relational Reasoner (URR) and the Option Dual Comparator (ODC). URR aims to implicitly extract dependencies between utterances, as well as utterances and options, and make reasoning with relational graph convolutional networks. ODC focuses on perceiving the difference between the options through dual comparison, which can eliminate the interference of the noise options. Experimental results on two multi-turn dialogue reasoning benchmark datasets MuTual and MuTualplus show that our method significantly improves the baseline of four pre-trained language models and achieves state-of-the-art performance. The model surpasses human performance for the first time on the MuTual dataset.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.584.pdf"
    },
    {
        "title": "Contrastive Learning with Expectation-Maximization for Weakly Supervised Phrase Grounding",
        "authors": [
            "Keqin Chen",
            "Richong Zhang",
            "Samuel Mensah",
            "Yongyi Mao"
        ],
        "published": "2022",
        "summary": "Weakly supervised phrase grounding aims to learn an alignment between phrases in a caption and objects in a corresponding image using only caption-image annotations, i.e., without phrase-object annotations. Previous methods typically use a caption-image contrastive loss to indirectly supervise the alignment between phrases and objects, which hinders the maximum use of the intrinsic structure of the multimodal data and leads to unsatisfactory performance. In this work, we directly use the phrase-object contrastive loss in the condition that no positive annotation is available in the first place. Specifically, we propose a novel contrastive learning framework based on the expectation-maximization algorithm that adaptively refines the target prediction. Experiments on two widely used benchmarks, Flickr30K Entities and RefCOCO+, demonstrate the effectiveness of our framework. We obtain 63.05% top-1 accuracy on Flickr30K Entities and 59.51%/43.46% on RefCOCO+ TestA/TestB, outperforming the previous methods by a large margin, even surpassing a previous SoTA that uses a pre-trained vision-language model. Furthermore, we deliver a theoretical analysis of the effectiveness of our method from the perspective of the maximum likelihood estimate with latent variables.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.586.pdf"
    },
    {
        "title": "Beyond prompting: Making Pre-trained Language Models Better Zero-shot Learners by Clustering Representations",
        "authors": [
            "Yu Fei",
            "Zhao Meng",
            "Ping Nie",
            "Roger Wattenhofer",
            "Mrinmaya Sachan"
        ],
        "published": "2022",
        "summary": "Recent work has demonstrated that pre-trained language models (PLMs) are zero-shot learners. However, most existing zero-shot methods involve heavy human engineering or complicated self-training pipelines, hindering their application to new situations. In this work, we show that zero-shot text classification can be improved simply by clustering texts in the embedding spaces of PLMs. Specifically, we fit the unlabeled texts with a Bayesian Gaussian Mixture Model after initializing cluster positions and shapes using class names. Despite its simplicity, this approach achieves superior or comparable performance on both topic and sentiment classification datasets and outperforms prior works significantly on unbalanced datasets. We further explore the applicability of our clustering approach by evaluating it on 14 datasets with more diverse topics, text lengths, and numbers of classes. Our approach achieves an average of 20% absolute improvement over prompt-based zero-shot learning. Finally, we compare different PLM embedding spaces and find that texts are well-clustered by topics even if the PLM is not explicitly pre-trained to generate meaningful sentence embeddings. This work indicates that PLM embeddings can categorize texts without task-specific fine-tuning, thus providing a new way to analyze and utilize their knowledge and zero-shot learning ability.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.587.pdf"
    },
    {
        "title": "POQue: Asking Participant-specific Outcome Questions for a Deeper Understanding of Complex Events",
        "authors": [
            "Sai Vallurupalli",
            "Sayontan Ghosh",
            "Katrin Erk",
            "Niranjan Balasubramanian",
            "Francis Ferraro"
        ],
        "published": "2022",
        "summary": "Knowledge about outcomes is critical for complex event understanding but is hard to acquire.We show that by pre-identifying a participant in a complex event, crowdworkers are ableto (1) infer the collective impact of salient events that make up the situation, (2) annotate the volitional engagement of participants in causing the situation, and (3) ground theoutcome of the situation in state changes of the participants. By creating a multi-step interface and a careful quality control strategy, we collect a high quality annotated dataset of8K short newswire narratives and ROCStories with high inter-annotator agreement (0.74-0.96weighted Fleiss Kappa). Our dataset, POQUe (Participant Outcome Questions), enables theexploration and development of models that address multiple aspects of semantic understanding. Experimentally, we show that current language models lag behind human performance in subtle ways through our task formulations that target abstract and specific comprehension of a complex event, its outcome, and a participant’s influence over the event culmination.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.594.pdf"
    },
    {
        "title": "T-STAR: Truthful Style Transfer using AMR Graph as Intermediate Representation",
        "authors": [
            "Anubhav Jangra",
            "Preksha Nema",
            "Aravindan Raghuveer"
        ],
        "published": "2022",
        "summary": "Unavailability of parallel corpora for training text style transfer (TST) models is a very challenging yet common scenario. Also, TST models implicitly need to preserve the content while transforming a source sentence into the target style. To tackle these problems, an intermediate representation is often constructed that is devoid of style while still preserving the meaning of the source sentence. In this work, we study the usefulness of Abstract Meaning Representation (AMR) graph as the intermediate style agnostic representation. We posit that semantic notations like AMR are a natural choice for an intermediate representation. Hence, we propose T-STAR: a model comprising of two components, text-to-AMR encoder and a AMR-to-text decoder. We propose several modeling improvements to enhance the style agnosticity of the generated AMR. To the best of our knowledge, T-STAR is the first work that uses AMR as an intermediate representation for TST. With thorough experimental evaluation we show T-STAR significantly outperforms state of the art techniques by achieving on an average 15.2% higher content preservation with negligible loss (~3%) in style accuracy. Through detailed human evaluation with 90,000 ratings, we also show that T-STAR has upto 50% lesser hallucinations compared to state of the art TST models.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.602.pdf"
    },
    {
        "title": "Distilled Dual-Encoder Model for Vision-Language Understanding",
        "authors": [
            "Zekun Wang",
            "Wenhui Wang",
            "Haichao Zhu",
            "Ming Liu",
            "Bing Qin",
            "Furu Wei"
        ],
        "published": "2022",
        "summary": "On vision-language understanding (VLU) tasks, fusion-encoder vision-language models achieve superior results but sacrifice efficiency because of the simultaneous encoding of images and text. On the contrary, the dual encoder model that separately encodes images and text has the advantage in efficiency, while failing on VLU tasks due to the lack of deep cross-modal interactions. To get the best of both worlds, we propose DiDE, a framework that distills the knowledge of the fusion-encoder teacher model into the dual-encoder student model. Since the cross-modal interaction is the key to the superior performance of teacher model but is absent in the student model, we encourage the student not only to mimic the predictions of teacher, but also to calculate the cross-modal attention distributions and align with the teacher. Experimental results demonstrate that DiDE is competitive with the fusion-encoder teacher model in performance (only a 1% drop) while enjoying 4 times faster inference. Further analyses reveal that the proposed cross-modal attention distillation is crucial to the success of our framework.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.608.pdf"
    },
    {
        "title": "Rainier: Reinforced Knowledge Introspector for Commonsense Question Answering",
        "authors": [
            "Jiacheng Liu",
            "Skyler Hallinan",
            "Ximing Lu",
            "Pengfei He",
            "Sean Welleck",
            "Hannaneh Hajishirzi",
            "Yejin Choi"
        ],
        "published": "2022",
        "summary": "Knowledge underpins reasoning. Recent research demonstrates that when relevant knowledge is provided as additional context to commonsense question answering (QA), it can substantially enhance the performance even on top of state-of-the-art. The fundamental challenge is where and how to find such knowledge that is high quality and on point with respect to the question; knowledge retrieved from knowledge bases are incomplete and knowledge generated from language models are inconsistent.We present Rainier, or Reinforced Knowledge Introspector, that learns to generate contextually relevant knowledge in response to given questions. Our approach starts by imitating knowledge generated by GPT-3, then learns to generate its own knowledge via reinforcement learning where rewards are shaped based on the increased performance on the resulting question answering. Rainier demonstrates substantial and consistent performance gains when tested over 9 different commonsense benchmarks: including 5 datasets that are seen during model training, as well as 4 datasets that are kept unseen. Our work is the first to report that knowledge generated by models that are orders of magnitude smaller than GPT-3, even without direct supervision on the knowledge itself, can exceed the quality of commonsense knowledge elicited from GPT-3.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.611.pdf"
    },
    {
        "title": "Few-shot Learning with Multilingual Generative Language Models",
        "authors": [
            "Xi Victoria Lin",
            "Todor Mihaylov",
            "Mikel Artetxe",
            "Tianlu Wang",
            "Shuohui Chen",
            "Daniel Simig",
            "Myle Ott",
            "Naman Goyal",
            "Shruti Bhosale",
            "Jingfei Du",
            "Ramakanth Pasunuru",
            "Sam Shleifer",
            "Punit Singh Koura",
            "Vishrav Chaudhary",
            "Brian O’Horo",
            "Jeff Wang",
            "Luke Zettlemoyer",
            "Zornitsa Kozareva",
            "Mona Diab",
            "Veselin Stoyanov",
            "Xian Li"
        ],
        "published": "2022",
        "summary": "Large-scale generative language models such as GPT-3 are competitive few-shot learners. While these models are known to be able to jointly represent many different languages, their training data is dominated by English, potentially limiting their cross-lingual generalization. In this work, we train multilingual generative language models on a corpus covering a diverse set of languages, and study their few- and zero-shot learning capabilities in a wide range of tasks. Our largest model with 7.5 billion parameters sets new state of the art in few-shot learning in more than 20 representative languages, outperforming GPT-3 of comparable size in multilingual commonsense reasoning (with +7.4% absolute accuracy improvement in 0-shot settings and +9.4% in 4-shot settings) and natural language inference (+5.4% in each of 0-shot and 4-shot settings). On the FLORES-101 machine translation benchmark, our model outperforms GPT-3 on 171 out of 182 directions with 32 training examples, while surpassing the official supervised baseline in 45 directions. We conduct an in-depth analysis of different multilingual prompting approaches, showing in particular that strong few-shot learning performance across languages can be achieved via cross-lingual transfer through both templates and demonstration examples.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.616.pdf"
    },
    {
        "title": "Are representations built from the ground up? An empirical examination of local composition in language models",
        "authors": [
            "Emmy Liu",
            "Graham Neubig"
        ],
        "published": "2022",
        "summary": "Compositionality, the phenomenon where the meaning of a phrase can be derived from its constituent parts, is a hallmark of human language. At the same time, many phrases are non-compositional, carrying a meaning beyond that of each part in isolation. Representing both of these types of phrases is critical for language understanding, but it is an open question whether modern language models (LMs) learn to do so; in this work we examine this question. We first formulate a problem of predicting the LM-internal representations of longer phrases given those of their constituents. We find that the representation of a parent phrase can be predicted with some accuracy given an affine transformation of its children. While we would expect the predictive accuracy to correlate with human judgments of semantic compositionality, we find this is largely not the case, indicating that LMs may not accurately distinguish between compositional and non-compositional phrases. We perform a variety of analyses, shedding light on when different varieties of LMs do and do not generate compositional representations, and discuss implications for future modeling work.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.617.pdf"
    },
    {
        "title": "Detecting Label Errors by Using Pre-Trained Language Models",
        "authors": [
            "Derek Chong",
            "Jenny Hong",
            "Christopher Manning"
        ],
        "published": "2022",
        "summary": "We show that large pre-trained language models are inherently highly capable of identifying label errors in natural language datasets: simply examining out-of-sample data points in descending order of fine-tuned task loss significantly outperforms more complex error-detection mechanisms proposed in previous work. To this end, we contribute a novel method for introducing realistic, human-originated label noise into existing crowdsourced datasets such as SNLI and TweetNLP. We show that this noise has similar properties to real, hand-verified label errors, and is harder to detect than existing synthetic noise, creating challenges for model robustness.We argue that human-originated noise is a better standard for evaluation than synthetic noise. Finally, we use crowdsourced verification to evaluate the detection of real errors on IMDB, Amazon Reviews, and Recon, and confirm that pre-trained models perform at a 9–36% higher absolute Area Under the Precision-Recall Curve than existing models.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.618.pdf"
    },
    {
        "title": "Intriguing Properties of Compression on Multilingual Models",
        "authors": [
            "Kelechi Ogueji",
            "Orevaoghene Ahia",
            "Gbemileke Onilude",
            "Sebastian Gehrmann",
            "Sara Hooker",
            "Julia Kreutzer"
        ],
        "published": "2022",
        "summary": "Multilingual models are often particularly dependent on scaling to generalize to a growing number of languages. Compression techniques are widely relied upon to reconcile the growth in model size with real world resource constraints, but compression can have a disparate effect on model performance for low-resource languages. It is thus crucial to understand the trade-offs between scale, multilingualism, and compression. In this work, we propose an experimental framework to characterize the impact of sparsifying multilingual pre-trained language models during fine-tuning.Applying this framework to mBERT named entity recognition models across 40 languages, we find that compression confers several intriguing and previously unknown generalization properties. In contrast to prior findings, we find that compression may improve model robustness over dense models. We additionally observe that under certain sparsification regimes compression may aid, rather than disproportionately impact the performance of low-resource languages.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.619.pdf"
    },
    {
        "title": "Active Example Selection for In-Context Learning",
        "authors": [
            "Yiming Zhang",
            "Shi Feng",
            "Chenhao Tan"
        ],
        "published": "2022",
        "summary": "With a handful of demonstration examples, large-scale language models demonstrate strong capability to perform various tasks by in-context learning from these examples, without any fine-tuning. We demonstrate that in-context learning performance can be highly unstable across samples of examples, indicating the idiosyncrasies of how language models acquire information. We formulate example selection for in-context learning as a sequential decision problem, and propose a reinforcement learning algorithm for identifying generalizable policies to select demonstration examples. For GPT-2, our learned policies demonstrate strong abilities of generalizing to unseen tasks in training, with a 5.8% improvement on average. Examples selected from our learned policies can even achieve a small improvement on GPT-3 Ada. However, the improvement diminishes on larger GPT-3 models, suggesting emerging capabilities of large language models.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.622.pdf"
    },
    {
        "title": "Evaluating the Impact of Model Scale for Compositional Generalization in Semantic Parsing",
        "authors": [
            "Linlu Qiu",
            "Peter Shaw",
            "Panupong Pasupat",
            "Tianze Shi",
            "Jonathan Herzig",
            "Emily Pitler",
            "Fei Sha",
            "Kristina Toutanova"
        ],
        "published": "2022",
        "summary": "Despite their strong performance on many tasks, pre-trained language models have been shown to struggle on out-of-distribution compositional generalization. Meanwhile, recent work has shown considerable improvements on many NLP tasks from model scaling. Can scaling up model size also improve compositional generalization in semantic parsing? We evaluate encoder-decoder models up to 11B parameters and decoder-only models up to 540B parameters, and compare model scaling curves for three different methods for applying a pre-trained language model to a new task: fine-tuning all parameters, prompt tuning, and in-context learning. We observe that fine-tuning generally has flat or negative scaling curves on out-of-distribution compositional generalization in semantic parsing evaluations. In-context learning has positive scaling curves, but is generally outperformed by much smaller fine-tuned models. Prompt-tuning can outperform fine-tuning, suggesting further potential improvements from scaling as it exhibits a more positive scaling curve. Additionally, we identify several error trends that vary with model scale. For example, larger models are generally better at modeling the syntax of the output space, but are also more prone to certain types of overfitting. Overall, our study highlights limitations of current techniques for effectively leveraging model scale for compositional generalization, while our analysis also suggests promising directions for future work.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.624.pdf"
    },
    {
        "title": "“I’m sorry to hear that”: Finding New Biases in Language Models with a Holistic Descriptor Dataset",
        "authors": [
            "Eric Michael Smith",
            "Melissa Hall",
            "Melanie Kambadur",
            "Eleonora Presani",
            "Adina Williams"
        ],
        "published": "2022",
        "summary": "As language models grow in popularity, it becomes increasingly important to clearly measure all possible markers of demographic identity in order to avoid perpetuating existing societal harms. Many datasets for measuring bias currently exist, but they are restricted in their coverage of demographic axes and are commonly used with preset bias tests that presuppose which types of biases models can exhibit. In this work, we present a new, more inclusive bias measurement dataset, HolisticBias, which includes nearly 600 descriptor terms across 13 different demographic axes. HolisticBias was assembled in a participatory process including experts and community members with lived experience of these terms. These descriptors combine with a set of bias measurement templates to produce over 450,000 unique sentence prompts, which we use to explore, identify, and reduce novel forms of bias in several generative models. We demonstrate that HolisticBias is effective at measuring previously undetectable biases in token likelihoods from language models, as well as in an offensiveness classifier. We will invite additions and amendments to the dataset, which we hope will serve as a basis for more easy-to-use and standardized methods for evaluating bias in NLP models.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.625.pdf"
    },
    {
        "title": "CN-AutoMIC: Distilling Chinese Commonsense Knowledge from Pretrained Language Models",
        "authors": [
            "Chenhao Wang",
            "Jiachun Li",
            "Yubo Chen",
            "Kang Liu",
            "Jun Zhao"
        ],
        "published": "2022",
        "summary": "Commonsense knowledge graphs (CKGs) are increasingly applied in various natural language processing tasks. However, most existing CKGs are limited to English, which hinders related research in non-English languages. Meanwhile, directly generating commonsense knowledge from pretrained language models has recently received attention, yet it has not been explored in non-English languages. In this paper, we propose a large-scale Chinese CKG generated from multilingual PLMs, named as **CN-AutoMIC**, aiming to fill the research gap of non-English CKGs. To improve the efficiency, we propose generate-by-category strategy to reduce invalid generation. To ensure the filtering quality, we develop cascaded filters to discard low-quality results. To further increase the diversity and density, we introduce a bootstrapping iteration process to reuse generated results. Finally, we conduct detailed analyses on CN-AutoMIC from different aspects. Empirical results show the proposed CKG has high quality and diversity, surpassing the direct translation version of similar English CKGs. We also find some interesting deficiency patterns and differences between relations, which reveal pending problems in commonsense knowledge generation. We share the resources and related models for further study.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.628.pdf"
    },
    {
        "title": "Calibrating Student Models for Emotion-related Tasks",
        "authors": [
            "Mahshid Hosseini",
            "Cornelia Caragea"
        ],
        "published": "2022",
        "summary": "Knowledge Distillation (KD) is an effective method to transfer knowledge from one network (a.k.a. teacher) to another (a.k.a. student). In this paper, we study KD on the emotion-related tasks from a new perspective: calibration. We further explore the impact of the mixup data augmentation technique on the distillation objective and propose to use a simple yet effective mixup method informed by training dynamics for calibrating the student models. Underpinned by the regularization impact of the mixup process by providing better training signals to the student models using training dynamics, our proposed mixup strategy gradually enhances the student model’s calibration while effectively improving its performance. We evaluate the calibration of pre-trained language models through knowledge distillation over three tasks of emotion detection, sentiment analysis, and empathy detection. By conducting extensive experiments on different datasets, with both in-domain and out-of-domain test sets, we demonstrate that student models distilled from teacher models trained using our proposed mixup method obtained the lowest Expected Calibration Errors (ECEs) and best performance on both in-domain and out-of-domain test sets.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.629.pdf"
    },
    {
        "title": "Improving Large-scale Paraphrase Acquisition and Generation",
        "authors": [
            "Yao Dou",
            "Chao Jiang",
            "Wei Xu"
        ],
        "published": "2022",
        "summary": "This paper addresses the quality issues in existing Twitter-based paraphrase datasets, and discusses the necessity of using two separate definitions of paraphrase for identification and generation tasks. We present a new Multi-Topic Paraphrase in Twitter (MultiPIT) corpus that consists of a total of 130k sentence pairs with crowdsoursing (MultiPIT_crowd) and expert (MultiPIT_expert) annotations using two different paraphrase definitions for paraphrase identification, in addition to a multi-reference test set (MultiPIT_NMR) and a large automatically constructed training set (MultiPIT_Auto) for paraphrase generation. With improved data annotation quality and task-specific paraphrase definition, the best pre-trained language model fine-tuned on our dataset achieves the state-of-the-art performance of 84.2 F1 for automatic paraphrase identification. Furthermore, our empirical results also demonstrate that the paraphrase generation models trained on MultiPIT_Auto generate more diverse and high-quality paraphrases compared to their counterparts fine-tuned on other corpora such as Quora, MSCOCO, and ParaNMT.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.631.pdf"
    },
    {
        "title": "Entropy- and Distance-Based Predictors From GPT-2 Attention Patterns Predict Reading Times Over and Above GPT-2 Surprisal",
        "authors": [
            "Byung-Doh Oh",
            "William Schuler"
        ],
        "published": "2022",
        "summary": "Transformer-based large language models are trained to make predictions about the next word by aggregating representations of previous tokens through their self-attention mechanism. In the field of cognitive modeling, such attention patterns have recently been interpreted as embodying the process of cue-based retrieval, in which attention over multiple targets is taken to generate interference and latency during retrieval. Under this framework, this work first defines an entropy-based predictor that quantifies the diffuseness of self-attention, as well as distance-based predictors that capture the incremental change in attention patterns across timesteps. Moreover, following recent studies that question the informativeness of attention weights, we also experiment with alternative methods for incorporating vector norms into attention weights. Regression experiments using predictors calculated from the GPT-2 language model show that these predictors deliver a substantially better fit to held-out self-paced reading and eye-tracking data over a rigorous baseline including GPT-2 surprisal.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.632.pdf"
    },
    {
        "title": "Learning Cross-Task Dependencies for Joint Extraction of Entities, Events, Event Arguments, and Relations",
        "authors": [
            "Minh Van Nguyen",
            "Bonan Min",
            "Franck Dernoncourt",
            "Thien Nguyen"
        ],
        "published": "2022",
        "summary": "Extracting entities, events, event arguments, and relations (i.e., task instances) from text represents four main challenging tasks in information extraction (IE), which have been solved jointly (JointIE) to boost the overall performance for IE. As such, previous work often leverages two types of dependencies between the tasks, i.e., cross-instance and cross-type dependencies representing relatedness between task instances and correlations between information types of the tasks. However, the cross-task dependencies in prior work are not optimal as they are only designed manually according to some task heuristics. To address this issue, we propose a novel model for JointIE that aims to learn cross-task dependencies from data. In particular, we treat each task instance as a node in a dependency graph where edges between the instances are inferred through information from different layers of a pretrained language model (e.g., BERT). Furthermore, we utilize the Chow-Liu algorithm to learn a dependency tree between information types for JointIE by seeking to approximate the joint distribution of the types from data. Finally, the Chow-Liu dependency tree is used to generate cross-type patterns, serving as anchor knowledge to guide the learning of representations and dependencies between instances for JointIE. Experimental results show that our proposed model significantly outperforms strong JointIE baselines over four datasets with different languages.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.634.pdf"
    },
    {
        "title": "Don’t Copy the Teacher: Data and Model Challenges in Embodied Dialogue",
        "authors": [
            "So Yeon Min",
            "Hao Zhu",
            "Ruslan Salakhutdinov",
            "Yonatan Bisk"
        ],
        "published": "2022",
        "summary": "Embodied dialogue instruction following requires an agent to complete a complex sequence of tasks from a natural language exchange. The recent introduction of benchmarks raises the question of how best to train and evaluate models for this multi-turn, multi-agent, long-horizon task. This paper contributes to that conversation, by arguing that imitation learning (IL) and related low-level metrics are actually misleading and do not align with the goals of embodied dialogue research and may hinder progress.We provide empirical comparisons of metrics, analysis of three models, and make suggestions for how the field might best progress. First, we observe that models trained with IL take spurious actions during evaluation. Second, we find that existing models fail to ground query utterances, which are essential for task completion. Third, we argue evaluation should focus on higher-level semantic goals. We will release code to additionally filter the data and benchmark models for improved evaluation.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.635.pdf"
    },
    {
        "title": "ALFRED-L: Investigating the Role of Language for Action Learning in Interactive Visual Environments",
        "authors": [
            "Arjun Akula",
            "Spandana Gella",
            "Aishwarya Padmakumar",
            "Mahdi Namazifar",
            "Mohit Bansal",
            "Jesse Thomason",
            "Dilek Hakkani-Tur"
        ],
        "published": "2022",
        "summary": "Embodied Vision and Language Task Completion requires an embodied agent to interpret natural language instructions and egocentric visual observations to navigate through and interact with environments. In this work, we examine ALFRED, a challenging benchmark for embodied task completion, with the goal of gaining insight into how effectively models utilize language. We find evidence that sequence-to-sequence and transformer-based models trained on this benchmark are not sufficiently sensitive to changes in input language instructions. Next, we construct a new test split – ALFRED-L to test whether ALFRED models can generalize to task structures not seen during training that intuitively require the same types of language understanding required in ALFRED. Evaluation of existing models on ALFRED-L suggests that (a) models are overly reliant on the sequence in which objects are visited in typical ALFRED trajectories and fail to adapt to modifications of this sequence and (b) models trained with additional augmented trajectories are able to adapt relatively better to such changes in input language instructions.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.636.pdf"
    },
    {
        "title": "Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence",
        "authors": [
            "Chris Callison-Burch",
            "Gaurav Singh Tomar",
            "Lara J. Martin",
            "Daphne Ippolito",
            "Suma Bailis",
            "David Reitter"
        ],
        "published": "2022",
        "summary": "AI researchers have posited Dungeons and Dragons (D&D) as a challenge problem to test systems on various language-related capabilities. In this paper, we frame D&D specifically as a dialogue system challenge, where the tasks are to both generate the next conversational turn in the game and predict the state of the game given the dialogue history. We create a gameplay dataset consisting of nearly 900 games, with a total of 7,000 players, 800,000 dialogue turns, 500,000 dice rolls, and 58 million words. We automatically annotate the data with partial state information about the game play. We train a large language model (LM) to generate the next game turn, conditioning it on different information. The LM can respond as a particular character or as the player who runs the game—i.e., the Dungeon Master (DM). It is trained to produce dialogue that is either in-character (roleplaying in the fictional world) or out-of-character (discussing rules or strategy). We perform a human evaluation to determine what factors make the generated output plausible and interesting. We further perform an automatic evaluation to determine how well the model can predict the game state given the history and examine how well tracking the game state improves its ability to produce plausible conversational output.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.637.pdf"
    },
    {
        "title": "Towards Teachable Reasoning Systems: Using a Dynamic Memory of User Feedback for Continual System Improvement",
        "authors": [
            "Bhavana Dalvi Mishra",
            "Oyvind Tafjord",
            "Peter Clark"
        ],
        "published": "2022",
        "summary": "Our goal is a teachable reasoning system for question-answering (QA), where a user can interact with faithful answer explanations, and correct its errors so that the system improves over time. Our approach is to augment a QA model with a dynamic memory of user feedback, containing user-supplied corrections toerroneous model beliefs that users identify during interaction. Retrievals from memory are used as additional context for QA, to help avoid previous mistakes in similar new situations - a novel application of memory-based continuous learning. With simulated feedback, we find that our system (called TeachMe) continually improves with time, and without model retraining, requiring feedback on only 25% of training examples to reach within 1% of the upper-bound (feedback on all examples). Similarly, in experiments with real users, we observe a similar trend, with performance improving by over 15% on a hidden test set after teaching. This suggests new opportunities for using frozen language models in an interactive setting where users can inspect, debug, and correct the model’s beliefs, leading to improved system’s performance over time.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.644.pdf"
    },
    {
        "title": "Perturbation Augmentation for Fairer NLP",
        "authors": [
            "Rebecca Qian",
            "Candace Ross",
            "Jude Fernandes",
            "Eric Michael Smith",
            "Douwe Kiela",
            "Adina Williams"
        ],
        "published": "2022",
        "summary": "Unwanted and often harmful social biases are becoming ever more salient in NLP research, affecting both models and datasets. In this work, we ask whether training on demographically perturbed data leads to fairer language models. We collect a large dataset of human annotated text perturbations and train a neural perturbation model, which we show outperforms heuristic alternatives. We find that (i) language models (LMs) pre-trained on demographically perturbed corpora are typically more fair, and (ii) LMs finetuned on perturbed GLUE datasets exhibit less demographic bias on downstream tasks, and (iii) fairness improvements do not come at the expense of performance on downstream tasks. Lastly, we discuss outstanding questions about how best to evaluate the (un)fairness of large language models. We hope that this exploration of neural demographic perturbation will help drive more improvement towards fairer NLP.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.646.pdf"
    },
    {
        "title": "Automatic Document Selection for Efficient Encoder Pretraining",
        "authors": [
            "Yukun Feng",
            "Patrick Xia",
            "Benjamin Van Durme",
            "João Sedoc"
        ],
        "published": "2022",
        "summary": "Building pretrained language models is considered expensive and data-intensive, but must we increase dataset size to achieve better performance? We propose an alternative to larger training sets by automatically identifying smaller yet domain-representative subsets. We extend Cynical Data Selection, a statistical sentence scoring method that conditions on a representative target domain corpus. As an example, we treat the OntoNotes corpus as a target domain and pretrain a RoBERTa-like encoder from a cynically selected subset of the Pile. On both perplexity and across several downstream tasks in the target domain, it consistently outperforms random selection with 20x less data, 3x fewer training iterations, and 2x less estimated cloud compute cost, validating the recipe of automatic document selection for LM pretraining.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.647.pdf"
    },
    {
        "title": "DEMETR: Diagnosing Evaluation Metrics for Translation",
        "authors": [
            "Marzena Karpinska",
            "Nishant Raj",
            "Katherine Thai",
            "Yixiao Song",
            "Ankita Gupta",
            "Mohit Iyyer"
        ],
        "published": "2022",
        "summary": "While machine translation evaluation metrics based on string overlap (e.g., BLEU) have their limitations, their computations are transparent: the BLEU score assigned to a particular candidate translation can be traced back to the presence or absence of certain words. The operations of newer learned metrics (e.g., BLEURT, COMET), which leverage pretrained language models to achieve higher correlations with human quality judgments than BLEU, are opaque in comparison. In this paper, we shed light on the behavior of these learned metrics by creating DEMETR, a diagnostic dataset with 31K English examples (translated from 10 source languages) for evaluating the sensitivity of MT evaluation metrics to 35 different linguistic perturbations spanning semantic, syntactic, and morphological error categories. All perturbations were carefully designed to form minimal pairs with the actual translation (i.e., differ in only one aspect). We find that learned metrics perform substantially better than string-based metrics on DEMETR. Additionally, learned metrics differ in their sensitivity to various phenomena (e.g., BERTScore is sensitive to untranslated words but relatively insensitive to gender manipulation, while COMET is much more sensitive to word repetition than to aspectual changes). We publicly release DEMETR to spur more informed future development of machine translation evaluation metrics",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.649.pdf"
    },
    {
        "title": "Empowering Language Models with Knowledge Graph Reasoning for Open-Domain Question Answering",
        "authors": [
            "Ziniu Hu",
            "Yichong Xu",
            "Wenhao Yu",
            "Shuohang Wang",
            "Ziyi Yang",
            "Chenguang Zhu",
            "Kai-Wei Chang",
            "Yizhou Sun"
        ],
        "published": "2022",
        "summary": "Answering open-domain questions requires world knowledge about in-context entities. As pre-trained Language Models (LMs) lack the power to store all required knowledge, external knowledge sources, such as knowledge graphs, are often used to augment LMs. In this work, we propose knOwledge REasOning empowered Language Model(OREO-LM), which consists of a novel Knowledge Interaction Layer that can be flexibly plugged into existing Transformer-based LMs to interact with a differentiable Knowledge Graph Reasoning module collaboratively. In this way, LM guides KG to walk towards the desired answer, while the retrieved knowledge improves LM.By adopting OREO-LM to RoBERTa and T5, we show significant performance gain, achieving state-of-art results in the Closed-Book setting. The performance enhancement is mainly from the KG reasoning’s capacity to infer missing relational facts. In addition, OREO-LM provides reasoning paths as rationales to interpret the model’s decision.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.650.pdf"
    },
    {
        "title": "RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners",
        "authors": [
            "Soumya Sanyal",
            "Zeyi Liao",
            "Xiang Ren"
        ],
        "published": "2022",
        "summary": "Transformers have been shown to be able to perform deductive reasoning on inputs containing rules and statements written in the English natural language. However, it is unclear if these models indeed follow rigorous logical reasoning to arrive at the prediction or rely on spurious correlation patterns in making decisions. A strong deductive reasoning model should consistently understand the semantics of different logical operators. To this end, we present RobustLR, a diagnostic benchmark that evaluates the robustness of language models to minimal logical edits in the inputs and different logical equivalence conditions. In our experiments with RoBERTa, T5, and GPT3 we show that the models trained on deductive reasoning datasets do not perform consistently on the RobustLR test set, thus showing that the models are not robust to our proposed logical perturbations. Further, we observe that the models find it especially hard to learn logical negation operators. Our results demonstrate the shortcomings of current language models in logical reasoning and call for the development of better inductive biases to teach the logical semantics to language models. All the datasets and code base have been made publicly available.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.653.pdf"
    },
    {
        "title": "Referee: Reference-Free Sentence Summarization with Sharper Controllability through Symbolic Knowledge Distillation",
        "authors": [
            "Melanie Sclar",
            "Peter West",
            "Sachin Kumar",
            "Yulia Tsvetkov",
            "Yejin Choi"
        ],
        "published": "2022",
        "summary": "We present Referee, a novel framework for sentence summarization that can be trained reference-free (i.e., requiring no gold summaries for supervision), while allowing direct control for compression ratio. Our work is the first to demonstrate that reference-free, controlled sentence summarization is feasible via the conceptual framework of Symbolic Knowledge Distillation (West et al., 2022), where latent knowledge in pre-trained language models is distilled via explicit examples sampled from the teacher models, further purified with three types of filters: length, fidelity, and Information Bottleneck. Moreover, we uniquely propose iterative distillation of knowledge, where student models from the previous iteration of distillation serve as teacher models in the next iteration. Starting off from a relatively modest set of GPT3-generated summaries, we demonstrate how iterative knowledge distillation can lead to considerably smaller, but better summarizers with sharper controllability. A useful by-product of this iterative distillation process is a high-quality dataset of sentence-summary pairs with varying degrees of compression ratios. Empirical results demonstrate that the final student models vastly outperform the much larger GPT3-Instruct model in terms of the controllability of compression ratios, without compromising the quality of resulting summarization.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.655.pdf"
    },
    {
        "title": "MABEL: Attenuating Gender Bias using Textual Entailment Data",
        "authors": [
            "Jacqueline He",
            "Mengzhou Xia",
            "Christiane Fellbaum",
            "Danqi Chen"
        ],
        "published": "2022",
        "summary": "Pre-trained language models encode undesirable social biases, which are further exacerbated in downstream use. To this end, we propose MABEL (a Method for Attenuating Gender Bias using Entailment Labels), an intermediate pre-training approach for mitigating gender bias in contextualized representations. Key to our approach is the use of a contrastive learning objective on counterfactually augmented, gender-balanced entailment pairs from natural language inference (NLI) datasets. We also introduce an alignment regularizer that pulls identical entailment pairs along opposite gender directions closer. We extensively evaluate our approach on intrinsic and extrinsic metrics, and show that MABEL outperforms previous task-agnostic debiasing approaches in terms of fairness. It also preserves task performance after fine-tuning on downstream tasks. Together, these findings demonstrate the suitability of NLI data as an effective means of bias mitigation, as opposed to only using unlabeled sentences in the literature. Finally, we identify that existing approaches often use evaluation settings that are insufficient or inconsistent. We make an effort to reproduce and compare previous methods, and call for unifying the evaluation settings across gender debiasing methods for better future comparison.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.657.pdf"
    },
    {
        "title": "Breakpoint Transformers for Modeling and Tracking Intermediate Beliefs",
        "authors": [
            "Kyle Richardson",
            "Ronen Tamari",
            "Oren Sultan",
            "Dafna Shahaf",
            "Reut Tsarfaty",
            "Ashish Sabharwal"
        ],
        "published": "2022",
        "summary": "Can we teach models designed for language understanding tasks to track and improve their beliefs through intermediate points in text? Besides making their inner workings more transparent, this would also help make models more reliable and consistent. To this end, we propose a representation learning framework called breakpoint modeling that allows for efficient and robust learning of this type. Given any text encoder and data marked with intermediate states (breakpoints) along with corresponding textual queries viewed as true/false propositions (i.e., the candidate intermediate beliefs of a model), our approach trains models in an efficient and end-to-end fashion to build intermediate representations that facilitate direct querying and training of beliefs at arbitrary points in text, alongside solving other end-tasks. We evaluate breakpoint modeling on a diverse set of NLU tasks including relation reasoning on Cluttr and narrative understanding on bAbI. Using novel proposition prediction tasks alongside these end-tasks, we show the benefit of our T5-based breakpoint transformer over strong conventional representation learning approaches in terms of processing efficiency, belief accuracy, and belief consistency, all with minimal to no degradation on the end-task. To show the feasibility of incorporating our belief tracker into more complex reasoning pipelines, we also obtain state-of-the-art performance on the three-tiered reasoning challenge for the recent TRIP benchmark (23-32% absolute improvement on Tasks 2-3).",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.658.pdf"
    },
    {
        "title": "Leveraging QA Datasets to Improve Generative Data Augmentation",
        "authors": [
            "Dheeraj Mekala",
            "Tu Vu",
            "Timo Schick",
            "Jingbo Shang"
        ],
        "published": "2022",
        "summary": "The ability of generative language models (GLMs) to generate text has improved considerably in the last few years, enabling their use for generative data augmentation. In this work, we propose CONDA, an approach to further improve GLM’s ability to generate synthetic data by reformulating data generation as context generation for a given question-answer (QA) pair and leveraging QA datasets for training context generators. Then, we cast downstream tasks into the same question answering format and adapt the fine-tuned context generators to the target task domain. Finally, we use the fine-tuned GLM to generate relevant contexts, which are in turn used as synthetic training data for their corresponding tasks. We perform extensive experiments on multiple classification datasets and demonstrate substantial improvements in performance for both few- and zero-shot settings. Our analysis reveals that QA datasets that require high-level reasoning abilities (e.g., abstractive and common-sense QA datasets) tend to give the best boost in performance in both few-shot and zero-shot settings.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.660.pdf"
    },
    {
        "title": "Meta-Learning Fast Weight Language Models",
        "authors": [
            "Kevin Clark",
            "Kelvin Guu",
            "Ming-Wei Chang",
            "Panupong Pasupat",
            "Geoffrey Hinton",
            "Mohammad Norouzi"
        ],
        "published": "2022",
        "summary": "Dynamic evaluation of language models (LMs) adapts model parameters at test time using gradient information from previous tokens and substantially improves LM performance. However, it requires over 3x more compute than standard inference. We present Fast Weight Layers (FWLs), a neural component that provides the benefits of dynamic evaluation much more efficiently by expressing gradient updates as linear attention. A key improvement over dynamic evaluation is that FWLs can also be applied at training time, so the model learns to make good use of gradient updates. FWLs can easily be added on top of existing transformer models, require relatively little extra compute or memory to run, and significantly improve language modeling perplexity.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.661.pdf"
    },
    {
        "title": "Hard Gate Knowledge Distillation - Leverage Calibration for Robust and Reliable Language Model",
        "authors": [
            "Dongkyu Lee",
            "Zhiliang Tian",
            "Yingxiu Zhao",
            "Ka Chun Cheung",
            "Nevin Zhang"
        ],
        "published": "2022",
        "summary": "In knowledge distillation, a student model is trained with supervisions from both knowledge from a teacher and observations drawn from a training data distribution. Knowledge of a teacher is considered a subject that holds inter-class relations which send a meaningful supervision to a student; hence, much effort has been put to find such knowledge to be distilled. In this paper, we explore a question that has been given little attention: “when to distill such knowledge.” The question is answered in our work with the concept of model calibration; we view a teacher model not only as a source of knowledge but also as a gauge to detect miscalibration of a student. This simple and yet novel view leads to a hard gate knowledge distillation scheme that switches between learning from a teacher model and training data. We verify the gating mechanism in the context of natural language generation at both the token-level and the sentence-level. Empirical comparisons with strong baselines show that hard gate knowledge distillation not only improves model generalization, but also significantly lowers model calibration error.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.665.pdf"
    },
    {
        "title": "Correcting Diverse Factual Errors in Abstractive Summarization via Post-Editing and Language Model Infilling",
        "authors": [
            "Vidhisha Balachandran",
            "Hannaneh Hajishirzi",
            "William Cohen",
            "Yulia Tsvetkov"
        ],
        "published": "2022",
        "summary": "Abstractive summarization models often generate inconsistent summaries containing factual errors or hallucinated content. Recent works focus on correcting factual errors in generated summaries via post-editing. Such correction models are trained using adversarial non-factual summaries constructed using heuristic rules for injecting errors. However, generating non-factual summaries using heuristics often does not generalize well to actual model errors. In this work, we propose to generate hard, representative synthetic examples of non-factual summaries through infilling language models. With this data, we train a more robust fact-correction model to post-edit the summaries to improve factual consistency. Through quantitative and qualitative experiments on two popular summarization datasets— CNN/DM and XSum—we show that our approach vastly outperforms prior methods in correcting erroneous summaries. Our model—FactEdit—improves factuality scores by over ~11 points on CNN/DM and over ~31 points on XSum on average across multiple summarization models, producing more factual summaries while maintaining competitive summarization quality.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.667.pdf"
    },
    {
        "title": "Polyglot Prompt: Multilingual Multitask Prompt Training",
        "authors": [
            "Jinlan Fu",
            "See-Kiong Ng",
            "Pengfei Liu"
        ],
        "published": "2022",
        "summary": "This paper aims for a potential architectural improvement for multilingual learning and asks: Can different tasks from different languages be modeled in a monolithic framework, i.e. without any task/language-specific module? The benefit of achieving this could open new doors for future multilingual research, including allowing systems trained on low resources to be further assisted by other languages as well as other tasks. We approach this goal by developing a learning framework named Polyglot Prompting to exploit prompting methods for learning a unified semantic space for different languages and tasks with multilingual prompt engineering. We performed a comprehensive evaluation of 6 tasks, namely topic classification, sentiment classification, named entity recognition, question answering, natural language inference, and summarization, covering 24 datasets and 49 languages. The experimental results demonstrated the efficacy of multilingual multitask prompt-based learning and led to inspiring observations. We also present an interpretable multilingual evaluation methodology and show how the proposed framework, multilingual multitask prompt training, works. We release all datasets prompted in the best setting and code.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.674.pdf"
    },
    {
        "title": "An Empirical Revisiting of Linguistic Knowledge Fusion in Language Understanding Tasks",
        "authors": [
            "Changlong Yu",
            "Tianyi Xiao",
            "Lingpeng Kong",
            "Yangqiu Song",
            "Wilfred Ng"
        ],
        "published": "2022",
        "summary": "Though linguistic knowledge emerges during large-scale language model pretraining, recent work attempt to explicitly incorporate human-defined linguistic priors into task-specific fine-tuning. Infusing language models with syntactic or semantic knowledge from parsers has shown improvements on many language understanding tasks. To further investigate the effectiveness of structural linguistic priors, we conduct empirical study of replacing parsed graphs or trees with trivial ones (rarely carrying linguistic knowledge e.g., balanced tree) for tasks in the GLUE benchmark. Encoding with trivial graphs achieves competitive or even better performance in fully-supervised and few-shot settings. It reveals that the gains might not be significantly attributed to explicit linguistic priors but rather to more feature interactions brought by fusion layers. Hence we call for attention to using trivial graphs as necessary baselines to design advanced knowledge fusion methods in the future.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.684.pdf"
    },
    {
        "title": "Prompt-based Distribution Alignment for Domain Generalization in Text Classification",
        "authors": [
            "Chen Jia",
            "Yue Zhang"
        ],
        "published": "2022",
        "summary": "Prompt-based learning (a.k.a. prompting) achieves high performance by bridging the gap between the objectives of language modeling and downstream tasks. Domain generalization ability can be improved by prompting since classification across different domains can be unified into the prediction of the same set of label words. The remaining challenge for domain generalization by prompting comes from discrepancies between the data distribution of different domains. To improve domain generalization with prompting, we learn distributional invariance across source domains via two alignment regularization loss functions. The first is vocabulary distribution alignment, which uses a Kullback-Leibler divergence regularization on source-domain vocabulary distributions. The second is feature distribution alignment, which uses a novel adversarial training strategy to learn domain invariant representation across source domains. Experiments on sentiment analysis and natural language inference show the effectiveness of our method and achieve state-of-the-art results on six datasets.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.690.pdf"
    },
    {
        "title": "Adapting a Language Model While Preserving its General Knowledge",
        "authors": [
            "Zixuan Ke",
            "Yijia Shao",
            "Haowei Lin",
            "Hu Xu",
            "Lei Shu",
            "Bing Liu"
        ],
        "published": "2022",
        "summary": "Domain-adaptive pre-training (or DA-training for short), also known as post-training, aimsto train a pre-trained general-purpose language model (LM) using an unlabeled corpus of aparticular domain to adapt the LM so that end-tasks in the domain can give improved performances. However, existing DA-training methods are in some sense blind as they do not explicitly identify what knowledge in the LM should be preserved and what should be changed by the domain corpus. This paper shows that the existing methods are suboptimal and proposes a novel method to perform a more informed adaptation of the knowledge in the LM by (1) soft-masking the attention heads based on their importance to best preserve the general knowledge in the LM and (2) contrasting the representations of the general and the full (both general and domain knowledge) to learn an integrated representation with both general and domain-specific knowledge. Experimental results will demonstrate the effectiveness of the proposed approach.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.693.pdf"
    },
    {
        "title": "Continual Training of Language Models for Few-Shot Learning",
        "authors": [
            "Zixuan Ke",
            "Haowei Lin",
            "Yijia Shao",
            "Hu Xu",
            "Lei Shu",
            "Bing Liu"
        ],
        "published": "2022",
        "summary": "Recent work on applying large language models (LMs) achieves impressive performance in many NLP applications. Adapting or posttraining an LM using an unlabeled domain corpus can produce even better performance for end-tasks in the domain. This paper proposes the problem of continually extending an LM by incrementally post-train the LM with a sequence of unlabeled domain corpora to expand its knowledge without forgetting its previous skills. The goal is to improve the few-shot end-task learning in these domains. The resulting system is called CPT (Continual PostTraining), which to our knowledge, is the first continual post-training system. Experimental results verify its effectiveness.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.695.pdf"
    },
    {
        "title": "Dictionary-Assisted Supervised Contrastive Learning",
        "authors": [
            "Patrick Y. Wu",
            "Richard Bonneau",
            "Joshua A. Tucker",
            "Jonathan Nagler"
        ],
        "published": "2022",
        "summary": "Text analysis in the social sciences often involves using specialized dictionaries to reason with abstract concepts, such as perceptions about the economy or abuse on social media. These dictionaries allow researchers to impart domain knowledge and note subtle usages of words relating to a concept(s) of interest. We introduce the dictionary-assisted supervised contrastive learning (DASCL) objective, allowing researchers to leverage specialized dictionaries when fine-tuning pretrained language models. The text is first keyword simplified: a common, fixed token replaces any word in the corpus that appears in the dictionary(ies) relevant to the concept of interest. During fine-tuning, a supervised contrastive objective draws closer the embeddings of the original and keyword-simplified texts of the same class while pushing further apart the embeddings of different classes. The keyword-simplified texts of the same class are more textually similar than their original text counterparts, which additionally draws the embeddings of the same class closer together. Combining DASCL and cross-entropy improves classification performance metrics in few-shot learning settings and social science applications compared to using cross-entropy alone and alternative contrastive and data augmentation methods.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.696.pdf"
    },
    {
        "title": "Fine-Tuning Pre-trained Transformers into Decaying Fast Weights",
        "authors": [
            "Huanru Henry Mao"
        ],
        "published": "2022",
        "summary": "Autoregressive Transformers are strong language models but incur O(T) complexity during per-token generation due to the self-attention mechanism. Recent work proposes kernel-based methods to approximate causal self-attention by replacing it with recurrent formulations with various update rules and feature maps to achieve O(1) time and memory complexity. We explore these approaches and find that they are unnecessarily complex, and propose a simple alternative - decaying fast weights - that runs fast on GPU, outperforms prior methods, and retains 99% of attention’s performance for GPT-2. We also show competitive performance on WikiText-103 against more complex attention substitutes.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.697.pdf"
    },
    {
        "title": "PRO-CS : An Instance-Based Prompt Composition Technique for Code-Switched Tasks",
        "authors": [
            "Srijan Bansal",
            "Suraj Tripathi",
            "Sumit Agarwal",
            "Teruko Mitamura",
            "Eric Nyberg"
        ],
        "published": "2022",
        "summary": "Code-switched (CS) data is ubiquitous in today’s globalized world, but the dearth of annotated datasets in code-switching poses a significant challenge for learning diverse tasks across different language pairs. Parameter-efficient prompt-tuning approaches conditioned on frozen language models have shown promise for transfer learning in limited-resource setups. In this paper, we propose a novel instance-based prompt composition technique, PRO-CS, for CS tasks that combine language and task knowledge. We compare our approach with prompt-tuning and fine-tuning for code-switched tasks on 10 datasets across 4 language pairs. Our model outperforms the prompt-tuning approach by significant margins across all datasets and outperforms or remains at par with fine-tuning by using just 0.18% of total parameters. We also achieve competitive results when compared with the fine-tuned model in the low-resource cross-lingual and cross-task setting, indicating the effectiveness of our approach to incorporate new code-switched tasks.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.698.pdf"
    },
    {
        "title": "Graph-Induced Transformers for Efficient Multi-Hop Question Answering",
        "authors": [
            "Giwon Hong",
            "Jeonghwan Kim",
            "Junmo Kang",
            "Sung-Hyon Myaeng"
        ],
        "published": "2022",
        "summary": "A graph is a suitable data structure to represent the structural information of text. Recently, multi-hop question answering (MHQA) tasks, which require inter-paragraph/sentence linkages, have come to exploit such properties of a graph. Previous approaches to MHQA relied on leveraging the graph information along with the pre-trained language model (PLM) encoders. However, this trend exhibits the following drawbacks: (i) sample inefficiency while training in a low-resource setting; (ii) lack of reusability due to changes in the model structure or input. Our work proposes the Graph-Induced Transformer (GIT) that applies graph-derived attention patterns directly into a PLM, without the need to employ external graph modules. GIT can leverage the useful inductive bias of graphs while retaining the unperturbed Transformer structure and parameters. Our experiments on HotpotQA successfully demonstrate both the sample efficient characteristic of GIT and its capacity to replace the graph modules while preserving model performance.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.702.pdf"
    },
    {
        "title": "DiscoSense: Commonsense Reasoning with Discourse Connectives",
        "authors": [
            "Prajjwal Bhargava",
            "Vincent Ng"
        ],
        "published": "2022",
        "summary": "We present DiscoSense, a benchmark for commonsense reasoning via understanding a wide variety of discourse connectives. We generate compelling distractors in DiscoSense using Conditional Adversarial Filtering, an extension of Adversarial Filtering that employs conditional generation. We show that state-of-the-art pre-trained language models struggle to perform well on DiscoSense, which makes this dataset ideal for evaluating next-generation commonsense reasoning systems.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.703.pdf"
    },
    {
        "title": "MOCHA: A Multi-Task Training Approach for Coherent Text Generation from Cognitive Perspective",
        "authors": [
            "Zhe Hu",
            "Hou Pong Chan",
            "Lifu Huang"
        ],
        "published": "2022",
        "summary": "Teaching neural models to generate narrative coherent texts is a critical problem. Recent pre-trained language models have achieved promising results, but there is still a gap between human written texts and machine-generated outputs. In this work, we propose a novel multi-task training strategy for long text generation grounded on the cognitive theory of writing, which empowers the model to learn essential subskills needed for writing including planning and reviewing besides end-to-end generation. We extensively evaluate our model on three open-ended generation tasks including story generation, news article writing and argument generation. Experiments show that our model achieves better results on both few-shot and fully-supervised settings than strong baselines, and human evaluations confirm that our model can generate more coherent outputs.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.705.pdf"
    },
    {
        "title": "AMAL: Meta Knowledge-Driven Few-Shot Adapter Learning",
        "authors": [
            "S. K. Hong",
            "Tae Young Jang"
        ],
        "published": "2022",
        "summary": "NLP has advanced greatly together with the proliferation of Transformer-based pre-trained language models. To adapt to a downstream task, the pre-trained language models need to be fine-tuned with a sufficient supply of annotated examples. In recent years, Adapter-based fine-tuning methods have expanded the applicability of pre-trained language models by substantially lowering the required amount of annotated examples. However, existing Adapter-based methods still fail to yield meaningful results in the few-shot regime where only a few annotated examples are provided. In this study, we present a meta-learning-driven low-rank adapter pooling method, called AMAL, for leveraging pre-trained language models even with just a few data points. We evaluate our method on five text classification benchmark datasets. The results show that AMAL significantly outperforms previous few-shot learning methods and achieves a new state-of-the-art.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.709.pdf"
    },
    {
        "title": "“Covid vaccine is against Covid but Oxford vaccine is made at Oxford!” Semantic Interpretation of Proper Noun Compounds",
        "authors": [
            "Keshav Kolluru",
            "Gabriel Stanovsky",
            "Mausam -"
        ],
        "published": "2022",
        "summary": "Proper noun compounds, e.g., “Covid vaccine”, convey information in a succinct manner (a “Covid vaccine” is a “vaccine that immunizes against the Covid disease”). These are commonly used in short-form domains, such as news headlines, but are largely ignored in information-seeking applications. To address this limitation, we release a new manually annotated dataset, ProNCI, consisting of 22.5K proper noun compounds along with their free-form semantic interpretations. ProNCI is 60 times larger than prior noun compound datasets and also includes non-compositional examples, which have not been previously explored. We experiment with various neural models for automatically generating the semantic interpretations from proper noun compounds, ranging from few-shot prompting to supervised learning, with varying degrees of knowledge about the constituent nouns. We find that adding targeted knowledge, particularly about the common noun, results in performance gains of upto 2.8%. Finally, we integrate our model generated interpretations with an existing Open IE system and observe an 7.5% increase in yield at a precision of 85%. The dataset and code are available at https://github.com/dair-iitd/pronci.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.711.pdf"
    },
    {
        "title": "Context Limitations Make Neural Language Models More Human-Like",
        "authors": [
            "Tatsuki Kuribayashi",
            "Yohei Oseki",
            "Ana Brassard",
            "Kentaro Inui"
        ],
        "published": "2022",
        "summary": "Language models (LMs) have been used in cognitive modeling as well as engineering studies—they compute information-theoretic complexity metrics that simulate humans’ cognitive load during reading.This study highlights a limitation of modern neural LMs as the model of choice for this purpose: there is a discrepancy between their context access capacities and that of humans.Our results showed that constraining the LMs’ context access improved their simulation of human reading behavior.We also showed that LM-human gaps in context access were associated with specific syntactic constructions; incorporating syntactic biases into LMs’ context access might enhance their cognitive plausibility.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.712.pdf"
    },
    {
        "title": "A Generative Model for End-to-End Argument Mining with Reconstructed Positional Encoding and Constrained Pointer Mechanism",
        "authors": [
            "Jianzhu Bao",
            "Yuhang He",
            "Yang Sun",
            "Bin Liang",
            "Jiachen Du",
            "Bing Qin",
            "Min Yang",
            "Ruifeng Xu"
        ],
        "published": "2022",
        "summary": "Argument mining (AM) is a challenging task as it requires recognizing the complex argumentation structures involving multiple subtasks.To handle all subtasks of AM in an end-to-end fashion, previous works generally transform AM into a dependency parsing task.However, such methods largely require complex pre- and post-processing to realize the task transformation.In this paper, we investigate the end-to-end AM task from a novel perspective by proposing a generative framework, in which the expected outputs of AM are framed as a simple target sequence. Then, we employ a pre-trained sequence-to-sequence language model with a constrained pointer mechanism (CPM) to model the clues for all the subtasks of AM in the light of the target sequence. Furthermore, we devise a reconstructed positional encoding (RPE) to alleviate the order biases induced by the autoregressive generation paradigm.Experimental results show that our proposed framework achieves new state-of-the-art performance on two AM benchmarks.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.713.pdf"
    },
    {
        "title": "Reflect, Not Reflex: Inference-Based Common Ground Improves Dialogue Response Quality",
        "authors": [
            "Pei Zhou",
            "Hyundong Cho",
            "Pegah Jandaghi",
            "Dong-Ho Lee",
            "Bill Yuchen Lin",
            "Jay Pujara",
            "Xiang Ren"
        ],
        "published": "2022",
        "summary": "Human communication relies on common ground (CG), the mutual knowledge and beliefs shared by participants, to produce coherent and interesting conversations. In this paper, we demonstrate that current response generation (RG) models produce generic and dull responses in dialogues because they act reflexively, failing to explicitly model CG, both due to the lack of CG in training data and the standard RG training procedure. We introduce Reflect, a dataset that annotates dialogues with explicit CG (materialized as inferences approximating shared knowledge and beliefs) and solicits 9k diverse human-generated responses each following one common ground. Using Reflect, we showcase the limitations of current dialogue data and RG models: less than half of the responses in current data is rated as high quality (sensible, specific, and interesting) and models trained using this data have even lower quality, while most Reflect responses are judged high quality. Next, we analyze whether CG can help models produce better quality responses by using Reflect CG to guide RG models. Surprisingly, we find that simply prompting GPT3 to “think” about CG generates 30% more quality responses, showing promising benefits to integrating CG into the RG process.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.714.pdf"
    },
    {
        "title": "Evaluating the Knowledge Dependency of Questions",
        "authors": [
            "Hyeongdon Moon",
            "Yoonseok Yang",
            "Hangyeol Yu",
            "Seunghyun Lee",
            "Myeongho Jeong",
            "Juneyoung Park",
            "Jamin Shin",
            "Minsam Kim",
            "Seungtaek Choi"
        ],
        "published": "2022",
        "summary": "The automatic generation of Multiple Choice Questions (MCQ) has the potential to reduce the time educators spend on student assessment significantly. However, existing evaluation metrics for MCQ generation, such as BLEU, ROUGE, and METEOR, focus on the n-gram based similarity of the generated MCQ to the gold sample in the dataset and disregard their educational value.They fail to evaluate the MCQ’s ability to assess the student’s knowledge of the corresponding target fact. To tackle this issue, we propose a novel automatic evaluation metric, coined Knowledge Dependent Answerability (KDA), which measures the MCQ’s answerability given knowledge of the target fact. Specifically, we first show how to measure KDA based on student responses from a human survey.Then, we propose two automatic evaluation metrics, KDA_disc and KDA_cont, that approximate KDA by leveraging pre-trained language models to imitate students’ problem-solving behavior.Through our human studies, we show that KDA_disc and KDA_soft have strong correlations with both (1) KDA and (2) usability in an actual classroom setting, labeled by experts. Furthermore, when combined with n-gram based similarity metrics, KDA_disc and KDA_cont are shown to have a strong predictive power for various expert-labeled MCQ quality measures.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.718.pdf"
    },
    {
        "title": "Eliciting Knowledge from Large Pre-Trained Models for Unsupervised Knowledge-Grounded Conversation",
        "authors": [
            "Yanyang Li",
            "Jianqiao Zhao",
            "Michael Lyu",
            "Liwei Wang"
        ],
        "published": "2022",
        "summary": "Recent advances in large-scale pre-training provide large models with the potential to learn knowledge from the raw text. It is thus natural to ask whether it is possible to leverage these large models as knowledge bases for downstream tasks. In this work, we answer the aforementioned question in unsupervised knowledge-grounded conversation. We explore various methods that best elicit knowledge from large models. Our human study indicates that, though hallucinations exist, large models post the unique advantage of being able to output common sense and summarize facts that cannot be directly retrieved from the search engine. To better exploit such generated knowledge in dialogue generation, we treat the generated knowledge as a noisy knowledge source and propose the posterior-based reweighing as well as the noisy training strategy. Empirical results on two benchmarks show advantages over the state-of-the-art methods.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.721.pdf"
    },
    {
        "title": "An Unsupervised, Geometric and Syntax-aware Quantification of Polysemy",
        "authors": [
            "Anmol Goel",
            "Charu Sharma",
            "Ponnurangam Kumaraguru"
        ],
        "published": "2022",
        "summary": "Polysemy is the phenomenon where a single word form possesses two or more related senses. It is an extremely ubiquitous part of natural language and analyzing it has sparked rich discussions in the linguistics, psychology and philosophy communities alike. With scarce attention paid to polysemy in computational linguistics, and even scarcer attention toward quantifying polysemy, in this paper, we propose a novel, unsupervised framework to compute and estimate polysemy scores for words in multiple languages. We infuse our proposed quantification with syntactic knowledge in the form of dependency structures. This informs the final polysemy scores of the lexicon motivated by recent linguistic findings that suggest there is an implicit relation between syntax and ambiguity/polysemy. We adopt a graph based approach by computing the discrete Ollivier Ricci curvature on a graph of the contextual nearest neighbors. We test our framework on curated datasets controlling for different sense distributions of words in 3 typologically diverse languages - English, French and Spanish. The effectiveness of our framework is demonstrated by significant correlations of our quantification with expert human annotated language resources like WordNet. We observe a 0.3 point increase in the correlation coefficient as compared to previous quantification studies in English. Our research leverages contextual language models and syntactic structures to empirically support the widely held theoretical linguistic notion that syntax is intricately linked to ambiguity/polysemy.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.722.pdf"
    },
    {
        "title": "AdapterShare: Task Correlation Modeling with Adapter Differentiation",
        "authors": [
            "Zhi Chen",
            "Bei Chen",
            "Lu Chen",
            "Kai Yu",
            "Jian-Guang Lou"
        ],
        "published": "2022",
        "summary": "Thanks to the development of pre-trained language models, multitask learning (MTL) methods achieve a great success in natural language understanding area.However, current MTL methods pay more attention to task selection or model design to fuse as much knowledge as possible, while intrinsic task correlation is often neglected. It is important to learn sharing strategy among multiple tasks rather than sharing everything.%The MTL model is directly shared among all the tasks. %For example, in traditional MTL methods, the last classification layers or the decoder layers are manually separated. More deeply, In this paper, we propose AdapterShare, an adapter differentiation method to explicitly model the task correlation among multiple tasks. AdapterShare is automatically learned based on the gradients on tiny held-out validation data. Compared to single-task learning and fully shared MTL methods, our proposed method obtains obvious performance improvement. Compared to the existing MTL method AdapterFusion, AdapterShare achieves absolute 1.90 average points improvement on five dialogue understanding tasks and 2.33 points gain on NLU tasks.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.728.pdf"
    },
    {
        "title": "Rethinking Task-Specific Knowledge Distillation: Contextualized Corpus as Better Textbook",
        "authors": [
            "Chang Liu",
            "Chongyang Tao",
            "Jianxin Liang",
            "Tao Shen",
            "Jiazhan Feng",
            "Quzhe Huang",
            "Dongyan Zhao"
        ],
        "published": "2022",
        "summary": "Knowledge distillation has been proven effective when customizing small language models for specific tasks. Here, a corpus as ‘textbook’ plays an indispensable role, only through which the teacher can teach the student. Prevailing methods adopt a two-stage distillation paradigm: general distillation first with task-agnostic general corpus and task-specific distillation next with augmented task-specific corpus. We argue that such a paradigm may not be optimal. In general distillation, it’s extravagant to let the diverse but desultory general knowledge overwhelms the limited model capacity of the student. While in task-specific distillation, the task corpus is usually limited and narrow, preventing the student from learning enough knowledge. To mitigate the issues in the two gapped corpora, we present a better textbook for the student to learn: contextualized corpus that contextualizes task corpus with large-scale general corpus through relevance-based text retrieval. Experimental results on GLUE benchmark demonstrate that contextualized corpus is the better textbook compared with jointly using general corpus and augmented task-specific corpus. Surprisingly, it enables task-specific distillation from scratch without general distillation while maintaining comparable performance, making it more flexible to customize the student model with desired model size under various computation constraints.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.729.pdf"
    },
    {
        "title": "Quality Scoring of Source Words in Neural Translation Models",
        "authors": [
            "Priyesh Jain",
            "Sunita Sarawagi",
            "Tushar Tomar"
        ],
        "published": "2022",
        "summary": "Word-level quality scores on input source sentences can provide useful feedback to an end-user when translating into an unfamiliar target language. Recent approaches either require training special word-scoring models based on synthetic data or require repeated invocation of the translation model. We propose a simple approach based on comparing the difference of probabilities from two language models. The basic premise of our method is to reason how well each source word is explained by the target sentence as against the source language model. Our approach provides up to five points higher F1 scores and is significantly faster than the state of the art methods on three language pairs. Also, our method does not require training any new model. We release a public dataset on word omissions and mistranslations on a new language pair.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.732.pdf"
    },
    {
        "title": "Pneg: Prompt-based Negative Response Generation for Dialogue Response Selection Task",
        "authors": [
            "Nyoungwoo Lee",
            "ChaeHun Park",
            "Ho-Jin Choi",
            "Jaegul Choo"
        ],
        "published": "2022",
        "summary": "In retrieval-based dialogue systems, a response selection model acts as a ranker to select the most appropriate response among several candidates. However, such selection models tend to rely on context-response content similarity, which makes models vulnerable to adversarial responses that are semantically similar but not relevant to the dialogue context. Recent studies have shown that leveraging these adversarial responses as negative training samples is useful for improving the discriminating power of the selection model. Nevertheless, collecting human-written adversarial responses is expensive, and existing synthesizing methods often have limited scalability. To overcome these limitations, this paper proposes a simple but efficient method for generating adversarial negative responses leveraging a large-scale language model. Experimental results on dialogue selection tasks show that our method outperforms other methods of synthesizing adversarial negative responses. These results suggest that our method can be an effective alternative to human annotators in generating adversarial responses. Our code and dataset will be released if the paper is accepted.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.733.pdf"
    },
    {
        "title": "Don’t Stop Fine-Tuning: On Training Regimes for Few-Shot Cross-Lingual Transfer with Multilingual Language Models",
        "authors": [
            "Fabian David Schmidt",
            "Ivan Vulić",
            "Goran Glavaš"
        ],
        "published": "2022",
        "summary": "A large body of recent work highlights the fallacies of zero-shot cross-lingual transfer (ZS-XLT) with large multilingual language models. Namely, their performance varies substantially for different target languages and is the weakest where needed the most: for low-resource languages distant to the source language. One remedy is few-shot transfer (FS-XLT), where leveraging only a few task-annotated instances in the target language(s) may yield sizable performance gains. However, FS-XLT also succumbs to large variation, as models easily overfit to the small datasets. In this work, we present a systematic study focused on a spectrum of FS-XLT fine-tuning regimes, analyzing key properties such as effectiveness, (in)stability, and modularity. We conduct extensive experiments on both higher-level (NLI, paraphrasing) and lower-level tasks (NER, POS), presenting new FS-XLT strategies that yield both improved and more stable FS-XLT across the board. Our findings challenge established FS-XLT methods: e.g., we propose to replace sequential fine-tuning with joint fine-tuning on source and target language instances, offering consistent gains with different number of shots (including resource-rich scenarios). We also show that further gains can be achieved with multi-stage FS-XLT training in which joint multilingual fine-tuning precedes the bilingual source-target specialization.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.736.pdf"
    },
    {
        "title": "Structural Constraints and Natural Language Inference for End-to-End Flowchart Grounded Dialog Response Generation",
        "authors": [
            "Dinesh Raghu",
            "Suraj Joshi",
            "Sachindra Joshi",
            "Mausam -"
        ],
        "published": "2022",
        "summary": "Flowchart grounded dialog systems converse with users by following a given flowchart and a corpus of FAQs. The existing state-of-the-art approach (Raghu et al, 2021) for learning such a dialog system, named FLONET, has two main limitations. (1) It uses a Retrieval Augmented Generation (RAG) framework which represents a flowchart as a bag of nodes. By doing so, it loses the connectivity structure between nodes that can aid in better response generation. (2) Typically dialogs progress with the agent asking polar (Y/N) questions, but users often respond indirectly without the explicit use of polar words. In such cases, it fails to understand the correct polarity of the answer. To overcome these issues, we propose Structure-Aware FLONET (SA-FLONET) which infuses structural constraints derived from the connectivity structure of flowcharts into the RAG framework. It uses natural language inference to better predict the polarity of indirect Y/N answers. We find that SA-FLONET outperforms FLONET, with a success rate improvement of 68% and 123% in flowchart grounded response generation and zero-shot flowchart grounded response generation tasks respectively.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.739.pdf"
    },
    {
        "title": "SLICER: Sliced Fine-Tuning for Low-Resource Cross-Lingual Transfer for Named Entity Recognition",
        "authors": [
            "Fabian David Schmidt",
            "Ivan Vulić",
            "Goran Glavaš"
        ],
        "published": "2022",
        "summary": "Large multilingual language models generally demonstrate impressive results in zero-shot cross-lingual transfer, yet often fail to successfully transfer to low-resource languages, even for token-level prediction tasks like named entity recognition (NER). In this work, we introduce a simple yet highly effective approach for improving zero-shot transfer for NER to low-resource languages. We observe that NER fine-tuning in the source language decontextualizes token representations, i.e., tokens increasingly attend to themselves. This increased reliance on token information itself, we hypothesize, triggers a type of overfitting to properties that NE tokens within the source languages share, but are generally not present in NE mentions of target languages. As a remedy, we propose a simple yet very effective sliced fine-tuning for NER (SLICER) that forces stronger token contextualization in the Transformer: we divide the transformed token representations and classifier into disjoint slices that are then independently classified during training. We evaluate SLICER on two standard benchmarks for NER that involve low-resource languages, WikiANN and MasakhaNER, and show that it (i) indeed reduces decontextualization (i.e., extent to which NE tokens attend to themselves), consequently (ii) yielding consistent transfer gains, especially prominent for low-resource target languages distant from the source language.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.740.pdf"
    },
    {
        "title": "The better your Syntax, the better your Semantics? Probing Pretrained Language Models for the English Comparative Correlative",
        "authors": [
            "Leonie Weissweiler",
            "Valentin Hofmann",
            "Abdullatif Köksal",
            "Hinrich Schütze"
        ],
        "published": "2022",
        "summary": "Construction Grammar (CxG) is a paradigm from cognitive linguistics emphasising the connection between syntax and semantics. Rather than rules that operate on lexical items, it posits constructions as the central building blocks of language, i.e., linguistic units of different granularity that combine syntax and semantics. As a first step towards assessing the compatibility of CxG with the syntactic and semantic knowledge demonstrated by state-of-the-art pretrained language models (PLMs), we present an investigation of their capability to classify and understand one of the most commonly studied constructions, the English comparative correlative (CC). We conduct experiments examining the classification accuracy of a syntactic probe on the one hand and the models’ behaviour in a semantic application task on the other, with BERT, RoBERTa, and DeBERTa as the example PLMs. Our results show that all three investigated PLMs are able to recognise the structure of the CC but fail to use its meaning. While human-like performance of PLMs on many NLP tasks has been alleged, this indicates that PLMs still suffer from substantial shortcomings in central domains of linguistic knowledge.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.746.pdf"
    },
    {
        "title": "FETA: A Benchmark for Few-Sample Task Transfer in Open-Domain Dialogue",
        "authors": [
            "Alon Albalak",
            "Yi-Lin Tuan",
            "Pegah Jandaghi",
            "Connor Pryor",
            "Luke Yoffe",
            "Deepak Ramachandran",
            "Lise Getoor",
            "Jay Pujara",
            "William Yang Wang"
        ],
        "published": "2022",
        "summary": "Task transfer, transferring knowledge contained in related tasks, holds the promise of reducing the quantity of labeled data required to fine-tune language models. Dialogue understanding encompasses many diverse tasks, yet task transfer has not been thoroughly studied in conversational AI. This work explores conversational task transfer by introducing FETA: a benchmark for FEw-sample TAsk transfer in open-domain dialogue.FETA contains two underlying sets of conversations upon which there are 10 and 7 tasks annotated, enabling the study of intra-dataset task transfer; task transfer without domain adaptation. We utilize three popular language models and three learning algorithms to analyze the transferability between 132 source-target task pairs and create a baseline for future work.We run experiments in the single- and multi-source settings and report valuable findings, e.g., most performance trends are model-specific, and span extraction and multiple-choice tasks benefit the most from task transfer.In addition to task transfer, FETA can be a valuable resource for future research into the efficiency and generalizability of pre-training datasets and model architectures, as well as for learning settings such as continual and multitask learning.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.751.pdf"
    },
    {
        "title": "Do Children Texts Hold The Key To Commonsense Knowledge?",
        "authors": [
            "Julien Romero",
            "Simon Razniewski"
        ],
        "published": "2022",
        "summary": "Compiling comprehensive repositories of commonsense knowledge is a long-standing problem in AI. Many concerns revolve around the issue of reporting bias, i.e., that frequency in text sources is not a good proxy for relevance or truth. This paper explores whether children’s texts hold the key to commonsense knowledge compilation, based on the hypothesis that such content makes fewer assumptions on the reader’s knowledge, and therefore spells out commonsense more explicitly. An analysis with several corpora shows that children’s texts indeed contain much more, and more typical commonsense assertions. Moreover, experiments show that this advantage can be leveraged in popular language-model-based commonsense knowledge extraction settings, where task-unspecific fine-tuning on small amounts of children texts (childBERT) already yields significant improvements. This provides a refreshing perspective different from the common trend of deriving progress from ever larger models and corpora.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.752.pdf"
    },
    {
        "title": "IndicXNLI: Evaluating Multilingual Inference for Indian Languages",
        "authors": [
            "Divyanshu Aggarwal",
            "Vivek Gupta",
            "Anoop Kunchukuttan"
        ],
        "published": "2022",
        "summary": "While Indic NLP has made rapid advances recently in terms of the availability of corpora and pre-trained models, benchmark datasets on standard NLU tasks are limited. To this end, we introduce INDICXNLI, an NLI dataset for 11 Indic languages. It has been created by high-quality machine translation of the original English XNLI dataset and our analysis attests to the quality of INDICXNLI. By finetuning different pre-trained LMs on this INDICXNLI, we analyze various cross-lingual transfer techniques with respect to the impact of the choice of language models, languages, multi-linguality, mix-language input, etc. These experiments provide us with useful insights into the behaviour of pre-trained models for a diverse set of languages.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.755.pdf"
    },
    {
        "title": "XPrompt: Exploring the Extreme of Prompt Tuning",
        "authors": [
            "Fang Ma",
            "Chen Zhang",
            "Lei Ren",
            "Jingang Wang",
            "Qifan Wang",
            "Wei Wu",
            "Xiaojun Quan",
            "Dawei Song"
        ],
        "published": "2022",
        "summary": "Prompt tuning learns soft prompts to condition the frozen Pre-trained Language Models (PLMs) for performing downstream tasks in a parameter-efficient manner. While prompt tuning has gradually reached the performance level of fine-tuning as the model scale increases, there is still a large performance gap between prompt tuning and fine-tuning for models of moderate and small scales (typically less than 11B parameters). In this paper, we empirically show that the trained prompt tokens can have a negative impact on a downstream task and thus degrade its performance. To bridge the gap, we propose a novel Prompt tuning model with an eXtremely small scale (XPrompt) under the regime of lottery tickets hypothesis. Specifically, XPrompt eliminates the negative prompt tokens at different granularity levels through a hierarchical structured pruning, yielding a more parameter-efficient prompt yet with a competitive performance. Comprehensive experiments are carried out on the SuperGLUE tasks, and the results indicate that XPrompt is able to close the performance gap at smaller model scales.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.758.pdf"
    },
    {
        "title": "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?",
        "authors": [
            "Sewon Min",
            "Xinxi Lyu",
            "Ari Holtzman",
            "Mikel Artetxe",
            "Mike Lewis",
            "Hannaneh Hajishirzi",
            "Luke Zettlemoyer"
        ],
        "published": "2022",
        "summary": "Large language models (LMs) are able to in-context learn—perform a new task via inference alone by conditioning on a few input-label pairs (demonstrations) and making predictions for new inputs. However, there has been little understanding of how the model learns and which aspects of the demonstrations contribute to end task performance. In this paper, we show that ground truth demonstrations are in fact not required—randomly replacing labels in the demonstrations barely hurts performance on a range of classification and multi-choce tasks, consistently over 12 different models including GPT-3. Instead, we find that other aspects of the demonstrations are the key drivers of endtask performance, including the fact that they provide a few examples of (1) the label space, (2) the distribution of the input text, and (3) the overall format of the sequence. Together, our analysis provides a new way of understanding how and why in-context learning works, while opening up new questions about how much can be learned from large language models through inference alone.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.759.pdf"
    },
    {
        "title": "The Curious Case of Control",
        "authors": [
            "Elias Stengel-Eskin",
            "Benjamin Van Durme"
        ],
        "published": "2022",
        "summary": "Children acquiring English make systematic errors on subject control sentences even after they have reached near-adult competence (Chomsky, 1969), possibly due to heuristics based on semantic roles (Maratsos, 1974).Given the advanced fluency of large generative language models, we ask whether model outputs are consistent with these heuristics, and to what degree different models are consistent with each other. We find that models can be categorized by behavior into three separate groups, with broad differences between the groups. The outputs of models in the largest group are consistent with positional heuristics that succeed on subject control but fail on object control. This result is surprising, given that object control is orders of magnitude more frequent in the text data used to train such models. We examine to what degree the models are sensitive to prompting with agent-patient information, finding that raising the salience of agent and patient relations results in significant changes in the outputs of most models. Based on this observation, we leverage an existing dataset of semantic proto-role annotations (White et al. 2020) to explore the connections between control and labeling event participants with properties typically associated with agents and patients.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.760.pdf"
    },
    {
        "title": "PEVL: Position-enhanced Pre-training and Prompt Tuning for Vision-language Models",
        "authors": [
            "Yuan Yao",
            "Qianyu Chen",
            "Ao Zhang",
            "Wei Ji",
            "Zhiyuan Liu",
            "Tat-Seng Chua",
            "Maosong Sun"
        ],
        "published": "2022",
        "summary": "Vision-language pre-training (VLP) has shown impressive performance on a wide range of cross-modal tasks, where VLP models without reliance on object detectors are becoming the mainstream due to their superior computation efficiency and competitive performance. However, the removal of object detectors also deprives the capability of VLP models in explicit object modeling, which is essential to various position-sensitive vision-language (VL) tasks, such as referring expression comprehension and visual commonsense reasoning. To address the challenge, we introduce PEVL that enhances the pre-training and prompt tuning of VLP models with explicit object position modeling. Specifically, PEVL reformulates discretized object positions and language in a unified language modeling framework, which facilitates explicit VL alignment during pre-training, and also enables flexible prompt tuning for various downstream tasks. We show that PEVL enables state-of-the-art performance of detector-free VLP models on position-sensitive tasks such as referring expression comprehension and phrase grounding, and also improves the performance on position-insensitive tasks with grounded inputs. We make the data and code for this paper publicly available at https://github.com/thunlp/PEVL.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.763.pdf"
    },
    {
        "title": "Pre-training Language Models with Deterministic Factual Knowledge",
        "authors": [
            "Shaobo Li",
            "Xiaoguang Li",
            "Lifeng Shang",
            "Chengjie Sun",
            "Bingquan Liu",
            "Zhenzhou Ji",
            "Xin Jiang",
            "Qun Liu"
        ],
        "published": "2022",
        "summary": "Previous works show that Pre-trained Language Models (PLMs) can capture factual knowledge. However, some analyses reveal that PLMs fail to perform it robustly, e.g., being sensitive to the changes of prompts when extracting factual knowledge. To mitigate this issue, we propose to let PLMs learn the deterministic relationship between the remaining context and the masked content. The deterministic relationship ensures that the masked factual content can be deterministically inferable based on the existing clues in the context. That would provide more stable patterns for PLMs to capture factual knowledge than randomly masking. Two pre-training tasks are further introduced to motivate PLMs to rely on the deterministic relationship when filling masks. Specifically, we use an external Knowledge Base (KB) to identify deterministic relationships and continuously pre-train PLMs with the proposed methods. The factual knowledge probing experiments indicate that the continuously pre-trained PLMs achieve better robustness in factual knowledge capturing. Further experiments on question-answering datasets show that trying to learn a deterministic relationship with the proposed methods can also help other knowledge-intensive tasks.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.764.pdf"
    },
    {
        "title": "Finding Skill Neurons in Pre-trained Transformer-based Language Models",
        "authors": [
            "Xiaozhi Wang",
            "Kaiyue Wen",
            "Zhengyan Zhang",
            "Lei Hou",
            "Zhiyuan Liu",
            "Juanzi Li"
        ],
        "published": "2022",
        "summary": "Transformer-based pre-trained language models have demonstrated superior performance on various natural language processing tasks. However, it remains unclear how the skills required to handle these tasks distribute among model parameters. In this paper, we find that after prompt tuning for specific tasks, the activations of some neurons within pre-trained Transformers are highly predictive of the task labels. We dub these neurons skill neurons and confirm they encode task-specific skills by finding that: (1) Skill neurons are crucial for handling tasks. Performances of pre-trained Transformers on a task significantly drop when corresponding skill neurons are perturbed. (2) Skill neurons are task-specific. Similar tasks tend to have similar distributions of skill neurons. Furthermore, we demonstrate the skill neurons are most likely generated in pre-training rather than fine-tuning by showing that the skill neurons found with prompt tuning are also crucial for other fine-tuning methods freezing neuron weights, such as the adapter-based tuning and BitFit. We also explore the applications of skill neurons, including accelerating Transformers with network pruning and building better transferability indicators. These findings may promote further research on understanding Transformers. The source code can be obtained from https://github.com/THU-KEG/Skill-Neuron.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.765.pdf"
    },
    {
        "title": "Can Transformers Reason in Fragments of Natural Language?",
        "authors": [
            "Viktor Schlegel",
            "Kamen Pavlov",
            "Ian Pratt-Hartmann"
        ],
        "published": "2022",
        "summary": "State-of-the-art deep-learning-based approaches to Natural Language Processing (NLP) are credited with various capabilities that involve reasoning with natural language texts. %However, reasoning in this setting is often ill-defined and shallow. In this paper we carry out a large-scale empirical study investigating the detection of formally valid inferences in controlled fragments of natural language for which the satisfiability problem becomes increasingly complex. We find that, while transformer-based language models perform surprisingly well in these scenarios, a deeper analysis reveals that they appear to overfit to superficial patterns in the data rather than acquiring the logical principles governing the reasoning in these fragments.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.768.pdf"
    },
    {
        "title": "Instance Regularization for Discriminative Language Model Pre-training",
        "authors": [
            "Zhuosheng Zhang",
            "Hai Zhao",
            "Ming Zhou"
        ],
        "published": "2022",
        "summary": "Discriminative pre-trained language models (PrLMs) can be generalized as denoising auto-encoders that work with two procedures, ennoising and denoising. First, an ennoising process corrupts texts with arbitrary noising functions to construct training instances. Then, a denoising language model is trained to restore the corrupted tokens. Existing studies have made progress by optimizing independent strategies of either ennoising or denosing. They treat training instances equally throughout the training process, with little attention on the individual contribution of those instances. To model explicit signals of instance contribution, this work proposes to estimate the complexity of restoring the original sentences from corrupted ones in language model pre-training. The estimations involve the corruption degree in the ennoising data construction process and the prediction confidence in the denoising counterpart. Experimental results on natural language understanding and reading comprehension benchmarks show that our approach improves pre-training efficiency, effectiveness, and robustness. Code is publicly available at https://github.com/cooelf/InstanceReg.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.773.pdf"
    },
    {
        "title": "ScienceWorld: Is your Agent Smarter than a 5th Grader?",
        "authors": [
            "Ruoyao Wang",
            "Peter Jansen",
            "Marc-Alexandre Côté",
            "Prithviraj Ammanabrolu"
        ],
        "published": "2022",
        "summary": "We present ScienceWorld, a benchmark to test agents’ scientific reasoning abilities in a new interactive text environment at the level of a standard elementary school science curriculum. Despite the transformer-based progress seen in question-answering and scientific text processing, we find that current models cannot reason about or explain learned science concepts in novel contexts. For instance, models can easily answer what the conductivity of a known material is but struggle when asked how they would conduct an experiment in a grounded environment to find the conductivity of an unknown material. This begs the question of whether current models are simply retrieving answers by way of seeing a large number of similar examples or if they have learned to reason about concepts in a reusable manner. We hypothesize that agents need to be grounded in interactive environments to achieve such reasoning capabilities. Our experiments provide empirical evidence supporting this hypothesis – showing that a 1.5 million parameter agent trained interactively for 100k steps outperforms a 11 billion parameter model statically trained for scientific question-answering and reasoning from millions of expert demonstrations.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.775.pdf"
    },
    {
        "title": "Prompting ELECTRA: Few-Shot Learning with Discriminative Pre-Trained Models",
        "authors": [
            "Mengzhou Xia",
            "Mikel Artetxe",
            "Jingfei Du",
            "Danqi Chen",
            "Veselin Stoyanov"
        ],
        "published": "2022",
        "summary": "Pre-trained masked language models successfully perform few-shot learning by formulating downstream tasks as text infilling. How- ever, as a strong alternative in full-shot settings, discriminative pre-trained models like ELECTRA do not fit into the paradigm. In this work, we adapt prompt-based few-shot learning to ELECTRA and show that it outperforms masked language models in a wide range of tasks. ELECTRA is pre-trained to distinguish if a token is generated or original. We naturally extend that to prompt-based few-shot learning by training to score the originality of the target options without introducing new parameters. Our method can be easily adapted to tasks involving multi-token predictions without extra computation overhead. Analysis shows that ELECTRA learns distributions that align better with downstream tasks.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.780.pdf"
    },
    {
        "title": "Robustifying Sentiment Classification by Maximally Exploiting Few Counterfactuals",
        "authors": [
            "Maarten De Raedt",
            "Fréderic Godin",
            "Chris Develder",
            "Thomas Demeester"
        ],
        "published": "2022",
        "summary": "For text classification tasks, finetuned language models perform remarkably well. Yet, they tend to rely on spurious patterns in training data, thus limiting their performance on out-of-distribution (OOD) test data. Among recent models aiming to avoid this spurious pattern problem, adding extra counterfactual samples to the training data has proven to be very effective. Yet, counterfactual data generation is costly since it relies on human annotation. Thus, we propose a novel solution that only requires annotation of a small fraction (e.g., 1%) of the original training data, and uses automatic generation of extra counterfactuals in an encoding vector space. We demonstrate the effectiveness of our approach in sentiment classification, using IMDb data for training and other sets for OOD tests (i.e., Amazon, SemEval and Yelp). We achieve noticeable accuracy improvements by adding only 1% manual counterfactuals: +3% compared to adding +100% in-distribution training samples, +1.3% compared to alternate counterfactual approaches.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.783.pdf"
    },
    {
        "title": "GENIE: Toward Reproducible and Standardized Human Evaluation for Text Generation",
        "authors": [
            "Daniel Khashabi",
            "Gabriel Stanovsky",
            "Jonathan Bragg",
            "Nicholas Lourie",
            "Jungo Kasai",
            "Yejin Choi",
            "Noah A. Smith",
            "Daniel Weld"
        ],
        "published": "2022",
        "summary": "While often assumed a gold standard, effective human evaluation of text generation remains an important, open area for research.We revisit this problem with a focus on producing consistent evaluations that are reproducible—over time and across different populations. We study this goal in different stages of the human evaluation pipeline. In particular, we consider design choices for the annotation interface used to elicit human judgments and their impact on reproducibility. Furthermore, we develop an automated mechanism for maintaining annotator quality via a probabilistic model that detects and excludes noisy annotators. Putting these lessons together, we introduce GENIE: a system for running standardized human evaluations across different generation tasks.We instantiate GENIE with datasets representing four core challenges in text generation: machine translation, summarization, commonsense reasoning, and machine comprehension.For each task, GENIE offers a leaderboard that automatically crowdsources annotations for submissions, evaluating them along axes such as correctness, conciseness, and fluency.We have made the GENIE leaderboards publicly available, and have already ranked 50 submissions from 10 different research groups. We hope GENIE encourages further progress toward effective, standardized evaluations for text generation.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.787.pdf"
    },
    {
        "title": "Zero-shot Cross-lingual Transfer of Prompt-based Tuning with a Unified Multilingual Prompt",
        "authors": [
            "Lianzhe Huang",
            "Shuming Ma",
            "Dongdong Zhang",
            "Furu Wei",
            "Houfeng Wang"
        ],
        "published": "2022",
        "summary": "Prompt-based tuning has been proven effective for pretrained language models (PLMs). While most of the existing work focuses on the monolingual prompts, we study the multilingual prompts for multilingual PLMs, especially in the zero-shot cross-lingual setting. To alleviate the effort of designing different prompts for multiple languages, we propose a novel model that uses a unified prompt for all languages, called UniPrompt. Different from the discrete prompts and soft prompts, the unified prompt is model-based and language-agnostic. Specifically, the unified prompt is initialized by a multilingual PLM to produce language-independent representation, after which is fused with the text input. During inference, the prompts can be pre-computed so that no extra computation cost is needed. To collocate with the unified prompt, we propose a new initialization method for the target label word to further improve the model’s transferability across languages. Extensive experiments show that our proposed methods can significantly outperform the strong baselines across different languages. We release data and code to facilitate future research.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.790.pdf"
    },
    {
        "title": "Predicting Fine-Tuning Performance with Probing",
        "authors": [
            "Zining Zhu",
            "Soroosh Shahtalebi",
            "Frank Rudzicz"
        ],
        "published": "2022",
        "summary": "Large NLP models have recently shown impressive performance in language understanding tasks, typically evaluated by their fine-tuned performance. Alternatively, probing has received increasing attention as being a lightweight method for interpreting the intrinsic mechanisms of large NLP models. In probing, post-hoc classifiers are trained on “out-of-domain” datasets that diagnose specific abilities. While probing the language models has led to insightful findings, they appear disjointed from the development of models. This paper explores the utility of probing deep NLP models to extract a proxy signal widely used in model development – the fine-tuning performance. We find that it is possible to use the accuracies of only three probing tests to predict the fine-tuning performance with errors 40% - 80% smaller than baselines. We further discuss possible avenues where probing can empower the development of deep NLP models.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.793.pdf"
    },
    {
        "title": "Agent-Specific Deontic Modality Detection in Legal Language",
        "authors": [
            "Abhilasha Sancheti",
            "Aparna Garimella",
            "Balaji Vasan Srinivasan",
            "Rachel Rudinger"
        ],
        "published": "2022",
        "summary": "Legal documents are typically long and written in legalese, which makes it particularly difficult for laypeople to understand their rights and duties. While natural language understanding technologies can be valuable in supporting such understanding in the legal domain, the limited availability of datasets annotated for deontic modalities in the legal domain, due to the cost of hiring experts and privacy issues, is a bottleneck. To this end, we introduce, LEXDEMOD, a corpus of English contracts annotatedwith deontic modality expressed with respect to a contracting party or agent along with the modal triggers. We benchmark this dataset on two tasks: (i) agent-specific multi-label deontic modality classification, and (ii) agent-specific deontic modality and trigger span detection using Transformer-based (Vaswani et al., 2017) language models. Transfer learning experiments show that the linguistic diversity of modal expressions in LEXDEMOD generalizes reasonably from lease to employment andrental agreements. A small case study indicates that a model trained on LEXDEMOD can detect red flags with high recall. We believe our work offers a new research direction for deontic modality detection in the legal domain.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.795.pdf"
    },
    {
        "title": "COLD: A Benchmark for Chinese Offensive Language Detection",
        "authors": [
            "Jiawen Deng",
            "Jingyan Zhou",
            "Hao Sun",
            "Chujie Zheng",
            "Fei Mi",
            "Helen Meng",
            "Minlie Huang"
        ],
        "published": "2022",
        "summary": "Offensive language detection is increasingly crucial for maintaining a civilized social media platform and deploying pre-trained language models. However, this task in Chinese is still under exploration due to the scarcity of reliable datasets. To this end, we propose a benchmark –COLD for Chinese offensive language analysis, including a Chinese Offensive Language Dataset –COLDATASET and a baseline detector –COLDETECTOR which is trained on the dataset. We show that the COLD benchmark contributes to Chinese offensive language detection which is challenging for existing resources. We then deploy the COLDETECTOR and conduct detailed analyses on popular Chinese pre-trained language models. We first analyze the offensiveness of existing generative models and show that these models inevitably expose varying degrees of offensive issues. Furthermore, we investigate the factors that influence the offensive generations, and we find that anti-bias contents and keywords referring to certain groups or revealing negative attitudes trigger offensive outputs easier.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.796.pdf"
    },
    {
        "title": "ZeroGen: Efficient Zero-shot Learning via Dataset Generation",
        "authors": [
            "Jiacheng Ye",
            "Jiahui Gao",
            "Qintong Li",
            "Hang Xu",
            "Jiangtao Feng",
            "Zhiyong Wu",
            "Tao Yu",
            "Lingpeng Kong"
        ],
        "published": "2022",
        "summary": "There is a growing interest in dataset generation recently due to the superior generative capacity of large pre-trained language models (PLMs). In this paper, we study a flexible and efficient zero-short learning method, ZeroGen.Given a zero-shot task, we first generate a dataset from scratch using PLMs in an unsupervised manner. Then, we train a tiny task model (e.g., LSTM) under the supervision of the synthesized dataset. This approach allows highly efficient inference as the final task model only has orders of magnitude fewer parameters comparing to PLMs (e.g., GPT2-XL).Apart from being annotation-free and efficient, we argue that ZeroGen can also provide useful insights from the perspective of data-free model-agnostic knowledge distillation, and unreferenced text generation evaluation. Experiments and analysis on different NLP tasks, namely, text classification, question answering, and natural language inference, show the effectiveness of ZeroGen.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.801.pdf"
    },
    {
        "title": "Neighborhood Contrastive Learning for Scientific Document Representations with Citation Embeddings",
        "authors": [
            "Malte Ostendorff",
            "Nils Rethmeier",
            "Isabelle Augenstein",
            "Bela Gipp",
            "Georg Rehm"
        ],
        "published": "2022",
        "summary": "Learning scientific document representations can be substantially improved through contrastive learning objectives, where the challenge lies in creating positive and negative training samples that encode the desired similarity semantics. Prior work relies on discrete citation relations to generate contrast samples. However, discrete citations enforce a hard cut-off to similarity. This is counter-intuitive to similarity-based learning and ignores that scientific papers can be very similar despite lacking a direct citation - a core problem of finding related research. Instead, we use controlled nearest neighbor sampling over citation graph embeddings for contrastive learning. This control allows us to learn continuous similarity, to sample hard-to-learn negatives and positives, and also to avoid collisions between negative and positive samples by controlling the sampling margin between them. The resulting method SciNCL outperforms the state-of-the-art on the SciDocs benchmark. Furthermore, we demonstrate that it can train (or tune) language models sample-efficiently and that it can be combined with recent training-efficient methods. Perhaps surprisingly, even training a general-domain language model this way outperforms baselines pretrained in-domain.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.802.pdf"
    },
    {
        "title": "SPE: Symmetrical Prompt Enhancement for Fact Probing",
        "authors": [
            "Yiyuan Li",
            "Tong Che",
            "Yezhen Wang",
            "Zhengbao Jiang",
            "Caiming Xiong",
            "Snigdha Chaturvedi"
        ],
        "published": "2022",
        "summary": "Pretrained language models (PLMs) have been shown to accumulate factual knowledge during pretraining (Petroni et al. 2019). Recent works probe PLMs for the extent of this knowledge through prompts either in discrete or continuous forms. However, these methods do not consider symmetry of the task: object prediction and subject prediction. In this work, we propose Symmetrical Prompt Enhancement (SPE), a continuous prompt-based method for factual probing in PLMs that leverages the symmetry of the task by constructing symmetrical prompts for subject and object prediction. Our results on a popular factual probing dataset, LAMA, show significant improvement of SPE over previous probing methods.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.803.pdf"
    },
    {
        "title": "MedJEx: A Medical Jargon Extraction Model with Wiki’s Hyperlink Span and Contextualized Masked Language Model Score",
        "authors": [
            "Sunjae Kwon",
            "Zonghai Yao",
            "Harmon Jordan",
            "David Levy",
            "Brian Corner",
            "Hong Yu"
        ],
        "published": "2022",
        "summary": "This paper proposes a new natural language processing (NLP) application for identifying medical jargon terms potentially difficult for patients to comprehend from electronic health record (EHR) notes. We first present a novel and publicly available dataset with expert-annotated medical jargon terms from 18K+ EHR note sentences (MedJ). Then, we introduce a novel medical jargon extraction (MedJEx) model which has been shown to outperform existing state-of-the-art NLP models. First, MedJEx improved the overall performance when it was trained on an auxiliary Wikipedia hyperlink span dataset, where hyperlink spans provide additional Wikipedia articles to explain the spans (or terms), and then fine-tuned on the annotated MedJ data. Secondly, we found that a contextualized masked language model score was beneficial for detecting domain-specific unfamiliar jargon terms. Moreover, our results show that training on the auxiliary Wikipedia hyperlink span datasets improved six out of eight biomedical named entity recognition benchmark datasets. MedJEx is publicly available.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.805.pdf"
    },
    {
        "title": "Discourse Comprehension: A Question Answering Framework to Represent Sentence Connections",
        "authors": [
            "Wei-Jen Ko",
            "Cutter Dalton",
            "Mark Simmons",
            "Eliza Fisher",
            "Greg Durrett",
            "Junyi Jessy Li"
        ],
        "published": "2022",
        "summary": "While there has been substantial progress in text comprehension through simple factoid question answering, more holistic comprehension of a discourse still presents a major challenge (Dunietz et al., 2020). Someone critically reflecting on a text as they read it will pose curiosity-driven, often open-ended questions, which reflect deep understanding of the content and require complex reasoning to answer (Ko et al., 2020; Westera et al., 2020). A key challenge in building and evaluating models for this type of discourse comprehension is the lack of annotated data, especially since collecting answers to such questions requires high cognitive load for annotators.This paper presents a novel paradigm that enables scalable data collection targeting the comprehension of news documents, viewing these questions through the lens of discourse. The resulting corpus, DCQA (Discourse Comprehension by Question Answering), captures both discourse and semantic links between sentences in the form of free-form, open-ended questions. On an evaluation set that we annotated on questions from Ko et al. (2020), we show that DCQA provides valuable supervision for answering open-ended questions. We additionally design pre-training methods utilizing existing question-answering resources, and use synthetic data to accommodate unanswerable questions.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.806.pdf"
    },
    {
        "title": "A Systematic Investigation of Commonsense Knowledge in Large Language Models",
        "authors": [
            "Xiang Lorraine Li",
            "Adhiguna Kuncoro",
            "Jordan Hoffmann",
            "Cyprien de Masson d’Autume",
            "Phil Blunsom",
            "Aida Nematzadeh"
        ],
        "published": "2022",
        "summary": "Language models (LMs) trained on large amounts of data have shown impressive performance on many NLP tasks under the zero-shot and few-shot setup. Here we aim to better understand the extent to which such models learn commonsense knowledge — a critical component of many NLP applications. We conduct a systematic and rigorous zero-shot and few-shot commonsense evaluation of large pre-trained LMs, where we: (i) carefully control for the LMs’ ability to exploit potential surface cues and annotation artefacts, and (ii) account for variations in performance that arise from factors that are not related to commonsense knowledge. Our findings highlight the limitations of pre-trained LMs in acquiring commonsense knowledge without task-specific supervision; furthermore, using larger models or few-shot evaluation is insufficient to achieve human-level commonsense performance.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.812.pdf"
    },
    {
        "title": "Transforming Sequence Tagging Into A Seq2Seq Task",
        "authors": [
            "Karthik Raman",
            "Iftekhar Naim",
            "Jiecao Chen",
            "Kazuma Hashimoto",
            "Kiran Yalasangi",
            "Krishna Srinivasan"
        ],
        "published": "2022",
        "summary": "Pretrained, large, generative language models (LMs) have had great success in a wide range of sequence tagging and structured prediction tasks. Casting a sequence tagging task as a Seq2Seq one requires deciding the formats of the input and output sequences. However, we lack a principled understanding of the trade-offs associated with these formats (such as the effect on model accuracy, sequence length, multilingual generalization, hallucination). In this paper, we rigorously study different formats one could use for casting input text sentences and their output labels into the input and target (i.e., output) of a Seq2Seq model. Along the way, we introduce a new format, which we show to to be both simpler and more effective. Additionally the new format demonstrates significant gains in the multilingual settings – both zero-shot transfer learning and joint training. Lastly, we find that the new format is more robust and almost completely devoid of hallucination – an issue we find common in existing formats. With well over a 1000 experiments studying 14 different formats, over 7 diverse public benchmarks – including 3 multilingual datasets spanning 7 languages – we believe our findings provide a strong empirical basis in understanding how we should tackle sequence tagging tasks.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.813.pdf"
    },
    {
        "title": "Model Criticism for Long-Form Text Generation",
        "authors": [
            "Yuntian Deng",
            "Volodymyr Kuleshov",
            "Alexander Rush"
        ],
        "published": "2022",
        "summary": "Language models have demonstrated the ability to generate highly fluent text; however, it remains unclear whether their output retains coherent high-level structure (e.g., story progression). Here, we propose to apply a statistical tool, model criticism in latent space, to evaluate the high-level structure of the generated text. Model criticism compares the distributions between real and generated data in a latent space obtained according to an assumptive generative process. Different generative processes identify specific failure modes of the underlying model. We perform experiments on three representative aspects of high-level discourse—coherence, coreference, and topicality—and find that transformer-based language models are able to capture topical structures but have a harder time maintaining structural coherence or modeling coreference.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.815.pdf"
    },
    {
        "title": "Improving Faithfulness by Augmenting Negative Summaries from Fake Documents",
        "authors": [
            "Tianshu Wang",
            "Faisal Ladhak",
            "Esin Durmus",
            "He He"
        ],
        "published": "2022",
        "summary": "Current abstractive summarization systems tend to hallucinate content that is unfaithful to the source document, posing a risk of misinformation. To mitigate hallucination, we must teach the model to distinguish hallucinated summaries from faithful ones. However, the commonly used maximum likelihood training does not disentangle factual errors from other model errors. To address this issue,we propose a back-translation-style approach to augment negative samples that mimic factual errors made by the model. Specifically, we train an elaboration model that generates hallucinated documents given the reference summaries, and then generates negative summaries from the fake documents. We incorporate the negative samples into training through a controlled generator, which produces faithful/unfaithful summaries conditioned on the control codes. Additionally, we find that adding textual entailment data through multitasking further boosts the performance. Experiments on three datasets (XSum, Gigaword, and WikiHow) show that our method consistently improves faithfulness without sacrificing informativeness according to both human and automatic evaluation",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.816.pdf"
    },
    {
        "title": "Injecting Domain Knowledge in Language Models for Task-oriented Dialogue Systems",
        "authors": [
            "Denis Emelin",
            "Daniele Bonadiman",
            "Sawsan Alqahtani",
            "Yi Zhang",
            "Saab Mansour"
        ],
        "published": "2022",
        "summary": "Pre-trained language models (PLM) have advanced the state-of-the-art across NLP applications, but lack domain-specific knowledge that does not naturally occur in pre-training data. Previous studies augmented PLMs with symbolic knowledge for different downstream NLP tasks. However, knowledge bases (KBs) utilized in these studies are usually large-scale and static, in contrast to small, domain-specific, and modifiable knowledge bases that are prominent in real-world task-oriented dialogue (TOD) systems. In this paper, we showcase the advantages of injecting domain-specific knowledge prior to fine-tuning on TOD tasks. To this end, we utilize light-weight adapters that can be easily integrated with PLMs and serve as a repository for facts learned from different KBs. To measure the efficacy of proposed knowledge injection methods, we introduce Knowledge Probing using Response Selection (KPRS) – a probe designed specifically for TOD models. Experiments on KPRS and the response generation task show improvements of knowledge injection with adapters over strong baselines.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.820.pdf"
    },
    {
        "title": "Improving Low-Resource Languages in Pre-Trained Multilingual Language Models",
        "authors": [
            "Viktor Hangya",
            "Hossain Shaikh Saadi",
            "Alexander Fraser"
        ],
        "published": "2022",
        "summary": "Pre-trained multilingual language models are the foundation of many NLP approaches, including cross-lingual transfer solutions. However, languages with small available monolingual corpora are often not well-supported by these models leading to poor performance. We propose an unsupervised approach to improve the cross-lingual representations of low-resource languages by bootstrapping word translation pairs from monolingual corpora and using them to improve language alignment in pre-trained language models. We perform experiments on nine languages, using contextual word retrieval and zero-shot named entity recognition to measure both intrinsic cross-lingual word representation quality and downstream task performance, showing improvements on both tasks. Our results show that it is possible to improve pre-trained multilingual language models by relying only on non-parallel resources.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.822.pdf"
    },
    {
        "title": "PCL: Peer-Contrastive Learning with Diverse Augmentations for Unsupervised Sentence Embeddings",
        "authors": [
            "Qiyu Wu",
            "Chongyang Tao",
            "Tao Shen",
            "Can Xu",
            "Xiubo Geng",
            "Daxin Jiang"
        ],
        "published": "2022",
        "summary": "Learning sentence embeddings in an unsupervised manner is fundamental in natural language processing. Recent common practice is to couple pre-trained language models with unsupervised contrastive learning, whose success relies on augmenting a sentence with a semantically-close positive instance to construct contrastive pairs. Nonetheless, existing approaches usually depend on a mono-augmenting strategy, which causes learning shortcuts towards the augmenting biases and thus corrupts the quality of sentence embeddings. A straightforward solution is resorting to more diverse positives from a multi-augmenting strategy, while an open question remains about how to unsupervisedly learn from the diverse positives but with uneven augmenting qualities in the text field. As one answer, we propose a novel Peer-Contrastive Learning (PCL) with diverse augmentations. PCL constructs diverse contrastive positives and negatives at the group level for unsupervised sentence embeddings. PCL performs peer-positive contrast as well as peer-network cooperation, which offers an inherent anti-bias ability and an effective way to learn from diverse augmentations. Experiments on STS benchmarks verify the effectiveness of PCL against its competitors in unsupervised sentence embeddings.",
        "pdf_link": "https://aclanthology.org/2022.emnlp-main.826.pdf"
    },
    {
        "title": "Acceptability Judgements via Examining the Topology of Attention Maps",
        "authors": [
            "Daniil Cherniavskii",
            "Eduard Tulchinskii",
            "Vladislav Mikhailov",
            "Irina Proskurina",
            "Laida Kushnareva",
            "Ekaterina Artemova",
            "Serguei Barannikov",
            "Irina Piontkovskaya",
            "Dmitri Piontkovski",
            "Evgeny Burnaev"
        ],
        "published": "2022",
        "summary": "The role of the attention mechanism in encoding linguistic knowledge has received special interest in NLP. However, the ability of the attention heads to judge the grammatical acceptability of a sentence has been underexplored. This paper approaches the paradigm of acceptability judgments with topological data analysis (TDA), showing that the geometric properties of the attention graph can be efficiently exploited for two standard practices in linguistics: binary judgments and linguistic minimal pairs. Topological features enhance the BERT-based acceptability classifier scores by 8%-24% on CoLA in three languages (English, Italian, and Swedish). By revealing the topological discrepancy between attention maps of minimal pairs, we achieve the human-level performance on the BLiMP benchmark, outperforming nine statistical and Transformer LM baselines. At the same time, TDA provides the foundation for analyzing the linguistic functions of attention heads and interpreting the correspondence between the graph features and grammatical phenomena. We publicly release the code and other materials used in the experiments.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.7.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Clip-Tuning: Towards Derivative-free Prompt Learning with a Mixture of Rewards",
        "authors": [
            "Yekun Chai",
            "Shuohuan Wang",
            "Yu Sun",
            "Hao Tian",
            "Hua Wu",
            "Haifeng Wang"
        ],
        "published": "2022",
        "summary": "Derivative-free prompt learning has emerged as a lightweight alternative to prompt tuning, which only requires model inference to optimize the prompts. However, existing work did not take full advantage of the over-parameterized characteristics of large pre-trained language models (PLMs). In this paper, we propose Clip-Tuning, a simple yet effective method that adopts diverse frozen “thinned” networks of PLMs to obtain *a mixture of rewards* and thus advance the derivative-free prompt learning. The thinned networks consist of all the hidden units that survive a stationary dropout strategy, whose inference predictions reflect an ensemble of partial views over prompted training samples. Our method outperforms previous gradient-free prompt learning methods and achieves parity with gradient-based counterparts on seven language understanding benchmarks under few-shot settings.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.8.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Language Models Understand Us, Poorly",
        "authors": [
            "Jared Moore"
        ],
        "published": "2022",
        "summary": "Some claim language models understand us. Others won’t hear it. To clarify, I investigate three views of human language understanding: as-mapping, as-reliability and as-representation. I argue that while behavioral reliability is necessary for understanding, internal representations are sufficient; they climb the right hill. I review state-of-the-art language and multi-modal models: they are pragmatically challenged by under-specification of form. I question the Scaling Paradigm: limits on resources may prohibit scaled-up models from approaching understanding. Last, I describe how as-representation advances a science of understanding. We need work which probes model internals, adds more of human language, and measures what models can learn.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.16.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Learning from the Dictionary: Heterogeneous Knowledge Guided Fine-tuning for Chinese Spell Checking",
        "authors": [
            "Yinghui Li",
            "Shirong Ma",
            "Qingyu Zhou",
            "Zhongli Li",
            "Li Yangning",
            "Shulin Huang",
            "Ruiyang Liu",
            "Chao Li",
            "Yunbo Cao",
            "Haitao Zheng"
        ],
        "published": "2022",
        "summary": "Chinese Spell Checking (CSC) aims to detect and correct Chinese spelling errors. Recent researches start from the pretrained knowledge of language models and take multimodal information into CSC models to improve the performance. However, they overlook the rich knowledge in the dictionary, the reference book where one can learn how one character should be pronounced, written, and used. In this paper, we propose the LEAD framework, which renders the CSC model to learn heterogeneous knowledge from the dictionary in terms of phonetics, vision, and meaning. LEAD first constructs positive and negative samples according to the knowledge of character phonetics, glyphs, and definitions in the dictionary. Then a unified contrastive learning-based training scheme is employed to refine the representations of the CSC models. Extensive experiments and detailed analyses on the SIGHAN benchmark datasets demonstrate the effectiveness of our proposed methods.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.18.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "When Language Model Meets Private Library",
        "authors": [
            "Daoguang Zan",
            "Bei Chen",
            "Zeqi Lin",
            "Bei Guan",
            "Wang Yongji",
            "Jian-Guang Lou"
        ],
        "published": "2022",
        "summary": "With the rapid development of pre-training techniques, a number of language models have been pre-trained on large-scale code corpora and perform well in code generation. In this paper, we investigate how to equip pre-trained language models with the ability of code generation for private libraries. In practice, it is common for programmers to write code using private libraries. However, this is a challenge for language models since they have never seen private APIs during training. Motivated by the fact that private libraries usually come with elaborate API documentation, we propose a novel framework with two modules: the APIRetriever finds useful APIs, and then the APICoder generates code using these APIs. For APIRetriever, we present a dense retrieval system and also design a friendly interaction to involve uses. For APICoder, we can directly use off-the-shelf language models, or continually pre-train the base model on a code corpus containing API information. Both modules are trained with data from public libraries and can be generalized to private ones. Furthermore, we craft three benchmarks for private libraries, named TorchDataEval, MonkeyEval, and BeatNumEval. Experimental results demonstrate the impressive performance of our framework.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.21.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Fine-mixing: Mitigating Backdoors in Fine-tuned Language Models",
        "authors": [
            "Zhiyuan Zhang",
            "Lingjuan Lyu",
            "Xingjun Ma",
            "Chenguang Wang",
            "Xu Sun"
        ],
        "published": "2022",
        "summary": "Deep Neural Networks (DNNs) are known to be vulnerable to backdoor attacks. In Natural Language Processing (NLP), DNNs are often backdoored during the fine-tuning process of a large-scale Pre-trained Language Model (PLM) with poisoned samples. Although the clean weights of PLMs are readily available, existing methods have ignored this information in defending NLP models against backdoor attacks. In this work, we take the first step to exploit the pre-trained (unfine-tuned) weights to mitigate backdoors in fine-tuned language models. Specifically, we leverage the clean pre-trained weights via two complementary techniques: (1) a two-step Fine-mixing technique, which first mixes the backdoored weights (fine-tuned on poisoned data) with the pre-trained weights, then fine-tunes the mixed weights on a small subset of clean data; (2) an Embedding Purification (E-PUR) technique, which mitigates potential backdoors existing in the word embeddings. We compare Fine-mixing with typical backdoor mitigation methods on three single-sentence sentiment classification tasks and two sentence-pair classification tasks and show that it outperforms the baselines by a considerable margin in all scenarios. We also show that our E-PUR method can benefit existing mitigation methods. Our work establishes a simple but strong baseline defense for secure fine-tuned NLP models against backdoor attacks.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.26.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Language Models that Seek for Knowledge: Modular Search & Generation for Dialogue and Prompt Completion",
        "authors": [
            "Kurt Shuster",
            "Mojtaba Komeili",
            "Leonard Adolphs",
            "Stephen Roller",
            "Arthur Szlam",
            "Jason Weston"
        ],
        "published": "2022",
        "summary": "Language models (LMs) have recently been shown to generate more factual responses by employing modularity (Zhou et al., 2022) in combination with retrieval (Adolphs et al., 2021). We extend the recent approach of Adolphs et al. (2021) to include internet search as a module. Our SeeKeR (Search engine->Knowledge->Response) method thus applies a single LM to three modular tasks in succession: search, generating knowledge, and generating a final response. We show that, when using SeeKeR as a dialogue model, it outperforms the state-of-the-art model BlenderBot 2 (Chen et al., 2021) on open-domain knowledge-grounded conversations for the same number of parameters, in terms of consistency, knowledge and per-turn engagingness. SeeKeR applied to topical prompt completions as a standard language model outperforms GPT2 (Radford et al., 2019) and GPT3 (Brown et al., 2020) in terms of factuality and topicality, despite GPT3 being a vastly larger model. Our code and models are made publicly available.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.27.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Towards Realistic Low-resource Relation Extraction: A Benchmark with Empirical Baseline Study",
        "authors": [
            "Xin Xu",
            "Xiang Chen",
            "Ningyu Zhang",
            "Xin Xie",
            "Xi Chen",
            "Huajun Chen"
        ],
        "published": "2022",
        "summary": "This paper presents an empirical study to build relation extraction systems in low-resource settings. Based upon recent pre-trained language models, we comprehensively investigate three schemes to evaluate the performance in low-resource settings: (i) different types of prompt-based methods with few-shot labeled data; (ii) diverse balancing methods to address the long-tailed distribution issue; (iii) data augmentation technologies and self-training to generate more labeled in-domain data. We create a benchmark with 8 relation extraction (RE) datasets covering different languages, domains and contexts and perform extensive comparisons over the proposed schemes with combinations. Our experiments illustrate: (i) Though prompt-based tuning is beneficial in low-resource RE, there is still much potential for improvement, especially in extracting relations from cross-sentence contexts with multiple relational triples; (ii) Balancing methods are not always helpful for RE with long-tailed distribution; (iii) Data augmentation complements existing baselines and can bring much performance gain, while self-training may not consistently achieve advancement to low-resource RE. Code and datasets are in https://github.com/zjunlp/LREBench.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.29.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "LEMON: Language-Based Environment Manipulation via Execution-Guided Pre-training",
        "authors": [
            "Qi Shi",
            "Qian Liu",
            "Bei Chen",
            "Yu Zhang",
            "Ting Liu",
            "Jian-Guang Lou"
        ],
        "published": "2022",
        "summary": "Language-based environment manipulation requires agents to manipulate the environment following natural language instructions, which is challenging due to the huge space of the environments.To address this challenge, various approaches have been proposed in recent work. Although these approaches work well for their intended environments, they are difficult to generalize across environments. In this work, we propose LEMON, a general framework for language-based environment manipulation tasks. Specifically, we first specify a general approach for language-based environment manipulation tasks, which can deal with various environments using the same generative language model. Then we propose an execution-guided pre-training strategy to inject prior knowledge of environments to the language model with a pure synthetic pre-training corpus. Experimental results on tasks including Alchemy, Scene, Tangrams, ProPara and Recipes demonstrate the effectiveness of LEMON: it achieves new state-of-the-art results on four of the tasks, and the execution-guided pre-training strategy brings remarkable improvements on all experimental tasks.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.33.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Towards Unified Prompt Tuning for Few-shot Text Classification",
        "authors": [
            "Jianing Wang",
            "Chengyu Wang",
            "Fuli Luo",
            "Chuanqi Tan",
            "Minghui Qiu",
            "Fei Yang",
            "Qiuhui Shi",
            "Songfang Huang",
            "Ming Gao"
        ],
        "published": "2022",
        "summary": "Prompt-based fine-tuning has boosted the performance of Pre-trained Language Models (PLMs) on few-shot text classification by employing task-specific prompts. Yet, PLMs are unfamiliar with prompt-style expressions during pre-training, which limits the few-shot learning performance on downstream tasks.It would be desirable if the models can acquire some prompting knowledge before adapting to specific NLP tasks. We present the Unified Prompt Tuning (UPT) framework, leading to better few-shot text classification for BERT-style models by explicitly capturing prompting semantics from non-target NLP datasets. In UPT, a novel paradigm Prompt-Options-Verbalizer is proposed for joint prompt learning across different NLP tasks, forcing PLMs to capture task-invariant prompting knowledge. We further design a self-supervised task named Knowledge-enhanced Selective Masked Language Modeling to improve the PLM’s generalization abilities for accurate adaptation to previously unseen tasks. After multi-task learning across multiple tasks, the PLM can be better prompt-tuned towards any dissimilar target tasks in low-resourced settings. Experiments over a variety of NLP tasks show that UPT consistently outperforms state-of-the-arts for prompt-based fine-tuning.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.37.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Can language models learn from explanations in context?",
        "authors": [
            "Andrew Lampinen",
            "Ishita Dasgupta",
            "Stephanie Chan",
            "Kory Mathewson",
            "Mh Tessler",
            "Antonia Creswell",
            "James McClelland",
            "Jane Wang",
            "Felix Hill"
        ],
        "published": "2022",
        "summary": "Language Models (LMs) can perform new tasks by adapting to a few in-context examples. For humans, explanations that connect examples to task principles can improve learning. We therefore investigate whether explanations of few-shot examples can help LMs. We annotate questions from 40 challenging tasks with answer explanations, and various matched control explanations. We evaluate how different types of explanations, instructions, and controls affect zero- and few-shot performance. We analyze these results using statistical multilevel modeling techniques that account for the nested dependencies among conditions, tasks, prompts, and models. We find that explanations can improve performance—even without tuning. Furthermore, explanations hand-tuned for performance on a small validation set offer substantially larger benefits, and building a prompt by selecting examples and explanations together substantially improves performance over selecting examples alone. Finally, even untuned explanations outperform carefully matched controls, suggesting that the benefits are due to the link between an example and its explanation, rather than lower-level features. However, only large models benefit. In summary, explanations can support the in-context learning of large LMs on challenging tasks.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.38.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "System 1 + System 2 = Better World: Neural-Symbolic Chain of Logic Reasoning",
        "authors": [
            "Wenyue Hua",
            "Yongfeng Zhang"
        ],
        "published": "2022",
        "summary": "Logical reasoning is a challenge for many current NLP neural network models since it requires more than the ability of learning informative representations from data. Inspired by the Dual Process Theory in cognitive science — which proposes that human cognition process involves two stages: an intuitive, unconscious and fast process relying on perception calledSystem 1, and a logical, conscious and slow process performing complex reasoning called System 2 — we leverage neural logic reasoning (System 2) on top of the representation learning models (System 1), which conducts explicit neural-based differentiable logical reasoning on top of the representations learned by the base neural models. Based on experiments on the commonsense knowledge graph completion task, we show that the two-system architecture always improves from its System 1 model alone. Experiments also show that both the rule-driven logical regularizer and the data-driven value regularizer are important and the performance improvement is marginal without the two regularizers, which indicates that learning from both logical prior and training data is important for reasoning tasks.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.42.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Visualizing the Obvious: A Concreteness-based Ensemble Model for Noun Property Prediction",
        "authors": [
            "Yue Yang",
            "Artemis Panagopoulou",
            "Marianna Apidianaki",
            "Mark Yatskar",
            "Chris Callison-Burch"
        ],
        "published": "2022",
        "summary": "Neural language models encode rich knowledge about entities and their relationships which can be extracted from their representations using probing. Common properties of nouns (e.g., red strawberries, small ant) are, however, more challenging to extract compared to other types of knowledge because they are rarely explicitly stated in texts.We hypothesize this to mainly be the case for perceptual properties which are obvious to the participants in the communication. We propose to extract these properties from images and use them in an ensemble model, in order to complement the information that is extracted from language models. We consider perceptual properties to be more concrete than abstract properties (e.g., interesting, flawless). We propose to use the adjectives’ concreteness score as a lever to calibrate the contribution of each source (text vs. images). We evaluate our ensemble model in a ranking task where the actual properties of a noun need to be ranked higher than other non-relevant properties. Our results show that the proposed combination of text and images greatly improves noun property prediction compared to powerful text-based language models.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.45.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Diving Deep into Modes of Fact Hallucinations in Dialogue Systems",
        "authors": [
            "Souvik Das",
            "Sougata Saha",
            "Rohini Srihari"
        ],
        "published": "2022",
        "summary": "Knowledge Graph(KG) grounded conversations often use large pre-trained models and usually suffer from fact hallucination. Frequently entities with no references in knowledge sources and conversation history are introduced into responses, thus hindering the flow of the conversation—existing work attempt to overcome this issue by tweaking the training procedure or using a multi-step refining method. However, minimal effort is put into constructing an entity-level hallucination detection system, which would provide fine-grained signals that control fallacious content while generating responses. As a first step to address this issue, we dive deep to identify various modes of hallucination in KG-grounded chatbots through human feedback analysis. Secondly, we propose a series of perturbation strategies to create a synthetic dataset named FADE (FActual Dialogue Hallucination DEtection Dataset). Finally, we conduct comprehensive data analyses and create multiple baseline models for hallucination detection to compare against human-verified data and already established benchmarks.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.48.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Representation Learning for Resource-Constrained Keyphrase Generation",
        "authors": [
            "Di Wu",
            "Wasi Ahmad",
            "Sunipa Dev",
            "Kai-Wei Chang"
        ],
        "published": "2022",
        "summary": "State-of-the-art keyphrase generation methods generally depend on large annotated datasets, limiting their performance in domains with limited annotated data. To overcome this challenge, we design a data-oriented approach that first identifies salient information using retrieval-based corpus-level statistics, and then learns a task-specific intermediate representation based on a pre-trained language model using large-scale unlabeled documents. We introduce salient span recovery and salient span prediction as denoising training objectives that condense the intra-article and inter-article knowledge essential for keyphrase generation. Through experiments on multiple keyphrase generation benchmarks, we show the effectiveness of the proposed approach for facilitating low-resource keyphrase generation and zero-shot domain adaptation. Our method especially benefits the generation of absent keyphrases, approaching the performance of models trained with large training sets.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.49.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Systematicity in GPT-3’s Interpretation of Novel English Noun Compounds",
        "authors": [
            "Siyan Li",
            "Riley Carlson",
            "Christopher Potts"
        ],
        "published": "2022",
        "summary": "Levin et al. (2019) show experimentally that the interpretations of novel English noun compounds (e.g., stew skillet), while not fully compositional, are highly predictable based on whether the modifier and head refer to artifacts or natural kinds. Is the large language model GPT-3 governed by the same interpretive principles? To address this question, we first compare Levin et al.’s experimental data with GPT-3 generations, finding a high degree of similarity. However, this evidence is consistent with GPT-3 reasoning only about specific lexical items rather than the more abstract conceptual categories of Levin et al.’s theory. To probe more deeply, we construct prompts that require the relevant kind of conceptual reasoning. Here, we fail to find convincing evidence that GPT-3 is reasoning about more than just individual lexical items. These results highlight the importance of controlling for low-level distributional regularities when assessing whether a large language model latently encodes a deeper theory.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.50.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "BARLE: Background-Aware Representation Learning for Background Shift Out-of-Distribution Detection",
        "authors": [
            "Hanyu Duan",
            "Yi Yang",
            "Ahmed Abbasi",
            "Kar Yan Tam"
        ],
        "published": "2022",
        "summary": "Machine learning models often suffer from a performance drop when they are applied to out-of-distribution (OOD) samples, i.e., those drawn far away from the training data distribution. Existing OOD detection work mostly focuses on identifying semantic-shift OOD samples, e.g., instances from unseen new classes. However, background-shift OOD detection, which identifies samples with domain or style-change, represents a more practical yet challenging task. In this paper, we propose Background-Aware Representation Learning (BARLE) for background-shift OOD detection in NLP. Specifically, we generate semantics-preserving background-shifted pseudo OOD samples from pretrained masked language models. We then contrast the in-distribution (ID) samples with their pseudo OOD counterparts. Unlike prior semantic-shift OOD detection work that often leverages an external text corpus, BARLE only uses ID data, which is more flexible and cost-efficient. In experiments across several text classification tasks, we demonstrate that BARLE is capable of improving background-shift OOD detection performance while maintaining ID classification accuracy. We further investigate the properties of the generated pseudo OOD samples, uncovering the working mechanism of BARLE.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.53.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "What Language Model to Train if You Have One Million GPU Hours?",
        "authors": [
            "Teven Le Scao",
            "Thomas Wang",
            "Daniel Hesslow",
            "Stas Bekman",
            "M Saiful Bari",
            "Stella Biderman",
            "Hady Elsahar",
            "Niklas Muennighoff",
            "Jason Phang",
            "Ofir Press",
            "Colin Raffel",
            "Victor Sanh",
            "Sheng Shen",
            "Lintang Sutawika",
            "Jaesung Tae",
            "Zheng Xin Yong",
            "Julien Launay",
            "Iz Beltagy"
        ],
        "published": "2022",
        "summary": "The crystallization of modeling methods around the Transformer architecture has been a boon for practitioners. Simple, well-motivated architectural variations can transfer across tasks and scale, increasing the impact of modeling research. However, with the emergence of state-of-the-art 100B+ parameters models, large language models are increasingly expensive to accurately design and train. Notably, it can be difficult to evaluate how modeling decisions may impact emergent capabilities, given that these capabilities arise mainly from sheer scale alone.In the process of building BLOOM–the Big Science Large Open-science Open-access Multilingual language model–our goal is to identify an architecture and training setup that makes the best use of our 1,000,000 A100-GPU-hours budget.Specifically, we perform an ablation study at the billion-parameter scale comparing different modeling practices and their impact on zero-shot generalization.In addition, we study the impact of various popular pre-training corpora on zero-shot generalization. We also study the performance of a multilingual model and how it compares to the English-only one. Finally, we consider the scaling behaviour of Transformers to choose the target model size, shape, and training setup. All our models and code are open-sourced at https://huggingface.co/bigscience.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.54.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Enhancing Out-of-Distribution Detection in Natural Language Understanding via Implicit Layer Ensemble",
        "authors": [
            "Hyunsoo Cho",
            "Choonghyun Park",
            "Jaewook Kang",
            "Kang Min Yoo",
            "Taeuk Kim",
            "Sang-goo Lee"
        ],
        "published": "2022",
        "summary": "Out-of-distribution (OOD) detection aims to discern outliers from the intended data distribution, which is crucial to maintaining high reliability and a good user experience.Most recent studies in OOD detection utilize the information from a single representation that resides in the penultimate layer to determine whether the input is anomalous or not.Although such a method is straightforward, the potential of diverse information in the intermediate layers is overlooked.In this paper, we propose a novel framework based on contrastive learning that encourages intermediate features to learn layer-specialized representations and assembles them implicitly into a single representation to absorb rich information in the pre-trained language model. Extensive experiments in various intent classification and OOD datasets demonstrate that our approach is significantly more effective than other works.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.55.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Contrastive Demonstration Tuning for Pre-trained Language Models",
        "authors": [
            "Xiaozhuan Liang",
            "Ningyu Zhang",
            "Siyuan Cheng",
            "Zhenru Zhang",
            "Chuanqi Tan",
            "Huajun Chen"
        ],
        "published": "2022",
        "summary": "Pretrained language models can be effectively stimulated by textual prompts or demonstrations, especially in low-data scenarios. Recent works have focused on automatically searching discrete or continuous prompts or optimized verbalizers, yet studies for the demonstration are still limited. Concretely, the demonstration examples are crucial for an excellent final performance of prompt-tuning. In this paper, we propose a novel pluggable, extensible, and efficient approach named contrastive demonstration tuning, which is free of demonstration sampling. Furthermore, the proposed approach can be: (i) Plugged into any previous prompt-tuning approaches; (ii) Extended to widespread classification tasks with a large number of categories. Experimental results on 16 datasets illustrate that our method integrated with previous approaches LM-BFF and P-tuning can yield better performance. Code is available in https://github.com/zjunlp/PromptKG/tree/main/research/Demo-Tuning.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.56.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Detect-Localize-Repair: A Unified Framework for Learning to Debug with CodeT5",
        "authors": [
            "Nghi Bui",
            "Yue Wang",
            "Steven C.H. Hoi"
        ],
        "published": "2022",
        "summary": "Automated software debugging is a crucial task for improving the productivity of software developers. Many neural-based techniques have been proven effective for debugging-related tasks such as bug localization and program repair (or bug fixing). However, these techniques often focus only on either one of them or approach them in a stage-wise manner, ignoring the mutual benefits between them. In this work, we propose a novel unified Detect-Localize-Repair framework based on a pretrained programming language model CodeT5 to seamlessly address these tasks, named CodeT5-DLR. Specifically, we propose three objectives to adapt the generic CodeT5 for debugging: a bug detection objective to determine whether a given code snippet is buggy or not, a bug localization objective to identify the buggy lines, and a program repair objective to translate the buggy code to its fixed version. We evaluate it on each of these tasks and their combined setting on two newly collected line-level debugging datasets in Java and Python. Extensive results show that our model significantly outperforms existing baselines from both NLP and software engineering domains.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.57.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Impact of Pretraining Term Frequencies on Few-Shot Numerical Reasoning",
        "authors": [
            "Yasaman Razeghi",
            "Robert L Logan IV",
            "Matt Gardner",
            "Sameer Singh"
        ],
        "published": "2022",
        "summary": "Pretrained Language Models (LMs) have demonstrated ability to perform numerical reasoning by extrapolating from a few examples in few-shot settings. However, the extent to which this extrapolation relies on robust reasoning is unclear. In this paper, we investigate how well these models reason with terms that are less frequent in the pretraining data. In particular, we examine the correlations between the model performance on test instances and the frequency of terms from those instances in the pretraining data. We measure the strength of this correlation for a number of GPT-based language models (pretrained on the Pile dataset) on various numerical deduction tasks (e.g., arithmetic and unit conversion). Our results consistently demonstrate that models are more accurate on instances whose terms are more prevalent, in some cases above 70% (absolute) more accurate on the top 10% frequent terms in comparison to the bottom 10%. Overall, although LMs appear successful at few-shot numerical reasoning, our results raise the question of how much models actually generalize beyond pretraining data, and we encourage researchers to take the pretraining data into account when interpreting evaluation results.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.59.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Syntactic and Semantic Uniformity for Semantic Parsing and Task-Oriented Dialogue Systems",
        "authors": [
            "Bowen Chen",
            "Yusuke Miyao"
        ],
        "published": "2022",
        "summary": "This paper proposes a data representation framework for semantic parsing and task-oriented dialogue systems, aiming to achieve a uniform representation for syntactically and semantically diverse machine-readable formats.Current NLP systems heavily rely on adapting pre-trained language models to specific tasks, and this approach has been proven effective for modeling natural language texts.However, little attention has been paid to the representation of machine-readable formats, such as database queries and dialogue states.We present a method for converting original machine-readable formats of semantic parsing and task-oriented dialogue datasets into a syntactically and semantically uniform representation.We define a meta grammar for syntactically uniform representations and translate semantically equivalent functions into a uniform vocabulary.Empirical experiments on 13 datasets show that accuracy consistently improves over original formats, revealing the advantage of the proposed representation.Additionally, we show that the proposed representation allows for transfer learning across datasets.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.60.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Language Models Are Poor Learners of Directional Inference",
        "authors": [
            "Tianyi Li",
            "Mohammad Javad Hosseini",
            "Sabine Weber",
            "Mark Steedman"
        ],
        "published": "2022",
        "summary": "We examine LMs’ competence of directional predicate entailments by supervised fine-tuning with prompts. Our analysis shows that contrary to their apparent success on standard NLI, LMs show limited ability to learn such directional inference; moreover, existing datasets fail to test directionality, and/or are infested by artefacts that can be learnt as proxy for entailments, yielding over-optimistic results. In response, we present BoOQA (Boolean Open QA), a robust multi-lingual evaluation benchmark for directional predicate entailments, extrinsic to existing training sets. On BoOQA, we establish baselines and show evidence of existing LM-prompting models being incompetent directional entailment learners, in contrast to entailment graphs, however limited by sparsity.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.64.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Plug-and-Play VQA: Zero-shot VQA by Conjoining Large Pretrained Models with Zero Training",
        "authors": [
            "Anthony Meng Huat Tiong",
            "Junnan Li",
            "Boyang Li",
            "Silvio Savarese",
            "Steven C.H. Hoi"
        ],
        "published": "2022",
        "summary": "Visual question answering (VQA) is a hallmark of vision and language reasoningand a challenging task under the zero-shot setting.We propose Plug-and-Play VQA (PNP-VQA),a modular framework for zero-shot VQA.In contrast to most existing works, which require substantial adaptation of pretrained language models (PLMs) for the vision modality,PNP-VQA requires no additional training of the PLMs.Instead, we propose to use natural language and network interpretation as an intermediate representation that glues pretrained models together. We first generate question-guided informative image captions,and pass the captions to a PLM as context for question answering.Surpassing end-to-end trained baselines, PNP-VQA achieves state-of-the-art results on zero-shot VQAv2 and GQA. With 11B parameters, it outperforms the 80B-parameter Flamingo model by 8.5% on VQAv2. With 738M PLM parameters, PNP-VQA achieves an improvement of 9.1% on GQA over FewVLM with 740M PLM parameters.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.67.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "TSGP: Two-Stage Generative Prompting for Unsupervised Commonsense Question Answering",
        "authors": [
            "Yueqing Sun",
            "Yu Zhang",
            "Le Qi",
            "Qi Shi"
        ],
        "published": "2022",
        "summary": "Without training on labeled task data, unsupervised commonsense question answering seems challenging since it requires commonsense knowledge beyond the context of questions. Previous methods typically retrieved from traditional knowledge bases or used pre-trained language models (PrLMs) to generate fixed types of knowledge, which have poor generalization ability.In this paper, we aim to address the above limitation by leveraging the implicit knowledge stored in PrLMs and propose a two-stage prompt-based unsupervised commonsense question answering framework (TSGP). We first use knowledge generation prompts to generate the knowledge required for questions with unlimited types and possible candidate answers independent of specified choices. Then, we further utilize answer generation prompts to generate possible candidate answers independent of specified choices. Experimental results and analysis on three different commonsense reasoning tasks, CommonsenseQA, OpenBookQA, and SocialIQA, demonstrate that TSGP significantly improves the reasoning ability of language models in unsupervised settings.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.68.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Autoregressive Structured Prediction with Language Models",
        "authors": [
            "Tianyu Liu",
            "Yuchen Eleanor Jiang",
            "Nicholas Monath",
            "Ryan Cotterell",
            "Mrinmaya Sachan"
        ],
        "published": "2022",
        "summary": "Recent years have seen a paradigm shift in NLP towards using pretrained language models (PLM) for a wide range of tasks. However, there are many difficult design decisions to represent structures (e.g. tagged text, coreference chains) in a way such that they can be captured by PLMs. Prior work on structured prediction with PLMs typically flattens the structured output into a sequence, which limits the quality of structural information being learned and leads to inferior performance compared to classic discriminative models. In this work, we describe an approach to model structures as sequences of actions in an autoregressive manner with PLMs, allowing in-structure dependencies to be learned without any loss. Our approach achieves the new state-of-the-art on all the structured prediction tasks we looked at, namely, named entity recognition, end-to-end relation extraction, and coreference resolution.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.70.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "ExpertPLM: Pre-training Expert Representation for Expert Finding",
        "authors": [
            "Qiyao Peng",
            "Hongtao Liu"
        ],
        "published": "2022",
        "summary": "Expert Finding is an important task in Community Question Answering (CQA) platforms, which could help route questions to potential users to answer. The key is to learn representations of experts based on their historical answered questions accurately. In this paper, inspired by the strong text understanding ability of Pretrained Language modelings (PLMs), we propose a pre-training and fine-tuning expert finding framework. The core is that we design an expert-level pre-training paradigm, that effectively integrates expert interest and expertise simultaneously. Specifically different from the typical corpus-level pre-training, we treat each expert as the basic pre-training unit including all the historical answered question titles of the expert, which could fully indicate the expert interests for questions. Besides, we integrate the vote score information along with each answer of the expert into the pre-training phrase to model the expert ability explicitly. Finally, we propose a novel reputation-augmented Masked Language Model (MLM) pre-training strategy to capture the expert reputation information. In this way, our method could learn expert representation comprehensively, which then will be adopted and fine-tuned in the down-streaming expert-finding task. Extensive experimental results on six real-world CQA datasets demonstrate the effectiveness of our method.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.74.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "You Truly Understand What I Need : Intellectual and Friendly Dialog Agents grounding Persona and Knowledge",
        "authors": [
            "Jungwoo Lim",
            "Myugnhoon Kang",
            "Yuna Hur",
            "Seung Won Jeong",
            "Jinsung Kim",
            "Yoonna Jang",
            "Dongyub Lee",
            "Hyesung Ji",
            "DongHoon Shin",
            "Seungryong Kim",
            "Heuiseok Lim"
        ],
        "published": "2022",
        "summary": "To build a conversational agent that interacts fluently with humans, previous studies blend knowledge or personal profile into the pre-trained language model. However, the model that considers knowledge and persona at the same time is still limited, leading to hallucination and a passive way of using personas. We propose an effective dialogue agent that grounds external knowledge and persona simultaneously. The agent selects the proper knowledge and persona to use for generating the answers with our candidate scoring implemented with a poly-encoder. Then, our model generates the utterance with lesser hallucination and more engagingness utilizing retrieval augmented generation with knowledge-persona enhanced query. We conduct experiments on the persona-knowledge chat and achieve state-of-the-art performance in grounding and generation tasks on the automatic metrics. Moreover, we validate the answers from the models regarding hallucination and engagingness through human evaluation and qualitative results. We show our retriever’s effectiveness in extracting relevant documents compared to the other previous retrievers, along with the comparison of multiple candidate scoring methods. Code is available at https://github.com/dlawjddn803/INFO",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.75.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Faithful to the Document or to the World? Mitigating Hallucinations via Entity-Linked Knowledge in Abstractive Summarization",
        "authors": [
            "Yue Dong",
            "John Wieting",
            "Pat Verga"
        ],
        "published": "2022",
        "summary": "Existing abstractive summarization systems are hampered by content hallucinations in which models generate text that is not directly inferable from the source alone. Annotations from prior work have shown that some of these hallucinations, while being ‘unfaithful’ to the source, are nonetheless factual. Our analysis in this paper suggests that these factual hallucinations occur as a result of the prevalence of factual yet unfaithful entities in summarization datasets. We find that these entities are not aberrations, but instead examples of additional world knowledge being readily used to latently connect entities and concepts – in this case connecting entities in the source document to those in the target summary. In our analysis and experiments, we demonstrate that connecting entities to an external knowledge base can lend provenance to many of these unfaithful yet factual entities, and further, this knowledge can be used to improve the factuality of summaries without simply making them more extractive.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.76.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "RL with KL penalties is better viewed as Bayesian inference",
        "authors": [
            "Tomasz Korbak",
            "Ethan Perez",
            "Christopher Buckley"
        ],
        "published": "2022",
        "summary": "Reinforcement learning (RL) is frequently employed in fine-tuning large language models (LMs), such as GPT-3, to penalize them for undesirable features of generated sequences, such as offensiveness, social bias, harmfulness or falsehood. The RL formulation involves treating the LM as a policy and updating it to maximise the expected value of a reward function which captures human preferences, such as non-offensiveness. In this paper, we analyze challenges associated with treating a language model as an RL policy and show how avoiding those challenges requires moving beyond the RL paradigm. We start by observing that the standard RL approach is flawed as an objective for fine-tuning LMs because it leads to distribution collapse: turning the LM into a degenerate distribution. Then, we analyze KL-regularised RL, a widely used recipe for fine-tuning LMs, which additionally constrains the fine-tuned LM to stay close to its original distribution in terms of Kullback-Leibler (KL) divergence. We show that KL-regularised RL is equivalent to variational inference: approximating a Bayesian posterior which specifies how to update a prior LM to conform with evidence provided by the reward function. We argue that this Bayesian inference view of KL-regularised RL is more insightful than the typically employed RL perspective. The Bayesian inference view explains how KL-regularised RL avoids the distribution collapse problem and offers a first-principles derivation for its objective. While this objective happens to be equivalent to RL (with a particular choice of parametric reward), there exist other objectives for fine-tuning LMs which are no longer equivalent to RL. That observation leads to a more general point: RL is not an adequate formal framework for problems such as fine-tuning language models. These problems are best viewed as Bayesian inference: approximating a pre-defined target distribution.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.77.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Progressive Sentiment Analysis for Code-Switched Text Data",
        "authors": [
            "Sudhanshu Ranjan",
            "Dheeraj Mekala",
            "Jingbo Shang"
        ],
        "published": "2022",
        "summary": "Multilingual transformer language models have recently attracted much attention from researchers and are used in cross-lingual transfer learning for many NLP tasks such as text classification and named entity recognition.However, similar methods for transfer learning from monolingual text to code-switched text have not been extensively explored mainly due to the following challenges:(1) Code-switched corpus, unlike monolingual corpus, consists of more than one language and existing methods can’t be applied efficiently,(2) Code-switched corpus is usually made of resource-rich and low-resource languages and upon using multilingual pre-trained language models, the final model might bias towards resource-rich language. In this paper, we focus on code-switched sentiment analysis where we have a labelled resource-rich language dataset and unlabelled code-switched data. We propose a framework that takes the distinction between resource-rich and low-resource language into account.Instead of training on the entire code-switched corpus at once, we create buckets based on the fraction of words in the resource-rich language and progressively train from resource-rich language dominated samples to low-resource language dominated samples. Extensive experiments across multiple language pairs demonstrate that progressive training helps low-resource language dominated samples.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.82.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Knowledge Stimulated Contrastive Prompting for Low-Resource Stance Detection",
        "authors": [
            "Kai Zheng",
            "Qingfeng Sun",
            "Yaming Yang",
            "Fei Xu"
        ],
        "published": "2022",
        "summary": "Stance Detection Task (SDT) aims at identifying the stance of the sentence towards a specific target and is usually modeled as a classification problem. Backgound knowledge is often necessary for stance detection with respect to a specific target, especially when there is no target explicitly mentioned in text. This paper focuses on the knowledge stimulation for low-resource stance detection tasks. We firstly explore to formalize stance detection as a prompt based contrastive learning task. At the same time, to make prompt learning suit to stance detection, we design a template mechanism to incorporate corresponding target into instance representation. Furthermore, we propose a masked language prompt joint contrastive learning approach to stimulate the knowledge inherit from the pre-trained model. The experimental results on three benchmarks show that knowledge stimulation is effective in stance detection accompanied with our proposed mechanism.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.83.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Exploring Compositional Image Retrieval with Hybrid Compositional Learning and Heuristic Negative Mining",
        "authors": [
            "Chao Wang",
            "Ehsan Nezhadarya",
            "Tanmana Sadhu",
            "Shengdong Zhang"
        ],
        "published": "2022",
        "summary": "Compositional image retrieval (CIR) is a challenging retrieval task, where the query is composed of a reference image and a modification text, and the target is another image reflecting the modification to the reference image. Due to the great success of the pre-trained vision-and-language model CLIP and its favorable applicability to large-scale retrieval tasks, we propose a CIR model HyCoLe-HNM with CLIP as the backbone. In HyCoLe-HNM, we follow the contrastive pre-training method of CLIP to perform cross-modal representation learning. On this basis, we propose a hybrid compositional learning mechanism, which includes both image compositional learning and text compositional learning. In hybrid compositional learning, we borrow a gated fusion mechanism from a question answering model to perform compositional fusion, and propose a heuristic negative mining method to filter negative samples. Privileged information in the form of image-related texts is utilized in cross-modal representation learning and hybrid compositional learning. Experimental results show that HyCoLe-HNM achieves state-of-the-art performance on three CIR datasets, namely FashionIQ, Fashion200K, and MIT-States.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.92.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Outlier Dimensions that Disrupt Transformers are Driven by Frequency",
        "authors": [
            "Giovanni Puccetti",
            "Anna Rogers",
            "Aleksandr Drozd",
            "Felice Dell’Orletta"
        ],
        "published": "2022",
        "summary": "While Transformer-based language models are generally very robust to pruning, there is the recently discovered outlier phenomenon: disabling only 48 out of 110M parameters in BERT-base drops its performance by nearly 30% on MNLI. We replicate the original evidence for the outlier phenomenon and we link it to the geometry of the embedding space. We find that in both BERT and RoBERTa the magnitude of hidden state coefficients corresponding to outlier dimensions correlate with the frequencies of encoded tokens in pre-training data, and they also contribute to the “vertical” self-attention pattern enabling the model to focus on the special tokens. This explains the drop in performance from disabling the outliers, and it suggests that to decrease anisotopicity in future models we need pre-training schemas that would better take into account the skewed token distributions.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.93.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "MICO: A Multi-alternative Contrastive Learning Framework for Commonsense Knowledge Representation",
        "authors": [
            "Ying Su",
            "Zihao Wang",
            "Tianqing Fang",
            "Hongming Zhang",
            "Yangqiu Song",
            "Tong Zhang"
        ],
        "published": "2022",
        "summary": "Commonsense reasoning tasks such as commonsense knowledge graph completion and commonsense question answering require powerful representation learning. In this paper, we propose to learn commonsense knowledge representation by MICO, a Multi-alternative contrastIve learning framework on COmmonsense knowledge graphs (MICO). MICO generates the commonsense knowledge representation by contextual interaction between entity nodes and relations with multi-alternative contrastive learning. In MICO, the head and tail entities in an (h,r,t) knowledge triple are converted to two relation-aware sequence pairs (a premise and an alternative) in the form of natural language. Semantic representations generated by MICO can benefit the following two tasks by simply comparing the similarity score between the representations: 1) zero-shot commonsense question answering tasks; 2) inductive commonsense knowledge graph completion tasks. Extensive experiments show the effectiveness of our method.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.96.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Leveraging Only the Category Name for Aspect Detection through Prompt-based Constrained Clustering",
        "authors": [
            "Yazheng Li",
            "Pengyun Wang",
            "Yasheng Wang",
            "Yong Dai",
            "Yadao Wang",
            "Lujia Pan",
            "Zenglin Xu"
        ],
        "published": "2022",
        "summary": "Aspect category detection (ACD) aims to automatically identify user-concerned aspects from online reviews, which is of great value for evaluating the fine-grained performance of a product. The most recent solutions tackle this problem via weakly supervised methods, achieving remarkable improvement over unsupervised methods. However, a closer look at these methods reveals that the required human efforts are nontrivial and can sometimes be hard to obtain. In this study, we explore the possibility of minimizing human guidance while improving detection performance, with a deep clustering method that relies merely on the category name of each aspect and a pretrained language model (LM). The LM, combined with prompt techniques, is employed as a knowledge base to automatically generate constraints for clustering, as well as to provide a representation space to perform the clustering. Our method (1) extracts extensive keywords to expand our understanding of each aspect, (2) automatically generates instance-level and concept-level constraints for clustering, and (3) trains the clustering model with the above constraints. We demonstrate the capability of the proposed framework through extensive experiments on nine benchmark datasets. Our model not only performs noticeably better than existing unsupervised approaches but also considerably surpasses weakly supervised methods that require more human efforts.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.97.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Transformer Language Models without Positional Encodings Still Learn Positional Information",
        "authors": [
            "Adi Haviv",
            "Ori Ram",
            "Ofir Press",
            "Peter Izsak",
            "Omer Levy"
        ],
        "published": "2022",
        "summary": "Causal transformer language models (LMs), such as GPT-3, typically require some form of positional encoding, such as positional embeddings. However, we show that LMs without any explicit positional encoding are still competitive with standard models and that this phenomenon is robust across different datasets, model sizes, and sequence lengths.Probing experiments reveal that such models acquire an implicit notion of absolute positions throughout the network, effectively compensating for the missing information.We conjecture that causal attention enables the model to infer the number of predecessors that each token can attend to, thereby approximating its absolute position.Our findings indicate that causal LMs might derive positional awareness not only from the explicit positioning mechanism but also from the effects of the causal mask.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.99.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "How Much Does Attention Actually Attend? Questioning the Importance of Attention in Pretrained Transformers",
        "authors": [
            "Michael Hassid",
            "Hao Peng",
            "Daniel Rotem",
            "Jungo Kasai",
            "Ivan Montero",
            "Noah A. Smith",
            "Roy Schwartz"
        ],
        "published": "2022",
        "summary": "The attention mechanism is considered the backbone of the widely-used Transformer architecture. It contextualizes the input by computing input-specific attention matrices. We find that this mechanism, while powerful and elegant, is not as important as typically thought for pretrained language models. We introduce PAPA, a new probing method that replaces the input-dependent attention matrices with constant ones—the average attention weights over multiple inputs. We use PAPA to analyze several established pretrained Transformers on six downstream tasks. We find that without any input-dependent attention, all models achieve competitive performance—an average relative drop of only 8% from the probing baseline. Further, little or no performance drop is observed when replacing half of the input-dependent attention matrices with constant (input-independent) ones. Interestingly, we show that better-performing models lose more from applying our method than weaker models, suggesting that the utilization of the input-dependent attention mechanism might be a factor in their success. Our results motivate research on simpler alternatives to input-dependent attention, as well as on methods for better utilization of this mechanism in the Transformer architecture.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.101.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "What Has Been Enhanced in my Knowledge-Enhanced Language Model?",
        "authors": [
            "Yifan Hou",
            "Guoji Fu",
            "Mrinmaya Sachan"
        ],
        "published": "2022",
        "summary": "A number of knowledge integration (KI) methods have recently been proposed to incorporate external knowledge into pretrained language models (LMs). Even though knowledge-enhanced LMs (KELMs) outperform base LMs on knowledge-intensive tasks, the inner-workings of these KI methods are not well-understood. For instance, it is unclear which knowledge is effectively integrated into KELMs and which is not; and if such integration led to catastrophic forgetting of already learned knowledge. We show that existing model interpretation methods such as linear probes and prompts have some key limitations in answering these questions. Then, we revisit KI from an information-theoretic view and propose a new theoretically sound probe model called Graph Convolution Simulator (GCS) for KI interpretation. GCS is eventually quite simple – it uses graph attention on the corresponding knowledge graph for interpretation.We conduct various experiments to verify that GCS provides reasonable interpretation results for two well-known KELMs: ERNIE and K-Adapter. Our experiments reveal that only little knowledge is successfully integrated in these models, and simply increasing the size of the KI corpus may not lead to better KELMs.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.102.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Mask More and Mask Later: Efficient Pre-training of Masked Language Models by Disentangling the [MASK] Token",
        "authors": [
            "Baohao Liao",
            "David Thulke",
            "Sanjika Hewavitharana",
            "Hermann Ney",
            "Christof Monz"
        ],
        "published": "2022",
        "summary": "The pre-training of masked language models (MLMs) consumes massive computation to achieve good results on downstream NLP tasks, resulting in a large carbon footprint. In the vanilla MLM, the virtual tokens, [MASK]s, act as placeholders and gather the contextualized information from unmasked tokens to restore the corrupted information. It raises the question of whether we can append [MASK]s at a later layer, to reduce the sequence length for earlier layers and make the pre-training more efficient. We show: (1) [MASK]s can indeed be appended at a later layer, being disentangled from the word embedding; (2) The gathering of contextualized information from unmasked tokens can be conducted with a few layers. By further increasing the masking rate from 15% to 50%, we can pre-train RoBERTa-base and RoBERTa-large from scratch with only 78% and 68% of the original computational budget without any degradation on the GLUE benchmark. When pre-training with the original budget, our method outperforms RoBERTa for 6 out of 8 GLUE tasks, on average by 0.4%.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.106.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Residual Learning of Neural Text Generation with n-gram Language Model",
        "authors": [
            "Huayang Li",
            "Deng Cai",
            "Jin Xu",
            "Taro Watanabe"
        ],
        "published": "2022",
        "summary": "N-gram language models (LM) has been largely superseded by neural LMs as the latter exhibits better performance. However, we find that n-gram models can achieve satisfactory performance on a large proportion of testing cases, indicating they have already captured abundant knowledge of the language with relatively low computational cost. With this observation, we propose to learn a neural LM that fits the residual between an n-gram LM and the real-data distribution. The combination of n-gram LMs and neural LMs not only allows the neural part to focus on deeper understanding of the language, but also provides a flexible way to customize a LM by switching the underlying n-gram model without changing the neural model. Experimental results on three typical language tasks (i.e., language modeling, machine translation, and summarization) demonstrate that our approach attains additional performance gains over popular standalone neural models consistently. We also show that our approach allows for effective domain adaptation by simply switching to a domain-specific n-gram model, without any extra training.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.109.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "DiffG-RL: Leveraging Difference between Environment State and Common Sense",
        "authors": [
            "Tsunehiko Tanaka",
            "Daiki Kimura",
            "Michiaki Tatsubori"
        ],
        "published": "2022",
        "summary": "Taking into account background knowledge as the context has always been an important part of solving tasks that involve natural language. One representative example of such tasks is text-based games, where players need to make decisions based on both description text previously shown in the game, and their own background knowledge about the language and common sense. In this work, we investigate not simply giving common sense, as can be seen in prior research, but also its effective usage. We assume that a part of the environment states different from common sense should constitute one of the grounds for action selection. We propose a novel agent, DiffG-RL, which constructs a Difference Graph that organizes the environment states and common sense by means of interactive objects with a dedicated graph encoder. DiffG-RL also contains a framework for extracting the appropriate amount and representation of common sense from the source to support the construction of the graph. We validate DiffG-RL in experiments with text-based games that require common sense and show that it outperforms baselines by 17% of scores. We will make our code publicly available.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.110.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Can AMR Assist Legal and Logical Reasoning?",
        "authors": [
            "Nikolaus Schrack",
            "Ruixiang Cui",
            "Hugo López",
            "Daniel Hershcovich"
        ],
        "published": "2022",
        "summary": "Abstract Meaning Representation (AMR) has been shown to be useful for many downstream tasks. In this work, we explore the use of AMR for legal and logical reasoning. Specifically, we investigate if AMR can help capture logical relationships on multiple choice question answering (MCQA) tasks. We propose neural architectures that utilize linearised AMR graphs in combination with pre-trained language models. While these models are not able to outperform text-only baselines, they correctly solve different instances than the text models, suggesting complementary abilities. Error analysis further reveals that AMR parsing quality is the most prominent challenge, especially regarding inputs with multiple sentences. We conduct a theoretical analysis of how logical relations are represented in AMR and conclude it might be helpful in some logical statements but not for others.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.112.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Knowledge Graph Generation From Text",
        "authors": [
            "Igor Melnyk",
            "Pierre Dognin",
            "Payel Das"
        ],
        "published": "2022",
        "summary": "In this work we propose a novel end-to-end multi-stage Knowledge Graph (KG) generation system from textual inputs, separating the overall process into two stages. The graph nodes are generated first using pretrained language model, followed by a simple edge construction head, enabling efficient KG extraction from the text. For each stage we consider several architectural choices that can be used depending on the available training resources. We evaluated the model on a recent WebNLG 2020 Challenge dataset, matching the state-of-the-art performance on text-to-RDF generation task, as well as on New York Times (NYT) and a large-scale TekGen datasets, showing strong overall performance, outperforming the existing baselines. We believe that the proposed system can serve as a viable KG construction alternative to the existing linearization or sampling-based graph generation approaches.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.116.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Investigating Ensemble Methods for Model Robustness Improvement of Text Classifiers",
        "authors": [
            "Jieyu Zhao",
            "Xuezhi Wang",
            "Yao Qin",
            "Jilin Chen",
            "Kai-Wei Chang"
        ],
        "published": "2022",
        "summary": "Large pre-trained language models have shown remarkable performance over the past few years. These models, however, sometimes learn superficial features from the dataset and cannot generalize to the distributions that are dissimilar to the training scenario. There have been several approaches proposed to reduce model’s reliance on these bias features which can improve model robustness in the out-of-distribution setting. However, existing methods usually use a fixed low-capacity model to deal with various bias features, which ignore the learnability of those features. In this paper, we analyze a set of existing bias features and demonstrate there is no single model that works best for all the cases. We further show that by choosing an appropriate bias model, we can obtain a better robustness result than baselines with a more sophisticated model design.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.118.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models",
        "authors": [
            "Victor Bursztyn",
            "David Demeter",
            "Doug Downey",
            "Larry Birnbaum"
        ],
        "published": "2022",
        "summary": "How to usefully encode compositional task structure has long been a core challenge in AI. Recent work in chain of thought prompting has shown that for very large neural language models (LMs), explicitly demonstrating the inferential steps involved in a target task may improve performance over end-to-end learning that focuses on the target task alone. However, chain of thought prompting has significant limitations due to its dependency on huge pretrained LMs. In this work, we present compositional fine-tuning (CFT): an approach based on explicitly decomposing a target task into component tasks, and then fine-tuning smaller LMs on a curriculum of such component tasks. We apply CFT to recommendation tasks in two domains, world travel and local dining, as well as a previously studied inferential task (sports understanding). We show that CFT outperforms end-to-end learning even with equal amounts of data, and gets consistently better as more component tasks are modeled via fine-tuning. Compared with chain of thought prompting, CFT performs at least as well using LMs only 7.4% of the size, and is moreover applicable to task domains for which data are not available during pretraining.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.121.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Towards Explaining Subjective Ground of Individuals on Social Media",
        "authors": [
            "Younghun Lee",
            "Dan Goldwasser"
        ],
        "published": "2022",
        "summary": "Large-scale language models have been reducing the gap between machines and humans in understanding the real world, yet understanding an individual’s theory of mind and behavior from text is far from being resolved. This research proposes a neural model—Subjective Ground Attention—that learns subjective grounds of individuals and accounts for their judgments on situations of others posted on social media. Using simple attention modules as well as taking one’s previous activities into consideration, we empirically show that our model provides human-readable explanations of an individual’s subjective preference in judging social situations. We further qualitatively evaluate the explanations generated by the model and claim that our model learns an individual’s subjective orientation towards abstract moral concepts.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.126.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Do Language Models Understand Measurements?",
        "authors": [
            "Sungjin Park",
            "Seungwoo Ryu",
            "Edward Choi"
        ],
        "published": "2022",
        "summary": "Recent success of pre-trained language models (PLMs) has stimulated interest in their ability to understand and work with numbers. Yet, the numerical reasoning over measurements has not been formally studied despite their importance. In this study, we show that PLMs lack the capability required for reasoning over measurements. Furthermore, we find that a language model trained on a measurement-rich corpus shows better performance on understanding measurements. We propose a simple embedding strategy to better distinguish between numbers and units, which leads to a significant improvement in the probing tasks.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.128.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "ASDOT: Any-Shot Data-to-Text Generation with Pretrained Language Models",
        "authors": [
            "Jiannan Xiang",
            "Zhengzhong Liu",
            "Yucheng Zhou",
            "Eric Xing",
            "Zhiting Hu"
        ],
        "published": "2022",
        "summary": "Data-to-text generation is challenging due to the great variety of the input data in terms of domains (e.g., finance vs sports) or schemata (e.g., diverse predicates). Recent end-to-end neural methods thus require substantial training examples to learn to disambiguate and describe the data. Yet, real-world data-to-text problems often suffer from various data-scarce issues: one may have access to only a handful of or no training examples, and/or have to rely on examples in a different domain or schema. To fill this gap, we propose Any-Shot Data-to-Text (ASDOT), a new approach flexibly applicable to diverse settings by making efficient use of any given (or no) examples. ASDOT consists of two steps, data disambiguation and sentence fusion, both of which are amenable to be solved with off-the-shelf pretrained language models (LMs) with optional finetuning. In the data disambiguation stage, we employ the prompted GPT-3 model to understand possibly ambiguous triples from the input data and convert each into a short sentence with reduced ambiguity. The sentence fusion stage then uses an LM like T5 to fuse all the resulting sentences into a coherent paragraph as the final description. We evaluate extensively on various datasets in different scenarios, including the zero-/few-/full-shot settings, and generalization to unseen predicates and out-of-domain data. Experimental results show that ASDOT consistently achieves significant improvement over baselines, e.g., a 30.81 BLEU gain on the DART dataset under the zero-shot setting.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.136.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Audience-Centric Natural Language Generation via Style Infusion",
        "authors": [
            "Samraj Moorjani",
            "Adit Krishnan",
            "Hari Sundaram",
            "Ewa Maslowska",
            "Aravind Sankar"
        ],
        "published": "2022",
        "summary": "Adopting contextually appropriate, audience-tailored linguistic styles is critical to the success of user-centric language generation systems (e.g., chatbots, computer-aided writing, dialog systems). While existing approaches demonstrate text style transfer (TST) with large volumes of parallel or non-parallel data, we argue that grounding style on audience-independent external factors is innately limiting for two reasons. First, it is difficult to collect large volumes of audience-specific stylistic data. Second, some stylistic objectives (e.g., persuasiveness, memorability, empathy) are hard to define without audience feedback. In this paper, we propose the novel task of style infusion - infusing the stylistic preferences of audiences in pretrained language generation models. Since humans are better at pairwise comparisons than direct scoring - i.e., is Sample-A more persuasive/polite/empathic than Sample-B - we leverage limited pairwise human judgments to bootstrap a style analysis model and augment our seed set of judgments. We then infuse the learned textual style in a GPT-2 based text generator while balancing fluency and style adoption. With quantitative and qualitative assessments, we show that our infusion approach can generate compelling stylized examples with generic text prompts. We make the anonymized code and data accessible.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.138.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "MatRank: Text Re-ranking by Latent Preference Matrix",
        "authors": [
            "Jinwen Luo",
            "Jiuding Yang",
            "Weidong Guo",
            "Chenglin Li",
            "Di Niu",
            "Yu Xu"
        ],
        "published": "2022",
        "summary": "Text ranking plays a key role in providing content that best answers user queries. It is usually divided into two sub-tasks to perform efficient information retrieval given a query: text retrieval and text re-ranking. Recent research on pretrained language models (PLM) has demonstrated efficiency and gain on both sub-tasks. However, while existing methods have benefited from pre-trained language models and achieved high recall rates on passage retrieval, the ranking performance still demands further improvement. In this paper, we propose MatRank, which learns to re-rank the text retrieved for a given query by learning to predict the most relevant passage based on a latent preference matrix. Specifically, MatRank uses a PLM to generate an asymmetric latent matrix of relative preference scores between all pairs of retrieved passages. Then, the latent matrix is aggregated row-wise and column-wise to obtain global preferences and predictions of the most relevant passage in two of these directions, respectively. We conduct extensive experiments on MS MACRO, WikiAQ, and SemEval datasets. Experimental results show that MatRank has achieved new state-of-the-art results on these datasets, outperforming all prior methods on ranking performance metrics.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.146.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Can Language Models Serve as Temporal Knowledge Bases?",
        "authors": [
            "Ruilin Zhao",
            "Feng Zhao",
            "Guandong Xu",
            "Sixiao Zhang",
            "Hai Jin"
        ],
        "published": "2022",
        "summary": "Recent progress regarding the use of language models (LMs) as knowledge bases (KBs) has shown that language models can act as structured knowledge bases for storing relational facts. However, most existing works only considered the LM-as-KB paradigm in a static setting, which ignores the analysis of temporal dynamics of world knowledge. Furthermore, a basic function of KBs, i.e., the ability to store conflicting information (i.e., 1-N, N-1, and N-M relations), is underexplored. In this paper, we formulate two practical requirements for treating LMs as temporal KBs: (i) The capacity to store temporally-scoped knowledge that contains conflicting information and (ii) the ability to use stored knowledge for temporally-scoped knowledge queries. We introduce a new dataset called LAMA-TK which is aimed at probing temporally-scoped knowledge, and investigate the two above requirements to explore the LM-as-KB paradigm in the temporal domain. On the one hand, experiments show that LMs can memorize millions of temporally-scoped facts with relatively high accuracy and transfer stored knowledge to temporal knowledge queries, thereby expanding the LM-as-KB paradigm to the temporal domain. On the other hand, we show that memorizing conflicting information, which has been neglected by previous works, is still challenging for LMs and hinders the memorization of other unrelated one-to-one relationships.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.147.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Are Large Pre-Trained Language Models Leaking Your Personal Information?",
        "authors": [
            "Jie Huang",
            "Hanyin Shao",
            "Kevin Chen-Chuan Chang"
        ],
        "published": "2022",
        "summary": "Are Large Pre-Trained Language Models Leaking Your Personal Information? In this paper, we analyze whether Pre-Trained Language Models (PLMs) are prone to leaking personal information. Specifically, we query PLMs for email addresses with contexts of the email address or prompts containing the owner’s name. We find that PLMs do leak personal information due to memorization. However, since the models are weak at association, the risk of specific personal information being extracted by attackers is low. We hope this work could help the community to better understand the privacy risk of PLMs and bring new insights to make PLMs safe.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.148.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Scientific and Creative Analogies in Pretrained Language Models",
        "authors": [
            "Tamara Czinczoll",
            "Helen Yannakoudakis",
            "Pushkar Mishra",
            "Ekaterina Shutova"
        ],
        "published": "2022",
        "summary": "This paper examines the encoding of analogy in large-scale pretrained language models, such as BERT and GPT-2. Existing analogy datasets typically focus on a limited set of analogical relations, with a high similarity of the two domains between which the analogy holds. As a more realistic setup, we introduce the Scientific and Creative Analogy dataset (SCAN), a novel analogy dataset containing systematic mappings of multiple attributes and relational structures across dissimilar domains. Using this dataset, we test the analogical reasoning capabilities of several widely-used pretrained language models (LMs). We find that state-of-the-art LMs achieve low performance on these complex analogy tasks, highlighting the challenges still posed by analogy understanding.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.153.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "A Neural-Symbolic Approach to Natural Language Understanding",
        "authors": [
            "Zhixuan Liu",
            "Zihao Wang",
            "Yuan Lin",
            "Hang Li"
        ],
        "published": "2022",
        "summary": "Deep neural networks, empowered by pre-trained language models, have achieved remarkable results in natural language understanding (NLU) tasks. However, their performances can drastically deteriorate when logical reasoning is needed. This is because NLU in principle depends on not only analogical reasoning, which deep neural networks are good at, but also logical reasoning. According to the dual-process theory, analogical reasoning and logical reasoning are respectively carried out by System 1 and System 2 in the human brain. Inspired by the theory, we present a novel framework for NLU called Neural-Symbolic Processor (NSP), which performs analogical reasoning based on neural processing and logical reasoning based on both neural and symbolic processing. As a case study, we conduct experiments on two NLU tasks, question answering (QA) and natural language inference (NLI), when numerical reasoning (a type of logical reasoning) is necessary. The experimental results show that our method significantly outperforms state-of-the-art methods in both tasks.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.158.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "SparseAdapter: An Easy Approach for Improving the Parameter-Efficiency of Adapters",
        "authors": [
            "Shwai He",
            "Liang Ding",
            "Daize Dong",
            "Jeremy Zhang",
            "Dacheng Tao"
        ],
        "published": "2022",
        "summary": "Adapter Tuning, which freezes the pretrained language models (PLMs) and only fine-tunes a few extra modules, becomes an appealing efficient alternative to the full model fine-tuning. Although computationally efficient, the recent Adapters often increase parameters (e.g. bottleneck dimension) for matching the performance of full model fine-tuning, which we argue goes against their original intention. In this work, we re-examine the parameter-efficiency of Adapter through the lens of network pruning (we name such plug-in concept as SparseAdapter) and find that SparseAdapter can achieve comparable or better performance than standard Adapters when the sparse ratio reaches up to 80%. Based on our findings, we introduce an easy but effective setting “Large-Sparse” to improve the model capacity of Adapters under the same parameter budget. Experiments on five competitive Adapters upon three advanced PLMs show that with proper sparse method (e.g. SNIP) and ratio (e.g. 40%) SparseAdapter can consistently outperform their corresponding counterpart. Encouragingly, with the Large-Sparse setting, we can obtain further appealing gains, even outperforming the full fine-tuning by a large margin.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.160.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Snapshot-Guided Domain Adaptation for ELECTRA",
        "authors": [
            "Daixuan Cheng",
            "Shaohan Huang",
            "Jianfeng Liu",
            "Yuefeng Zhan",
            "Hao Sun",
            "Furu Wei",
            "Denvy Deng",
            "Qi Zhang"
        ],
        "published": "2022",
        "summary": "Discriminative pre-trained language models, such as ELECTRA, have achieved promising performances in a variety of general tasks. However, these generic pre-trained models struggle to capture domain-specific knowledge of domain-related tasks. In this work, we propose a novel domain-adaptation method for ELECTRA, which can dynamically select domain-specific tokens and guide the discriminator to emphasize them, without introducing new training parameters. We show that by re-weighting the losses of domain-specific tokens, ELECTRA can be effectively adapted to different domains. The experimental results in both computer science and biomedical domains show that the proposed method can achieve state-of-the-art results on the domain-related tasks.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.163.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Using Developer Discussions to Guide Fixing Bugs in Software",
        "authors": [
            "Sheena Panthaplackel",
            "Milos Gligoric",
            "Junyi Jessy Li",
            "Raymond Mooney"
        ],
        "published": "2022",
        "summary": "Automatically fixing software bugs is a challenging task. While recent work showed that natural language context is useful in guiding bug-fixing models, the approach required prompting developers to provide this context, which was simulated through commit messages written after the bug-fixing code changes were made. We instead propose using bug report discussions, which are available before the task is performed and are also naturally occurring, avoiding the need for any additional information from developers. For this, we augment standard bug-fixing datasets with bug report discussions. Using these newly compiled datasets, we demonstrate that various forms of natural language context derived from such discussions can aid bug-fixing, even leading to improved performance over using commit messages corresponding to the oracle bug-fixing commits.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.169.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "A Multi-Modal Knowledge Graph for Classical Chinese Poetry",
        "authors": [
            "Yuqing Li",
            "Yuxin Zhang",
            "Bin Wu",
            "Ji-Rong Wen",
            "Ruihua Song",
            "Ting Bai"
        ],
        "published": "2022",
        "summary": "Classical Chinese poetry has a long history and is a precious cultural heritage of humankind. Displaying the classical Chinese poetry in a visual way, helps to cross cultural barriers in different countries, making it enjoyable for all the people. In this paper, we construct a multi-modal knowledge graph for classical Chinese poetry (PKG), in which the visual information of words in the poetry are incorporated. Then a multi-modal pre-training language model, PKG-Bert, is proposed to obtain the poetry representation with visual information, which bridges the semantic gap between different modalities. PKG-Bert achieves the state-of-the-art performance on the poetry-image retrieval task, showing the effectiveness of incorporating the multi-modal knowledge. The large-scale multi-modal knowledge graph of classical Chinese poetry will be released to promote the researches in classical Chinese culture area.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.171.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Assessing Non-autoregressive Alignment in Neural Machine Translation via Word Reordering",
        "authors": [
            "Chun-Hin Tse",
            "Ester Leung",
            "William K. Cheung"
        ],
        "published": "2022",
        "summary": "Recent work on non-autoregressive neural machine translation (NAT) that leverages alignment information to explicitly reduce the modality of target distribution has reported comparable performance with counterparts that tackle multi-modality problem by implicitly modeling dependencies. Effectiveness in handling alignment is vital for models that follow this approach, where a token reordering mechanism is typically involved and plays a vital role. We review the reordering capability of the respective mechanisms in recent NAT models, and our experimental results show that their performance is sub-optimal. We propose to learn a non-autoregressive language model (NALM) based on transformer which can be combined with Viterbi decoding to achieve better reordering performance. We evaluate the proposed NALM using the PTB dataset where sentences with words permuted in different ways are expected to have their ordering recovered. Our empirical results show that the proposed method can outperform the state-of-the-art reordering mechanisms under different word permutation settings, with a 2-27 BLEU improvement, suggesting high potential for word alignment in NAT.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.172.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "MAGMA – Multimodal Augmentation of Generative Models through Adapter-based Finetuning",
        "authors": [
            "Constantin Eichenberg",
            "Sidney Black",
            "Samuel Weinbach",
            "Letitia Parcalabescu",
            "Anette Frank"
        ],
        "published": "2022",
        "summary": "Large-scale pretraining is fast becoming the norm in Vision-Language (VL) modeling. However, prevailing VL approaches are limited by the requirement for labeled data and the use of complex multi-step pretraining objectives. We present MAGMA - a simple method for augmenting generative language models with additional modalities using adapter-based finetuning. Building on Frozen, we train a series of VL models that autoregressively generate text from arbitrary combinations of visual and textual input. The pretraining is entirely end-to-end using a single language modeling objective, simplifying optimization compared to previous approaches. Importantly, the language model weights remain unchanged during training, allowing for transfer of encyclopedic knowledge and in-context learning abilities from language pretraining. MAGMA outperforms Frozen on open-ended generative tasks, achieving state of the art results on the OKVQA benchmark and competitive results on a range of other popular VL benchmarks, while pretraining on 0.2 % of the number of samples used to train SimVLM.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.179.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Towards Tracing Knowledge in Language Models Back to the Training Data",
        "authors": [
            "Ekin Akyurek",
            "Tolga Bolukbasi",
            "Frederick Liu",
            "Binbin Xiong",
            "Ian Tenney",
            "Jacob Andreas",
            "Kelvin Guu"
        ],
        "published": "2022",
        "summary": "Language models (LMs) have been shown to memorize a great deal of factual knowledge contained in their training data. But when an LM generates an assertion, it is often difficult to determine where it learned this information and whether it is true. In this paper, we propose the problem of fact tracing: identifying which training examples taught an LM to generate a particular factual assertion. Prior work on training data attribution (TDA) may offer effective tools for identifying such examples, known as “proponents”. We present the first quantitative benchmark to evaluate this. We compare two popular families of TDA methods — gradient-based and embedding-based — and find that much headroom remains. For example, both methods have lower proponent-retrieval precision than an information retrieval baseline (BM25) that does not have access to the LM at all. We identify key challenges that may be necessary for further improvement such as overcoming the problem of gradient saturation, and also show how several nuanced implementation details of existing neural TDA methods can significantly improve overall fact tracing performance.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.180.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Quadapter: Adapter for GPT-2 Quantization",
        "authors": [
            "Minseop Park",
            "Jaeseong You",
            "Markus Nagel",
            "Simyung Chang"
        ],
        "published": "2022",
        "summary": "Transformer language models such as GPT-2 are difficult to quantize because of outliers in the activations leading to a large quantization error. To adapt to the error, one must use quantization-aware training, which entails a fine-tuning process based on the dataset and the training pipeline identical to those for the original model. Pretrained language models, however, often do not grant access to their datasets and training pipelines, forcing us to rely on arbitrary ones for fine-tuning. In that case, it is observed that quantization-aware training overfits the model to the fine-tuning data. To this end introduced is a quantization adapter (Quadapter), a small set of parameters that are learned to make activations quantization-friendly by scaling them channel-wise.For quantization without overfitting, we introduce a quantization adapter (Quadapter), a small set of parameters that are learned to make activations quantization-friendly by scaling them channel-wise. It keeps the model parameters unchanged. By applying our method to the challenging task of quantizing GPT-2, we demonstrate that it effectively prevents the overfitting and improves the quantization performance.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.185.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "BanglaRQA: A Benchmark Dataset for Under-resourced Bangla Language Reading Comprehension-based Question Answering with Diverse Question-Answer Types",
        "authors": [
            "Syed Mohammed Sartaj Ekram",
            "Adham Arik Rahman",
            "Md. Sajid Altaf",
            "Mohammed Saidul Islam",
            "Mehrab Mustafy Rahman",
            "Md Mezbaur Rahman",
            "Md Azam Hossain",
            "Abu Raihan Mostofa Kamal"
        ],
        "published": "2022",
        "summary": "High-resource languages, such as English, have access to a plethora of datasets with various question-answer types resembling real-world reading comprehension. However, there is a severe lack of diverse and comprehensive question-answering datasets in under-resourced languages like Bangla. The ones available are either translated versions of English datasets with a niche answer format or created by human annotations focusing on a specific domain, question type, or answer type. To address these limitations, this paper introduces BanglaRQA, a reading comprehension-based Bangla question-answering dataset with various question-answer types. BanglaRQA consists of 3,000 context passages and 14,889 question-answer pairs created from those passages. The dataset comprises answerable and unanswerable questions covering four unique categories of questions and three types of answers. In addition, this paper also implemented four different Transformer models for question-answering on the proposed dataset. The best-performing model achieved an overall 62.42% EM and 78.11% F1 score. However, detailed analyses showed that the performance varies across question-answer types, leaving room for substantial improvement of the model performance. Furthermore, we demonstrated the effectiveness of BanglaRQA as a training resource by showing strong results on the bn_squad dataset. Therefore, BanglaRQA has the potential to contribute to the advancement of future research by enhancing the capability of language models. The dataset and codes are available at https://github.com/sartajekram419/BanglaRQA",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.186.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Inferring Implicit Relations in Complex Questions with Language Models",
        "authors": [
            "Uri Katz",
            "Mor Geva",
            "Jonathan Berant"
        ],
        "published": "2022",
        "summary": "A prominent challenge for modern language understanding systems is the ability to answer implicit reasoning questions, where the required reasoning steps for answering the question are not mentioned in the text explicitly. In this work, we investigate why current models struggle with implicit reasoning question answering (QA) tasks, by decoupling inference of reasoning steps from their execution.We define a new task of implicit relation inference and construct a benchmark, IMPLICITRELATIONS, where given a question, a model should output a list of concept-relation pairs, where the relations describe the implicit reasoning steps required for answering the question.Using IMPLICITRELATIONS, we evaluate models from the GPT-3 family and find that, while these models struggle on the implicit reasoning QA task, they often succeed at inferring implicit relations.This suggests that the challenge in implicit reasoning questions does not stem from the need to plan a reasoning strategy alone, but to do it while also retrieving and reasoning over relevant information.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.188.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Partially-Random Initialization: A Smoking Gun for Binarization Hypothesis of BERT",
        "authors": [
            "Arash Ardakani"
        ],
        "published": "2022",
        "summary": "In the past few years, pre-trained BERT has become one of the most popular deep-learning language models due to their remarkable performance in natural language processing (NLP) tasks. However, the superior performance of BERT comes at the cost of high computational and memory complexity, hindering its envisioned widespread deployment in edge devices with limited computing resources. Binarization can alleviate these limitations by reducing storage requirements and improving computing performance. However, obtaining a comparable accuracy performance for binary BERT w.r.t. its full-precision counterpart is still a difficult task. We observe that direct binarization of pre-trained BERT provides a poor initialization during the fine-tuning phase, making the model incapable of achieving a decent accuracy on downstream tasks. Based on this observation, we put forward the following hypothesis: partially randomly-initialized BERT with binary weights and activations can reach to a decent accuracy performance by distilling knowledge from the its full-precision counterpart. We show that BERT with pre-trained embedding layer and randomly-initialized encoder is a smoking gun for this hypothesis. We identify the smoking gun through a series of experiments and show that it yields a new set of state-of-the-art results on the GLUE and SQuAD benchmarks.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.191.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Prompt Consistency for Zero-Shot Task Generalization",
        "authors": [
            "Chunting Zhou",
            "Junxian He",
            "Xuezhe Ma",
            "Taylor Berg-Kirkpatrick",
            "Graham Neubig"
        ],
        "published": "2022",
        "summary": "One of the most impressive results of recent NLP history is the ability of pre-trained language models to solve new tasks in a zero-shot setting. To achieve this, NLP tasks are framed as natural language prompts, generating a response indicating the predicted output. Nonetheless, the performance in such settings often lags far behind its supervised counterpart, suggesting a large space for potential improvement. In this paper, we explore methods to utilize unlabeled data to improve zero-shot performance. Specifically, we take advantage of the fact that multiple prompts can be used to specify a single task, and propose to regularize prompt consistency, encouraging consistent predictions over this diverse set of prompts. Our method makes it possible to fine-tune the model either with extra unlabeled training data, or directly on test input at inference time in an unsupervised manner. In experiments, our approach outperforms the state-of-the-art zero-shot learner, T0, on 9 out of 11 datasets across 4 NLP tasks by up to 10.6 absolute points in terms of accuracy. The gains are often attained with a small number of unlabeled examples.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.192.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "In-Context Learning for Few-Shot Dialogue State Tracking",
        "authors": [
            "Yushi Hu",
            "Chia-Hsuan Lee",
            "Tianbao Xie",
            "Tao Yu",
            "Noah A. Smith",
            "Mari Ostendorf"
        ],
        "published": "2022",
        "summary": "Collecting and annotating task-oriented dialogues is time-consuming and costly. Thus, zero and few shot learning for dialogue tasks presents an exciting opportunity. In this work, we propose an in-context (IC) learning framework for zero-shot and few-shot learning dialogue state tracking (DST), where a large pretrained language model (LM) takes a test instance and a few exemplars as input, and directly decodes the dialogue state without any parameter updates. This approach is more flexible and scalable than prior DST work when adapting to new domains and scenarios. To better leverage a tabular domain description in the LM prompt, we reformulate DST into a text-to-SQL problem. We also propose a novel approach to retrieve annotated dialogues as exemplars. Empirical results on MultiWOZ show that our method IC-DST substantially outperforms previous fine-tuned state-of-the-art models in few-shot settings. In addition, we test IC-DST in zero-shot settings, in which the model only takes a fixed task instruction as input, finding that it outperforms previous zero-shot methods by a large margin.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.193.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "On Advances in Text Generation from Images Beyond Captioning: A Case Study in Self-Rationalization",
        "authors": [
            "Shruti Palaskar",
            "Akshita Bhagia",
            "Yonatan Bisk",
            "Florian Metze",
            "Alan W Black",
            "Ana Marasovic"
        ],
        "published": "2022",
        "summary": "Combining the visual modality with pretrained language models has been surprisingly effective for simple descriptive tasks such as image captioning. More general text generation however remains elusive. We take a step back and ask: How do these models work for more complex generative tasks, i.e. conditioning on both text and images? Are multimodal models simply visually adapted language models, or do they combine they reason jointly over modalities?We investigate these questions in the context of self-rationalization (jointly generating task labels/answers and free-text explanations) of three tasks: (i) visual question answering in VQA-X, (ii) visual commonsense reasoning in VCR, and (iii) visual-textual entailment in E-SNLI-VE. We show that recent unimodal advances, CLIP image representations and scaling of language models, do not consistently improveself-rationalization in multimodal tasks. We find that no single model type works universally best across tasks, datasets, and finetuning data sizes. Our findings motivate the need for novel general backbones that move text generation from images and text beyond image captioning.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.194.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "The challenges of temporal alignment on Twitter during crises",
        "authors": [
            "Aniket Pramanick",
            "Tilman Beck",
            "Kevin Stowe",
            "Iryna Gurevych"
        ],
        "published": "2022",
        "summary": "Language use changes over time, and this impacts the effectiveness of NLP systems. This phenomenon is even more prevalent in social media data during crisis events where meaning and frequency of word usage may change over the course of days. Contextual language models fail to adapt temporally, emphasizing the need for temporal adaptation in models which need to be deployed over an extended period of time. While existing approaches consider data spanning large periods of time (from years to decades), shorter time spans are critical for crisis data. We quantify temporal degradation for this scenario and propose methods to cope with performance loss by leveraging techniques from domain adaptation. To the best of our knowledge, this is the first effort to explore effects of rapid language change driven by adversarial adaptations, particularly during natural and human-induced disasters. Through extensive experimentation on diverse crisis datasets, we analyze under what conditions our approaches outperform strong baselines while highlighting the current limitations of temporal adaptation methods in scenarios where access to unlabeled data is scarce.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.195.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Few-Shot Anaphora Resolution in Scientific Protocols via Mixtures of In-Context Experts",
        "authors": [
            "Nghia T. Le",
            "Fan Bai",
            "Alan Ritter"
        ],
        "published": "2022",
        "summary": "Anaphora resolution is an important task for information extraction across a range of languages, text genres, and domains, motivating the need for methods that do not require large annotated datasets. In-context learning has emerged as a promising approach, yet there are a number of challenges in applying in-context learning to resolve anaphora. For example, encoding a single in-context demonstration that consists of: an anaphor, a paragraph-length context, and a list of corresponding antecedents, requires conditioning a language model on a long sequence of tokens, limiting the number of demonstrations per prompt.In this paper, we present Mice (Mixtures of In-Context Experts), which we demonstrate is effective for few-shot anaphora resolution in scientific protocols. Given only a handful of training examples, Mice combines the predictions of hundreds of in-context experts, yielding a 30% increase in F1 score over a competitive prompt retrieval baseline. Furthermore, we show Mice can be used to train compact student models without sacrificing performance. As far as we are aware, this is the first work to present experimental results demonstrating the effectiveness of in-context learning on the task of few-shot anaphora resolution in scientific protocols.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.197.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "SpaBERT: A Pretrained Language Model from Geographic Data for Geo-Entity Representation",
        "authors": [
            "Zekun Li",
            "Jina Kim",
            "Yao-Yi Chiang",
            "Muhao Chen"
        ],
        "published": "2022",
        "summary": "Named geographic entities (geo-entities for short) are the building blocks of many geographic datasets. Characterizing geo-entities is integral to various application domains, such as geo-intelligence and map comprehension, while a key challenge is to capture the spatial-varying context of an entity. We hypothesize that we shall know the characteristics of a geo-entity by its surrounding entities, similar to knowing word meanings by their linguistic context. Accordingly, we propose a novel spatial language model, SpaBERT, which provides a general-purpose geo-entity representation based on neighboring entities in geospatial data. SpaBERT extends BERT to capture linearized spatial context, while incorporating a spatial coordinate embedding mechanism to preserve spatial relations of entities in the 2-dimensional space. SpaBERT is pretrained with masked language modeling and masked entity prediction tasks to learn spatial dependencies. We apply SpaBERT to two downstream tasks: geo-entity typing and geo-entity linking. Compared with the existing language models that do not use spatial context, SpaBERT shows significant performance improvement on both tasks. We also analyze the entity representation from SpaBERT in various settings and the effect of spatial coordinate embedding.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.200.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Probing for Incremental Parse States in Autoregressive Language Models",
        "authors": [
            "Tiwalayo Eisape",
            "Vineet Gangireddy",
            "Roger Levy",
            "Yoon Kim"
        ],
        "published": "2022",
        "summary": "Next-word predictions from autoregressive neural language models show remarkable sensitivity to syntax. This work evaluates the extent to which this behavior arises as a result of a learned ability to maintain implicit representations of incremental syntactic structures. We extend work in syntactic probing to the incremental setting and present several probes for extracting incomplete syntactic structure (operationalized through parse states from a stack-based parser) from autoregressive language models. We find that our probes can be used to predict model preferences on ambiguous sentence prefixes and causally intervene on model representations and steer model behavior. This suggests implicit incremental syntactic inferences underlie next-word predictions in autoregressive neural language models.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.203.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Do Text-to-Text Multi-Task Learners Suffer from Task Conflict?",
        "authors": [
            "David Mueller",
            "Nicholas Andrews",
            "Mark Dredze"
        ],
        "published": "2022",
        "summary": "Traditional multi-task learning architectures learn a single model across multiple tasks through a shared encoder followed by task-specific decoders. Learning these models often requires specialized training algorithms that address task-conflict in the shared parameter updates, which otherwise can lead to negative transfer. A new type of multi-task learning within NLP homogenizes multi-task architectures as a shared encoder and language model decoder, which does surprisingly well across a range of diverse tasks. Does this new architecture suffer from task-conflicts that require specialized training algorithms? We study how certain factors in the shift towards text-to-text models affects multi-task conflict and negative transfer, finding that both directional conflict and transfer are surprisingly constant across architectures.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.206.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "MANTa: Efficient Gradient-Based Tokenization for End-to-End Robust Language Modeling",
        "authors": [
            "Nathan Godey",
            "Roman Castagné",
            "Éric de la Clergerie",
            "Benoît Sagot"
        ],
        "published": "2022",
        "summary": "Static subword tokenization algorithms have been an essential component of recent works on language modeling. However, their static nature results in important flaws that degrade the models’ downstream performance and robustness. In this work, we propose MANTa, a Module for Adaptive Neural TokenizAtion. MANTa is a differentiable tokenizer trained end-to-end with the language model. The resulting system offers a trade-off between the expressiveness of byte-level models and the speed of models trained using subword tokenization. In addition, our tokenizer is highly explainable since it produces an explicit segmentation of sequences into blocks. We evaluate our pre-trained model on several English datasets from different domains as well as on synthetic noise. We find that MANTa improves robustness to character perturbations and out-of-domain data. We then show that MANTa performs comparably to other models on the general-domain GLUE benchmark. Finally, we show that it is considerably faster than strictly byte-level models.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.207.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Multilingual Sentence Transformer as A Multilingual Word Aligner",
        "authors": [
            "Weikang Wang",
            "Guanhua Chen",
            "Hanqing Wang",
            "Yue Han",
            "Yun Chen"
        ],
        "published": "2022",
        "summary": "Multilingual pretrained language models (mPLMs) have shown their effectiveness in multilingual word alignment induction. However, these methods usually start from mBERT or XLM-R. In this paper, we investigate whether multilingual sentence Transformer LaBSE is a strong multilingual word aligner. This idea is non-trivial as LaBSE is trained to learn language-agnostic sentence-level embeddings, while the alignment extraction task requires the more fine-grained word-level embeddings to be language-agnostic. We demonstrate that the vanilla LaBSE outperforms other mPLMs currently used in the alignment task, and then propose to finetune LaBSE on parallel corpus for further improvement. Experiment results on seven language pairs show that our best aligner outperforms previous state-of-the-art models of all varieties. In addition, our aligner supports different language pairs in a single model, and even achieves new state-of-the-art on zero-shot language pairs that does not appear in the finetuning process.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.215.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "CORE: A Retrieve-then-Edit Framework for Counterfactual Data Generation",
        "authors": [
            "Tanay Dixit",
            "Bhargavi Paranjape",
            "Hannaneh Hajishirzi",
            "Luke Zettlemoyer"
        ],
        "published": "2022",
        "summary": "Counterfactual data augmentation (CDA) – i.e., adding minimally perturbed inputs during training – helps reduce model reliance on spurious correlations and improves generalization to out-of-distribution (OOD) data. Prior work on generating counterfactuals only considered restricted classes of perturbations, limiting their effectiveness. We present Counterfactual Generation via Retrieval and Editing (CORE), a retrieval-augmented generation framework for creating diverse counterfactual perturbations for CDA. For each training example, CORE first performs a dense retrieval over a task-related unlabeled text corpus using a learned bi-encoder and extracts relevant counterfactual excerpts. CORE then incorporates these into prompts to a large language model with few-shot learning capabilities, for counterfactual editing. Conditioning language model edits on naturally occurring data results in more diverse perturbations. Experiments on natural language inference and sentiment analysis benchmarks show that CORE counterfactuals are more effective at improving generalization to OOD data compared to other DA approaches. We also show that the CORE retrieval framework can be used to encourage diversity in manually authored perturbations.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.216.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "You can’t pick your neighbors, or can you? When and How to Rely on Retrieval in the kNN-LM",
        "authors": [
            "Andrew Drozdov",
            "Shufan Wang",
            "Razieh Rahimi",
            "Andrew McCallum",
            "Hamed Zamani",
            "Mohit Iyyer"
        ],
        "published": "2022",
        "summary": "Retrieval-enhanced language models (LMs), which condition their predictions on text retrieved from large external datastores, have recently shown significant perplexity improvements compared to standard LMs. One such approach, the kNN-LM, interpolates any existing LM’s predictions with the output of a k-nearest neighbors model and requires no additional training. In this paper, we explore the importance of lexical and semantic matching in the context of items retrieved by kNN-LM. We find two trends: (1) the presence of large overlapping n-grams between the datastore and evaluation set plays an important factor in strong performance, even when the datastore is derived from the training data; and (2) the kNN-LM is most beneficial when retrieved items have high semantic similarity with the query. Based on our analysis, we define a new formulation of the kNN-LM that uses retrieval quality to assign the interpolation coefficient. We empirically measure the effectiveness of our approach on two English language modeling datasets, Wikitext-103 and PG-19. Our re-formulation of the kNN-LM is beneficial in both cases, and leads to nearly 4% improvement in perplexity on the Wikitext-103 test set.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.218.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "StuBot: Learning by Teaching a Conversational Agent Through Machine Reading Comprehension",
        "authors": [
            "Nayoung Jin",
            "Hana Lee"
        ],
        "published": "2022",
        "summary": "This paper proposes StuBot, a text-based conversational agent that provides adaptive feedback for learning by teaching. StuBot first asks the users to teach the learning content by summarizing and explaining it in their own words. After the users inputted the explanation text for teaching, StuBot uses a machine reading comprehension (MRC) engine to provide adaptive feedback with further questions about the insufficient parts of the explanation text. We conducted a within-subject study to evaluate the effectiveness of adaptive feedback by StuBot. Both the quantitative and qualitative results showed that learning by teaching with adaptive feedback can improve learning performance, immersion, and overall experience.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.219.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Improved Universal Sentence Embeddings with Prompt-based Contrastive Learning and Energy-based Learning",
        "authors": [
            "Yuxin Jiang",
            "Linhan Zhang",
            "Wei Wang"
        ],
        "published": "2022",
        "summary": "Contrastive learning has been demonstrated to be effective in enhancing pre-trained language models (PLMs) to derive superior universal sentence embeddings. However, existing contrastive methods still have two limitations. Firstly, previous works may acquire poor performance under domain shift settings, thus hindering the application of sentence representations in practice. We attribute this low performance to the over-parameterization of PLMs with millions of parameters. To alleviate it, we propose PromCSE (Prompt-based Contrastive Learning for Sentence Embeddings), which only trains small-scale Soft Prompt (i.e., a set of trainable vectors) while keeping PLMs fixed. Secondly, the commonly used NT-Xent loss function of contrastive learning does not fully exploit hard negatives in supervised learning settings. To this end, we propose to integrate an Energy-based Hinge loss to enhance the pairwise discriminative power, inspired by the connection between the NT-Xent loss and the Energy-based Learning paradigm. Empirical results on seven standard semantic textual similarity (STS) tasks and a domain-shifted STS task both show the effectiveness of our method compared with the current state-of-the-art sentence embedding models.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.220.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "InfoCSE: Information-aggregated Contrastive Learning of Sentence Embeddings",
        "authors": [
            "Xing Wu",
            "Chaochen Gao",
            "Zijia Lin",
            "Jizhong Han",
            "Zhongyuan Wang",
            "Songlin Hu"
        ],
        "published": "2022",
        "summary": "Contrastive learning has been extensively studied in sentence embedding learning, which assumes that the embeddings of different views of the same sentence are closer. The constraint brought by this assumption is weak, and a good sentence representation should also be able to reconstruct the original sentence fragments. Therefore, this paper proposes an information-aggregated contrastive learning framework for learning unsupervised sentence embeddings, termed InfoCSE.InfoCSE forces the representation of [CLS] positions to aggregate denser sentence information by introducing an additional Masked language model task and a well-designed network. We evaluate the proposed InfoCSE on several benchmark datasets w.r.t the semantic text similarity (STS) task. Experimental results show that InfoCSE outperforms SimCSE by an average Spearman correlation of 2.60% on BERT-base, and 1.77% on BERT-large, achieving state-of-the-art results among unsupervised sentence representation learning methods.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.223.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Benchmarking Language Models for Code Syntax Understanding",
        "authors": [
            "Da Shen",
            "Xinyun Chen",
            "Chenguang Wang",
            "Koushik Sen",
            "Dawn Song"
        ],
        "published": "2022",
        "summary": "Pre-trained language models have demonstrated impressive performance in both natural language processing and program understanding, which represent the input as a token sequence without explicitly modeling its structure. Some prior works show that pre-trained language models can capture the syntactic rules of natural languages without finetuning on syntax understanding tasks. However, there is limited understanding of how well pre-trained models understand the code structure so far. In this work, we perform the first thorough benchmarking of the state-of-the-art pre-trained models for identifying the syntactic structures of programs. Specifically, we introduce CodeSyntax, a large-scale dataset of programs annotated with the syntactic relationships in their corresponding abstract syntax trees. Our key observation is that pre-training on massive code data does not result in decent code syntax understanding. In fact, these pre-trained programming language models fail to match the performance of naive baselines based on positional offsets and keywords. We also present a natural language benchmark to highlight the differences between natural languages and programming languages in terms of understanding corresponding syntactic structures. Our findings point out key limitations of existing pre-training methods and suggest the importance of modeling syntactic structures for the programming language.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.224.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Third-Party Aligner for Neural Word Alignments",
        "authors": [
            "Jinpeng Zhang",
            "Chuanqi Dong",
            "Xiangyu Duan",
            "Yuqi Zhang",
            "Min Zhang"
        ],
        "published": "2022",
        "summary": "Word alignment is to find translationally equivalent words between source and target sentences. Previous work has demonstrated that self-training can achieve competitive word alignment results. In this paper, we propose to use word alignments generated by a third-party word aligner to supervise the neural word alignment training. Specifically, source word and target word of each word pair aligned by the third-party aligner are trained to be close neighbors to each other in the contextualized embedding space when fine-tuning a pre-trained cross-lingual language model. Experiments on the benchmarks of various language pairs show that our approach can surprisingly do self-correction over the third-party supervision by finding more accurate word alignments and deleting wrong word alignments, leading to better performance than various third-party word aligners, including the currently best one. When we integrate all supervisions from various third-party aligners, we achieve state-of-the-art word alignment performances, with averagely more than two points lower alignment error rates than the best third-party aligner.We released our code at https://github.com/sdongchuanqi/Third-Party-Supervised-Aligner.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.228.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Generative Prompt Tuning for Relation Classification",
        "authors": [
            "Jiale Han",
            "Shuai Zhao",
            "Bo Cheng",
            "Shengkun Ma",
            "Wei Lu"
        ],
        "published": "2022",
        "summary": "Using prompts to explore the knowledge contained within pre-trained language models for downstream tasks has now become an active topic. Current prompt tuning methods mostly convert the downstream tasks to masked language modeling problems by adding cloze-style phrases and mapping all labels to verbalizations with fixed length, which has proven effective for tasks with simple label spaces. However, when applied to relation classification exhibiting complex label spaces, vanilla prompt tuning methods may struggle with label verbalizations with arbitrary lengths due to rigid prompt restrictions. Inspired by the text infilling task for pre-training generative models that can flexibly predict missing spans, we propose a novel generative prompt tuning method to reformulate relation classification as an infilling problem, which frees our approach from limitations of current prompt based approaches and thus fully exploits rich semantics of entity and relation types. In addition, we design entity-guided decoding and discriminative relation scoring to generate and align relations effectively and efficiently during inference. Extensive experiments under fully supervised settings and low-resource settings demonstrate the effectiveness of our approach.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.231.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Formulating Few-shot Fine-tuning Towards Language Model Pre-training: A Pilot Study on Named Entity Recognition",
        "authors": [
            "Zihan Wang",
            "Kewen Zhao",
            "Zilong Wang",
            "Jingbo Shang"
        ],
        "published": "2022",
        "summary": "Fine-tuning pre-trained language models is a common practice in building NLP models for various tasks, including the case with less supervision. We argue that under the few-shot setting, formulating fine-tuning closer to the pre-training objective shall be able to unleash more benefits from the pre-trained language models. In this work, we take few-shot named entity recognition (NER) for a pilot study, where existing fine-tuning strategies are much different from pre-training. We propose a novel few-shot fine-tuning framework for NER, FFF-NER. Specifically, we introduce three new types of tokens, “is-entity”, “which-type” and “bracket”, so we can formulate the NER fine-tuning as (masked) token prediction or generation, depending on the choice of the pre-training objective. In our experiments, we apply to fine-tune both BERT and BART for few-shot NER on several benchmark datasets and observe significant improvements over existing fine-tuning strategies, including sequence labeling, prototype meta-learning, and prompt-based approaches. We further perform a series of ablation studies, showing few-shot NER performance is strongly correlated with the similarity between fine-tuning and pre-training.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.232.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Masked Language Models Know Which are Popular: A Simple Ranking Strategy for Commonsense Question Answering",
        "authors": [
            "Xuan Luo",
            "Chuang Fan",
            "Yice Zhang",
            "Wanguo Jiang",
            "Bing Qin",
            "Ruifeng Xu"
        ],
        "published": "2022",
        "summary": "We propose a simple ranking strategy to solve a generative commonsense question answering (QA) problem. Compared with multiple-choice QA, it is challenging because the answers to a question are not unique and they are supposed to be popular and diverse. Our strategy exploits the dataset itself and negative samples that we collect from WordNet to train a ranker that picks out the most popular answers for commonsense questions. The effectiveness of our strategy is verified on different pre-trained masked language models (MLMs) in a pipeline framework, where an MLM reranks the generated answers. Further, we explore an end-to-end framework where MLMs are utilized to guide the generation of generative language models (GLMs). Taking advantage of reinforcement learning, we apply policy gradient to train a GLM with the rewards fed back by an MLM. Empirical results on ProtoQA dataset demonstrate that MLMs can acquire the ability to distinguish the popular answers and improve the typical answer generation of GLMs as well.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.233.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Low-resource Interactive Active Labeling for Fine-tuning Language Models",
        "authors": [
            "Seiji Maekawa",
            "Dan Zhang",
            "Hannah Kim",
            "Sajjadur Rahman",
            "Estevam Hruschka"
        ],
        "published": "2022",
        "summary": "Recently, active learning (AL) methods have been used to effectively fine-tune pre-trained language models for various NLP tasks such as sentiment analysis and document classification. However, given the task of fine-tuning language models, understanding the impact of different aspects on AL methods such as labeling cost, sample acquisition latency, and the diversity of the datasets necessitates a deeper investigation. This paper examines the performance of existing AL methods within a low-resource, interactive labeling setting. We observe that existing methods often underperform in such a setting while exhibiting higher latency and a lack of generalizability. To overcome these challenges, we propose a novel active learning method TYROUGE that employs a hybrid sampling strategy to minimize labeling cost and acquisition latency while providing a framework for adapting to dataset diversity via user guidance. Through our experiments, we observe that compared to SOTA methods, TYROUGE reduces the labeling cost by up to 43% and the acquisition latency by as much as 11X, while achieving comparable accuracy. Finally, we discuss the strengths and weaknesses of TYROUGE by exploring the impact of dataset characteristics.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.235.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "A Unified Framework for Pun Generation with Humor Principles",
        "authors": [
            "Yufei Tian",
            "Divyanshu Sheth",
            "Nanyun Peng"
        ],
        "published": "2022",
        "summary": "We propose a unified framework to generate both homophonic and homographic puns to resolve the split-up in existing works. Specifically, we incorporate three linguistic attributes of puns to the language models: ambiguity, distinctiveness, and surprise. Our framework consists of three parts: 1) a context words/phrases selector to promote the aforementioned attributes, 2) a generation model trained on non-pun sentences to incorporate the context words/phrases into the generation output, and 3) a label predictor that learns the structure of puns which is used to steer the generation model at inference time. Evaluation results on both pun types demonstrate the efficacy of our model over strong baselines.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.237.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "AlphaTuning: Quantization-Aware Parameter-Efficient Adaptation of Large-Scale Pre-Trained Language Models",
        "authors": [
            "Se Jung Kwon",
            "Jeonghoon Kim",
            "Jeongin Bae",
            "Kang Min Yoo",
            "Jin-Hwa Kim",
            "Baeseong Park",
            "Byeongwook Kim",
            "Jung-Woo Ha",
            "Nako Sung",
            "Dongsoo Lee"
        ],
        "published": "2022",
        "summary": "There are growing interests in adapting large-scale language models using parameter-efficient fine-tuning methods. However, accelerating the model itself and achieving better inference efficiency through model compression has not been thoroughly explored yet.Model compression could provide the benefits of reducing memory footprints, enabling low-precision computations, and ultimately achieving cost-effective inference.To combine parameter-efficient adaptation and model compression, we propose AlphaTuning consisting of post-training quantization of the pre-trained language model and fine-tuning only some parts of quantized parameters for a target task.Specifically, AlphaTuning works by employing binary-coding quantization, which factorizes the full-precision parameters into binary parameters and a separate set of scaling factors.During the adaptation phase, the binary values are frozen for all tasks, while the scaling factors are fine-tuned for the downstream task.We demonstrate that AlphaTuning, when applied to GPT-2 and OPT, performs competitively with full fine-tuning on a variety of downstream tasks while achieving >10x compression ratio under 4-bit quantization and >1,000x reduction in the number of trainable parameters.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.240.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Learning Invariant Representation Improves Robustness for MRC Models",
        "authors": [
            "Yu Hai",
            "Liang Wen",
            "Haoran Meng",
            "Tianyu Liu",
            "Houfeng Wang"
        ],
        "published": "2022",
        "summary": "The prosperity of Pretrained Language Models(PLM) has greatly promoted the development of Machine Reading Comprehension (MRC). However, these models are vulnerable and not robust to adversarial examples. In this paper, we propose Stable and Contrastive Question Answering (SCQA) to improve invariance of representation to alleviate these robustness issues. Specifically, we first construct positive example pairs which have same answer through data augmentation. Then SCQA learns enhanced representations with better alignment between positive pairs by introducing stability and contrastive loss. Experimental results show that our approach can boost the robustness of QA models cross different MRC tasks and attack sets significantly and consistently.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.241.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "ER-Test: Evaluating Explanation Regularization Methods for Language Models",
        "authors": [
            "Brihi Joshi",
            "Aaron Chan",
            "Ziyi Liu",
            "Shaoliang Nie",
            "Maziar Sanjabi",
            "Hamed Firooz",
            "Xiang Ren"
        ],
        "published": "2022",
        "summary": "By explaining how humans would solve a given task, human rationales can provide strong learning signal for neural language models (NLMs). Explanation regularization (ER) aims to improve NLM generalization by pushing the NLM’s machine rationales (Which input tokens did the NLM focus on?) to align with human rationales (Which input tokens would humans focus on). Though prior works primarily study ER via in-distribution (ID) evaluation, out-of-distribution (OOD) generalization is often more critical in real-world scenarios, yet ER’s effect on OOD generalization has been underexplored.In this paper, we introduce ER-Test, a framework for evaluating ER models’ OOD generalization along three dimensions: unseen datasets, contrast set tests, and functional tests. Using ER-Test, we comprehensively analyze how ER models’ OOD generalization varies with the rationale alignment criterion (loss function), human rationale type (instance-level v/s task-level), number and choice of rationale-annotated instances, and time budget for rationale annotation. Across two tasks and six datasets, we show that ER has little impact on ID performance but yields large OOD performance gains, with the best ER criterion being task-dependent. Also, ER can improve OOD performance even with task-level or few human rationales. Finally, we find that rationale annotation is more time-efficient than label annotation for improving OOD performance. Our results with ER-Test help demonstrate ER’s utility and establish best practices for using ER effectively.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.242.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Different Tunes Played with Equal Skill: Exploring a Unified Optimization Subspace for Parameter-Efficient Tuning",
        "authors": [
            "Jing Yi",
            "Weize Chen",
            "Yujia Qin",
            "Yankai Lin",
            "Ning Ding",
            "Xu Han",
            "Zhiyuan Liu",
            "Maosong Sun",
            "Jie Zhou"
        ],
        "published": "2022",
        "summary": "Delta tuning (DET, also known as parameter-efficient tuning) is deemed as the new paradigm for using pre-trained language models (PLMs). Up to now, various DETs with distinct design elements have been proposed, achieving performance on par with fine-tuning. However, the mechanisms behind the above success are still under-explored, especially the connections among various DETs. To fathom the mystery, we hypothesize that the adaptations of different DETs could all be reparameterized as low-dimensional optimizations in a unified optimization subspace, which could be found by jointly decomposing independent solutions of different DETs. Then we explore the connections among different DETs by conducting optimization within the subspace. In experiments, we find that, for a certain DET, conducting optimization simply in the subspace could achieve comparable performance to its original space, and the found solution in the subspace could be transferred to another DET and achieve non-trivial performance. We also visualize the performance landscape of the subspace, and find that, there exists a substantial region where different DETs all perform well. Finally, we extend our analysis and show the strong connections between fine-tuning and DETs. The codes are publicly available at https://github.com/thunlp/Unified-DeltaTuning.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.244.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "PseudoReasoner: Leveraging Pseudo Labels for Commonsense Knowledge Base Population",
        "authors": [
            "Tianqing Fang",
            "Quyet V. Do",
            "Hongming Zhang",
            "Yangqiu Song",
            "Ginny Y. Wong",
            "Simon See"
        ],
        "published": "2022",
        "summary": "Commonsense Knowledge Base (CSKB) Population aims at reasoning over unseen entities and assertions on CSKBs, and is an important yet hard commonsense reasoning task. One challenge is that it requires out-of-domain generalization ability as the source CSKB for training is of a relatively smaller scale (1M) while the whole candidate space for population is way larger (200M). We propose PseudoReasoner, a semi-supervised learning framework for CSKB population that uses a teacher model pre-trained on CSKBs to provide pseudo labels on the unlabeled candidate dataset for a student model to learn from. The teacher can be a generative model rather than restricted to discriminative models as previous works.In addition, we design a new filtering procedure for pseudo labels based on influence function and the student model’s prediction to further improve the performance. The framework can improve the backbone model KG-BERT (RoBERTa-large) by 3.3 points on the overall performance and especially, 5.3 points on the out-of-domain performance, and achieves the state-of-the-art. The codes will be made public on acceptance. Codes and data are available at https://github.com/HKUST-KnowComp/PseudoReasoner.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.246.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "History-Aware Hierarchical Transformer for Multi-session Open-domain Dialogue System",
        "authors": [
            "Tong Zhang",
            "Yong Liu",
            "Boyang Li",
            "Zhiwei Zeng",
            "Pengwei Wang",
            "Yuan You",
            "Chunyan Miao",
            "Lizhen Cui"
        ],
        "published": "2022",
        "summary": "With the evolution of pre-trained language models, current open-domain dialogue systems have achieved great progress in conducting one-session conversations. In contrast, Multi-Session Conversation (MSC), which consists of multiple sessions over a long term with the same user, is under-investigated. In this paper, we propose History-Aware Hierarchical Transformer (HAHT) for multi-session open-domain dialogue. HAHT maintains a long-term memory of history conversations and utilizes history information to understand current conversation context and generate well-informed and context-relevant responses. Specifically, HAHT first encodes history conversation sessions hierarchically into a history memory. Then, HAHT leverages historical information to facilitate the understanding of the current conversation context by encoding the history memory together with the current context with attention-based mechanisms. Finally, to explicitly utilize historical information, HAHT uses a history-aware response generator that switches between a generic vocabulary and a history-aware vocabulary. Experimental results on a large-scale MSC dataset suggest that the proposed HAHT model consistently outperforms baseline models. Human evaluation results support that HAHT generates more human-like, context-relevant, and history-relevant responses than baseline models.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.247.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Truncation Sampling as Language Model Desmoothing",
        "authors": [
            "John Hewitt",
            "Christopher Manning",
            "Percy Liang"
        ],
        "published": "2022",
        "summary": "Long samples of text from neural language models can be of poor quality. Truncation sampling algorithms–like top-p or top-k—address this by setting some words’ probabilities to zero at each step. This work investigates why these methods are important, and how to improve them. We propose thinking of a neural language model as a mixture of a true distribution and a smoothing distribution that avoids infinite perplexity. In this light, truncation algorithms aim to perform desmoothing, estimating a subset of the support of the true distribution. Finding a good subset is crucial: we show that top-p unnecessarily truncates high-probability words, for example causing it to truncate all words but Trump for a document that starts with Donald. We introduce eta-sampling, which truncates words below an entropy-dependent probability threshold. Compared to previous algorithms, our eta-sampling generates more plausible long documents according to humans, is better at breaking out of repetition, and behaves more reasonably on a battery of test distributions.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.249.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "DORE: Document Ordered Relation Extraction based on Generative Framework",
        "authors": [
            "Qipeng Guo",
            "Yuqing Yang",
            "Hang Yan",
            "Xipeng Qiu",
            "Zheng Zhang"
        ],
        "published": "2022",
        "summary": "In recent years, there is a surge of generation-based information extraction work, which allows a more direct use of pre-trained language models and efficiently captures output dependencies. However, previous generative methods using lexical representation do not naturally fit document-level relation extraction (DocRE) where there are multiple entities and relational facts. In this paper, we investigate the root cause of the underwhelming performance of the existing generative DocRE models and discover that the culprit is the inadequacy of the training paradigm, instead of the capacities of the models. We propose to generate a symbolic and ordered sequence from the relation matrix which is deterministic and easier for model to learn. Moreover, we design a parallel row generation method to process overlong target sequences. Besides, we introduce several negative sampling strategies to improve the performance with balanced signals. Experimental results on four datasets show that our proposed method can improve the performance of the generative DocRE models.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.253.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "RoChBert: Towards Robust BERT Fine-tuning for Chinese",
        "authors": [
            "Zihan Zhang",
            "Jinfeng Li",
            "Ning Shi",
            "Bo Yuan",
            "Xiangyu Liu",
            "Rong Zhang",
            "Hui Xue",
            "Donghong Sun",
            "Chao Zhang"
        ],
        "published": "2022",
        "summary": "Despite of the superb performance on a wide range of tasks, pre-trained language models (e.g., BERT) have been proved vulnerable to adversarial texts. In this paper, we present RoChBERT, a framework to build more Robust BERT-based models by utilizing a more comprehensive adversarial graph to fuse Chinese phonetic and glyph features into pre-trained representations during fine-tuning. Inspired by curriculum learning, we further propose to augment the training dataset with adversarial texts in combination with intermediate samples. Extensive experiments demonstrate that RoChBERT outperforms previous methods in significant ways: (i) robust – RoChBERT greatly improves the model robustness without sacrificing accuracy on benign texts. Specifically, the defense lowers the success rates of unlimited and limited attacks by 59.43% and 39.33% respectively, while remaining accuracy of 93.30%; (ii) flexible – RoChBERT can easily extend to various language models to solve different downstream tasks with excellent performance; and (iii) efficient – RoChBERT can be directly applied to the fine-tuning stage without pre-training language model from scratch, and the proposed data augmentation method is also low-cost.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.256.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Improving the Sample Efficiency of Prompt Tuning with Domain Adaptation",
        "authors": [
            "Xu Guo",
            "Boyang Li",
            "Han Yu"
        ],
        "published": "2022",
        "summary": "Prompt tuning, or the conditioning of a frozen pretrained language model (PLM) with soft prompts learned from data, has demonstrated impressive performance on a wide range of NLP tasks. However, prompt tuning requires a large training dataset to be effective and is outperformed by finetuning the entire PLM in data-scarce regimes. Previous work (Gu et al., 2022, Vu et al., 2022) proposed to transfer soft prompts pretrained on the source domain to the target domain. In this paper, we explore domain adaptation for prompt tuning, a problem setting where unlabeled data from the target domain are available during pretraining. We propose bOosting Prompt TunIng with doMain Adaptation (OPTIMA), which regularizes the decision boundary to be smooth around regions where source and target data distributions are similar. Extensive experiments demonstrate that OPTIMA significantly enhances the transferability and sample-efficiency of prompt tuning compared to strong baselines. Moreover, in few-shot settings, OPTIMA exceeds full-model tuning by a large margin.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.258.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "CANarEx: Contextually Aware Narrative Extraction for Semantically Rich Text-as-data Applications",
        "authors": [
            "Nandini Anantharama",
            "Simon Angus",
            "Lachlan O’Neill"
        ],
        "published": "2022",
        "summary": "Narrative modelling is an area of active research, motivated by the acknowledgement of narratives as drivers of societal decision making. These research efforts conceptualize narratives as connected entity chains, and modeling typically focuses on the identification of entities and their connections within a text. An emerging approach to narrative modelling is the use of semantic role labeling (SRL) to extract Entity-Verb-Entity (E-V-Es) tuples from a text, followed by dimensionality reduction to reduce the space of entities and connections separately. This process penalises the semantic richness of narratives and discards much contextual information along the way. Here, we propose an alternate narrative extraction approach - CANarEx, incorporating a pipeline of common contextual constructs through co-reference resolution, micro-narrative generation and clustering of these narratives through sentence embeddings. We evaluate our approach through testing the recovery of “narrative time-series clusters”, mimicking a desirable text-as-data task. The evaluation framework leverages synthetic data generated using a GPT-3 model. The GPT-3 model is trained to generate similar sentences using a large dataset of news articles. The synthetic data maps to three topics in the news dataset. We then generate narrative time-series document cluster representations by mapping the synthetic data to three distinct signals synthetically injected into the testing corpus. Evaluation results demonstrate the superior ability of CANarEx to recover narrative time-series through reduced MSE and improved precision/recall relative to existing methods. The validity is further reinforced through ablation studies and qualitative analysis.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.260.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Narrate Dialogues for Better Summarization",
        "authors": [
            "Ruochen Xu",
            "Chenguang Zhu",
            "Michael Zeng"
        ],
        "published": "2022",
        "summary": "Dialogue summarization models aim to generate a concise and accurate summary for multi-party dialogue. The complexity of dialogue, including coreference, dialogue acts, and inter-speaker interactions bring unique challenges to dialogue summarization. Most recent neural models achieve state-of-art performance following the pretrain-then-finetune recipe, where the large-scale language model (LLM) is pretrained on large-scale single-speaker written text, but later finetuned on multi-speaker dialogue text. To mitigate the gap between pretraining and finetuning, we propose several approaches to convert the dialogue into a third-person narrative style and show that the narration serves as a valuable annotation for LLMs. Empirical results on three benchmark datasets show our simple approach achieves higher scores on the ROUGE and a factual correctness metric.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.261.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Probing Structural Knowledge from Pre-trained Language Model for Argumentation Relation Classification",
        "authors": [
            "Yang Sun",
            "Bin Liang",
            "Jianzhu Bao",
            "Min Yang",
            "Ruifeng Xu"
        ],
        "published": "2022",
        "summary": "Extracting fine-grained structural information between argumentation component (AC) pairs is essential for argumentation relation classification (ARC). However, most previous studies attempt to model the relationship between AC pairs using AC level similarity or semantically relevant features. They ignore the complex interaction between AC pairs and cannot effectively reason the argumentation relation deeply.Therefore, in this paper, we propose a novel dual prior graph neural network (DPGNN) to jointly explore the probing knowledge derived from pre-trained language models (PLMs) and the syntactical information for comprehensively modeling the relationship between AC pairs. Specifically, we construct a probing graph by using probing knowledge derived from PLMs to recognize and align the relational information within and across the argumentation components. In addition, we propose a mutual dependency graph for the AC pair to reason the fine-grained syntactic structural information, in which the syntactical correlation between words is set by the dependency information within AC and mutual attention mechanism across ACs. The knowledge learned from the probing graph and the dependency graph are combined to comprehensively capture the aligned relationships of AC pairs for improving the results of ARC. Experimental results on three public datasets show that DPGNN outperforms the state-of-the-art baselines by a noticeable margin.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.264.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "LogicNMR: Probing the Non-monotonic Reasoning Ability of Pre-trained Language Models",
        "authors": [
            "Yeliang Xiu",
            "Zhanhao Xiao",
            "Yongmei Liu"
        ],
        "published": "2022",
        "summary": "The logical reasoning capabilities of pre-trained language models have recently received much attention. As one of the vital reasoning paradigms, non-monotonic reasoning refers to the fact that conclusions may be invalidated with new information. Existing work has constructed a non-monotonic inference dataset 𝛿-NLI and explored the performance of language models on it. However, the 𝛿-NLI dataset is entangled with commonsense reasoning. In this paper, we explore the pure non-monotonic reasoning ability of pre-trained language models. We build a non-monotonic reasoning benchmark, named LogicNMR, with explicit default rules and iterative updates. In the experimental part, the performance of popular language models on LogicNMR is explored from the perspectives of accuracy, generalization, proof-based traceability and robustness. The experimental results show that even though the fine-tuned language models achieve an accuracy of more than 94.4% on LogicNMR, they perform unsatisfactorily, with a significant drop, in generalization and proof-based traceability.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.265.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "PoeLM: A Meter- and Rhyme-Controllable Language Model for Unsupervised Poetry Generation",
        "authors": [
            "Aitor Ormazabal",
            "Mikel Artetxe",
            "Manex Agirrezabal",
            "Aitor Soroa",
            "Eneko Agirre"
        ],
        "published": "2022",
        "summary": "Formal verse poetry imposes strict constraints on the meter and rhyme scheme of poems. Most prior work on generating this type of poetry uses existing poems for supervision, which are difficult to obtain for most languages and poetic forms. In this work, we propose an unsupervised approach to generate poems that follow any given meter and rhyme scheme, without requiring any poetic text for training. Our method works by splitting a regular, non-poetic corpus into phrases, prepending control codes that describe the length and end rhyme of each phrase, and training a transformer language model in the augmented corpus. The transformer learns to link the structure descriptor with the control codes to the number of lines, their length and their end rhyme. During inference, we build control codes for the desired meter and rhyme scheme, and condition our language model on them to generate formal verse poetry. Experiments in Spanish and Basque show that our approach is able to generate valid poems, which are often comparable in quality to those written by humans.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.268.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "ProGen: Progressive Zero-shot Dataset Generation via In-context Feedback",
        "authors": [
            "Jiacheng Ye",
            "Jiahui Gao",
            "Zhiyong Wu",
            "Jiangtao Feng",
            "Tao Yu",
            "Lingpeng Kong"
        ],
        "published": "2022",
        "summary": "Recently, dataset-generation-based zero-shot learning has shown promising results by training a task-specific model with a dataset synthesized from large pre-trained language models (PLMs). The final task-specific model often achieves compatible or even better performance than PLMs under the zero-shot setting, with orders of magnitude fewer parameters.However, synthetic datasets have their drawbacks. They have long being suffering from the low-quality issue (e.g., low informativeness, redundancy). This explains why the massive synthetic data does not lead to better performance – a scenario we would expect in the human-labeled data. To improve the quality in dataset synthesis, we propose a progressive zero-shot dataset generation framework, ProGen, which leverages the feedback from the task-specific model to guide the generation of new training data via in-context examples.Extensive experiments on five text classification datasets demonstrate the effectiveness of the proposed approach. We also show ProGen achieves on-par or superior performance with only 1% synthetic dataset size, when comparing to baseline methods without in-context feedback.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.269.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Constructing Highly Inductive Contexts for Dialogue Safety through Controllable Reverse Generation",
        "authors": [
            "Zhexin Zhang",
            "Jiale Cheng",
            "Hao Sun",
            "Jiawen Deng",
            "Fei Mi",
            "Yasheng Wang",
            "Lifeng Shang",
            "Minlie Huang"
        ],
        "published": "2022",
        "summary": "Large pretrained language models can easily produce toxic or biased content, which is prohibitive for practical use. In order to detect such toxic generations, existing methods rely on templates, real-world data extraction, crowdsourcing workers or automatic generation to construct adversarial contexts that are likely to induce toxic generations. However, what type of context is more likely to induce unsafe responses is still under-explored. In this paper, we identify that context toxicity and context category (e.g., profanity, insult, drugs, etc.) are two important factors to cause safety issues in response generation. Hence, we propose a method called reverse generation to construct adversarial contexts conditioned on a given response, with the flexibility to control category, toxicity level and inductivity of the generated contexts. Via reverse generation, we augment the existing BAD dataset and construct a new dataset BAD+ which contains more than 120K diverse and highly inductive contexts in 12 categories. We test three popular pretrained dialogue models (Blender, DialoGPT and Plato2) and find that BAD+ can largely expose their safety problems. Furthermore, we show that BAD+ can greatly enhance the safety of generation, and we reveal the key factors of safety improvement. Our code and dataset is available at https://github.com/thu-coai/Reverse_Generation.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.270.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "A Unified Dialogue User Simulator for Few-shot Data Augmentation",
        "authors": [
            "Dazhen Wan",
            "Zheng Zhang",
            "Qi Zhu",
            "Lizi Liao",
            "Minlie Huang"
        ],
        "published": "2022",
        "summary": "Pre-trained language models have shown superior performance in task-oriented dialogues. However, existing datasets are on limited scales, which cannot support large-scale pre-training. Fortunately, various data augmentation methods have been developed to augment large-scale task-oriented dialogue corpora. However, they heavily rely on annotated data in the target domain, which require a tremendous amount of data collection and human labeling work. In this paper, we build a unified dialogue user simulation model by pre-training on several publicly available datasets. The model can then be tuned on a target domain with few-shot data. The experiments on a target dataset across multiple domains show that our proposed model brings remarkable performance increases through data augmentation.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.277.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Describing Sets of Images with Textual-PCA",
        "authors": [
            "Oded Hupert",
            "Idan Schwartz",
            "Lior Wolf"
        ],
        "published": "2022",
        "summary": "We seek to semantically describe a set of images, capturing both the attributes of single images and the variations within the set. Our procedure is analogous to Principle Component Analysis, in which the role of projection vectors is replaced with generated phrases. First, a centroid phrase that has the largest average semantic similarity to the images in the set is generated, where both the computation of the similarity and the generation are based on pretrained vision-language models. Then, the phrase that generates the highest variation among the similarity scores is generated, using the same models. The next phrase maximizes the variance subject to being orthogonal, in the latent space, to the highest-variance phrase, and the process continues. Our experiments show that our method is able to convincingly capture the essence of image sets and describe the individual elements in a semantically meaningful way within the context of the entire set. Our code is available at: https://github.com/OdedH/textual-pca.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.279.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Learning to Model Editing Processes",
        "authors": [
            "Machel Reid",
            "Graham Neubig"
        ],
        "published": "2022",
        "summary": "Most existing sequence generation models produce outputs in one pass, usually left-to-right. However, this is in contrast with a more natural approach that humans use in generating content; iterative refinement and editing. Recent work has introduced edit-based models for various tasks (such as neural machine translation and text style transfer), but these generally model a single edit step. In this work, we propose modeling editing processes, modeling the whole process of iteratively generating sequences. We form a conceptual framework to describe the likelihood of multi-step edits, and describe neural models that can learn a generative model of sequences based on these multistep edits. We introduce baseline results and metrics on this task, finding that modeling editing processes improves performance on a variety of axes on both our proposed task and related downstream tasks compared to previous single-step models of edits.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.280.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "PALT: Parameter-Lite Transfer of Language Models for Knowledge Graph Completion",
        "authors": [
            "Jianhao Shen",
            "Chenguang Wang",
            "Ye Yuan",
            "Jiawei Han",
            "Heng Ji",
            "Koushik Sen",
            "Ming Zhang",
            "Dawn Song"
        ],
        "published": "2022",
        "summary": "This paper presents a parameter-lite transfer learning approach of pretrained language models (LM) for knowledge graph (KG) completion. Instead of finetuning, which modifies all LM parameters, we only tune a few new parameters while keeping the original LM parameters fixed. We establish this via reformulating KG completion as a “fill-in-the-blank” task, and introducing a parameter-lite encoder on top of the original LMs. We show that, by tuning far fewer parameters than finetuning, LMs transfer non-trivially to most tasks and reach competitiveness with prior state-of-the-art approaches. For instance, we outperform the fully finetuning approaches on a KG completion benchmark by tuning only 1% of the parameters.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.281.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "SYGMA: A System for Generalizable and Modular Question Answering Over Knowledge Bases",
        "authors": [
            "Sumit Neelam",
            "Udit Sharma",
            "Hima Karanam",
            "Shajith Ikbal",
            "Pavan Kapanipathi",
            "Ibrahim Abdelaziz",
            "Nandana Mihindukulasooriya",
            "Young-Suk Lee",
            "Santosh Srivastava",
            "Cezar Pendus",
            "Saswati Dana",
            "Dinesh Garg",
            "Achille Fokoue",
            "G P Shrivatsa Bhargav",
            "Dinesh Khandelwal",
            "Srinivas Ravishankar",
            "Sairam Gurajada",
            "Maria Chang",
            "Rosario Uceda-Sosa",
            "Salim Roukos",
            "Alexander Gray",
            "Guilherme Lima",
            "Ryan Riegel",
            "Francois Luus",
            "L V Subramaniam"
        ],
        "published": "2022",
        "summary": "Knowledge Base Question Answering (KBQA) involving complex reasoning is emerging as an important research direction. However, most KBQA systems struggle with generalizability, particularly on two dimensions: (a) across multiple knowledge bases, where existing KBQA approaches are typically tuned to a single knowledge base, and (b) across multiple reasoning types, where majority of datasets and systems have primarily focused on multi-hop reasoning. In this paper, we present SYGMA, a modular KBQA approach developed with goal of generalization across multiple knowledge bases and multiple reasoning types. To facilitate this, SYGMA is designed as two high level modules: 1) KB-agnostic question understanding module that remain common across KBs, and generates logic representation of the question with high level reasoning constructs that are extensible, and 2) KB-specific question mapping and answering module to address the KB-specific aspects of the answer extraction. We evaluated SYGMA on multiple datasets belonging to distinct knowledge bases (DBpedia and Wikidata) and distinct reasoning types (multi-hop and temporal). State-of-the-art or competitive performances achieved on those datasets demonstrate its generalization capability.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.284.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Adapters for Enhanced Modeling of Multilingual Knowledge and Text",
        "authors": [
            "Yifan Hou",
            "Wenxiang Jiao",
            "Meizhen Liu",
            "Carl Allen",
            "Zhaopeng Tu",
            "Mrinmaya Sachan"
        ],
        "published": "2022",
        "summary": "Large language models appear to learn facts from the large text corpora they are trained on. Such facts are encoded implicitly within their many parameters, making it difficult to verify or manipulate what knowledge has been learned. Language models have recently been extended to multilingual language models (MLLMs), enabling knowledge to be learned across hundreds of languages. Meanwhile, knowledge graphs contain facts in an explicit triple format, which require careful and costly curation and are only available in a few high-resource languages, restricting their research and application. To address these issues, we propose to enhance MLLMs with knowledge from multilingual knowledge graphs (MLKGs) so as to tackle language and knowledge graph tasks across many languages, including low-resource ones. Specifically, we introducea lightweight adapter set to enhance MLLMs with cross-lingual entity alignment and facts from MLKGs for many languages. Experiments on common benchmarks show that such enhancement benefits both MLLMs and MLKGs, achieving: (1) comparable or improved performance for knowledge graph completion and entity alignment relative to baselines, especially for low-resource languages (for which knowledge graphs are unavailable); and (2) improved MLLM performance on language understanding tasks that require multilingual factual knowledge; all while maintaining performance on other general language tasks.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.287.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Probing Relational Knowledge in Language Models via Word Analogies",
        "authors": [
            "Kiamehr Rezaee",
            "Jose Camacho-Collados"
        ],
        "published": "2022",
        "summary": "Understanding relational knowledge plays an integral part in natural language comprehension. When it comes to pre-trained language models (PLM), prior work has been focusing on probing relational knowledge this by filling the blanks in pre-defined prompts such as “The capital of France is —\". However, these probes may be affected by the co-occurrence of target relation words and entities (e.g. “capital”, “France” and “Paris”) in the pre-training corpus. In this work, we extend these probing methodologies leveraging analogical proportions as a proxy to probe relational knowledge in transformer-based PLMs without directly presenting the desired relation. In particular, we analysed the ability of PLMs to understand (1) the directionality of a given relation (e.g. Paris-France is not the same as France-Paris); (2) the ability to distinguish types on a given relation (both France and Japan are countries); and (3) the relation itself (Paris is the capital of France, but not Rome). Our results show how PLMs are extremely accurate at (1) and (2), but have clear room for improvement for (3). To better understand the reasons behind this behaviour and mistakes made by PLMs, we provide an extended quantitative analysis based on relevant factors such as frequency.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.289.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Parameter-free Automatically Prompting: A Latent Pseudo Label Mapping Model for Prompt-based Learning",
        "authors": [
            "Jirui Qi",
            "Richong Zhang",
            "Junfan Chen",
            "Jaein Kim",
            "Yongyi Mao"
        ],
        "published": "2022",
        "summary": "Prompt-based learning has achieved excellent performance in few-shot learning by mapping the outputs of the pre-trained language model to the labels with the help of a label mapping component. Existing manual label mapping (MLM) methods achieve good results but heavily rely on expensive human knowledge. Automatic label mapping (ALM) methods that learn the mapping functions with extra parameters have shown their potentiality. However, no effective ALM model comparable to MLM methods is developed yet due to the limited data. In this paper, we propose a Latent Pseudo Label Mapping (LPLM) method that optimizes the label mapping without human knowledge and extra parameters. LPLM is built upon a probabilistic latent model and is iteratively self-improved with the EM-style algorithm. The empirical results demonstrate that our LPLM method is superior to the mainstream ALM methods and significantly outperforms the SOTA method in few-shot classification tasks. Moreover, LPLM also shows impressively better performance than the vanilla MLM method which requires extra task-specific prior knowledge.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.291.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Exploring Logographic Image for Chinese Aspect-based Sentiment Classification",
        "authors": [
            "Xiabing Zhou",
            "Renjie Feng",
            "Xiaotong Jiang",
            "Zhongqing Wang"
        ],
        "published": "2022",
        "summary": "In logographic languages like Chinese, word meanings are constructed using specific character formations, which can help to disambiguate word senses and are beneficial for sentiment classification. However, such knowledge is rarely explored in previous sentiment analysis methods. In this paper, we focus on exploring the logographic information for aspect-based sentiment classification in Chinese text. Specifically, we employ a logographic image to capture an internal morphological structure from the character sequence. The logographic image is also used to learn the external relations among context and aspect words. Furthermore, we propose a multimodal language model to explicitly incorporate a logographic image with review text for aspect-based sentiment classification in Chinese. Experimental results show that our method brings substantial performance improvement over strong baselines. The results also indicate that the logographic image is very important for exploring the internal structure and external relations from the character sequence.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.292.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "On the Role of Bidirectionality in Language Model Pre-Training",
        "authors": [
            "Mikel Artetxe",
            "Jingfei Du",
            "Naman Goyal",
            "Luke Zettlemoyer",
            "Veselin Stoyanov"
        ],
        "published": "2022",
        "summary": "Prior work on language model pre-training has explored different architectures and learning objectives, but differences in data, hyperparameters and evaluation make a principled comparison difficult. In this work, we focus on bidirectionality as a key factor that differentiates existing approaches, and present a comprehensive study of its role in next token prediction, text infilling, zero-shot priming and fine-tuning. We propose a new framework that generalizes prior approaches, including fully unidirectional models like GPT, fully bidirectional models like BERT, and hybrid models like CM3 and prefix LM. Our framework distinguishes between two notions of bidirectionality (bidirectional context and bidirectional attention) and allows us to control each of them separately. We find that the optimal configuration is largely application-dependent (e.g., bidirectional attention is beneficial for fine-tuning and infilling, but harmful for next token prediction and zero-shot priming). We train models with up to 6.7B parameters, and find differences to remain consistent at scale. While prior work on scaling has focused on left-to-right autoregressive models, our results suggest that this approach comes with some trade-offs, and it might be worthwhile to develop very large bidirectional models.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.293.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Learning to Revise References for Faithful Summarization",
        "authors": [
            "Griffin Adams",
            "Han-Chin Shing",
            "Qing Sun",
            "Christopher Winestock",
            "Kathleen McKeown",
            "Noémie Elhadad"
        ],
        "published": "2022",
        "summary": "In real-world scenarios with naturally occurring datasets, reference summaries are noisy and may contain information that cannot be inferred from the source text. On large news corpora, removing low quality samples has been shown to reduce model hallucinations. Yet, for smaller, and/or noisier corpora, filtering is detrimental to performance. To improve reference quality while retaining all data, we propose a new approach: to selectively re-write unsupported reference sentences to better reflect source data. We automatically generate a synthetic dataset of positive and negative revisions by corrupting supported sentences and learn to revise reference sentences with contrastive learning. The intensity of revisions is treated as a controllable attribute so that, at inference, diverse candidates can be over-generated-then-rescored to balance faithfulness and abstraction. To test our methods, we extract noisy references from publicly available MIMIC-III discharge summaries for the task of hospital-course summarization, and vary the data on which models are trained. According to metrics and human evaluation, models trained on revised clinical references are much more faithful, informative, and fluent than models trained on original or filtered data.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.296.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Towards Intention Understanding in Suicidal Risk Assessment with Natural Language Processing",
        "authors": [
            "Shaoxiong Ji"
        ],
        "published": "2022",
        "summary": "Recent applications of natural language processing techniques to suicidal ideation detection and risk assessment frame the detection or assessment task as a text classification problem. Recent advances have developed many models, especially deep learning models, to boost predictive performance.Though the performance (in terms of aggregated evaluation scores) is improving, this position paper urges that better intention understanding is required for reliable suicidal risk assessment with computational methods. This paper reflects the state of natural language processing applied to suicide-associated text classification tasks, differentiates suicidal risk assessment and intention understanding, and points out potential limitations of sentiment features and pretrained language models in suicidal intention understanding.Besides, it urges the necessity for sequential intention understanding and risk assessment, discusses some critical issues in evaluation such as uncertainty, and studies the lack of benchmarks.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.297.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Improving Sharpness-Aware Minimization with Fisher Mask for Better Generalization on Language Models",
        "authors": [
            "Qihuang Zhong",
            "Liang Ding",
            "Li Shen",
            "Peng Mi",
            "Juhua Liu",
            "Bo Du",
            "Dacheng Tao"
        ],
        "published": "2022",
        "summary": "Fine-tuning large pretrained language models on a limited training corpus usually suffers from poor generalization. Prior works show that the recently-proposed sharpness-aware minimization (SAM) optimization method can improve the model generalization. However, SAM adds a perturbation to each model parameter equally (but not all parameters contribute equally to the optimization of training), which we argue is sub-optimal and will lead to excessive computation. In this paper, we propose a novel optimization procedure, namely FSAM, which introduces a Fisher mask to improve the efficiency and performance of SAM. In short, instead of adding perturbation to all parameters, FSAM uses the Fisher information to identity the important parameters and formulates a Fisher mask to obtain the sparse perturbation, i.e., making the optimizer focus on these important parameters. Experiments on various tasks in GLUE and SuperGLUE benchmarks show that FSAM consistently outperforms the vanilla SAM by 0.67 1.98 average score among four different pretrained models. We also empirically show that FSAM works well in other complex scenarios, e.g., fine-tuning on generation tasks or limited training data. Encouragingly, when training data is limited, FSAM improves the SAM by a large margin, i.e., up to 15.1.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.300.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "TINA: Textual Inference with Negation Augmentation",
        "authors": [
            "Chadi Helwe",
            "Simon Coumes",
            "Chloé Clavel",
            "Fabian Suchanek"
        ],
        "published": "2022",
        "summary": "Transformer-based language models achieve state-of-the-art results on several natural language processing tasks. One of these is textual entailment, i.e., the task of determining whether a premise logically entails a hypothesis. However, the models perform poorly on this task when the examples contain negations. In this paper, we propose a new definition of textual entailment that captures also negation. This allows us to develop TINA (Textual Inference with Negation Augmentation), a principled technique for negated data augmentation that can be combined with the unlikelihood loss function.Our experiments with different transformer-based models show that our method can significantly improve the performance of the models on textual entailment datasets with negation – without sacrificing performance on datasets without negation.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.301.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Improving Bilingual Lexicon Induction with Cross-Encoder Reranking",
        "authors": [
            "Yaoyiran Li",
            "Fangyu Liu",
            "Ivan Vulić",
            "Anna Korhonen"
        ],
        "published": "2022",
        "summary": "Bilingual lexicon induction (BLI) with limited bilingual supervision is a crucial yet challenging task in multilingual NLP. Current state-of-the-art BLI methods rely on the induction of cross-lingual word embeddings (CLWEs) to capture cross-lingual word similarities; such CLWEs are obtained <b>1)</b> via traditional static models (e.g., VecMap), or <b>2)</b> by extracting type-level CLWEs from multilingual pretrained language models (mPLMs), or <b>3)</b> through combining the former two options. In this work, we propose a novel semi-supervised <i>post-hoc</i> reranking method termed <b>BLICEr</b> (<b>BLI</b> with <b>C</b>ross-<b>E</b>ncoder <b>R</b>eranking), applicable to any precalculated CLWE space, which improves their BLI capability. The key idea is to ‘extract’ cross-lingual lexical knowledge from mPLMs, and then combine it with the original CLWEs. This crucial step is done via <b>1)</b> creating a word similarity dataset, comprising positive word pairs (i.e., true translations) and hard negative pairs induced from the original CLWE space, and then <b>2)</b> fine-tuning an mPLM (e.g., mBERT or XLM-R) in a cross-encoder manner to predict the similarity scores. At inference, we <b>3)</b> combine the similarity score from the original CLWE space with the score from the BLI-tuned cross-encoder. BLICEr establishes new state-of-the-art results on two standard BLI benchmarks spanning a wide spectrum of diverse languages: it substantially outperforms a series of strong baselines across the board. We also validate the robustness of BLICEr with different CLWEs.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.302.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "The Effects of Corpus Choice and Morphosyntax on Multilingual Space Induction",
        "authors": [
            "Vinit Ravishankar",
            "Joakim Nivre"
        ],
        "published": "2022",
        "summary": "In an effort to study the inductive biases of language models, numerous studies have attempted to use linguistically motivated tasks as a proxy of sorts, wherein performance on these tasks would imply an inductive bias towards a specific linguistic phenomenon. In this study, we attempt to analyse the inductive biases of language models with respect to natural language phenomena, in the context of building multilingual embedding spaces.We sample corpora from 2 sources in 15 languages and train language models on pseudo-bilingual variants of each corpus, created by duplicating each corpus and shifting token indices for half the resulting corpus. We evaluate the cross-lingual capabilities of these LMs, and show that while correlations with language families tend to be weak, other corpus-level characteristics, such as type-token ratio, tend to be more strongly correlated. Finally, we show that multilingual spaces can be built, albeit less effectively, even when additional destructive perturbations are applied to the training corpora, implying that (effectively) bag-of-words models also have an inductive bias that is sufficient for inducing multilingual spaces.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.304.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Mind Your Bias: A Critical Review of Bias Detection Methods for Contextual Language Models",
        "authors": [
            "Silke Husse",
            "Andreas Spitz"
        ],
        "published": "2022",
        "summary": "The awareness and mitigation of biases are of fundamental importance for the fair and transparent use of contextual language models, yet they crucially depend on the accurate detection of biases as a precursor. Consequently, numerous bias detection methods have been proposed, which vary in their approach, the considered type of bias, and the data used for evaluation. However, while most detection methods are derived from the word embedding association test for static word embeddings, the reported results are heterogeneous, inconsistent, and ultimately inconclusive. To address this issue, we conduct a rigorous analysis and comparison of bias detection methods for contextual language models. Our results show that minor design and implementation decisions (or errors) have a substantial and often significant impact on the derived bias scores. Overall, we find the state of the field to be both worse than previously acknowledged due to systematic and propagated errors in implementations, yet better than anticipated since divergent results in the literature homogenize after accounting for implementation errors. Based on our findings, we conclude with a discussion of paths towards more robust and consistent bias detection methods.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.311.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "ZeroPrompt: Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization",
        "authors": [
            "Hanwei Xu",
            "Yujun Chen",
            "Yulun Du",
            "Nan Shao",
            "Wang Yanggang",
            "Haiyu Li",
            "Zhilin Yang"
        ],
        "published": "2022",
        "summary": "We propose a multitask pretraining approach ZeroPrompt for zero-shot generalization, focusing on task scaling and zero-shot prompting.While previous models are trained on only a few dozen tasks, we scale to 1,000 tasks for the first time using real-world data. This leads to a crucial discovery that task scaling can be an efficient alternative to model scaling; i.e., the model size has less impact on performance with an extremely large number of tasks. Our results show that task scaling can improve training efficiency by 30 times in FLOPs.Empirically, ZeroPrompt substantially improves both the efficiency and the performance of zero-shot learning across a variety of academic and production datasets.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.312.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Is anisotropy really the cause of BERT embeddings not being semantic?",
        "authors": [
            "Alejandro Fuster Baggetto",
            "Victor Fresno"
        ],
        "published": "2022",
        "summary": "In this paper we conduct a set of experiments aimed to improve our understanding of the lack of semantic isometry in BERT, i.e. the lack of correspondence between the embedding and meaning spaces of its contextualized word representations. Our empirical results show that, contrary to popular belief, the anisotropy is not the root cause of the poor performance of these contextual models’ embeddings in semantic tasks. What does affect both the anisotropy and semantic isometry is a set of known biases: frequency, subword, punctuation, and case. For each one of them, we measure its magnitude and the effect of its removal, showing that these biases contribute but do not completely explain the phenomenon of anisotropy and lack of semantic isometry of these contextual language models.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.314.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Controllable Dialogue Simulation with In-context Learning",
        "authors": [
            "Zekun Li",
            "Wenhu Chen",
            "Shiyang Li",
            "Hong Wang",
            "Jing Qian",
            "Xifeng Yan"
        ],
        "published": "2022",
        "summary": "Building dialogue systems requires a large corpus of annotated dialogues. Such datasets are usually created via crowdsourcing, which is expensive and time-consuming. In this paper, we propose Dialogic, a novel dialogue simulation method based on large language model in-context learning to automate dataset creation. Seeded with a few annotated dialogues, Dialogic automatically selects in-context examples for demonstration and prompts GPT-3 to generate new dialogues and annotations in a controllable way. Our method can rapidly expand a small set of dialogue data with minimum or zero human involvement and parameter update and is thus much more cost-efficient and time-saving than crowdsourcing. Experimental results on the MultiWOZ dataset demonstrate that training a model on the simulated dialogues leads to even better performance than using the same amount of human-generated dialogues under the challenging low-resource settings, with as few as 85 dialogues as a seed. When the full training set is given, our method can still serve as an effective data augmentation method to further improve performance. Human evaluation results also show that our simulated dialogues have near-human fluency and annotation accuracy. The code and data are available at https://github.com/Leezekun/dialogic.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.318.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "HumSet: Dataset of Multilingual Information Extraction and Classification for Humanitarian Crises Response",
        "authors": [
            "Selim Fekih",
            "Nicolo’ Tamagnone",
            "Benjamin Minixhofer",
            "Ranjan Shrestha",
            "Ximena Contla",
            "Ewan Oglethorpe",
            "Navid Rekabsaz"
        ],
        "published": "2022",
        "summary": "Timely and effective response to humanitarian crises requires quick and accurate analysis of large amounts of text data – a process that can highly benefit from expert-assisted NLP systems trained on validated and annotated data in the humanitarian response domain. To enable creation of such NLP systems, we introduce and release HumSet, a novel and rich multilingual dataset of humanitarian response documents annotated by experts in the humanitarian response community. The dataset provides documents in three languages (English, French, Spanish) and covers a variety of humanitarian crises from 2018 to 2021 across the globe. For each document, HUMSET provides selected snippets (entries) as well as assigned classes to each entry annotated using common humanitarian information analysis frameworks. HUMSET also provides novel and challenging entry extraction and multi-label entry classification tasks. In this paper, we take a first step towards approaching these tasks and conduct a set of experiments on Pre-trained Language Models (PLM) to establish strong baselines for future research in this domain. The dataset is available at https://blog.thedeep.io/humset/.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.321.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Lexical Generalization Improves with Larger Models and Longer Training",
        "authors": [
            "Elron Bandel",
            "Yoav Goldberg",
            "Yanai Elazar"
        ],
        "published": "2022",
        "summary": "While fine-tuned language models perform well on many language tasks, they were also shown to rely on superficial surface features such as lexical overlap. Excessive utilization of such heuristics can lead to failure on challenging inputs. We analyze the use of lexical overlap heuristics in natural language inference, paraphrase detection, and reading comprehension (using a novel contrastive dataset),and find that larger models are much less susceptible to adopting lexical overlap heuristics. We also find that longer training leads models to abandon lexical overlap heuristics. Finally, We provide evidence that the disparity between models size has its source in the pre-trained model.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.323.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Realistic Data Augmentation Framework for Enhancing Tabular Reasoning",
        "authors": [
            "Dibyakanti Kumar",
            "Vivek Gupta",
            "Soumya Sharma",
            "Shuo Zhang"
        ],
        "published": "2022",
        "summary": "Existing approaches to constructing training data for Natural Language Inference (NLI) tasks, such as for semi-structured table reasoning, are either via crowdsourcing or fully automatic methods. However, the former is expensive and time consuming and thus limits scale, and the latter often produces naive examples that may lack complex reasoning. This paper develops a realistic semi-automated framework for data augmentation for tabular inference. Instead of manually generating a hypothesis for each table, our methodology generates hypothesis templates transferable to similar tables. In addition, our framework entails the creation of rational counterfactual tables based on human written logical constraints and premise paraphrasing. For our case study, we use the INFOTABS (Gupta et al., 2020), which is an entity centric tabular inference dataset. We observed that our framework could generate human-like tabular inference examples, which could benefit training data augmentation, especially in the scenario with limited supervision.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.324.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "The Curious Case of Absolute Position Embeddings",
        "authors": [
            "Koustuv Sinha",
            "Amirhossein Kazemnejad",
            "Siva Reddy",
            "Joelle Pineau",
            "Dieuwke Hupkes",
            "Adina Williams"
        ],
        "published": "2022",
        "summary": "Transformer language models encode the notion of word order using positional information. Most commonly, this positional information is represented by absolute position embeddings (APEs), that are learned from the pretraining data. However, in natural language, it is not absolute position that matters, but relative position, and the extent to which APEs can capture this type of information has not been studied. In this work, we observe that models trained with APE over-rely on positional information to the point that they break-down when subjected to sentences with shifted position information. Specifically, when models are subjected to sentences starting from a non-zero position (excluding the effect of priming), they exhibit noticeably degraded performance on zero- to full-shot tasks, across a range of model families and model sizes. Our findings raise questions about the efficacy of APEs to model the relativity of position information, and invite further introspection on the sentence and word order processing strategies employed by these models.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.326.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Goal-oriented Vision-and-Dialog Navigation via Reinforcement Learning",
        "authors": [
            "Yan Cao",
            "Keting Lu",
            "David DeFazio",
            "Shiqi Zhang"
        ],
        "published": "2022",
        "summary": "Vision-and-dialog navigation is a recent benchmark for evaluating the AI capabilities of perception, interaction, and decision making. While existing methods developed for this benchmark have demonstrated great successes, they mostly rely on large datasets, where data collection can be a challenge, and the learned policies are not adaptive to domain changes. In this paper, we focus on a new problem, referred to as goal-oriented vision-and-dialog navigation (GVDN), where an agent uses reinforcement learning techniques to compute dialog-navigation policies from trial and error. A robot conducts visual navigation to locate target objects, and can talk to a remote human operator as needed. Our remote human is able to provide guidance on navigation only if the robot correctly conveys its location through dialog. Experiments have been conducted using photo-realistic simulation environments. Results suggest that, our agent outperforms competitive baselines in success rate.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.327.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Leveraging Data Recasting to Enhance Tabular Reasoning",
        "authors": [
            "Aashna Jena",
            "Vivek Gupta",
            "Manish Shrivastava",
            "Julian Eisenschlos"
        ],
        "published": "2022",
        "summary": "Creating challenging tabular inference data is essential for learning complex reasoning. Prior work has mostly relied on two data generation strategies. The first is human annotation, which yields linguistically diverse data but is difficult to scale. The second category for creation is synthetic generation, which is scalable and cost effective but lacks inventiveness. In this research, we present a framework for semi-automatically recasting existing tabular data to make use of the benefits of both approaches. We utilize our framework to build tabular NLI instances from five datasets that were initially intended for tasks like table2text creation, tabular Q/A, and semantic parsing. We demonstrate that recasted data could be used as evaluation benchmarks as well as augmentation data to enhance performance on tabular NLI tasks. Furthermore, we investigate the effectiveness of models trained on recasted data in the zero-shot scenario, and analyse trends in performance across different recasted datasets types.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.328.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Thinking about GPT-3 In-Context Learning for Biomedical IE? Think Again",
        "authors": [
            "Bernal Jimenez Gutierrez",
            "Nikolas McNeal",
            "Clayton Washington",
            "You Chen",
            "Lang Li",
            "Huan Sun",
            "Yu Su"
        ],
        "published": "2022",
        "summary": "Large pre-trained language models (PLMs) such as GPT-3 have shown strong in-context learning capabilities, which are highly appealing for domains such as biomedicine that feature high and diverse demands of language technologies but also high data annotation costs. In this paper, we present the first systematic and comprehensive study to compare the few-shot performance of GPT-3 in-context learning with fine-tuning smaller (i.e., BERT-sized) PLMs on two representative biomedical information extraction (IE) tasks: named entity recognition and relation extraction. We follow the true few-shot setting to avoid overestimating models’ few-shot performance by model selection over a large validation set. We also optimize GPT-3’s performance with known techniques such as contextual calibration and dynamic in-context example retrieval. However, our results show that GPT-3 still significantly underperforms compared to simply fine-tuning a smaller PLM. In addition, GPT-3 in-context learning also yields smaller gains in accuracy when more training data becomes available. More in-depth analyses further reveal issues of in-context learning that may be detrimental to IE tasks in general. Given the high cost of experimenting with GPT-3, we hope our study provides helpful guidance for biomedical researchers and practitioners towards more practical solutions such as fine-tuning small PLMs before better in-context learning is available for biomedical IE.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.329.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Attention weights accurately predict language representations in the brain",
        "authors": [
            "Mathis Lamarre",
            "Catherine Chen",
            "Fatma Deniz"
        ],
        "published": "2022",
        "summary": "In Transformer-based language models (LMs) the attention mechanism converts token embeddings into contextual embeddings that incorporate information from neighboring words. The resulting contextual hidden state embeddings have enabled highly accurate models of brain responses, suggesting that the attention mechanism constructs contextual embeddings that carry information reflected in language-related brain representations. However, it is unclear whether the attention weights that are used to integrate information across words are themselves related to language representations in the brain. To address this question we analyzed functional magnetic resonance imaging (fMRI) recordings of participants reading English language narratives. We provided the narrative text as input to two LMs (BERT and GPT-2) and extracted their corresponding attention weights. We then used encoding models to determine how well attention weights can predict recorded brain responses. We find that attention weights accurately predict brain responses in much of the frontal and temporal cortices. Our results suggest that the attention mechanism itself carries information that is reflected in brain representations. Moreover, these results indicate cortical areas in which context integration may occur.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.330.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Improving HowNet-Based Chinese Word Sense Disambiguation with Translations",
        "authors": [
            "Xiang Zhang",
            "Bradley Hauer",
            "Grzegorz Kondrak"
        ],
        "published": "2022",
        "summary": "Word sense disambiguation (WSD) is the task of identifying the intended sense of a word in context. While prior work on unsupervised WSD has leveraged lexical knowledge bases, such as WordNet and BabelNet, these resources have proven to be less effective for Chinese. Instead, the most widely used lexical knowledge base for Chinese is HowNet. Previous HowNet-based WSD methods have not exploited contextual translation information. In this paper, we present the first HowNet-based WSD system which combines monolingual contextual information from a pretrained neural language model with bilingual information obtained via machine translation and sense translation information from HowNet. The results of our evaluation experiment on a test set from prior work demonstrate that our new method achieves a new state of the art for unsupervised Chinese WSD.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.331.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "MOBA-E2C: Generating MOBA Game Commentaries via Capturing Highlight Events from the Meta-Data",
        "authors": [
            "Dawei Zhang",
            "Sixing Wu",
            "Yao Guo",
            "Xiangqun Chen"
        ],
        "published": "2022",
        "summary": "MOBA (Multiplayer Online Battle Arena) games such as Dota2 are currently one of the most popular e-sports gaming genres. Following professional commentaries is a great way to understand and enjoy a MOBA game. However, massive game competitions lack commentaries because of the shortage of professional human commentators. As an alternative, employing machine commentators that can work at any time and place is a feasible solution. Considering the challenges in modeling MOBA games, we propose a data-driven MOBA commentary generation framework, MOBA-E2C, allowing a model to generate commentaries based on the game meta-data. Subsequently, to alleviate the burden of collecting supervised data, we propose a MOBA-FuseGPT generator to generate MOBA game commentaries by fusing the power of a rule-based generator and a generative GPT generator. Finally, in the experiments, we take a popular MOBA game Dota2 as our case and construct a Chinese Dota2 commentary generation dataset Dota2-Commentary. Experimental results demonstrate the superior performance of our approach. To the best of our knowledge, this work is the first Dota2 machine commentator and Dota2-Commentary is the first dataset.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.333.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "You Are My Type! Type Embeddings for Pre-trained Language Models",
        "authors": [
            "Mohammed Saeed",
            "Paolo Papotti"
        ],
        "published": "2022",
        "summary": "One reason for the positive impact of Pre-trained Language Models (PLMs) in NLP tasks is their ability to encode semantic types, such as ‘European City’ or ‘Woman’. While previous work has analyzed such information in the context of interpretability, it is not clear how to use types to steer the PLM output. For example, in a cloze statement, it is desirable to steer the model to generate a token that satisfies a user-specified type, e.g., predict a date rather than a location. In this work, we introduce Type Embeddings (TEs), an input embedding that promotes desired types in a PLM. Our proposal is to define a type by a small set of word examples. We empirically study the ability of TEs both in representing types and in steering masking predictions without changes to the prompt text in BERT. Finally, using the LAMA datasets, we show how TEs highly improve the precision in extracting facts from PLMs.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.336.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Contextualizing Language Models for Norms Diverging from Social Majority",
        "authors": [
            "Niklas Kiehne",
            "Hermann Kroll",
            "Wolf-Tilo Balke"
        ],
        "published": "2022",
        "summary": "To comprehensibly contextualize decisions, artificial systems in social situations need a high degree of awareness of the rules of conduct of human behavior. Especially transformer-based language models have recently been shown to exhibit some such awareness. But what if norms in some social setting do not adhere to or even blatantly deviate from the mainstream? In this paper, we introduce a novel mechanism based on deontic logic to allow for a flexible adaptation of individual norms by de-biasing training data sets and a task-reduction to textual entailment. Building on the popular ‘Moral Stories’ dataset we on the one hand highlight the intrinsic bias of current language models, on the other hand characterize the adaptability of pre-trained models to deviating norms in fine-tuning settings.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.339.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Readability Controllable Biomedical Document Summarization",
        "authors": [
            "Zheheng Luo",
            "Qianqian Xie",
            "Sophia Ananiadou"
        ],
        "published": "2022",
        "summary": "Different from general documents, it is recognised that the ease with which people can understand a biomedical text is eminently varied, owing to the highly technical nature of biomedical documents and the variance of readers’ domain knowledge. However, existing biomedical document summarization systems have paid little attention to readability control, leaving users with summaries that are incompatible with their levels of expertise.In recognition of this urgent demand, we introduce a new task of readability controllable summarization for biomedical documents, which aims to recognise users’ readability demands and generate summaries that better suit their needs: technical summaries for experts and plain language summaries (PLS) for laymen.To establish this task, we construct a corpus consisting of biomedical papers with technical summaries and PLSs written by the authors, and benchmark multiple advanced controllable abstractive and extractive summarization models based on pre-trained language models (PLMs) with prevalent controlling and generation techniques.Moreover, we propose a novel masked language model (MLM) based metric and its variant to effectively evaluate the readability discrepancy between lay and technical summaries.Experimental results from automated and human evaluations show that though current control techniques allow for a certain degree of readability adjustment during generation, the performance of existing controllable summarization methods is far from desirable in this task.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.343.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Leveraging Training Dynamics and Self-Training for Text Classification",
        "authors": [
            "Tiberiu Sosea",
            "Cornelia Caragea"
        ],
        "published": "2022",
        "summary": "The effectiveness of pre-trained language models in downstream tasks is highly dependent on the amount of labeled data available for training. Semi-supervised learning (SSL) is a promising technique that has seen wide attention recently due to its effectiveness in improving deep learning models when training data is scarce. Common approaches employ a teacher-student self-training framework, where a teacher network generates pseudo-labels for unlabeled data, which are then used to iteratively train a student network. In this paper, we propose a new self-training approach for text classification that leverages training dynamics of unlabeled data. We evaluate our approach on a wide range of text classification tasks, including emotion detection, sentiment analysis, question classification and gramaticality, which span a variety of domains, e.g, Reddit, Twitter, and online forums. Notably, our method is successful on all benchmarks, obtaining an average increase in F1 score of 3.5% over strong baselines in low resource settings.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.350.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Learning to Infer from Unlabeled Data: A Semi-supervised Learning Approach for Robust Natural Language Inference",
        "authors": [
            "Mobashir Sadat",
            "Cornelia Caragea"
        ],
        "published": "2022",
        "summary": "Natural Language Inference (NLI) or Recognizing Textual Entailment (RTE) aims at predicting the relation between a pair of sentences (premise and hypothesis) as entailment, contradiction or semantic independence. Although deep learning models have shown promising performance for NLI in recent years, they rely on large scale expensive human-annotated datasets. Semi-supervised learning (SSL) is a popular technique for reducing the reliance on human annotation by leveraging unlabeled data for training. However, despite its substantial success on single sentence classification tasks where the challenge in making use of unlabeled data is to assign “good enough” pseudo-labels, for NLI tasks, the nature of unlabeled data is more complex: one of the sentences in the pair (usually the hypothesis) along with the class label are missing from the data and require human annotations, which makes SSL for NLI more challenging. In this paper, we propose a novel way to incorporate unlabeled data in SSL for NLI where we use a conditional language model, BART to generate the hypotheses for the unlabeled sentences (used as premises). Our experiments show that our SSL framework successfully exploits unlabeled data and substantially improves the performance of four NLI datasets in low-resource settings. We release our code here: https://github.com/msadat3/SSL_for_NLI",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.351.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "DOROTHIE: Spoken Dialogue for Handling Unexpected Situations in Interactive Autonomous Driving Agents",
        "authors": [
            "Ziqiao Ma",
            "Benjamin VanDerPloeg",
            "Cristian-Paul Bara",
            "Yidong Huang",
            "Eui-In Kim",
            "Felix Gervits",
            "Matthew Marge",
            "Joyce Chai"
        ],
        "published": "2022",
        "summary": "In the real world, autonomous driving agents navigate in highly dynamic environments full of unexpected situations where pre-trained models are unreliable. In these situations, what is immediately available to vehicles is often only human operators. Empowering autonomous driving agents with the ability to navigate in a continuous and dynamic environment and to communicate with humans through sensorimotor-grounded dialogue becomes critical. To this end, we introduce Dialogue On the ROad To Handle Irregular Events (DOROTHIE), a novel interactive simulation platform that enables the creation of unexpected situations on the fly to support empirical studies on situated communication with autonomous driving agents. Based on this platform, we created the Situated Dialogue Navigation (SDN), a navigation benchmark of 183 trials with a total of 8415 utterances, around 18.7 hours of control streams, and 2.9 hours of trimmed audio. SDN is developed to evaluate the agent’s ability to predict dialogue moves from humans as well as generate its own dialogue moves and physical navigation actions. We further developed a transformer-based baseline model for these SDN tasks. Our empirical results indicate that language guided-navigation in a highly dynamic environment is an extremely difficult task for end-to-end models. These results will provide insight towards future work on robust autonomous driving agents",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.354.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Dynamic Augmentation Data Selection for Few-shot Text Classification",
        "authors": [
            "Guangliang Liu",
            "Lifeng Jin",
            "Owen Yuan",
            "Jiayu Zhou"
        ],
        "published": "2022",
        "summary": "Data augmentation has been a popular method for fine-tuning pre-trained language models to increase model robustness and performance. With augmentation data coming from modifying gold train data (in-sample augmentation) or being harvested from general domain unlabeled data (out-of-sample augmentation), the quality of such data is the key to successful fine-tuning. In this paper, we propose a dynamic data selection method to select effective augmentation data from different augmentation sources according to the model’s learning stage, by identifying a set of augmentation samples that optimally facilitates the learning process of the most current model. The method firstly filters out augmentation samples with noisy pseudo labels through a curriculum learning strategy, then estimates the effectiveness of reserved augmentation data by its influence scores on the current model at every update, allowing the data selection process tightly tailored to model parameters. And the two-stage augmentation strategy considers in-sample augmentation and out-of-sample augmentation in different learning stages. Experiments with both kinds of augmentation data on a variety of sentence classification tasks show that our method outperforms strong baselines, proving the effectiveness of our method. Analysis confirms the dynamic nature of the data effectiveness and the importance of model learning stages in utilization of augmentation data.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.356.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Improving Generalization of Pre-trained Language Models via Stochastic Weight Averaging",
        "authors": [
            "Peng Lu",
            "Ivan Kobyzev",
            "Mehdi Rezagholizadeh",
            "Ahmad Rashid",
            "Ali Ghodsi",
            "Phillippe Langlais"
        ],
        "published": "2022",
        "summary": "Knowledge Distillation (KD) is a commonly used technique for improving the generalization of compact Pre-trained Language Models (PLMs) on downstream tasks. However, such methods impose the additional burden of training a separate teacher model for every new dataset.Alternatively, one may directly work on the improvement of the optimization procedure of the compact model towards better generalization. Recent works observe that the flatness of the local minimum correlates well with better generalization.In this work, we adapt Stochastic Weight Averaging (SWA), a method encouraging convergence to a flatter minimum, to fine-tuning PLMs. We conduct extensive experiments on various NLP tasks (text classification, question answering, and generation) and different model architectures and demonstrate that our adaptation improves the generalization without extra computation cost. Moreover, we observe that this simple optimization technique is able to outperform the state-of-the-art KD methods for compact models.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.363.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Learn What Is Possible, Then Choose What Is Best: Disentangling One-To-Many Relations in Language Through Text-based Games",
        "authors": [
            "Benjamin Towle",
            "Ke Zhou"
        ],
        "published": "2022",
        "summary": "Language models pre-trained on large self-supervised corpora, followed by task-specific fine-tuning has become the dominant paradigm in NLP. These pre-training datasets often have a one-to-many structure—e.g. in dialogue there are many valid responses for a given context. However, only some of these responses will be desirable in our downstream task. This raises the question of how we should train the model such that it can emulate the desirable behaviours, but not the undesirable ones. Current approaches train in a one-to-one setup—only a single target response is given for a single dialogue context—leading to models only learning to predict the average response, while ignoring the full range of possible responses. Using text-based games as a testbed, our approach, PASA, uses discrete latent variables to capture the range of different behaviours represented in our larger pre-training dataset. We then use knowledge distillation to distil the posterior probability distribution into a student model. This probability distribution is far richer than learning from only the hard targets of the dataset, and thus allows the student model to benefit from the richer range of actions the teacher model has learned. Results show up to 49% empirical improvement over the previous state-of-the-art model on the Jericho Walkthroughs dataset.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.364.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "HeLo: Learning-Free Lookahead Decoding for Conversation Infilling",
        "authors": [
            "Ivan Lee",
            "Taylor Berg-Kirkpatrick"
        ],
        "published": "2022",
        "summary": "We propose Heuristic Guided Lookahead Decoding (HeLo), a novel decoding strategy for conversation infilling. Conversation infilling aims to generate a seamless bridge of utterances connecting a given pair of source and target utterances. HeLo does not require fine-tuning or extra models – only the generating model itself. Instead, HeLo leverages a greedy lookahead phase before committing to any token. The HeLo framework is simple and can augment conventional decoding strategies paired with any autoregressive language model. Smooth transitions between utterances are encouraged with an annealing schedule. Our experiments show HeLo outperforms several baselines when evaluated with both automatic and human evaluation metrics, which, we argue, are appropriate for the task.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.367.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "NeuroCounterfactuals: Beyond Minimal-Edit Counterfactuals for Richer Data Augmentation",
        "authors": [
            "Phillip Howard",
            "Gadi Singer",
            "Vasudev Lal",
            "Yejin Choi",
            "Swabha Swayamdipta"
        ],
        "published": "2022",
        "summary": "While counterfactual data augmentation offers a promising step towards robust generalization in natural language processing, producing a set of counterfactuals that offer valuable inductive bias for models remains a challenge. Most existing approaches for producing counterfactuals, manual or automated, rely on small perturbations via minimal edits, resulting in simplistic changes. We introduce NeuroCounterfactuals, designed as loose counterfactuals, allowing for larger edits which result in naturalistic generations containing linguistic diversity, while still bearing similarity to the original document. Our novel generative approach bridges the benefits of constrained decoding, with those of language model adaptation for sentiment steering. Training data augmentation with our generations results in both in-domain and out-of-domain improvements for sentiment classification, outperforming even manually curated counterfactuals, under select settings. We further present detailed analyses to show the advantages of NeuroCounterfactuals over approaches involving simple, minimal edits.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.371.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Finding Memo: Extractive Memorization in Constrained Sequence Generation Tasks",
        "authors": [
            "Vikas Raunak",
            "Arul Menezes"
        ],
        "published": "2022",
        "summary": "Memorization presents a challenge for several constrained Natural Language Generation (NLG) tasks such as Neural Machine Translation (NMT), wherein the proclivity of neural models to memorize noisy and atypical samples reacts adversely with the noisy (web crawled) datasets. However, previous studies of memorization in constrained NLG tasks have only focused on counterfactual memorization, linking it to the problem of hallucinations. In this work, we propose a new, inexpensive algorithm for extractive memorization (exact training data generation under insufficient context) in constrained sequence generation tasks and use it to study extractive memorization and its effects in NMT. We demonstrate that extractive memorization poses a serious threat to NMT reliability by qualitatively and quantitatively characterizing the memorized samples as well as the model behavior in their vicinity. Based on empirical observations, we develop a simple algorithm which elicits non-memorized translations of memorized samples from the same model, for a large fraction of such samples. Finally, we show that the proposed algorithm could also be leveraged to mitigate memorization in the model through finetuning. We have released the code to reproduce our results at https://github.com/vyraun/Finding-Memo.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.378.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "SALTED: A Framework for SAlient Long-tail Translation Error Detection",
        "authors": [
            "Vikas Raunak",
            "Matt Post",
            "Arul Menezes"
        ],
        "published": "2022",
        "summary": "Traditional machine translation (MT) metrics provide an average measure of translation quality that is insensitive to the long tail of behavioral problems. Examples include translation of numbers, physical units, dropped content and hallucinations. These errors, which occur rarely and unpredictably in Neural Machine Translation (NMT), greatly undermine the reliability of state-of-the-art MT systems. Consequently, it is important to have visibility into these problems during model development.Towards this end, we introduce SALTED, a specifications-based framework for behavioral testing of NMT models. At the core of our approach is the use of high-precision detectors that flag errors (or alternatively, verify output correctness) between a source sentence and a system output. These detectors provide fine-grained measurements of long-tail errors, providing a trustworthy view of problems that were previously invisible. We demonstrate that such detectors could be used not just to identify salient long-tail errors in MT systems, but also for higher-recall filtering of the training data, fixing targeted errors with model fine-tuning in NMT and generating novel data for metamorphic testing to elicit further bugs in models.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.379.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "XRICL: Cross-lingual Retrieval-Augmented In-Context Learning for Cross-lingual Text-to-SQL Semantic Parsing",
        "authors": [
            "Peng Shi",
            "Rui Zhang",
            "He Bai",
            "Jimmy Lin"
        ],
        "published": "2022",
        "summary": "In-context learning using large language models has recently shown surprising results for semantic parsing tasks such as Text-to-SQL translation.Prompting GPT-3 or Codex using several examples of question-SQL pairs can produce excellent results, comparable to state-of-the-art finetuning-based models.However, existing work primarily focuses on English datasets, and it is unknown whether large language models can serve as competitive semantic parsers for other languages.To bridge this gap, our work focuses on cross-lingual Text-to-SQL semantic parsing for translating non-English utterances into SQL queries based on an English schema.We consider a zero-shot transfer learning setting with the assumption that we do not have any labeled examples in the target language (but have annotated examples in English).This work introduces the XRICL framework, which learns to retrieve relevant English exemplars for a given query to construct prompts.We also include global translation exemplars for a target language to facilitate the translation process for large language models.To systematically evaluate our model, we construct two new benchmark datasets, XSpider and XKaggle-dbqa, which include questions in Chinese, Vietnamese, Farsi, and Hindi.Our experiments show that XRICL effectively leverages large pre-trained language models to outperform existing baselines.Data and code are publicly available at https://github.com/Impavidity/XRICL.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.384.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Detecting Dementia from Long Neuropsychological Interviews",
        "authors": [
            "Nauman Dawalatabad",
            "Yuan Gong",
            "Sameer Khurana",
            "Rhoda Au",
            "James Glass"
        ],
        "published": "2022",
        "summary": "Neuropsychological exams are commonly used to diagnose various kinds of cognitive impairment. They typically involve a trained examiner who conducts a series of cognitive tests with a subject. In recent years, there has been growing interest in developing machine learning methods to extract speech and language biomarkers from exam recordings to provide automated input for cognitive assessment. Inspired by recent findings suggesting that the examiner’s language can influence cognitive impairment classifications, in this paper, we study the influence of the examiner on automatic dementia identification decisions in real-world neuropsychological exams. To mitigate the influence of the examiner, we propose a systematic three-stage pipeline for detecting dementia from exam recordings. In the first stage, we perform audio-based speaker diarization (i.e., estimating who spoke when?) by incorporating speaker discriminative features. In the second stage, we employ text-based language models to identify the role of the speaker (i.e., examiner or subject). Finally, in the third stage, we employ text- and audio-based models to detect cognitive impairment from hypothesized subject segments. Our studies suggest that incorporating audio-based diarization followed by text-based role identification helps mitigate the influences from the examiner’s segments. Further, we found that the text and audio modalities complement each other, and the performance improves when we use both modalities. We also perform several carefully designed experimental studies to assess the performance of each stage.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.386.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Open-domain Question Answering via Chain of Reasoning over Heterogeneous Knowledge",
        "authors": [
            "Kaixin Ma",
            "Hao Cheng",
            "Xiaodong Liu",
            "Eric Nyberg",
            "Jianfeng Gao"
        ],
        "published": "2022",
        "summary": "We propose a novel open-domain question answering (ODQA) framework for answering single/multi-hop questions across heterogeneous knowledge sources.The key novelty of our method is the introduction of the intermediary modules into the current retriever-reader pipeline.Unlike previous methods that solely rely on the retriever for gathering all evidence in isolation,our intermediary performs a chain of reasoning over the retrieved set.Specifically, our method links the retrieved evidence with its related global context into graphs and organizes them into a candidate list of evidence chains.Built upon pretrained language models, our system achieves competitive performance on two ODQA datasets, OTT-QA and NQ, against tables and passages from Wikipedia.In particular, our model substantially outperforms the previous state-of-the-art on OTT-QA with an exact match score of 47.3 (45% relative gain).",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.392.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Open-Vocabulary Argument Role Prediction For Event Extraction",
        "authors": [
            "Yizhu Jiao",
            "Sha Li",
            "Yiqing Xie",
            "Ming Zhong",
            "Heng Ji",
            "Jiawei Han"
        ],
        "published": "2022",
        "summary": "The argument role in event extraction refers to the relation between an event and an argument participating in it. Despite the great progress in event extraction, existing studies still depend on roles pre-defined by domain experts. These studies expose obvious weakness when extending to emerging event types or new domains without available roles. Therefore, more attention and effort needs to be devoted to automatically customizing argument roles. In this paper, we define this essential but under-explored task: open-vocabulary argument role prediction. The goal of this task is to infer a set of argument roles for a given event type. We propose a novel unsupervised framework, RolePred for this task. Specifically, we formulate the role prediction problem as an in-filling task and construct prompts for a pre-trained language model to generate candidate roles. By extracting and analyzing the candidate arguments, the event-specific roles are further merged and selected. To standardize the research of this task, we collect a new human-annotated event extraction dataset including 143 customized argument roles with rich semantics. On this dataset, RolePred outperforms the existing methods by a large margin.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.395.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Baked-in State Probing",
        "authors": [
            "Shubham Toshniwal",
            "Sam Wiseman",
            "Karen Livescu",
            "Kevin Gimpel"
        ],
        "published": "2022",
        "summary": "Neural language models have been analyzed for their linguistic and extra-linguistic knowledge via probing. Of particular interest has been the following question: how much can a language model trained only on form learn about meaning? Recent work has demonstrated via probing classifiers that in the setting of simple procedural text, where by “meaning” we mean the underlying world state, language models have a non-trivial performance on world state tracking. However, our proposed evaluation based on model predictions shows differing results, suggesting that these models are either not capturing the world state or not using it. How do these results change if the model has access to the world state? We explore this alternate setting with access to the underlying world state only during training and investigate ways of “baking in” the state knowledge along with the primary task of language modeling. Our proposed approaches allow for state probing during inference simply via text prompts, avoiding any probing classifier machinery. In terms of performance, we show that baking in the state knowledge during training leads to significant improvements in state tracking performance and text generation quality,",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.397.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "ClinicalT5: A Generative Language Model for Clinical Text",
        "authors": [
            "Qiuhao Lu",
            "Dejing Dou",
            "Thien Nguyen"
        ],
        "published": "2022",
        "summary": "In the past few years, large pre-trained language models (PLMs) have been widely adopted in different areas and have made fundamental improvements over a variety of downstream tasks in natural language processing (NLP). Meanwhile, domain-specific variants of PLMs are being proposed to address the needs of domains that demonstrate a specific pattern of writing and vocabulary, e.g., BioBERT for the biomedical domain and ClinicalBERT for the clinical domain. Recently, generative language models like BART and T5 are gaining popularity with their competitive performance on text generation as well as on tasks cast as generative problems. However, in the clinical domain, such domain-specific generative variants are still underexplored. To address this need, our work introduces a T5-based text-to-text transformer model pre-trained on clinical text, i.e., ClinicalT5. We evaluate the proposed model both intrinsically and extrinsically over a diverse set of tasks across multiple datasets, and show that ClinicalT5 dramatically outperforms T5 in the domain-specific tasks and compares favorably with its close baselines.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.398.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Prompt-Tuning Can Be Much Better Than Fine-Tuning on Cross-lingual Understanding With Multilingual Language Models",
        "authors": [
            "Lifu Tu",
            "Caiming Xiong",
            "Yingbo Zhou"
        ],
        "published": "2022",
        "summary": "Pre-trained multilingual language models show significant performance gains for zero-shot cross-lingual model transfer on a wide range of natural language understanding (NLU) tasks. Previously, for zero-shot cross-lingual evaluation, pre-trained models are only fine-tuned on English data and tested on a variety of target languages. In this paper, we do cross-lingualevaluation on various NLU tasks (sentence classification, sequence labeling, question answering) using prompt-tuning and compare it with fine-tuning. The results show that prompt tuning achieves much better cross-lingual transfer than fine-tuning across datasets, with only 0.1% to 0.3% tuned parameters. Additionally, we demonstrate through the analysis that prompt tuning can have better cross-lingual transfer-ability of representations on downstream tasks with better aligned decision boundaries.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.401.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "BERT Meets CTC: New Formulation of End-to-End Speech Recognition with Pre-trained Masked Language Model",
        "authors": [
            "Yosuke Higuchi",
            "Brian Yan",
            "Siddhant Arora",
            "Tetsuji Ogawa",
            "Tetsunori Kobayashi",
            "Shinji Watanabe"
        ],
        "published": "2022",
        "summary": "This paper presents BERT-CTC, a novel formulation of end-to-end speech recognition that adapts BERT for connectionist temporal classification (CTC). Our formulation relaxes the conditional independence assumptions used in conventional CTC and incorporates linguistic knowledge through the explicit output dependency obtained by BERT contextual embedding. BERT-CTC attends to the full contexts of the input and hypothesized output sequences via the self-attention mechanism. This mechanism encourages a model to learn inner/inter-dependencies between the audio and token representations while maintaining CTC’s training efficiency. During inference, BERT-CTC combines a mask-predict algorithm with CTC decoding, which iteratively refines an output sequence. The experimental results reveal that BERT-CTC improves over conventional approaches across variations in speaking styles and languages. Finally, we show that the semantic representations in BERT-CTC are beneficial towards downstream spoken language understanding tasks.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.402.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Language Model Detoxification in Dialogue with Contextualized Stance Control",
        "authors": [
            "Jing Qian",
            "Xifeng Yan"
        ],
        "published": "2022",
        "summary": "To reduce the toxic degeneration in a pretrained Language Model (LM), previous work on Language Model detoxification has focused on reducing the toxicity of the generation itself (self-toxicity) without consideration of the context. As a result, a type of implicit offensive language where the generations support the offensive language in the context is ignored. Different from the LM controlling tasks in previous work, where the desired attributes are fixed for generation, the desired stance of the generation depends on the offensiveness of the context. Therefore, we propose a novel control method to do context-dependent detoxification with the stance taken into consideration. We introduce meta prefixes to learn the contextualized stance control strategy and to generate the stance control prefix according to the input context. The generated stance prefix is then combined with the toxicity control prefix to guide the response generation. Experimental results show that our proposed method can effectively learn the context-dependent stance control strategies while keeping a low self-toxicity of the underlying LM.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.406.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Multilingual SubEvent Relation Extraction: A Novel Dataset and Structure Induction Method",
        "authors": [
            "Viet Lai",
            "Hieu Man",
            "Linh Ngo",
            "Franck Dernoncourt",
            "Thien Nguyen"
        ],
        "published": "2022",
        "summary": "Subevent Relation Extraction (SRE) is a task in Information Extraction that aims to recognize spatial and temporal containment relations between event mentions in text. Recent methods have utilized pre-trained language models to represent input texts for SRE. However, a key issue in existing SRE methods is the employment of sequential order of words in texts to feed into representation learning methods, thus unable to explicitly focus on important context words and their interactions to enhance representations. In this work, we introduce a new method for SRE that learns to induce effective graph structures for input texts to boost representation learning. Our method features a word alignment framework with dependency paths and optimal transport to identify important context words to form effective graph structures for SRE. In addition, to enable SRE research on non-English languages, we present a new multilingual SRE dataset for five typologically different languages. Extensive experiments reveal the state-of-the-art performance for our method on different datasets and languages.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.407.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Prompt Compression and Contrastive Conditioning for Controllability and Toxicity Reduction in Language Models",
        "authors": [
            "David Wingate",
            "Mohammad Shoeybi",
            "Taylor Sorensen"
        ],
        "published": "2022",
        "summary": "We explore the idea of compressing the prompts used to condition language models, and show that compressed prompts can retain a substantive amount of information about the original prompt. For severely compressed prompts, while fine-grained information is lost, abstract information and general sentiments can be retained with surprisingly few parameters, which can be useful in the context of decode-time algorithms for controllability and toxicity reduction. We find that some complex prompts can be effectively compressed into a single token to guide generation. We also show that compressed prompts are largely compositional, and can be constructed such that they can be used to control independent aspects of generated text.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.412.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Task Compass: Scaling Multi-task Pre-training with Task Prefix",
        "authors": [
            "Zhuosheng Zhang",
            "Shuohang Wang",
            "Yichong Xu",
            "Yuwei Fang",
            "Wenhao Yu",
            "Yang Liu",
            "Hai Zhao",
            "Chenguang Zhu",
            "Michael Zeng"
        ],
        "published": "2022",
        "summary": "Leveraging task-aware annotated data as supervised signals to assist with self-supervised learning on large-scale unlabeled data has become a new trend in pre-training language models. Existing studies show that multi-task learning with large-scale supervised tasks suffers from negative effects across tasks. To tackle the challenge, we propose a task prefix guided multi-task pre-training framework to explore the relationships among tasks. We conduct extensive experiments on 40 datasets, which show that our model can not only serve as the strong foundation backbone for a wide range of tasks but also be feasible as a probing tool for analyzing task relationships. The task relationships reflected by the prefixes align transfer learning performance between tasks. They also suggest directions for data augmentation with complementary tasks, which help our model achieve human-parity results on commonsense reasoning leaderboards. Code is available at https://github.com/cooelf/CompassMTL.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.416.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Hidden State Variability of Pretrained Language Models Can Guide Computation Reduction for Transfer Learning",
        "authors": [
            "Shuo Xie",
            "Jiahao Qiu",
            "Ankita Pasad",
            "Li Du",
            "Qing Qu",
            "Hongyuan Mei"
        ],
        "published": "2022",
        "summary": "While transferring a pretrained language model, common approaches conventionally attach their task-specific classifiers to the top layer and adapt all the pretrained layers. We investigate whether one could make a task-specific selection on which subset of the layers to adapt and where to place the classifier. The goal is to reduce the computation cost of transfer learning methods (e.g. fine-tuning or adapter-tuning) without sacrificing its performance.We propose to select layers based on the variability of their hidden states given a task-specific corpus. We say a layer is already “well-specialized” in a task if the within-class variability of its hidden states is low relative to the between-class variability. Our variability metric is cheap to compute and doesn’t need any training or hyperparameter tuning. It is robust to data imbalance and data scarcity. Extensive experiments on the GLUE benchmark demonstrate that selecting layers based on our metric can yield significantly stronger performance than using the same number of top layers and often match the performance of fine-tuning or adapter-tuning the entire language model.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.422.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Language Models as Agent Models",
        "authors": [
            "Jacob Andreas"
        ],
        "published": "2022",
        "summary": "Language models (LMs) are trained on collections of documents, written by individual human agents to achieve specific goals in the outside world. During training, LMs have access only to text of these documents, with no direct evidence of the internal states of the agents that produced them—a fact often used to argue that LMs are incapable of modeling goal-directed aspects of human language production and comprehension. Can LMs trained on text learn anything at all about the relationship between language and use? I argue that LMs are models of communicative intentions in a specific, narrow sense. When performing next word prediction given a textual context, an LM can infer and represent properties of an agent likely to have produced that context. These representations can in turn influence subsequent LM generation in the same way that agents’ communicative intentions influence their language. I survey findings from the recent literature showing that—even in today’s non-robust and error-prone models—LMs infer and use representations of fine-grained communicative intentions and high-level beliefs and goals. Despite the limited nature of their training data, they can thus serve as building blocks for systems that communicate and act intentionally.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.423.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Leveraging Open Data and Task Augmentation to Automated Behavioral Coding of Psychotherapy Conversations in Low-Resource Scenarios",
        "authors": [
            "Zhuohao Chen",
            "Nikolaos Flemotomos",
            "Zac Imel",
            "David Atkins",
            "Shrikanth Narayanan"
        ],
        "published": "2022",
        "summary": "In psychotherapy interactions, the quality of a session is assessed by codifying the communicative behaviors of participants during the conversation through manual observation and annotation. Developing computational approaches for automated behavioral coding can reduce the burden on human coders and facilitate the objective evaluation of the intervention. In the real world, however, implementing such algorithms is associated with data sparsity challenges since privacy concerns lead to limited available in-domain data. In this paper, we leverage a publicly available conversation-based dataset and transfer knowledge to the low-resource behavioral coding task by performing an intermediate language model training via meta-learning. We introduce a task augmentation method to produce a large number of “analogy tasks” — tasks similar to the target one — and demonstrate that the proposed framework predicts target behaviors more accurately than all the other baseline models.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.425.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Composition, Attention, or Both?",
        "authors": [
            "Ryo Yoshida",
            "Yohei Oseki"
        ],
        "published": "2022",
        "summary": "In this paper, we propose a novel architecture called Composition Attention Grammars (CAGs) that recursively compose subtrees into a single vector representation with a composition function, and selectively attend to previous structural information with a self-attention mechanism. We investigate whether these components—the composition function and the self-attention mechanism—can both induce human-like syntactic generalization. Specifically, we train language models (LMs) with and without these two components with the model sizes carefully controlled, and evaluate their syntactic generalization performance against six test circuits on the SyntaxGym benchmark. The results demonstrated that the composition function and the self-attention mechanism both play an important role to make LMs more human-like, and closer inspection of linguistic phenomenon implied that the composition function allowed syntactic features, but not semantic features, to percolate into subtree representations.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.428.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "CDGP: Automatic Cloze Distractor Generation based on Pre-trained Language Model",
        "authors": [
            "Shang-Hsuan Chiang",
            "Ssu-Cheng Wang",
            "Yao-Chung Fan"
        ],
        "published": "2022",
        "summary": "Manually designing cloze test consumes enormous time and efforts. The major challenge lies in wrong option (distractor) selection. Having carefully-design distractors improves the effectiveness of learner ability assessment. As a result, the idea of automatically generating cloze distractor is motivated. In this paper, we investigate cloze distractor generation by exploring the employment of pre-trained language models (PLMs) as an alternative for candidate distractor generation. Experiments show that the PLM-enhanced model brings a substantial performance improvement. Our best performing model advances the state-of-the-art result from 14.94 to 34.17 (NDCG@10 score). Our code and dataset is available at https://github.com/AndyChiangSH/CDGP.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.429.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Data-Efficient Concept Extraction from Pre-trained Language Models for Commonsense Explanation Generation",
        "authors": [
            "Yanbo Fang",
            "Yongfeng Zhang"
        ],
        "published": "2022",
        "summary": "Predicting the key explanation concept is essential for generating commonsense explanations. This paper introduces a method to predict the concept from pre-trained language models for commonsense explanation generation. Our experiment found that adopting a language model as the concept extractor and fine-tuning it with 20% training data can improve the quality and accuracy of the generated explanations over multiple evaluation metrics. Compared with conventional methods that search concepts over knowledge graphs, our method does not require the preparation and training models to search through knowledge graphs. To better understand the results from pre-trained language models, we also designed a metric to evaluate the retrieved concepts. Through analysis and experiments, we show the correlation between this metric and the performance of the generators, and we also show the importance of attaching concepts for generating high-quality sentences.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.433.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Foiling Training-Time Attacks on Neural Machine Translation Systems",
        "authors": [
            "Jun Wang",
            "Xuanli He",
            "Benjamin Rubinstein",
            "Trevor Cohn"
        ],
        "published": "2022",
        "summary": "Neural machine translation (NMT) systems are vulnerable to backdoor attacks, whereby an attacker injects poisoned samples into training such that a trained model produces malicious translations. Nevertheless, there is little research on defending against such backdoor attacks in NMT. In this paper, we first show that backdoor attacks that have been successful in text classification are also effective against machine translation tasks. We then present a novel defence method that exploits a key property of most backdoor attacks: namely the asymmetry between the source and target language sentences, which is used to facilitate malicious text insertions, substitutions and suchlike. Our technique uses word alignment coupled with language model scoring to detect outlier tokens, and thus can find and filter out training instances which may contain backdoors. Experimental results demonstrate that our technique can significantly reduce the success of various attacks by up to 89.0%, while not affecting predictive accuracy.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.435.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Calibrating Factual Knowledge in Pretrained Language Models",
        "authors": [
            "Qingxiu Dong",
            "Damai Dai",
            "Yifan Song",
            "Jingjing Xu",
            "Zhifang Sui",
            "Lei Li"
        ],
        "published": "2022",
        "summary": "Previous literature has proved that Pretrained Language Models (PLMs) can store factual knowledge. However, we find that facts stored in the PLMs are not always correct. It motivates us to explore a fundamental question: How do we calibrate factual knowledge in PLMs without re-training from scratch? In this work, we propose a simple and lightweight method CaliNet to achieve this goal. To be specific, we first detect whether PLMs can learn the right facts via a contrastive score between right and fake facts. If not, we then use a lightweight method to add and adapt new parameters to specific factual texts. Experiments on the knowledge probing task show the calibration effectiveness and efficiency. In addition, through closed-book question answering, we find that the calibrated PLM possesses knowledge generalization ability after finetuning.Beyond the calibration performance, we further investigate and visualize the knowledge calibration mechanism.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.438.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "WordTies: Measuring Word Associations in Language Models via Constrained Sampling",
        "authors": [
            "Peiran Yao",
            "Tobias Renwick",
            "Denilson Barbosa"
        ],
        "published": "2022",
        "summary": "Word associations are widely used in psychology to provide insights on how humans perceive and understand concepts. Comparing word associations in language models (LMs) to those generated by human subjects can serve as a proxy to uncover embedded lexical and commonsense knowledge in language models. While much helpful work has been done applying direct metrics, such as cosine similarity, to help understand latent spaces, these metrics are symmetric, while human word associativity is asymmetric. We propose WordTies, an algorithm based on constrained sampling from LMs, which allows an asymmetric measurement of associated words, given a cue word as the input. Comparing to existing methods, word associations found by this method share more overlap with associations provided by humans, and observe the asymmetric property of human associations. To examine possible reasons behind associations, we analyze the knowledge and reasoning behind the word pairings as they are linked to lexical and commonsense knowledge graphs.When the knowledge about the nature of the word pairings is combined with a probability that the LM has learned that information, we have a new way to examine what information is captured in LMs.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.440.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Exploring The Landscape of Distributional Robustness for Question Answering Models",
        "authors": [
            "Anas Awadalla",
            "Mitchell Wortsman",
            "Gabriel Ilharco",
            "Sewon Min",
            "Ian Magnusson",
            "Hannaneh Hajishirzi",
            "Ludwig Schmidt"
        ],
        "published": "2022",
        "summary": "We conduct a large empirical evaluation to investigate the landscape of distributional robustness in question answering. Our investigation spans over 350 models and 16 question answering datasets, including a diverse set of architectures, model sizes, and adaptation methods (e.g., fine-tuning, adapter tuning, in-context learning, etc.). We find that, in many cases, model variations do not affect robustness and in-distribution performance alone determines out-of-distribution performance.Moreover, our findings indicate thati) zero-shot and in-context learning methods are more robust to distribution shifts than fully fine-tuned models;ii) few-shot prompt fine-tuned models exhibit better robustness than few-shot fine-tuned span prediction models;iii) parameter-efficient and robustness enhancing training methods provide no significant robustness improvements.In addition, we publicly release all evaluations to encourage researchers to further analyze robustness trends for question answering models.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.441.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Collaborative Reasoning on Multi-Modal Semantic Graphs for Video-Grounded Dialogue Generation",
        "authors": [
            "Xueliang Zhao",
            "Yuxuan Wang",
            "Chongyang Tao",
            "Chenshuo Wang",
            "Dongyan Zhao"
        ],
        "published": "2022",
        "summary": "We study video-grounded dialogue generation, where a response is generated based on the dialogue context and the associated video. The primary challenges of this task lie in (1) the difficulty of integrating video data into pre-trained language models (PLMs) which presents obstacles to exploiting the power of large-scale pre-training; and (2) the necessity of taking into account the complementarity of various modalities throughout the reasoning process. Although having made remarkable progress in video-grounded dialogue generation, existing methods still fall short when it comes to integrating with PLMs in a way that allows information from different modalities to complement each other. To alleviate these issues, we first propose extracting pertinent information from videos and turning it into reasoning paths that are acceptable to PLMs. Additionally, we propose a multi-agent reinforcement learning method to collaboratively perform reasoning on different modalities (i.e., video and dialogue context). Empirical experiment results on two public datasets indicate that the proposed model can significantly outperform state-of-the-art models by large margins on both automatic and human evaluations.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.442.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "AdaPrompt: Adaptive Model Training for Prompt-based NLP",
        "authors": [
            "Yulong Chen",
            "Yang Liu",
            "Li Dong",
            "Shuohang Wang",
            "Chenguang Zhu",
            "Michael Zeng",
            "Yue Zhang"
        ],
        "published": "2022",
        "summary": "Prompt-based learning, with its capability to tackle zero-shot and few-shot NLP tasks, has gained much attention in the community.The main idea is to bridge the gap between NLP downstream tasks and language modeling (LM), by mapping these tasks into natural language prompts, which are then filled by pre-trained language models (PLMs).However, for prompt learning, there are still two salient gaps between NLP tasks and pretraining.First, prompt information is not necessarily sufficiently present during LM pre-training. Second, task-specific data are not necessarily well represented during pre-training. We address these two issues by proposing AdaPrompt, adaptively retrieving external data for continual pretraining of PLMs by making use of both task and prompt characteristics. In addition, we make use of knowledge in Natural Language Inference models for deriving adaptive verbalizers.Experimental results on five NLP benchmarks show that AdaPrompt can improve over standard PLMs in few-shot settings. In addition, in zero-shot settings, our method outperforms standard prompt-based methods by up to 26.35% relative error reduction.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.448.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Explore Unsupervised Structures in Pretrained Models for Relation Extraction",
        "authors": [
            "Xi Yang",
            "Tao Ji",
            "Yuanbin Wu"
        ],
        "published": "2022",
        "summary": "Syntactic trees have been widely applied in relation extraction (RE). However, since parsing qualities are not stable on different text domains and a pre-defined grammar may not well fit the target relation schema, the introduction of syntactic structures sometimes fails to improve RE performances consistently. In this work, we study RE models with various unsupervised structures mined from pre-trained language models (e.g., BERT). We show that, similar to syntactic trees, unsupervised structures are quite informative for RE task: they are able to obtain competitive (even the best) performance scores on benchmark RE datasets (ACE05, WebNLG, SciERC). We also conduct detailed analyses on their abilities of adapting new RE domains and influence of noise links in those structures. The results suggest that unsupervised structures are reasonable alternatives of commonly used syntactic structures in relation extraction models.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.453.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Answer Quality Aware Aggregation for Extractive QA Crowdsourcing",
        "authors": [
            "Peide Zhu",
            "Zhen Wang",
            "Claudia Hauff",
            "Jie Yang",
            "Avishek Anand"
        ],
        "published": "2022",
        "summary": "Quality control is essential for creating extractive question answering (EQA) datasets via crowdsourcing. Aggregation across answers, i.e. word spans within passages annotated, by different crowd workers is one major focus for ensuring its quality. However, crowd workers cannot reach a consensus on a considerable portion of questions. We introduce a simple yet effective answer aggregation method that takes into account the relations among the answer, question, and context passage. We evaluate answer quality from both the view of question answering model to determine how confident the QA model is about each answer and the view of the answer verification model to determine whether the answer is correct. Then we compute aggregation scores with each answer’s quality and its contextual embedding produced by pre-trained language models. The experiments on a large real crowdsourced EQA dataset show that our framework outperforms baselines by around 16% on precision and effectively conduct answer aggregation for extractive QA task.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.457.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "ParaMac: A General Unsupervised Paraphrase Generation Framework Leveraging Semantic Constraints and Diversifying Mechanisms",
        "authors": [
            "Jinxin Liu",
            "Jiaxin Shi",
            "Ji Qi",
            "Lei Hou",
            "Juanzi Li",
            "Qi Tian"
        ],
        "published": "2022",
        "summary": "Paraphrase generation reflects the ability to understand the meaning from the language surface form and rephrase it to other expressions. Recent paraphrase generation works have paid attention to unsupervised approaches based on Pre-trained Language Models (PLMs) to avoid heavy reliance on parallel data by utilizing PLMs’ generation ability. However, the generated pairs of existing unsupervised methods are usually weak either in semantic equivalence or expression diversity. In this paper, we present a novel unsupervised paraphrase generation framework called Paraphrase Machine. By employing multi-aspect equivalence constraints and multi-granularity diversifying mechanisms, Paraphrase Machine is able to achieve good semantic equivalence and expressive diversity, producing a high-quality unsupervised paraphrase dataset. Based on this dataset, we train a general paraphrase model, which can be directly applied to rewrite the input sentence of various domains without any fine-tuning, and achieves substantial gains of 9.1% and 3.3% absolutely in BLEU score over previous SOTA on Quora and MSCOCO. By further fine-tuning our model with domain-specific training sets, the improvement can be increased to even 18.0% and 4.6%. Most importantly, by applying it to language understanding and generation tasks under the low-resource setting, we demonstrate that our model can serve as a universal data augmentor to boost the few-shot performance (e.g., average 2.0% gain on GLUE).",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.461.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Con-NAT: Contrastive Non-autoregressive Neural Machine Translation",
        "authors": [
            "Hao Cheng",
            "Zhihua Zhang"
        ],
        "published": "2022",
        "summary": "Inspired by the success of contrastive learning in natural language processing, we incorporate contrastive learning into the conditional masked language model which is extensively used in non-autoregressive neural machine translation (NAT). Accordingly, we propose a Contrastive Non-autoregressive Neural Machine Translation (Con-NAT) model. Con-NAT optimizes the similarity of several different representations of the same token in the same sentence. We propose two methods to obtain various representations: Contrastive Common Mask and Contrastive Dropout. Positive pairs are various different representations of the same token, while negative pairs are representations of different tokens. In the feature space, the model with contrastive loss pulls positive pairs together and pushes negative pairs away. We conduct extensive experiments on six translation directions with different data sizes. The results demonstrate that Con-NAT showed a consistent and significant improvement in fully and iterative NAT. Con-NAT is state-of-the-art on WMT’16 Ro-En (34.18 BLEU).",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.463.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Improved Knowledge Distillation for Pre-trained Language Models via Knowledge Selection",
        "authors": [
            "Chenglong Wang",
            "Yi Lu",
            "Yongyu Mu",
            "Yimin Hu",
            "Tong Xiao",
            "Jingbo Zhu"
        ],
        "published": "2022",
        "summary": "Knowledge distillation addresses the problem of transferring knowledge from a teacher model to a student model.In this process, we typically have multiple types of knowledge extracted from the teacher model.The problem is to make full use of them to train the student model.Our preliminary study shows that: (1) not all of the knowledge is necessary for learning a good student model, and (2) knowledge distillation can benefit from certain knowledge at different training steps.In response to these, we propose an actor-critic approach to selecting appropriate knowledge to transfer during the process of knowledge distillation.In addition, we offer a refinement of the training algorithm to ease the computational burden.Experimental results on the GLUE datasets show that our method outperforms several strong knowledge distillation baselines significantly.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.464.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "A Benchmark and Dataset for Post-OCR text correction in Sanskrit",
        "authors": [
            "Ayush Maheshwari",
            "Nikhil Singh",
            "Amrith Krishna",
            "Ganesh Ramakrishnan"
        ],
        "published": "2022",
        "summary": "Sanskrit is a classical language with about 30 million extant manuscripts fit for digitisation, available in written, printed or scanned-image forms. However, it is still considered to be a low-resource language when it comes to available digital resources. In this work, we release a post-OCR text correction dataset containing around 218,000 sentences, with 1.5 million words, from 30 different books. Texts in Sanskrit are known to be diverse in terms of their linguistic and stylistic usage since Sanskrit was the ‘lingua francua’ for discourse in the Indian subcontinent for about 3 millennia. Keeping this in mind, we release a multi-domain dataset, from areas as diverse as astronomy, medicine and mathematics, with some of them as old as 18 centuries. Further, we release multiple strong baselines as benchmarks for the task, based on pre-trained Seq2Seq language models. We find that our best-performing model, consisting of byte level tokenization in conjunction with phonetic encoding (Byt5+SLP1), yields a 23% point increase over the OCR output in terms of word and character error rates. Moreover, we perform extensive experiments in evaluating these models on their performance and analyse common causes of mispredictions both at the graphemic and lexical levels. Our code and dataset is publicly available at https://github.com/ayushbits/pe-ocr-sanskrit.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.466.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "VarMAE: Pre-training of Variational Masked Autoencoder for Domain-adaptive Language Understanding",
        "authors": [
            "Dou Hu",
            "Xiaolong Hou",
            "Xiyang Du",
            "Mengyuan Zhou",
            "Lianxin Jiang",
            "Yang Mo",
            "Xiaofeng Shi"
        ],
        "published": "2022",
        "summary": "Pre-trained language models have been widely applied to standard benchmarks. Due to the flexibility of natural language, the available resources in a certain domain can be restricted to support obtaining precise representation. To address this issue, we propose a novel Transformer-based language model named VarMAE for domain-adaptive language understanding. Under the masked autoencoding objective, we design a context uncertainty learning module to encode the token’s context into a smooth latent distribution. The module can produce diverse and well-formed contextual representations. Experiments on science- and finance-domain NLU tasks demonstrate that VarMAE can be efficiently adapted to new domains with limited resources.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.468.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Exploring Methods for Building Dialects-Mandarin Code-Mixing Corpora: A Case Study in Taiwanese Hokkien",
        "authors": [
            "Sin-En Lu",
            "Bo-Han Lu",
            "Chao-Yi Lu",
            "Richard Tzong-Han Tsai"
        ],
        "published": "2022",
        "summary": "In natural language processing (NLP), code-mixing (CM) is a challenging task, especially when the mixed languages include dialects. In Southeast Asian countries such as Singapore, Indonesia, and Malaysia, Hokkien-Mandarin is the most widespread code-mixed language pair among Chinese immigrants, and it is also common in Taiwan. However, dialects such as Hokkien often have a scarcity of resources and the lack of an official writing system, limiting the development of dialect CM research. In this paper, we propose a method to construct a Hokkien-Mandarin CM dataset to mitigate the limitation, overcome the morphological issue under the Sino-Tibetan language family, and offer an efficient Hokkien word segmentation method through a linguistics-based toolkit. Furthermore, we use our proposed dataset and employ transfer learning to train the XLM (cross-lingual language model) for translation tasks. To fit the code-mixing scenario, we adapt XLM slightly. We found that by using linguistic knowledge, rules, and language tags, the model produces good results on CM data translation while maintaining monolingual translation quality.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.469.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "From Mimicking to Integrating: Knowledge Integration for Pre-Trained Language Models",
        "authors": [
            "Lei Li",
            "Yankai Lin",
            "Xuancheng Ren",
            "Guangxiang Zhao",
            "Peng Li",
            "Jie Zhou",
            "Xu Sun"
        ],
        "published": "2022",
        "summary": "Investigating better ways to reuse the released pre-trained language models (PLMs) can significantly reduce the computational cost and the potential environmental side-effects. This paper explores a novel PLM reuse paradigm, Knowledge Integration (KI). Without human annotations available, KI aims to merge the knowledge from different teacher-PLMs, each of which specializes in a different classification problem, into a versatile student model. To achieve this, we first derive the correlation between virtual golden supervision and teacher predictions. We then design a Model Uncertainty–aware Knowledge Integration (MUKI) framework to recover the golden supervision for the student. Specifically, MUKI adopts Monte-Carlo Dropout to estimate model uncertainty for the supervision integration. An instance-wise re-weighting mechanism based on the margin of uncertainty scores is further incorporated, to deal with the potential conflicting supervision from teachers.Experimental results demonstrate that MUKI achieves substantial improvements over baselines on benchmark datasets. Further analysis shows that MUKI can generalize well for merging teacher models with heterogeneous architectures, and even teachers major in cross-lingual datasets.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.477.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Model and Data Transfer for Cross-Lingual Sequence Labelling in Zero-Resource Settings",
        "authors": [
            "Iker García-Ferrero",
            "Rodrigo Agerri",
            "German Rigau"
        ],
        "published": "2022",
        "summary": "Zero-resource cross-lingual transfer approaches aim to apply supervised modelsfrom a source language to unlabelled target languages. In this paper we performan in-depth study of the two main techniques employed so far for cross-lingualzero-resource sequence labelling, based either on data or model transfer.Although previous research has proposed translation and annotation projection(data-based cross-lingual transfer) as an effective technique for cross-lingualsequence labelling, in this paper we experimentally demonstrate that highcapacity multilingual language models applied in a zero-shot (model-basedcross-lingual transfer) setting consistently outperform data-basedcross-lingual transfer approaches. A detailed analysis of our results suggeststhat this might be due to important differences in language use. Morespecifically, machine translation often generates a textual signal which isdifferent to what the models are exposed to when using gold standard data,which affects both the fine-tuning and evaluation processes. Our results alsoindicate that data-based cross-lingual transfer approaches remain a competitiveoption when high-capacity multilingual language models are not available.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.478.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Forging Multiple Training Objectives for Pre-trained Language Models via Meta-Learning",
        "authors": [
            "Hongqiu Wu",
            "Ruixue Ding",
            "Hai Zhao",
            "Boli Chen",
            "Pengjun Xie",
            "Fei Huang",
            "Min Zhang"
        ],
        "published": "2022",
        "summary": "Multiple pre-training objectives fill the vacancy of the understanding capability of single-objective language modeling, which serves the ultimate purpose of pre-trained language models (PrLMs), generalizing well on a mass of scenarios. However, learning multiple training objectives in a single model is challenging due to the unknown relative significance as well as the potential contrariety between them. Empirical studies have shown that the current objective sampling in an ad-hoc manual setting makes the learned language representation barely converge to the desired optimum. Thus, we propose MOMETAS, a novel adaptive sampler based on meta-learning, which learns the latent sampling pattern on arbitrary pre-training objectives. Such a design is lightweight with negligible additional training overhead. To validate our approach, we adopt five objectives and conduct continual pre-training with BERT-base and BERT-large models, where MOMETAS demonstrates universal performance gain over other rule-based sampling strategies on 14 natural language processing tasks.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.482.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Large-Scale Differentially Private BERT",
        "authors": [
            "Rohan Anil",
            "Badih Ghazi",
            "Vineet Gupta",
            "Ravi Kumar",
            "Pasin Manurangsi"
        ],
        "published": "2022",
        "summary": "In this work, we study the large-scale pretraining of BERT-Large (Devlin et al., 2019) with differentially private SGD (DP-SGD). We show that combined with a careful implementation, scaling up the batch size to millions (i.e., mega-batches) improves the utility of the DP-SGD step for BERT; we also enhance the training efficiency by using an increasing batch size schedule. Our implementation builds on the recent work of Subramani et al (2020), who demonstrated that the overhead of a DP-SGD step is minimized with effective use of JAX (Bradbury et al., 2018; Frostig et al., 2018) primitives in conjunction with the XLA compiler (XLA team and collaborators, 2017). Our implementation achieves a masked language model accuracy of 60.5% at a batch size of 2M, for epsilon=5, which is a reasonable privacy setting. To put this number in perspective, non-private BERT models achieve an accuracy of ∼70%.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.484.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "SMASH: Improving SMAll Language Models’ Few-SHot Ability with Prompt-Based Distillation",
        "authors": [
            "Yueqian Wang",
            "Chang Liu",
            "Kai Chen",
            "Xi Wang",
            "Dongyan Zhao"
        ],
        "published": "2022",
        "summary": "Large-scale language models coupled with prompts have shown remarkable performance on few-shot learning. However, through systematic experiments, we find that the few-shot performance of small language models is poor, and using prompts on them brings fewer improvements than on larger ones. In this paper, we propose SMASH, an approach to improve SMAll language models’ few-SHot ability by training on intermediate tasks before prompt-based fine-tuning on downstream tasks. We design intermediate tasks for sentence-pair tasks and sentiment classification tasks by creating training examples with prompt templates similar to downstream tasks using sentences sampled from a large-scale unsupervised corpus, and apply knowledge distillation to distill from outputs of larger pre-trained models as the training objective. We conduct extensive experiments and show that SMASH can make a 6-layer DistilRoBRETa-base achieve comparable performance on few-shot datasets with a 12-layer RoBERTa-base at a low cost.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.492.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Subword Segmental Language Modelling for Nguni Languages",
        "authors": [
            "Francois Meyer",
            "Jan Buys"
        ],
        "published": "2022",
        "summary": "Subwords have become the standard units of text in NLP, enabling efficient open-vocabulary models. With algorithms like byte-pair encoding (BPE), subword segmentation is viewed as a preprocessing step applied to the corpus before training. This can lead to sub-optimal segmentations for low-resource languages with complex morphologies. We propose a subword segmental language model (SSLM) that learns how to segment words while being trained for autoregressive language modelling. By unifying subword segmentation and language modelling, our model learns subwords that optimise LM performance. We train our model on the 4 Nguni languages of South Africa. These are low-resource agglutinative languages, so subword information is critical. As an LM, SSLM outperforms existing approaches such as BPE-based models on average across the 4 languages. Furthermore, it outperforms standard subword segmenters on unsupervised morphological segmentation. We also train our model as a word-level sequence model, resulting in an unsupervised morphological segmenter that outperforms existing methods by a large margin for all 4 languages. Our results show that learning subword segmentation is an effective alternative to existing subword segmenters, enabling the model to discover morpheme-like subwords that improve its LM capabilities.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.494.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "P3LM: Probabilistically Permuted Prophet Language Modeling for Generative Pre-Training",
        "authors": [
            "Junwei Bao",
            "Yifan Wang",
            "Ying Jiangyong",
            "Yeyun Gong",
            "Jing Zhao",
            "Youzheng Wu",
            "Xiaodong He"
        ],
        "published": "2022",
        "summary": "Conventional autoregressive left-to-right (L2R) sequence generation faces two issues during decoding: limited to unidirectional target sequence modeling, and constrained on strong local dependencies.To address the aforementioned problem, we propose P3LM, a probabilistically permuted prophet language model, which strengthens the modeling of bidirectional information and long token dependencies for sequence generation.Specifically, P3LM learns to generate tokens in permuted order upon an order-aware transformer decoder, as well as to generate the corresponding future N tokens with a multi-stream attention mechanism.Extensive experiments are conducted on the GLGE benchmark, which includes four datasets for summarization, two for question generation, one for conversational question answering, and one for dialog response generation, where P3LM achieves state-of-the-art results compared with strong publicly available generative pre-training methods.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.496.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Holistic Sentence Embeddings for Better Out-of-Distribution Detection",
        "authors": [
            "Sishuo Chen",
            "Xiaohan Bi",
            "Rundong Gao",
            "Xu Sun"
        ],
        "published": "2022",
        "summary": "Detecting out-of-distribution (OOD) instances is significant for the safe deployment of NLP models. Among recent textual OOD detection works based on pretrained language models (PLMs), distance-based methods have shown superior performance. However, they estimate sample distance scores in the last-layer CLS embedding space and thus do not make full use of linguistic information underlying in PLMs. To address the issue, we propose to boost OOD detection by deriving more holistic sentence embeddings. On the basis of the observations that token averaging and layer combination contribute to improving OOD detection, we propose a simple embedding approach named Avg-Avg, which averages all token representations from each intermediate layer as the sentence embedding and significantly surpasses the state-of-the-art on a comprehensive suite of benchmarks by a 9.33% FAR95 margin. Furthermore, our analysis demonstrates that it indeed helps preserve general linguistic knowledge in fine-tuned PLMs and substantially benefits detecting background shifts. The simple yet effective embedding method can be applied to fine-tuned PLMs with negligible extra costs, providing a free gain in OOD detection. Our code is available at https://github.com/lancopku/Avg-Avg.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.497.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "EntityCS: Improving Zero-Shot Cross-lingual Transfer with Entity-Centric Code Switching",
        "authors": [
            "Chenxi Whitehouse",
            "Fenia Christopoulou",
            "Ignacio Iacobacci"
        ],
        "published": "2022",
        "summary": "Accurate alignment between languages is fundamental for improving cross-lingual pre-trained language models (XLMs). Motivated by the natural phenomenon of code-switching (CS) in multilingual speakers, CS has been used as an effective data augmentation method that offers language alignment at word- or phrase-level, in contrast to sentence-level via parallel instances. Existing approaches either use dictionaries or parallel sentences with word-alignment to generate CS data by randomly switching words in a sentence. However, such methods can be suboptimal as dictionaries disregard semantics, and syntax might become invalid after random word switching. In this work, we propose EntityCS, a method that focuses on Entity-level Code-Switching to capture fine-grained cross-lingual semantics without corrupting syntax. We use Wikidata and the English Wikipedia to construct an entity-centric CS corpus by switching entities to their counterparts in other languages. We further propose entity-oriented masking strategies during intermediate model training on the EntityCS corpus for improving entity prediction. Evaluation of the trained models on four entity-centric downstream tasks shows consistent improvements over the baseline with a notable increase of 10% in Fact Retrieval. We release the corpus and models to assist research on code-switching and enriching XLMs with external knowledge.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.499.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "A Simple and Strong Baseline for End-to-End Neural RST-style Discourse Parsing",
        "authors": [
            "Naoki Kobayashi",
            "Tsutomu Hirao",
            "Hidetaka Kamigaito",
            "Manabu Okumura",
            "Masaaki Nagata"
        ],
        "published": "2022",
        "summary": "To promote and further develop RST-style discourse parsing models, we need a strong baseline that can be regarded as a reference for reporting reliable experimental results. This paper explores a strong baseline by integrating existing simple parsing strategies, top-down and bottom-up, with various transformer-based pre-trained language models.The experimental results obtained from two benchmark datasets demonstrate that the parsing performance strongly relies on the pre-trained language models rather than the parsing strategies.In particular, the bottom-up parser achieves large performance gains compared to the current best parser when employing DeBERTa.We further reveal that language models with a span-masking scheme especially boost the parsing performance through our analysis within intra- and multi-sentential parsing, and nuclearity prediction.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.501.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Probing for Constituency Structure in Neural Language Models",
        "authors": [
            "David Arps",
            "Younes Samih",
            "Laura Kallmeyer",
            "Hassan Sajjad"
        ],
        "published": "2022",
        "summary": "In this paper, we investigate to which extent contextual neural language models (LMs) implicitly learn syntactic structure. More concretely, we focus on constituent structure as represented in the Penn Treebank (PTB). Using standard probing techniques based on diagnostic classifiers, we assess the accuracy of representing constituents of different categories within the neuron activations of a LM such as RoBERTa. In order to make sure that our probe focuses on syntactic knowledge and not on implicit semantic generalizations, we also experiment on a PTB version that is obtained by randomly replacing constituents with each other while keeping syntactic structure, i.e., a semantically ill-formed but syntactically well-formed version of the PTB. We find that 4 pretrained transfomer LMs obtain high performance on our probing tasks even on manipulated data, suggesting that semantic and syntactic knowledge in their representations can be separated and that constituency information is in fact learned by the LM. Moreover, we show that a complete constituency tree can be linearly separated from LM representations.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.502.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "PaCo: Preconditions Attributed to Commonsense Knowledge",
        "authors": [
            "Ehsan Qasemi",
            "Filip Ilievski",
            "Muhao Chen",
            "Pedro Szekely"
        ],
        "published": "2022",
        "summary": "Humans can seamlessly reason with circumstantial preconditions of commonsense knowledge. We understand that a glass is used for drinking water, unless the glass is broken or the water is toxic. Despite state-of-the-art (SOTA) language models’ (LMs) impressive performance on inferring commonsense knowledge, it is unclear whether they understand the circumstantial preconditions. To address this gap, we propose a novel challenge of reasoning with circumstantial preconditions. We collect a dataset, called PaCo, consisting of 12.4 thousand preconditions of commonsense statements expressed in natural language. Based on this dataset, we create three canonical evaluation tasks and use them to examine the capability of existing LMs to understand situational preconditions. Our results reveal a 10-30% gap between machine and human performance on our tasks, which shows that reasoning with preconditions is an open challenge.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.505.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Improving Few-Shot Domain Transfer for Named Entity Disambiguation with Pattern Exploitation",
        "authors": [
            "Philip Blair",
            "Kfir Bar"
        ],
        "published": "2022",
        "summary": "Named entity disambiguation (NED) is a critical subtask of entity linking, which seeks to connect knowledge base entities with textual mentions of those entities. Naturally, the performance of a model depends on the domain it was trained on; thus, reducing the amount of data required to train models is advantageous. In this work, we leverage recent research on pattern exploitation for NED and explore whether it can reduce the amount of data required for domain adaptation by reformulating the disambiguation task as a masked language modeling problem. Using ADAPET (Tam et al., 2021), which implements a new approach for few-shot learning using fine-tuned transformer-based language models, we produce an NED model which yields, without any sacrifice of in-domain accuracy, a 7% improvement in zero-shot cross-domain performance as evaluated on NEDMed, a new NED dataset of mental health news which we release with this work.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.506.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Capturing Topic Framing via Masked Language Modeling",
        "authors": [
            "Xiaobo Guo",
            "Weicheng Ma",
            "Soroush Vosoughi"
        ],
        "published": "2022",
        "summary": "Differential framing of issues can lead to divergent world views on important issues. This is especially true in domains where the information presented can reach a large audience, such as traditional and social media. Scalable and reliable measurement of such differential framing is an important first step in addressing them. In this work, based on the intuition that framing affects the tone and word choices in written language, we propose a framework for modeling the differential framing of issues through masked token prediction via large-scale fine-tuned language models (LMs). Specifically, we explore three key factors for our framework: 1) prompt generation methods for the masked token prediction; 2) methods for normalizing the output of fine-tuned LMs; 3) robustness to the choice of pre-trained LMs used for fine-tuning. Through experiments on a dataset of articles from traditional media outlets covering five diverse and politically polarized topics, we show that our framework can capture differential framing of these topics with high reliability.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.507.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "WANLI: Worker and AI Collaboration for Natural Language Inference Dataset Creation",
        "authors": [
            "Alisa Liu",
            "Swabha Swayamdipta",
            "Noah A. Smith",
            "Yejin Choi"
        ],
        "published": "2022",
        "summary": "A recurring challenge of crowdsourcing NLP datasets at scale is that human writers often rely on repetitive patterns when crafting examples, leading to a lack of linguistic diversity. We introduce a novel approach for dataset creation based on worker and AI collaboration, which brings together the generative strength of language models and the evaluative strength of humans. Starting with an existing dataset, MultiNLI for natural language inference (NLI), our approach uses dataset cartography to automatically identify examples that demonstrate challenging reasoning patterns, and instructs GPT-3 to compose new examples with similar patterns. Machine generated examples are then automatically filtered, and finally revised and labeled by human crowdworkers. The resulting dataset, WANLI, consists of 107,885 NLI examples and presents unique empirical strengths over existing NLI datasets. Remarkably, training a model on WANLI improves performance on eight out-of-domain test sets we consider, including by 11% on HANS and 9% on Adversarial NLI, compared to training on the 4x larger MultiNLI. Moreover, it continues to be more effective than MultiNLI augmented with other NLI datasets. Our results demonstrate the promise of leveraging natural language generation techniques and re-imagining the role of humans in the dataset creation process.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.508.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Sequentially Controlled Text Generation",
        "authors": [
            "Alexander Spangher",
            "Yao Ming",
            "Xinyu Hua",
            "Nanyun Peng"
        ],
        "published": "2022",
        "summary": "While GPT-2 generates sentences that are remarkably human-like, longer documents can ramble and do not follow human-like writing structure. We study the problem of imposing structure on long-range text. We propose a novel controlled text generation task, sequentially controlled text generation, and identify a dataset, NewsDiscourse as a starting point for this task. We develop a sequential controlled text generation pipeline with generation and editing. We test different degrees of structural awareness and show that, in general, more structural awareness results in higher control- accuracy, grammaticality, coherency and topicality, approaching human-level writing performance.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.509.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Revisiting the Roles of “Text” in Text Games",
        "authors": [
            "Yi Gu",
            "Shunyu Yao",
            "Chuang Gan",
            "Josh Tenenbaum",
            "Mo Yu"
        ],
        "published": "2022",
        "summary": "Text games present opportunities for natural language understanding (NLU) methods to tackle reinforcement learning (RL) challenges. However, recent work has questioned the necessity of NLU by showing random text hashes could perform decently. In this paper, we pursue a fine-grained investigation into the roles of text in the face of different RL challenges, and reconcile that semantic and non-semantic language representations could be complementary rather than contrasting. Concretely, we propose a simple scheme to extract relevant contextual information into an approximate state hash as extra input for an RNN-based text agent. Such a lightweight plug-in achieves competitive performance with state-of-the-art text agents using advanced NLU techniques such as knowledge graph and passage retrieval, suggesting non-NLU methods might suffice to tackle the challenge of partial observability. However, if we remove RNN encoders and use approximate or even ground-truth state hash alone, the model performs miserably, which confirms the importance of semantic function approximation to tackle the challenge of combinatorially large observation and action spaces. Our findings and analysis provide new insights for designing better text game task setups and agents.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.510.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "FPT: Improving Prompt Tuning Efficiency via Progressive Training",
        "authors": [
            "Yufei Huang",
            "Yujia Qin",
            "Huadong Wang",
            "Yichun Yin",
            "Maosong Sun",
            "Zhiyuan Liu",
            "Qun Liu"
        ],
        "published": "2022",
        "summary": "Recently, prompt tuning (PT) has gained increasing attention as a parameter-efficient way of tuning pre-trained language models (PLMs). Despite extensively reducing the number of tunable parameters and achieving satisfying performance, PT is training-inefficient due to its slow convergence. To improve PT’s training efficiency, we first make some novel observations about the prompt transferability of “partial PLMs”, which are defined by compressing a PLM in depth or width. We observe that the soft prompts learned by different partial PLMs of various sizes are similar in the parameter space, implying that these soft prompts could potentially be transferred among partial PLMs. Inspired by these observations, we propose Fast Prompt Tuning (FPT), which starts by conducting PT using a small-scale partial PLM, and then progressively expands its depth and width until the full-model size. After each expansion, we recycle the previously learned soft prompts as initialization for the enlarged partial PLM and then proceed PT. We demonstrate the feasibility of FPT on 5 tasks and show that FPT could save over 30% training computations while achieving comparable performance. The codes are publicly available at https://github.com/thunlp/FastPromptTuning.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.511.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Prompt-learning for Fine-grained Entity Typing",
        "authors": [
            "Ning Ding",
            "Yulin Chen",
            "Xu Han",
            "Guangwei Xu",
            "Xiaobin Wang",
            "Pengjun Xie",
            "Haitao Zheng",
            "Zhiyuan Liu",
            "Juanzi Li",
            "Hong-Gee Kim"
        ],
        "published": "2022",
        "summary": "As an effective approach to adapting pre-trained language models (PLMs) for specific tasks, prompt-learning has recently attracted much attention from researchers. By using cloze-style language prompts to stimulate the versatile knowledge of PLMs, prompt-learning can achieve promising results on a series of NLP tasks, such as natural language inference, sentiment classification, and knowledge probing. In this work, we investigate the application of prompt-learning on fine-grained entity typing in fully supervised, few-shot, and zero-shot scenarios. We first develop a simple and effective prompt-learning pipeline by constructing entity-oriented verbalizers and templates and conducting masked language modeling. Further, to tackle the zero-shot regime, we propose a self-supervised strategy that carries out distribution-level optimization in prompt-learning to automatically summarize the information of entity types. Extensive experiments on four fine-grained entity typing benchmarks under fully supervised, few-shot, and zero-shot settings show the effectiveness of the prompt-learning paradigm and further make a powerful alternative to vanilla fine-tuning.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.512.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "What do Large Language Models Learn beyond Language?",
        "authors": [
            "Avinash Madasu",
            "Shashank Srivastava"
        ],
        "published": "2022",
        "summary": "Large language models (LMs) have rapidly become a mainstay in Natural Language Processing. These models are known to acquire rich linguistic knowledge from training on large amounts of text. In this paper, we investigate if pre-training on text also confers these models with helpful ‘inductive biases’ for non-linguistic reasoning. On a set of 19 diverse non-linguistic tasks involving quantitative computations, recognizing regular expressions and reasoning over strings. We find that pretrained models significantly outperform comparable non-pretrained neural models. This remains true also in experiments with training non-pretrained models with fewer parameters to account for model regularization effects. We further explore the effect of text domain on LMs by pretraining models from text from different domains and provenances. Our experiments surprisingly reveal that the positive effects of pre-training persist even when pretraining on multi-lingual text or computer code, and even for text generated from synthetic languages. Our findings suggest a hithertho unexplored deep connection between pre-training and inductive learning abilities of language models",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.516.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Efficient (Soft) Q-Learning for Text Generation with Limited Good Data",
        "authors": [
            "Han Guo",
            "Bowen Tan",
            "Zhengzhong Liu",
            "Eric Xing",
            "Zhiting Hu"
        ],
        "published": "2022",
        "summary": "Maximum likelihood estimation (MLE) is the predominant algorithm for training text generation models. This paradigm relies on direct supervision examples, which is not applicable to many emerging applications, such as generating adversarial attacks or generating prompts to control language models. Reinforcement learning (RL) on the other hand offers a more flexible solution by allowing users to plug in arbitrary task metrics as reward. Yet previous RL algorithms for text generation, such as policy gradient (on-policy RL) and Q-learning (off-policy RL), are often notoriously inefficient or unstable to train due to the large sequence space and the sparse reward received only at the end of sequences. In this paper, we introduce a new RL formulation for text generation from the soft Q-learning (SQL) perspective. It enables us to draw from the latest RL advances, such as path consistency learning, to combine the best of on-/off-policy updates, and learn effectively from sparse reward. We apply the approach to a wide range of novel text generation tasks, including learning from noisy/negative examples, adversarial attacks, and prompt generation. Experiments show our approach consistently outperforms both task-specialized algorithms and the previous RL methods.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.518.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Lexi: Self-Supervised Learning of the UI Language",
        "authors": [
            "Pratyay Banerjee",
            "Shweti Mahajan",
            "Kushal Arora",
            "Chitta Baral",
            "Oriana Riva"
        ],
        "published": "2022",
        "summary": "Humans can learn to operate the user interface (UI) of an application by reading an instruction manual or how-to guide. Along with text, these resources include visual content such as UI screenshots and images of application icons referenced in the text. We explore how to leverage this data to learn generic visio-linguistic representations of UI screens and their components. These representations are useful in many real applications, such as accessibility, voice navigation, and task automation. Prior UI representation models rely on UI metadata (UI trees and accessibility labels), which is often missing, incompletely defined, or not accessible. We avoid such a dependency, and propose Lexi, a pre-trained vision and language model designed to handle the unique features of UI screens, including their text richness and context sensitivity. To train Lexi we curate the UICaption dataset consisting of 114k UI images paired with descriptions of their functionality. We evaluate Lexi on four tasks: UI action entailment, instruction-based UI image retrieval, grounding referring expressions, and UI entity recognition.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.519.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Inferring the Reader: Guiding Automated Story Generation with Commonsense Reasoning",
        "authors": [
            "Xiangyu Peng",
            "Siyan Li",
            "Sarah Wiegreffe",
            "Mark Riedl"
        ],
        "published": "2022",
        "summary": "Transformer-based language model approaches to automated story generation currently provide state-of-the-art results. However, they still suffer from plot incoherence when generatingnarratives over time, and critically lack basiccommonsense reasoning. Furthermore, existing methods generally focus only on single-character stories, or fail to track charactersat all. To improve the coherence of generated narratives and to expand the scope ofcharacter-centric narrative generation, we introduce Commonsense-inference Augmentedneural StoryTelling (CAST), a framework forintroducing commonsense reasoning into thegeneration process with the option to model theinteraction between multiple characters. Wefind that our CAST method produces significantly more coherent, on-topic, enjoyable andfluent stories than existing models in both thesingle-character and two-character settings inthree storytelling domains.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.520.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "CORT: A New Baseline for Comparative Opinion Classification by Dual Prompts",
        "authors": [
            "Yequan Wang",
            "Hengran Zhang",
            "Aixin Sun",
            "Xuying Meng"
        ],
        "published": "2022",
        "summary": "Comparative opinion is a common linguistic phenomenon. The opinion is expressed by comparing multiple targets on a shared aspect, e.g., “camera A is better than camera B in picture quality”. Among the various subtasks in opinion mining, comparative opinion classification is relatively less studied. Current solutions use rules or classifiers to identify opinions, i.e., better, worse, or same, through feature engineering. Because the features are directly derived from the input sentence, these solutions are sensitive to the order of the targets mentioned in the sentence. For example, “camera A is better than camera B” means the same as “camera B is worse than camera A”; but the features of these two sentences are completely different. In this paper, we approach comparative opinion classification through prompt learning, taking the advantage of embedded knowledge in pre-trained language model. We design a twin framework with dual prompts, named CORT. This extremely simple model delivers state-of-the-art and robust performance on all benchmark datasets for comparative opinion classification. We believe CORT well serves as a new baseline for comparative opinion classification.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.524.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "APEACH: Attacking Pejorative Expressions with Analysis on Crowd-Generated Hate Speech Evaluation Datasets",
        "authors": [
            "Kichang Yang",
            "Wonjun Jang",
            "Won Ik Cho"
        ],
        "published": "2022",
        "summary": "In hate speech detection, developing training and evaluation datasets across various domains is the critical issue. Whereas, major approaches crawl social media texts and hire crowd-workers to annotate the data. Following this convention often restricts the scope of pejorative expressions to a single domain lacking generalization. Sometimes domain overlap between training corpus and evaluation set overestimate the prediction performance when pretraining language models on low-data language. To alleviate these problems in Korean, we propose APEACH that asks unspecified users to generate hate speech examples followed by minimal post-labeling. We find that APEACH can collect useful datasets that are less sensitive to the lexical overlaps between the pretraining corpus and the evaluation set, thereby properly measuring the model performance.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.525.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Guiding Neural Story Generation with Reader Models",
        "authors": [
            "Xiangyu Peng",
            "Kaige Xie",
            "Amal Alabdulkarim",
            "Harshith Kayam",
            "Samihan Dani",
            "Mark Riedl"
        ],
        "published": "2022",
        "summary": "Automated storytelling has long captured the attention of researchers for the ubiquity of narratives in everyday life. However, it is challenging to maintain coherence and stay on-topictoward a specific ending when generating narratives with neural language models. In this paper, we introduce Story generation with ReaderModels (StoRM), a framework in which areader model is used to reason about the storyshould progress. A reader model infers whata human reader believes about the concepts,entities, and relations about the fictional storyworld. We show how an explicit reader modelrepresented as a knowledge graph affords the storycoherence and provides controllability in theform of achieving a given story world stategoal. Experiments show that our model produces significantly more coherent and on-topicstories, outperforming baselines in dimensionsincluding plot plausibility and staying on topic",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.526.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Reason first, then respond: Modular Generation for Knowledge-infused Dialogue",
        "authors": [
            "Leonard Adolphs",
            "Kurt Shuster",
            "Jack Urbanek",
            "Arthur Szlam",
            "Jason Weston"
        ],
        "published": "2022",
        "summary": "Large language models can produce fluent dialogue but often hallucinate factual inaccuracies. While retrieval-augmented models help alleviate this issue, they still face a difficult challenge of both reasoning to provide correct knowledge and generating conversation simultaneously. In this work, we propose a modular model, Knowledge to Response (K2R), for incorporating knowledge into conversational agents, which breaks down this problem into two easier steps. K2R first generates a knowledge sequence, given a dialogue context, as an intermediate step. After this “reasoning step”, the model then attends to its own generated knowledge sequence, as well as the dialogue context, to produce a final response. In detailed experiments, we find that such a model hallucinates less in knowledge-grounded dialogue tasks, and has advantages in terms of interpretability and modularity. In particular, it can be used to fuse QA and dialogue systems together to enable dialogue agents to give knowledgeable answers, or QA models to give conversational responses in a zero-shot setting.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.527.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "SlovakBERT: Slovak Masked Language Model",
        "authors": [
            "Matúš Pikuliak",
            "Štefan Grivalský",
            "Martin Konôpka",
            "Miroslav Blšták",
            "Martin Tamajka",
            "Viktor Bachratý",
            "Marian Simko",
            "Pavol Balážik",
            "Michal Trnka",
            "Filip Uhlárik"
        ],
        "published": "2022",
        "summary": "We introduce a new Slovak masked language model called SlovakBERT. This is to our best knowledge the first paper discussing Slovak transformers-based language models. We evaluate our model on several NLP tasks and achieve state-of-the-art results. This evaluation is likewise the first attempt to establish a benchmark for Slovak language models. We publish the masked language model, as well as the fine-tuned models for part-of-speech tagging, sentiment analysis and semantic textual similarity.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.530.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Logical Fallacy Detection",
        "authors": [
            "Zhijing Jin",
            "Abhinav Lalwani",
            "Tejas Vaidhya",
            "Xiaoyu Shen",
            "Yiwen Ding",
            "Zhiheng Lyu",
            "Mrinmaya Sachan",
            "Rada Mihalcea",
            "Bernhard Schoelkopf"
        ],
        "published": "2022",
        "summary": "Reasoning is central to human intelligence. However, fallacious arguments are common, and some exacerbate problems such as spreading misinformation about climate change. In this paper, we propose the task of logical fallacy detection, and provide a new dataset (Logic) of logical fallacies generally found in text, together with an additional challenge set for detecting logical fallacies in climate change claims (LogicClimate). Detecting logical fallacies is a hard problem as the model must understand the underlying logical structure of the argument. We find that existing pretrained large language models perform poorly on this task. In contrast, we show that a simple structure-aware classifier outperforms the best language model by 5.46% F1 scores on Logic and 4.51% on LogicClimate. We encourage future work to explore this task since (a) it can serve as a new reasoning challenge for language models, and (b) it can have potential applications in tackling the spread of misinformation. Our dataset and code are available at https://github.com/causalNLP/logical-fallacy",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.532.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Time-aware Prompting for Text Generation",
        "authors": [
            "Shuyang Cao",
            "Lu Wang"
        ],
        "published": "2022",
        "summary": "In this paper, we study the effects of incorporating timestamps, such as document creation dates, into generation systems. Two types of time-aware prompts are investigated: (1) textual prompts that encode document timestamps in natural language sentences; and (2) linear prompts that convert timestamps into continuous vectors. To explore extrapolation to future data points, we further introduce a new data-to-text generation dataset, TempWikiBio, containing more than 4 millions of chronologically ordered revisions of biographical articles from English Wikipedia, each paired with structured personal profiles.Through data-to-text generation on TempWikiBio, text-to-text generation on the content transfer dataset, and summarization on XSum,we show that linear prompts on encoder and textual prompts improve the generation quality on all datasets.Despite having less performance drop when testing on data drawn from a later time, linear prompts focus more on non-temporal information and are less sensitive to the given timestamps, according to human evaluations and sensitivity analyses.Meanwhile, textual prompts establish the association between the given timestamps and the output dates, yielding more factual temporal information in the output.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.535.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Uncertainty Quantification with Pre-trained Language Models: A Large-Scale Empirical Analysis",
        "authors": [
            "Yuxin Xiao",
            "Paul Pu Liang",
            "Umang Bhatt",
            "Willie Neiswanger",
            "Ruslan Salakhutdinov",
            "Louis-Philippe Morency"
        ],
        "published": "2022",
        "summary": "Pre-trained language models (PLMs) have gained increasing popularity due to their compelling prediction performance in diverse natural language processing (NLP) tasks. When formulating a PLM-based prediction pipeline for NLP tasks, it is also crucial for the pipeline to minimize the calibration error, especially in safety-critical applications. That is, the pipeline should reliably indicate when we can trust its predictions. In particular, there are various considerations behind the pipeline: (1) the choice and (2) the size of PLM, (3) the choice of uncertainty quantifier, (4) the choice of fine-tuning loss, and many more. Although prior work has looked into some of these considerations, they usually draw conclusions based on a limited scope of empirical studies. There still lacks a holistic analysis on how to compose a well-calibrated PLM-based prediction pipeline. To fill this void, we compare a wide range of popular options for each consideration based on three prevalent NLP classification tasks and the setting of domain shift. In response, we recommend the following: (1) use ELECTRA for PLM encoding, (2) use larger PLMs if possible, (3) use Temp Scaling as the uncertainty quantifier, and (4) use Focal Loss for fine-tuning.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.538.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Dependency Parsing via Sequence Generation",
        "authors": [
            "Boda Lin",
            "Zijun Yao",
            "Jiaxin Shi",
            "Shulin Cao",
            "Binghao Tang",
            "Si Li",
            "Yong Luo",
            "Juanzi Li",
            "Lei Hou"
        ],
        "published": "2022",
        "summary": "Dependency parsing aims to extract syntactic dependency structure or semantic dependency structure for sentences.Existing methods for dependency parsing include transition-based method, graph-based method and sequence-to-sequence method.These methods obtain excellent performance and we notice them belong to labeling method.Therefore, it may be very valuable and interesting to explore the possibility of using generative method to implement dependency parsing.In this paper, we propose to achieve Dependency Parsing (DP) via Sequence Generation (SG) by utilizing only the pre-trained language model without any auxiliary structures.We first explore different serialization designing strategies for converting parsing structures into sequences.Then we design dependency units and concatenate these units into the sequence for DPSG.We verify the DPSG is capable of parsing on widely used DP benchmarks, i.e., PTB, UD2.2, SDP15 and SemEval16.In addition, we also investigate the astonishing low-resource applicability of DPSG, which includes unsupervised cross-domain conducted on CODT and few-shot cross-task conducted on SDP15.Our research demonstrates that sequence generation is one of the effective methods to achieve dependency parsing.Our codes are available now.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.543.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Analyzing the Limits of Self-Supervision in Handling Bias in Language",
        "authors": [
            "Lisa Bauer",
            "Karthik Gopalakrishnan",
            "Spandana Gella",
            "Yang Liu",
            "Mohit Bansal",
            "Dilek Hakkani-Tur"
        ],
        "published": "2022",
        "summary": "Prompting inputs with natural language task descriptions has emerged as a popular mechanism to elicit reasonably accurate outputs from large-scale generative language models with little to no in-context supervision. This also helps gain insight into how well language models capture the semantics of a wide range of downstream tasks purely from self-supervised pre-training on massive corpora of unlabeled text. Such models have naturally also been exposed to a lot of undesirable content like racist and sexist language and there is only some work on awareness of models along these dimensions. In this paper, we define and comprehensively evaluate how well such language models capture the semantics of four tasks for bias: diagnosis, identification, extraction and rephrasing. We define three broad classes of task descriptions for these tasks: statement, question, and completion, with numerous lexical variants within each class. We study the efficacy of prompting for each task using these classes and the null task description across several decoding methods and few-shot examples. Our analyses indicate that language models are capable of performing these tasks to widely varying degrees across different bias dimensions, such as gender and political affiliation. We believe our work is an important step towards unbiased language models by quantifying the limits of current self-supervision objectives at accomplishing such sociologically challenging tasks.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.545.pdf",
        "source": "emnlp2022"
    },
    {
        "title": "Grounded Keys-to-Text Generation: Towards Factual Open-Ended Generation",
        "authors": [
            "Faeze Brahman",
            "Baolin Peng",
            "Michel Galley",
            "Sudha Rao",
            "Bill Dolan",
            "Snigdha Chaturvedi",
            "Jianfeng Gao"
        ],
        "published": "2022",
        "summary": "Large pre-trained language models have recently enabled open-ended generation frameworks (e.g., prompt-to-text NLG) to tackle a variety of tasks going beyond the traditional data-to-text generation. While this framework is more general, it is under-specified and often leads to a lack of controllability restricting their real-world usage. We propose a new grounded keys-to-text generation task: the task is to generate a factual description about an entity given a set of guiding keys, and grounding passages. To address this task, we introduce a new dataset, called EntDeGen. Inspired by recent QA-based evaluation measures, we propose an automatic metric, MAFE, for factual correctness of generated descriptions. Our EntDescriptor model is equipped with strong rankers to fetch helpful passages and generate entity descriptions. Experimental result shows a good correlation (60.14) between our proposed metric and human judgments of factuality. Our rankers significantly improved the factual correctness of generated descriptions (15.95% and 34.51% relative gains in recall and precision). Finally, our ablation study highlights the benefit of combining keys and groundings.",
        "pdf_link": "https://aclanthology.org/2022.findings-emnlp.547.pdf",
        "source": "emnlp2022"
    }
]