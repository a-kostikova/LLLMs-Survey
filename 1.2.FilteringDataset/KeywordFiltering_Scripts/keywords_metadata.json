{
    "language models": {
        "iteration": 1,
        "tuple": [
            83.47825239539519,
            65,
            0.5
        ],
        "included": true
    },
    "large language models": {
        "iteration": 1,
        "tuple": [
            28.32527429981298,
            23,
            0.5
        ],
        "included": true
    },
    "language model": {
        "iteration": 3,
        "tuple": [
            23.601704563151202,
            19,
            0.5
        ],
        "included": true
    },
    "large language model": {
        "iteration": 6,
        "tuple": [
            21.520553269756043,
            17,
            0.5
        ],
        "included": true
    },
    "llms": {
        "iteration": 10,
        "tuple": [
            20.234053514660076,
            16,
            0.5
        ],
        "included": true
    },
    "in context learning": {
        "iteration": 11,
        "tuple": [
            22.83674077600947,
            18,
            0.5
        ],
        "included": true
    },
    "prompting": {
        "iteration": 13,
        "tuple": [
            20.236413223866123,
            16,
            0.5
        ],
        "included": true
    },
    "hallucination": {
        "iteration": 14,
        "tuple": [
            20.32946208989764,
            21,
            2
        ],
        "included": true
    },
    "hallucinations": {
        "iteration": 14,
        "tuple": [
            20.32946208989764,
            21,
            2
        ],
        "included": true
    },
    "multimodal large language models": {
        "iteration": 18,
        "tuple": [
            22.982067306401444,
            18,
            0.5
        ],
        "included": true
    },
    "instruction tuning": {
        "iteration": 21,
        "tuple": [
            20.6040236856865,
            18,
            1
        ],
        "included": true
    },
    "retrieval augmented generation": {
        "iteration": 23,
        "tuple": [
            20.608759158498803,
            18,
            1
        ],
        "included": true
    },
    "direct preference optimization": {
        "iteration": 25,
        "tuple": [
            20.284195240308634,
            16,
            0.5
        ],
        "included": true
    },
    "augmented generation": {
        "iteration": 26,
        "tuple": [
            20.2773369902781,
            16,
            0.5
        ],
        "included": true
    },
    "mathematical reasoning": {
        "iteration": 28,
        "tuple": [
            21.743044828688838,
            17,
            0.5
        ],
        "included": true
    },
    "chain of thought": {
        "iteration": 32,
        "tuple": [
            21.898386810549155,
            19,
            1
        ],
        "included": true
    },
    "cot": {
        "iteration": 32,
        "tuple": [
            21.898386810549155,
            19,
            1
        ],
        "included": true
    },
    "agent": {
        "iteration": 36,
        "tuple": [
            20.38273047430309,
            21,
            2
        ],
        "included": true
    },
    "visual reasoning": {
        "iteration": 41,
        "tuple": [
            20.32325654108227,
            16,
            0.5
        ],
        "included": true
    },
    "preference optimization": {
        "iteration": 43,
        "tuple": [
            20.566003694320067,
            18,
            1
        ],
        "included": true
    },
    "instruction tuned": {
        "iteration": 46,
        "tuple": [
            20.259221972050835,
            16,
            0.5
        ],
        "included": true
    },
    "jailbreak": {
        "iteration": 50,
        "tuple": [
            21.516942372029007,
            17,
            0.5
        ],
        "included": true
    },
    "jailbreaks": {
        "iteration": 50,
        "tuple": [
            21.516942372029007,
            17,
            0.5
        ],
        "included": true
    },
    "small language models": {
        "iteration": 50,
        "tuple": [
            20.424198533624494,
            18,
            1
        ],
        "included": true
    },
    "large language": {
        "iteration": 51,
        "tuple": [
            20.192481685981075,
            16,
            0.5
        ],
        "included": true
    },
    "speculative decoding": {
        "iteration": 53,
        "tuple": [
            20.184204818348977,
            16,
            0.5
        ],
        "included": true
    },
    "self consistency": {
        "iteration": 57,
        "tuple": [
            20.409786503200188,
            18,
            1
        ],
        "included": true
    },
    "knowledge editing": {
        "iteration": 58,
        "tuple": [
            20.397071319448248,
            18,
            1
        ],
        "included": true
    },
    "chain of thought reasoning": {
        "iteration": 65,
        "tuple": [
            20.228839653584558,
            16,
            0.5
        ],
        "included": true
    },
    "jailbreak attacks": {
        "iteration": 66,
        "tuple": [
            20.21822098874458,
            16,
            0.5
        ],
        "included": true
    },
    "multi agent framework": {
        "iteration": 78,
        "tuple": [
            20.252935720646985,
            16,
            0.5
        ],
        "included": true
    },
    "llm": {
        "iteration": 79,
        "tuple": [
            20.26827371212873,
            16,
            0.5
        ],
        "included": true
    },
    "multimodal large language model": {
        "iteration": 84,
        "tuple": [
            20.288024507355072,
            16,
            0.5
        ],
        "included": true
    },
    "theory of mind": {
        "iteration": 85,
        "tuple": [
            20.53831986036129,
            18,
            1
        ],
        "included": true
    },
    "complex reasoning": {
        "iteration": 87,
        "tuple": [
            20.286008116573992,
            16,
            0.5
        ],
        "included": true
    },
    "chain of thought prompting": {
        "iteration": 88,
        "tuple": [
            20.303201558529732,
            16,
            0.5
        ],
        "included": true
    },
    "generative large language models": {
        "iteration": 95,
        "tuple": [
            20.329439224940845,
            16,
            0.5
        ],
        "included": true
    },
    "commonsense reasoning": {
        "iteration": 101,
        "tuple": [
            22.982444463217043,
            23,
            2
        ],
        "included": true
    },
    "preference alignment": {
        "iteration": 102,
        "tuple": [
            20.352297126512443,
            16,
            0.5
        ],
        "included": true
    },
    "prompt engineering": {
        "iteration": 104,
        "tuple": [
            20.36396426807076,
            16,
            0.5
        ],
        "included": true
    },
    "safety alignment": {
        "iteration": 105,
        "tuple": [
            20.364920251273897,
            16,
            0.5
        ],
        "included": true
    },
    "lora": {
        "iteration": 110,
        "tuple": [
            20.381712398149443,
            16,
            0.5
        ],
        "included": true
    },
    "low rank adaptation": {
        "iteration": 110,
        "tuple": [
            20.381712398149443,
            16,
            0.5
        ],
        "included": true
    },
    "cot prompting": {
        "iteration": 111,
        "tuple": [
            20.38395305474028,
            16,
            0.5
        ],
        "included": true
    },
    "model editing": {
        "iteration": 138,
        "tuple": [
            25.915692761972846,
            22,
            1
        ],
        "included": true
    },
    "mllms": {
        "iteration": 151,
        "tuple": [
            25.823771636575312,
            20,
            0.5
        ],
        "included": true
    },
    "temporal reasoning": {
        "iteration": 159,
        "tuple": [
            25.964701744725645,
            22,
            1
        ],
        "included": true
    },
    "hallucination detection": {
        "iteration": 164,
        "tuple": [
            27.237084911155172,
            23,
            1
        ],
        "included": true
    },
    "augmented large language models": {
        "iteration": 164,
        "tuple": [
            25.823667083380453,
            20,
            0.5
        ],
        "included": true
    },
    "dpo": {
        "iteration": 168,
        "tuple": [
            25.92916004352999,
            22,
            1
        ],
        "included": true
    },
    "math reasoning": {
        "iteration": 168,
        "tuple": [
            25.83634265456687,
            20,
            0.5
        ],
        "included": true
    },
    "contamination": {
        "iteration": 173,
        "tuple": [
            25.801103464692147,
            20,
            0.5
        ],
        "included": true
    },
    "long context": {
        "iteration": 177,
        "tuple": [
            25.797289835510124,
            20,
            0.5
        ],
        "included": true
    },
    "language agents": {
        "iteration": 185,
        "tuple": [
            25.87370481315613,
            22,
            1
        ],
        "included": true
    },
    "chat": {
        "iteration": 185,
        "tuple": [
            25.509708015656962,
            25,
            2
        ],
        "included": true
    },
    "preference learning": {
        "iteration": 185,
        "tuple": [
            25.509708015656962,
            25,
            2
        ],
        "included": true
    },
    "prompting strategies": {
        "iteration": 191,
        "tuple": [
            25.78441882785493,
            20,
            0.5
        ],
        "included": true
    },
    "benchmarking large language models": {
        "iteration": 200,
        "tuple": [
            25.795411899121596,
            20,
            0.5
        ],
        "included": true
    },
    "tool learning": {
        "iteration": 208,
        "tuple": [
            25.795845804023077,
            20,
            0.5
        ],
        "included": true
    },
    "prompting strategy": {
        "iteration": 209,
        "tuple": [
            25.88765423281378,
            22,
            1
        ],
        "included": true
    },
    "jailbreak attack": {
        "iteration": 213,
        "tuple": [
            25.78962994747336,
            20,
            0.5
        ],
        "included": true
    },
    "multi agent collaboration": {
        "iteration": 215,
        "tuple": [
            25.8769284826961,
            22,
            1
        ],
        "included": true
    },
    "self correction": {
        "iteration": 217,
        "tuple": [
            25.877682144652503,
            22,
            1
        ],
        "included": true
    },
    "gpt": {
        "iteration": 221,
        "tuple": [
            25.766773600012364,
            20,
            0.5
        ],
        "included": true
    },
    "data contamination": {
        "iteration": 234,
        "tuple": [
            25.873203801528323,
            22,
            1
        ],
        "included": true
    },
    "rag": {
        "iteration": 234,
        "tuple": [
            25.784406994519323,
            20,
            0.5
        ],
        "included": true
    },
    "code completion": {
        "iteration": 235,
        "tuple": [
            25.870005117299815,
            22,
            1
        ],
        "included": true
    },
    "language model alignment": {
        "iteration": 236,
        "tuple": [
            25.860424392468026,
            22,
            1
        ],
        "included": true
    },
    "judge": {
        "iteration": 238,
        "tuple": [
            25.823535756229596,
            20,
            0.5
        ],
        "included": true
    },
    "jailbreaking attacks": {
        "iteration": 247,
        "tuple": [
            25.063902847761135,
            19,
            0.5
        ],
        "included": true
    },
    "prompt injection attacks": {
        "iteration": 247,
        "tuple": [
            25.063902847761135,
            19,
            0.5
        ],
        "included": true
    },
    "self evaluation": {
        "iteration": 247,
        "tuple": [
            25.063902847761135,
            19,
            0.5
        ],
        "included": true
    },
    "self reflection": {
        "iteration": 247,
        "tuple": [
            25.063902847761135,
            19,
            0.5
        ],
        "included": true
    },
    "generated text detection": {
        "iteration": 266,
        "tuple": [
            25.002771566827533,
            18,
            0.5
        ],
        "included": true
    },
    "injection attacks": {
        "iteration": 266,
        "tuple": [
            25.002771566827533,
            18,
            0.5
        ],
        "included": true
    },
    "prompt optimization": {
        "iteration": 282,
        "tuple": [
            25.01245835359307,
            19,
            1
        ],
        "included": true
    },
    "api": {
        "iteration": 282,
        "tuple": [
            25.01245835359307,
            19,
            1
        ],
        "included": true
    },
    "speculative": {
        "iteration": 291,
        "tuple": [
            25.0311087800684,
            17,
            0.5
        ],
        "included": true
    },
    "language model agents": {
        "iteration": 291,
        "tuple": [
            25.0311087800684,
            17,
            0.5
        ],
        "included": true
    },
    "context window": {
        "iteration": 291,
        "tuple": [
            25.0311087800684,
            17,
            0.5
        ],
        "included": true
    },
    "evaluating large language models": {
        "iteration": 424,
        "tuple": [
            40.744571644054204,
            15,
            0.5
        ],
        "included": true
    },
    "text watermarking": {
        "iteration": 426,
        "tuple": [
            40.54372992464833,
            14,
            0.5
        ],
        "included": true
    },
    "function calling": {
        "iteration": 426,
        "tuple": [
            40.54372992464833,
            14,
            0.5
        ],
        "included": true
    },
    "llm agents": {
        "iteration": 426,
        "tuple": [
            40.54372992464833,
            14,
            0.5
        ],
        "included": true
    },
    "machine generated text detection": {
        "iteration": 426,
        "tuple": [
            40.54372992464833,
            14,
            0.5
        ],
        "included": true
    },
    "aligning large language models": {
        "iteration": 429,
        "tuple": [
            40.81542260694173,
            13,
            0.5
        ],
        "included": true
    },
    "large language model inference": {
        "iteration": 429,
        "tuple": [
            40.81542260694173,
            13,
            0.5
        ],
        "included": true
    },
    "tree of thoughts": {
        "iteration": 432,
        "tuple": [
            40.25108565856114,
            12,
            0.5
        ],
        "included": true
    },
    "multimodal llms": {
        "iteration": 432,
        "tuple": [
            40.25108565856114,
            12,
            0.5
        ],
        "included": true
    },
    "prompting techniques": {
        "iteration": 437,
        "tuple": [
            40.31777704270932,
            11,
            0.5
        ],
        "included": true
    }
}
