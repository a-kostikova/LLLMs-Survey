[
    {
        "name": "Reasoning",
        "prompt": "Does the text example highlight limitations of large language models in performing reasoning or inference tasks, such as multi-hop reasoning or deductive logic?"
    },
    {
        "name": "Generalization",
        "prompt": "Does the text example highlight limitations in a model's ability to understand context or generalize effectively across different domains and scenarios?"
    },
    {
        "name": "Knowledge Editing",
        "prompt": "Does the text discuss limitations in storing, encoding, or updating knowledge in large language models, including factual inaccuracies or difficulties in modifying learned information?"
    },
    {
        "name": "Hallucination",
        "prompt": "Does the text describe instances where language models generate factually incorrect information, describe non-existent content, or produce contextually unfaithful data?"
    },
    {
        "name": "Language and Cultural Limitations",
        "prompt": "Does the text example highlight limitations of large language models in handling multilingual tasks, language-specific or cross-cultural issues?"
    },
    {
        "name": "Bias and Fairness",
        "prompt": "Does the text address issues related to social biases or stereotyping within language models, including challenges in presence, amplification, and mitigation thereof?"
    },
    {
        "name": "Security Risks",
        "prompt": "Does this text example address the susceptibility of language models to adversarial attacks, including backdoor or jailbreak methods?"
    },
    {
        "name": "Multimodality",
        "prompt": "Does the text example address the struggles of large language models or multimodal models in integrating and reasoning across different modalities?"
    },
    {
        "name": "Long Context",
        "prompt": "Does the text example discuss challenges faced by large language models in handling long contexts or maintaining coherence over extended inputs?"
    },
    {
        "name": "Privacy Risks",
        "prompt": "Does the text example discuss privacy risks associated with language models, such as data leakage or memorization of sensitive information?"
    },
    {
        "name": "Computational Cost",
        "prompt": "Does the text example highlight the high computational cost or resource demands associated with using large language models?"
    },
    {
        "name": "Catastrophic Forgetting",
        "prompt": "Does the example discuss problems caused by models forgetting previously learned information during fine-tuning or continual learning?"
    },
    {
        "name": "Data Contamination",
        "prompt": "Does the text example discuss issues of training data containing test data, causing overestimation of model performance through memorization?"
    }
]