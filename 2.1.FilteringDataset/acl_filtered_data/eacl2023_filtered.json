[
    {
        "title": "Shironaam: Bengali News Headline Generation using Auxiliary Information",
        "authors": [
            "Abu Ubaida Akash",
            "Mir Tafseer Nayeem",
            "Faisal Tareque Shohan",
            "Tanvir Islam"
        ],
        "published": "2023",
        "summary": "Automatic headline generation systems have the potential to assist editors in finding interesting headlines to attract visitors or readers. However, the performance of headline generation systems remains challenging due to the unavailability of sufficient parallel data for low-resource languages like Bengali and the lack of ideal approaches to develop a system for headline generation using pre-trained language models, especially for long news articles. To address these challenges, we present Shironaam, a large-scale dataset in Bengali containing over 240K news article-headline pairings with auxiliary data such as image captions, topic words, and category information. Unlike other headline generation models, this paper uses this auxiliary information to better model this task. Furthermore, we utilize the contextualized language models to design encoder-decoder model for Bengali news headline generation and follow a simple yet cost-effective coarse-to-fine approach using topic-words to retrieve important sentences considering the fixed length requirement of the pre-trained language models. Finally, we conduct extensive experiments on our dataset containing news articles of 13 different categories to demonstrate the effectiveness of incorporating auxiliary information and evaluate our system on a wide range of metrics. The experimental results demonstrate that our methods bring significant improvements (i.e., 3 to 10 percentage points across all evaluation metrics) over the baselines. Also to illustrate the utility and robustness, we report experimental results in few-shot and non-few-shot settings.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.4.pdf"
    },
    {
        "title": "PCC: Paraphrasing with Bottom-k Sampling and Cyclic Learning for Curriculum Data Augmentation",
        "authors": [
            "Hongyuan Lu",
            "Wai Lam"
        ],
        "published": "2023",
        "summary": "Curriculum Data Augmentation (CDA) improves neural models by presenting synthetic data with increasing difficulties from easy to hard. However, traditional CDA simply treats the ratio of word perturbation as the difficulty measure and goes through the curriculums only once. This paper presents PCC: Paraphrasing with Bottom-k Sampling and Cyclic Learning for Curriculum Data Augmentation, a novel CDA framework via paraphrasing, which exploits the textual paraphrase similarity as the curriculum difficulty measure. We propose a curriculum-aware paraphrase generation module composed of three units: a paraphrase candidate generator with bottom-k sampling, a filtering mechanism and a difficulty measure. We also propose a cyclic learning strategy that passes through the curriculums multiple times. The bottom-k sampling is proposed to generate super-hard instances for the later curriculums. Experimental results on few-shot text classification as well as dialogue generation indicate that PCC surpasses competitive baselines. Human evaluation and extensive case studies indicate that bottom-k sampling effectively generates super-hard instances, and PCC significantly improves the baseline dialogue agent.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.5.pdf"
    },
    {
        "title": "WinoDict: Probing language models for in-context word acquisition",
        "authors": [
            "Julian Martin Eisenschlos",
            "Jeremy R. Cole",
            "Fangyu Liu",
            "William W. Cohen"
        ],
        "published": "2023",
        "summary": "We introduce a new in-context learning paradigm to measure Large Language Models’ (LLMs) ability to learn novel words during inference. In particular, we rewrite Winograd-style co-reference resolution problems by replacing the key concept word with a synthetic but plausible word that the model must understand to complete the task. Solving this task requires the model to make use of the dictionary definition of the new word given in the prompt. This benchmark addresses word acquisition, one important aspect of the diachronic degradation known to afflict LLMs. As LLMs are frozen in time at the moment they are trained, they are normally unable to reflect the way language changes over time. We show that the accuracy of LLMs compared to the original Winograd tasks decreases radically in our benchmark, thus identifying a limitation of current models and providing a benchmark to measure future improvements in LLMs ability to do in-context learning.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.7.pdf"
    },
    {
        "title": "Nationality Bias in Text Generation",
        "authors": [
            "Pranav Narayanan Venkit",
            "Sanjana Gautam",
            "Ruchi Panchanadikar",
            "Ting-Hao Huang",
            "Shomir Wilson"
        ],
        "published": "2023",
        "summary": "Little attention is placed on analyzing nationality bias in language models, especially when nationality is highly used as a factor in increasing the performance of social NLP models. This paper examines how a text generation model, GPT-2, accentuates pre-existing societal biases about country-based demonyms. We generate stories using GPT-2 for various nationalities and use sensitivity analysis to explore how the number of internet users and the country’s economic status impacts the sentiment of the stories. To reduce the propagation of biases through large language models (LLM), we explore the debiasing method of adversarial triggering. Our results show that GPT-2 demonstrates significant bias against countries with lower internet users, and adversarial triggering effectively reduces the same.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.9.pdf"
    },
    {
        "title": "Do we need Label Regularization to Fine-tune Pre-trained Language Models?",
        "authors": [
            "Ivan Kobyzev",
            "Aref Jafari",
            "Mehdi Rezagholizadeh",
            "Tianda Li",
            "Alan Do-Omri",
            "Peng Lu",
            "Pascal Poupart",
            "Ali Ghodsi"
        ],
        "published": "2023",
        "summary": "Knowledge Distillation (KD) is a prominent neural model compression technique that heavily relies on teacher network predictions to guide the training of a student model. Considering the ever-growing size of pre-trained language models (PLMs), KD is often adopted in many NLP tasks involving PLMs. However, it is evident that in KD, deploying the teacher network during training adds to the memory and computational requirements of training. In the computer vision literature, the necessity of the teacher network is put under scrutiny by showing that KD is a label regularization technique that can be replaced with lighter teacher-free variants such as the label-smoothing technique. However, to the best of our knowledge, this issue is not investigated in NLP. Therefore, this work concerns studying different label regularization techniques and whether we actually need them to improve the fine-tuning of smaller PLM networks on downstream tasks. In this regard, we did a comprehensive set of experiments on different PLMs such as BERT, RoBERTa, and GPT with more than 600 distinct trials and ran each configuration five times. This investigation led to a surprising observation that KD and other label regularization techniques do not play any meaningful role over regular fine-tuning when the student model is pre-trained. We further explore this phenomenon in different settings of NLP and computer vision tasks and demonstrate that pre-training itself acts as a kind of regularization, and additional label regularization is unnecessary.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.13.pdf"
    },
    {
        "title": "Retrieval Enhanced Data Augmentation for Question Answering on Privacy Policies",
        "authors": [
            "Md Rizwan Parvez",
            "Jianfeng Chi",
            "Wasi Uddin Ahmad",
            "Yuan Tian",
            "Kai-Wei Chang"
        ],
        "published": "2023",
        "summary": "Prior studies in privacy policies frame the question answering (QA) task as identifying the most relevant text segment or a list of sentences from a policy document given a user query. Existing labeled datasets are heavily imbalanced (only a few relevant segments), limiting the QA performance in this domain. In this paper, we develop a data augmentation framework based on ensembling retriever models that captures the relevant text segments from unlabeled policy documents and expand the positive examples in the training set. In addition, to improve the diversity and quality of the augmented data, we leverage multiple pre-trained language models (LMs) and cascaded them with noise reduction oracles. Using our augmented data on the PrivacyQA benchmark, we elevate the existing baseline by a large margin (10% F1) and achieve a new state-of-the-art F1 score of 50%. Our ablation studies provide further insights into the effectiveness of our approach.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.16.pdf"
    },
    {
        "title": "Understanding Transformer Memorization Recall Through Idioms",
        "authors": [
            "Adi Haviv",
            "Ido Cohen",
            "Jacob Gidron",
            "Roei Schuster",
            "Yoav Goldberg",
            "Mor Geva"
        ],
        "published": "2023",
        "summary": "To produce accurate predictions, language models (LMs) must balance between generalization and memorization. Yet, little is known about the mechanism by which transformer LMs employ their memorization capacity. When does a model decide to output a memorized phrase, and how is this phrase then retrieved from memory? In this work, we offer the first methodological framework for probing and characterizing recall of memorized sequences in transformer LMs. First, we lay out criteria for detecting model inputs that trigger memory recall, and propose idioms as inputs that typically fulfill these criteria. Next, we construct a dataset of English idioms and use it to compare model behavior on memorized vs. non-memorized inputs. Specifically, we analyze the internal prediction construction process by interpreting the model’s hidden representations as a gradual refinement of the output probability distribution. We find that across different model sizes and architectures, memorized predictions are a two-step process: early layers promote the predicted token to the top of the output distribution, and upper layers increase model confidence. This suggests that memorized information is stored and retrieved in the early layers of the network. Last, we demonstrate the utility of our methodology beyond idioms in memorized factual statements. Overall, our work makes a first step towards understanding memory recall, and provides a methodological basis for future studies of transformer memorization.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.19.pdf"
    },
    {
        "title": "A Discerning Several Thousand Judgments: GPT-3 Rates the Article + Adjective + Numeral + Noun Construction",
        "authors": [
            "Kyle Mahowald"
        ],
        "published": "2023",
        "summary": "Knowledge of syntax includes knowledge of rare, idiosyncratic constructions. LLMs must overcome frequency biases in order to master such constructions. In this study, I prompt GPT-3 to give acceptability judgments on the English-language Article + Adjective + Numeral + Noun construction (e.g., “a lovely five days”). I validate the prompt using the CoLA corpus of acceptability judgments and then zero in on the AANN construction. I compare GPT- 3’s judgments to crowdsourced human judgments on a subset of sentences. GPT-3’s judgments are broadly similar to human judgments and generally align with proposed constraints in the literature but, in some cases, GPT-3’s judgments and human judgments diverge from the literature and from each other.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.20.pdf"
    },
    {
        "title": "Triple-Hybrid Energy-based Model Makes Better Calibrated Natural Language Understanding Models",
        "authors": [
            "Haotian Xu",
            "Yingying Zhang"
        ],
        "published": "2023",
        "summary": "Though pre-trained language models achieve notable success in many applications, it’s usually controversial for over-confident predictions. Specifically, the in-distribution (ID) miscalibration and out-of-distribution (OOD) detection are main concerns. Recently, some works based on energy-based models (EBM) have shown great improvements on both ID calibration and OOD detection for images. However, it’s rarely explored in natural language understanding tasks due to the non-differentiability of text data which makes it more difficult for EBM training. In this paper, we first propose a triple-hybrid EBM which combines the benefits of classifier, conditional generative model and marginal generative model altogether. Furthermore, we leverage contrastive learning to approximately train the proposed model, which circumvents the non-differentiability issue of text data. Extensive experiments have been done on GLUE and six other multiclass datasets in various domains. Our model outperforms previous methods in terms of ID calibration and OOD detection by a large margin while maintaining competitive accuracy.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.21.pdf"
    },
    {
        "title": "COMBO: A Complete Benchmark for Open KG Canonicalization",
        "authors": [
            "Chengyue Jiang",
            "Yong Jiang",
            "Weiqi Wu",
            "Yuting Zheng",
            "Pengjun Xie",
            "Kewei Tu"
        ],
        "published": "2023",
        "summary": "Open knowledge graph (KG) consists of (subject, relation, object) triples extracted from millions of raw text. The subject and object noun phrases and the relation in open KG have severe redundancy and ambiguity and need to be canonicalized. Existing datasets for open KG canonicalization only provide gold entity-level canonicalization for noun phrases. In this paper, we present COMBO, a Complete Benchmark for Open KG canonicalization. Compared with existing datasets, we additionally provide gold canonicalization for relation phrases, gold ontology-level canonicalization for noun phrases, as well as source sentences from which triples are extracted. We also propose metrics for evaluating each type of canonicalization. On the COMBO dataset, we empirically compare previously proposed canonicalization methods as well as a few simple baseline methods based on pretrained language models. We find that properly encoding the phrases in a triple using pretrained language models results in better relation canonicalization and ontology-level canonicalization of the noun phrase. We release our dataset, baselines, and evaluation scripts at path/to/url.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.26.pdf"
    },
    {
        "title": "Assistive Recipe Editing through Critiquing",
        "authors": [
            "Diego Antognini",
            "Shuyang Li",
            "Boi Faltings",
            "Julian McAuley"
        ],
        "published": "2023",
        "summary": "There has recently been growing interest in the automatic generation of cooking recipes that satisfy some form of dietary restrictions, thanks in part to the availability of online recipe data. Prior studies have used pre-trained language models, or relied on small paired recipe data (e.g., a recipe paired with a similar one that satisfies a dietary constraint). However, pre-trained language models generate inconsistent or incoherent recipes, and paired datasets are not available at scale. We address these deficiencies with RecipeCrit, a hierarchical denoising auto-encoder that edits recipes given ingredient-level critiques. The model is trained for recipe completion to learn semantic relationships within recipes. Our work’s main innovation is our unsupervised critiquing module that allows users to edit recipes by interacting with the predicted ingredients; the system iteratively rewrites recipes to satisfy users’ feedback. Experiments onthe Recipe1M recipe dataset show that our model can more effectively edit recipes compared to strong language-modeling baselines, creating recipes that satisfy user constraints and are more correct, serendipitous, coherent, and relevant as measured by human judges.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.28.pdf"
    },
    {
        "title": "“John is 50 years old, can his son be 65?” Evaluating NLP Models’ Understanding of Feasibility",
        "authors": [
            "Himanshu Gupta",
            "Neeraj Varshney",
            "Swaroop Mishra",
            "Kuntal Kumar Pal",
            "Saurabh Arjun Sawant",
            "Kevin Scaria",
            "Siddharth Goyal",
            "Chitta Baral"
        ],
        "published": "2023",
        "summary": "In current NLP research, large-scale language models and their abilities are widely being discussed. Some recent works have also found notable failures of these models. Often these failure examples involve complex reasoning abilities. This work focuses on a simple commonsense ability, reasoning about when an action (or its effect) is feasible. To this end, we introduce FeasibilityQA, a question-answering dataset involving binary classification (BCQ) and multi-choice multi-correct questions (MCQ) that test understanding of feasibility. We show that even state-of-the-art models such as GPT-3, GPT-2, and T5 struggle to answer the feasibility questions correctly. Specifically, on (MCQ, BCQ) questions, GPT-3 achieves accuracy of just (19%, 62%) and (25%, 64%) in zero-shot and few-shot settings, respectively. We also evaluate models by providing relevant knowledge statements required to answer the question and find that the additional knowledge leads to a 7% gain in performance, but the overall performance still remains low. These results make one wonder how much commonsense knowledge about action feasibility is encoded in state-of-the-art models and how well they can reason about it.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.30.pdf"
    },
    {
        "title": "Scaling Back-Translation with Domain Text Generation for Sign Language Gloss Translation",
        "authors": [
            "Jinhui Ye",
            "Wenxiang Jiao",
            "Xing Wang",
            "Zhaopeng Tu"
        ],
        "published": "2023",
        "summary": "Sign language gloss translation aims to translate the sign glosses into spoken language texts, which is challenging due to the scarcity of labeled gloss-text parallel data. Back translation (BT), which generates pseudo-parallel data by translating in-domain spoken language texts into sign glosses, has been applied to alleviate the data scarcity problem. However, the lack of large-scale high-quality in-domain spoken language text data limits the effect of BT. In this paper, to overcome the limitation, we propose a Prompt based domain text Generation (PGen) approach to produce the large-scale in-domain spoken language text data. Specifically, PGen randomly concatenates sentences from the original in-domain spoken language text data as prompts to induce a pre-trained language model (i.e., GPT-2) to generate spoken language texts in a similar style. Experimental results on three benchmarks of sign language gloss translation in varied languages demonstrate that BT with spoken language texts generated by PGen significantly outperforms the compared methods. In addition, as the scale of spoken language texts generated by PGen increases, the BT technique can achieve further improvements, demonstrating the effectiveness of our approach. We release the code and data for facilitating future research in this field.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.34.pdf"
    },
    {
        "title": "PANCETTA: Phoneme Aware Neural Completion to Elicit Tongue Twisters Automatically",
        "authors": [
            "Sedrick Scott Keh",
            "Steven Y. Feng",
            "Varun Gangal",
            "Malihe Alikhani",
            "Eduard Hovy"
        ],
        "published": "2023",
        "summary": "Tongue twisters are meaningful sentences that are difficult to pronounce. The process of automatically generating tongue twisters is challenging since the generated utterance must satisfy two conditions at once: phonetic difficulty and semantic meaning. Furthermore, phonetic difficulty is itself hard to characterize and is expressed in natural tongue twisters through a heterogeneous mix of phenomena such as alliteration and homophony. In this paper, we propose PANCETTA: Phoneme Aware Neural Completion to Elicit Tongue Twisters Automatically. We leverage phoneme representations to capture the notion of phonetic difficulty, and we train language models to generate original tongue twisters on two proposed task settings. To do this, we curate a dataset called TT-Corp, consisting of existing English tongue twisters. Through automatic and human evaluation, as well as qualitative analysis, we show that PANCETTA generates novel, phonetically difficult, fluent, and semantically meaningful tongue twisters.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.36.pdf"
    },
    {
        "title": "PromptDA: Label-guided Data Augmentation for Prompt-based Few Shot Learners",
        "authors": [
            "Canyu Chen",
            "Kai Shu"
        ],
        "published": "2023",
        "summary": "Recent advances in large pre-trained language models (PLMs) lead to impressive gains on natural language understanding (NLU) tasks with task-specific fine-tuning. However, directly fine-tuning PLMs heavily relies on sufficient labeled training instances, which are usually hard to obtain. Prompt-based tuning on PLMs has shown to be powerful for various downstream few-shot tasks. Existing works studying prompt-based tuning for few-shot NLU tasks mainly focus on deriving proper label words with a verbalizer or generating prompt templates to elicit semantics from PLMs. In addition, conventional data augmentation strategies such as synonym substitution are also widely adopted in low-resource scenarios. However, the improvements they bring to prompt-based few-shot learning have been demonstrated to be marginal. Thus, an important research question arises as follows: how to design effective data augmentation methods for prompt-based few-shot tuning? To this end, considering the label semantics are essential in prompt-based tuning, we propose a novel label-guided data augmentation framework PromptDA, which exploits the enriched label semantic information for data augmentation. Extensive experiment results on few-shot text classification tasks show that our proposed framework achieves superior performances by effectively leveraging label semantics and data augmentation for natural language understanding.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.41.pdf"
    },
    {
        "title": "Incorporating Context into Subword Vocabularies",
        "authors": [
            "Shaked Yehezkel",
            "Yuval Pinter"
        ],
        "published": "2023",
        "summary": "Most current popular subword tokenizers are trained based on word frequency statistics over a corpus, without considering information about co-occurrence or context. Nevertheless, the resulting vocabularies are used in language models’ highly contextualized settings. We present SaGe, a tokenizer that tailors subwords for their downstream use by baking in the contextualized signal at the vocabulary creation phase. We show that SaGe does a better job than current widespread tokenizers in keeping token contexts cohesive, while not incurring a large price in terms of encoding efficiency or domain robustness. SaGe improves performance on English GLUE classification tasks as well as on NER, and on Inference and NER in Turkish, demonstrating its robustness to language properties such as morphological exponence and agglutination.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.45.pdf"
    },
    {
        "title": "Combining Parameter-efficient Modules for Task-level Generalisation",
        "authors": [
            "Edoardo Maria Ponti",
            "Alessandro Sordoni",
            "Yoshua Bengio",
            "Siva Reddy"
        ],
        "published": "2023",
        "summary": "A modular design encourages neural models to disentangle and recombine different facets of knowledge to generalise more systematically to new tasks. In this work, we assume that each task is associated with a subset of latent skills from an (arbitrary size) inventory. In turn, each skill corresponds to a parameter-efficient (sparse / low-rank) model adapter. By jointly learning adapters and a routing function that allocates skills to each task, the full network is instantiated as the average of the parameters of active skills. We propose several inductive biases that encourage re-usage and composition of the skills, including variable-size skill allocation and a dual-speed learning rate. We evaluate our latent-skill model in two main settings: 1) multitask reinforcement learning for instruction following on 8 levels of the BabyAI platform; and 2) few-shot fine-tuning of language models on 160 NLP tasks of the CrossFit benchmark. We find that the modular design of our network enhances sample efficiency in reinforcement learning and few-shot generalisation in supervised learning, compared to a series of baselines. These include models where parameters are fully shared, task-specific, conditionally generated (HyperFormer), or sparse mixture-of-experts (TaskMoE).",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.49.pdf"
    },
    {
        "title": "Self-imitation Learning for Action Generation in Text-based Games",
        "authors": [
            "Zijing Shi",
            "Yunqiu Xu",
            "Meng Fang",
            "Ling Chen"
        ],
        "published": "2023",
        "summary": "In this work, we study reinforcement learning (RL) in solving text-based games. We address the challenge of combinatorial action space, by proposing a confidence-based self-imitation model to generate action candidates for the RL agent. Firstly, we leverage the self-imitation learning to rank and exploit past valuable trajectories to adapt a pre-trained language model (LM) towards a target game. Then, we devise a confidence-based strategy to measure the LM’s confidence with respect to a state, thus adaptively pruning the generated actions to yield a more compact set of action candidates. In multiple challenging games, our model demonstrates promising performance in comparison to the baselines.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.50.pdf"
    },
    {
        "title": "Investigating the Effect of Relative Positional Embeddings on AMR-to-Text Generation with Structural Adapters",
        "authors": [
            "Sebastien Montella",
            "Alexis Nasr",
            "Johannes Heinecke",
            "Frederic Bechet",
            "Lina M. Rojas Barahona"
        ],
        "published": "2023",
        "summary": "Text generation from Abstract Meaning Representation (AMR) has substantially benefited from the popularized Pretrained Language Models (PLMs). Myriad approaches have linearized the input graph as a sequence of tokens to fit the PLM tokenization requirements. Nevertheless, this transformation jeopardizes the structural integrity of the graph and is therefore detrimental to its resulting representation. To overcome this issue, Ribeiro et al. (2021b) have recently proposed StructAdapt, a structure-aware adapter which injects the input graph connectivity within PLMs using Graph Neural Networks (GNNs). In this paper, we investigate the influence of Relative Position Embeddings (RPE) on AMR-to-Text, and, in parallel, we examine the robustness of StructAdapt. Through ablation studies, graph attack and link prediction, we reveal that RPE might be partially encoding input graphs. We suggest further research regarding the role of RPE will provide valuable insights for Graph-to-Text generation.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.51.pdf"
    },
    {
        "title": "The Functional Relevance of Probed Information: A Case Study",
        "authors": [
            "Michael Hanna",
            "Roberto Zamparelli",
            "David Mareček"
        ],
        "published": "2023",
        "summary": "Recent studies have shown that transformer models like BERT rely on number information encoded in their representations of sentences’ subjects and head verbs when performing subject-verb agreement. However, probing experiments suggest that subject number is also encoded in the representations of all words in such sentences. In this paper, we use causal interventions to show that BERT only uses the subject plurality information encoded in its representations of the subject and words that agree with it in number. We also demonstrate that current probing metrics are unable to determine which words’ representations contain functionally relevant information. This both provides a revised view of subject-verb agreement in language models, and suggests potential pitfalls for current probe usage and evaluation.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.58.pdf"
    },
    {
        "title": "Do Pretrained Contextual Language Models Distinguish between Hebrew Homograph Analyses?",
        "authors": [
            "Avi Shmidman",
            "Cheyn Shmuel Shmidman",
            "Dan Bareket",
            "Moshe Koppel",
            "Reut Tsarfaty"
        ],
        "published": "2023",
        "summary": "Semitic morphologically-rich languages (MRLs) are characterized by extreme word ambiguity. Because most vowels are omitted in standard texts, many of the words are homographs with multiple possible analyses, each with a different pronunciation and different morphosyntactic properties. This ambiguity goes beyond word-sense disambiguation (WSD), and may include token segmentation into multiple word units. Previous research on MRLs claimed that standardly trained pre-trained language models (PLMs) based on word-pieces may not sufficiently capture the internal structure of such tokens in order to distinguish between these analyses.Taking Hebrew as a case study, we investigate the extent to which Hebrew homographs can be disambiguated and analyzed using PLMs. We evaluate all existing models for contextualized Hebrew embeddings on a novel Hebrew homograph challenge sets that we deliver. Our empirical results demonstrate that contemporary Hebrew contextualized embeddings outperform non-contextualized embeddings; and that they are most effective for disambiguating segmentation and morphosyntactic features, less so regarding pure word-sense disambiguation. We show that these embeddings are more effective when the number of word-piece splits is limited, and they are more effective for 2-way and 3-way ambiguities than for 4-way ambiguity. We show that the embeddings are equally effective for homographs of both balanced and skewed distributions, whether calculated as masked or unmasked tokens. Finally, we show that these embeddings are as effective for homograph disambiguation with extensive supervised training as with a few-shot setup.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.59.pdf"
    },
    {
        "title": "Parameter-Efficient Tuning with Special Token Adaptation",
        "authors": [
            "Xiaocong Yang",
            "James Y. Huang",
            "Wenxuan Zhou",
            "Muhao Chen"
        ],
        "published": "2023",
        "summary": "Parameter-efficient tuning aims at updating only a small subset of parameters when adapting a pretrained model to downstream tasks. In this work, we introduce PASTA, in which we only modify the special token representations (e.g., [SEP] and [CLS] in BERT) before the self-attention module at each layer in Transformer-based models. PASTA achieves comparable performance to fine-tuning in natural language understanding tasks including text classification and NER with up to only 0.029% of total parameters trained. Our work not only provides a simple yet effective way of parameter-efficient tuning, which has a wide range of practical applications when deploying finetuned models for multiple tasks, but also demonstrates the pivotal role of special tokens in pretrained language models.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.60.pdf"
    },
    {
        "title": "Probing Power by Prompting: Harnessing Pre-trained Language Models for Power Connotation Framing",
        "authors": [
            "Shima Khanehzar",
            "Trevor Cohn",
            "Gosia Mikolajczak",
            "Lea Frermann"
        ],
        "published": "2023",
        "summary": "When describing actions, subtle changes in word choice can evoke very different associations with the involved entities. For instance, a company ‘employing workers’ evokes a more positive connotation than the one ‘exploiting’ them. This concept is called connotation. This paper investigates whether pre-trained language models (PLMs) encode such subtle connotative information about power differentials between involved entities. We design a probing framework for power connotation, building on (CITATION)’s operationalization of connotation frames. We show that zero-shot prompting of PLMs leads to above chance prediction of power connotation, however fine-tuning PLMs using our framework drastically improves their accuracy. Using our fine-tuned models, we present a case study of power dynamics in US news reporting on immigration, showing the potential of our framework as a tool for understanding subtle bias in the media.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.61.pdf"
    },
    {
        "title": "Zero and Few-Shot Localization of Task-Oriented Dialogue Agents with a Distilled Representation",
        "authors": [
            "Mehrad Moradshahi",
            "Sina Semnani",
            "Monica Lam"
        ],
        "published": "2023",
        "summary": "Task-oriented Dialogue (ToD) agents are mostly limited to a few widely-spoken languages, mainly due to the high cost of acquiring training data for each language. Existing low-cost approaches that rely on cross-lingual embeddings or naive machine translation sacrifice a lot of accuracy for data efficiency, and largely fail in creating a usable dialogue agent. We propose automatic methods that use ToD training data in a source language to build a high-quality functioning dialogue agent in another target language that has no training data (i.e. zero-shot) or a small training set (i.e. few-shot). Unlike most prior work in cross-lingual ToD that only focuses on Dialogue State Tracking (DST), we build an end-to-end agent. We show that our approach closes the accuracy gap between few-shot and existing full-shot methods for ToD agents. We achieve this by (1) improving the dialogue data representation, (2) improving entity-aware machine translation, and (3) automatic filtering of noisy translations. We evaluate our approach on the recent bilingual dialogue dataset BiToD.In Chinese to English transfer, in the zero-shot setting, our method achieves 46.7% and 22.0% in Task Success Rate (TSR) and Dialogue Success Rate (DSR) respectively. In the few-shot setting where 10% of the data in the target language is used, we improve the state-of-the-art by 15.2% and 14.0%, coming within 5% of full-shot training.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.62.pdf"
    },
    {
        "title": "Contextual Semantic Parsing for Multilingual Task-Oriented Dialogues",
        "authors": [
            "Mehrad Moradshahi",
            "Victoria Tsai",
            "Giovanni Campagna",
            "Monica Lam"
        ],
        "published": "2023",
        "summary": "Robust state tracking for task-oriented dialogue systems currently remains restricted to a few popular languages. This paper shows that given a large-scale dialogue data set in one language, we can automatically produce an effective semantic parser for other languages using machine translation. We propose automatic translation of dialogue datasets with alignment to ensure faithful translation of slot values and eliminate costly human supervision used in previous benchmarks. We also propose a new contextual semantic parsing model, which encodes the formal slots and values, and only the last agent and user utterances. We show that the succinct representation reduces the compounding effect of translation errors, without harming the accuracy in practice. We evaluate our approach on several dialogue state tracking benchmarks. On RiSAWOZ, CrossWOZ, CrossWOZ-EN, and MultiWOZ-ZH datasets we improve the state of the art by 11%, 17%, 20%, and 0.3% in joint goal accuracy. We present a comprehensive error analysis for all three datasets showing erroneous annotations can lead to misguided judgments on the quality of the model. Finally, we present RiSAWOZ English and German datasets, created using our translation methodology. On these datasets, accuracy is within 11% of the original showing that high-accuracy multilingual dialogue datasets are possible without relying on expensive human annotations. We release our datasets and software open source.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.63.pdf"
    },
    {
        "title": "Find Parent then Label Children: A Two-stage Taxonomy Completion Method with Pre-trained Language Model",
        "authors": [
            "Fei Xia",
            "Yixuan Weng",
            "Shizhu He",
            "Kang Liu",
            "Jun Zhao"
        ],
        "published": "2023",
        "summary": "Taxonomies, which organize domain concepts into hierarchical structures, are crucial for building knowledge systems and downstream applications. As domain knowledge evolves, taxonomies need to be continuously updated to include new concepts. Previous approaches have mainly focused on adding concepts to the leaf nodes of the existing hierarchical tree, which does not fully utilize the taxonomy’s knowledge and is unable to update the original taxonomy structure (usually involving non-leaf nodes). In this paper, we propose a two-stage method called ATTEMPT for taxonomy completion. Our method inserts new concepts into the correct position by finding a parent node and labeling child nodes. Specifically, by combining local nodes with prompts to generate natural sentences, we take advantage of pre-trained language models for hypernym/hyponymy recognition. Experimental results on two public datasets (including six domains) show that ATTEMPT performs best on both taxonomy completion and extension tasks, surpassing existing methods.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.73.pdf"
    },
    {
        "title": "Looking for a Needle in a Haystack: A Comprehensive Study of Hallucinations in Neural Machine Translation",
        "authors": [
            "Nuno M. Guerreiro",
            "Elena Voita",
            "André Martins"
        ],
        "published": "2023",
        "summary": "Although the problem of hallucinations in neural machine translation (NMT) has received some attention, research on this highly pathological phenomenon lacks solid ground. Previous work has been limited in several ways: it often resorts to artificial settings where the problem is amplified, it disregards some (common) types of hallucinations, and it does not validate adequacy of detection heuristics. In this paper, we set foundations for the study of NMT hallucinations. First, we work in a natural setting, i.e., in-domain data without artificial noise neither in training nor in inference. Next, we annotate a dataset of over 3.4k sentences indicating different kinds of critical errors and hallucinations. Then, we turn to detection methods and both revisit methods used previously and propose using glass-box uncertainty-based detectors. Overall, we show that for preventive settings, (i) previously used methods are largely inadequate, (ii) sequence log-probability works best and performs on par with reference-based methods. Finally, we propose DeHallucinator, a simple method for alleviating hallucinations at test time that significantly reduces the hallucinatory rate.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.75.pdf"
    },
    {
        "title": "On Robustness of Prompt-based Semantic Parsing with Large Pre-trained Language Model: An Empirical Study on Codex",
        "authors": [
            "Terry Yue Zhuo",
            "Zhuang Li",
            "Yujin Huang",
            "Fatemeh Shiri",
            "Weiqing Wang",
            "Gholamreza Haffari",
            "Yuan-Fang Li"
        ],
        "published": "2023",
        "summary": "Semantic parsing is a technique aimed at constructing a structured representation of the meaning of a natural-language question. Recent advances in language models trained on code have shown superior performance in generating these representations compared to language models trained solely on natural language text. The existing fine-tuned neural semantic parsers are vulnerable to adversarial attacks on natural-language inputs. While it has been established that the robustness of smaller semantic parsers can be enhanced through adversarial training, this approach is not feasible for large language models in real-world scenarios, as it requires both substantial computational resources and expensive human annotation on in-domain semantic parsing data. This paper presents the first empirical study on the adversarial robustness of a prompt-based semantic parser based on CODEX, a stateof-the-art (SOTA) language model trained on code. Our results demonstrate that the large language model of code is vulnerable to carefully crafted adversarial examples. To overcome this challenge, we propose methods for enhancing robustness without requiring substantial amounts of labelled data or intensive computational resources.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.77.pdf"
    },
    {
        "title": "Persona Expansion with Commonsense Knowledge for Diverse and Consistent Response Generation",
        "authors": [
            "Donghyun Kim",
            "Youbin Ahn",
            "Wongyu Kim",
            "Chanhee Lee",
            "Kyungchan Lee",
            "Kyong-Ho Lee",
            "Jeonguk Kim",
            "Donghoon Shin",
            "Yeonsoo Lee"
        ],
        "published": "2023",
        "summary": "Generating diverse and consistent responses is the ultimate goal of a persona-based dialogue. Although many studies have been conducted, the generated responses tend to be generic and bland due to the personas’ limited descriptiveness. Therefore, it is necessary to expand the given personas for more attractive responses. However, indiscriminate expansion of personas threaten the consistency of responses and therefore reduce the interlocutor’s interest in conversation. To alleviate this issue, we propose a consistent persona expansion framework that improves not only the diversity but also the consistency of persona-based responses. To do so, we define consistency criteria to avoid possible contradictions among personas as follows: 1) Intra-Consistency and 2) Inter-Consistency. Then, we construct a silver profile dataset to deliver the ability to conform with the consistency criteria to the expansion model. Finally, we propose a persona expansion model with an encoder-decoder structure, which considers the relatedness and consistency among personas. Our experiments on the Persona-Chat dataset demonstrate the superiority of the proposed framework.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.81.pdf"
    },
    {
        "title": "MiniALBERT: Model Distillation via Parameter-Efficient Recursive Transformers",
        "authors": [
            "Mohammadmahdi Nouriborji",
            "Omid Rohanian",
            "Samaneh Kouchaki",
            "David A. Clifton"
        ],
        "published": "2023",
        "summary": "Pre-trained Language Models (LMs) have become an integral part of Natural Language Processing (NLP) in recent years, due to their superior performance in downstream applications. In spite of this resounding success, the usability of LMs is constrained by computational and time complexity, along with their increasing size; an issue that has been referred to as overparameterisation. Different strategies have been proposed in the literature to alleviate these problems, with the aim to create effective compact models that nearly match the performance of their bloated counterparts with negligible performance losses. One of the most popular techniques in this area of research is model distillation. Another potent but underutilised technique is cross-layer parameter sharing. In this work, we combine these two strategies and present MiniALBERT, a technique for converting the knowledge of fully parameterised LMs (such as BERT) into a compact recursive student. In addition, we investigate the application of bottleneck adapters for layer-wise adaptation of our recursive student, and also explore the efficacy of adapter tuning for fine-tuning of compact models. We test our proposed models on a number of general and biomedical NLP tasks to demonstrate their viability and compare them with the state-of-the-art and other existing compact models. All the codes used in the experiments and the pre-trained compact models will be made publicly available.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.83.pdf"
    },
    {
        "title": "Multilingual Normalization of Temporal Expressions with Masked Language Models",
        "authors": [
            "Lukas Lange",
            "Jannik Strötgen",
            "Heike Adel",
            "Dietrich Klakow"
        ],
        "published": "2023",
        "summary": "The detection and normalization of temporal expressions is an important task and preprocessing step for many applications. However, prior work on normalization is rule-based, which severely limits the applicability in real-world multilingual settings, due to the costly creation of new rules. We propose a novel neural method for normalizing temporal expressions based on masked language modeling. Our multilingual method outperforms prior rule-based systems in many languages, and in particular, for low-resource languages with performance improvements of up to 33 F1 on average compared to the state of the art.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.84.pdf"
    },
    {
        "title": "K-hop neighbourhood regularization for few-shot learning on graphs: A case study of text classification",
        "authors": [
            "Niels van der Heijden",
            "Ekaterina Shutova",
            "Helen Yannakoudakis"
        ],
        "published": "2023",
        "summary": "We present FewShotTextGCN, a novel method designed to effectively utilize the properties of word-document graphs for improved learning in low-resource settings. We introduce K-hop Neighbourhood Regularization, a regularizer for heterogeneous graphs, and show that it stabilizes and improves learning when only a few training samples are available. We furthermore propose a simplification in the graph-construction method, which results in a graph that is ∼7 times less dense and yields better performance in little-resource settings while performing on par with the state of the art in high-resource settings. Finally, we introduce a new variant of Adaptive Pseudo-Labeling tailored for word-document graphs. When using as little as 20 samples for training, we outperform a strong TextGCN baseline with 17% in absolute accuracy on average over eight languages. We demonstrate that our method can be applied to document classification without any language model pretraining on a wide range of typologically diverse languages while performing on par with large pretrained language models.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.85.pdf"
    },
    {
        "title": "Policy-based Reinforcement Learning for Generalisation in Interactive Text-based Environments",
        "authors": [
            "Edan Toledo",
            "Jan Buys",
            "Jonathan Shock"
        ],
        "published": "2023",
        "summary": "Text-based environments enable RL agents to learn to converse and perform interactive tasks through natural language. However, previous RL approaches applied to text-based environments show poor performance when evaluated on unseen games. This paper investigates the improvement of generalisation performance through the simple switch from a value-based update method to a policy-based one, within text-based environments. We show that by replacing commonly used value-based methods with REINFORCE with baseline, a far more general agent is produced. The policy-based agent is evaluated on Coin Collector and Question Answering with interactive text (QAit), two text-based environments designed to test zero-shot performance. We see substantial improvements on a variety of zero-shot evaluation experiments, including tripling accuracy on various QAit benchmark configurations. The results indicate that policy-based RL has significantly better generalisation capabilities than value-based methods within such text-based environments, suggesting that RL agents could be applied to more complex natural language environments.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.88.pdf"
    },
    {
        "title": "Poor Man’s Quality Estimation: Predicting Reference-Based MT Metrics Without the Reference",
        "authors": [
            "Vilém Zouhar",
            "Shehzaad Dhuliawala",
            "Wangchunshu Zhou",
            "Nico Daheim",
            "Tom Kocmi",
            "Yuchen Eleanor Jiang",
            "Mrinmaya Sachan"
        ],
        "published": "2023",
        "summary": "Machine translation quality estimation (QE) predicts human judgements of a translation hypothesis without seeing the reference. State-of-the-art QE systems based on pretrained language models have been achieving remarkable correlations with human judgements yet they are computationally heavy and require human annotations, which are slow and expensive to create. To address these limitations, we define the problem of metric estimation (ME) where one predicts the automated metric scores also without the reference. We show that even without access to the reference, our model can estimate automated metrics (ρ = 60% for BLEU, ρ = 51% for other metrics) at the sentence-level. Because automated metrics correlate with human judgements, we can leverage the ME task for pre-training a QE model. For the QE task, we find that pre-training on TER is better (ρ = 23%) than training for scratch (ρ = 20%).",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.95.pdf"
    },
    {
        "title": "Robustification of Multilingual Language Models to Real-world Noise in Crosslingual Zero-shot Settings with Robust Contrastive Pretraining",
        "authors": [
            "Asa Cooper Stickland",
            "Sailik Sengupta",
            "Jason Krone",
            "Saab Mansour",
            "He He"
        ],
        "published": "2023",
        "summary": "Advances in neural modeling have achieved state-of-the-art (SOTA) results on public natural language processing (NLP) benchmarks, at times surpassing human performance. However, there is a gap between public benchmarks and real-world applications where noise, such as typographical or grammatical mistakes, is abundant and can result in degraded performance. Unfortunately, works which evaluate the robustness of neural models on noisy data and propose improvements, are limited to the English language. Upon analyzing noise in different languages, we observe that noise types vary greatly across languages. Thus, existing investigations do not generalize trivially to multilingual settings. To benchmark the performance of pretrained multilingual language models, we construct noisy datasets covering five languages and four NLP tasks and observe a clear gap in the performance between clean and noisy data in the zero-shot cross-lingual setting. After investigating several ways to boost the robustness of multilingual models in this setting, we propose Robust Contrastive Pretraining (RCP). RCP combines data augmentation with a contrastive loss term at the pretraining stage and achieves large improvements on noisy (and original test data) across two sentence-level (+3.2%) and two sequence-labeling (+10 F1-score) multilingual classification tasks.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.100.pdf"
    },
    {
        "title": "Made of Steel? Learning Plausible Materials for Components in the Vehicle Repair Domain",
        "authors": [
            "Annerose Eichel",
            "Helena Schlipf",
            "Sabine Schulte im Walde"
        ],
        "published": "2023",
        "summary": "We propose a novel approach to learn domain-specific plausible materials for components in the vehicle repair domain by probing Pretrained Language Models (PLMs) in a cloze task style setting to overcome the lack of annotated datasets. We devise a new method to aggregate salient predictions from a set of cloze query templates and show that domain-adaptation using either a small, high-quality or a customized Wikipedia corpus boosts performance. When exploring resource-lean alternatives, we find a distilled PLM clearly outperforming a classic pattern-based algorithm. Further, given that 98% of our domain-specific components are multiword expressions, we successfully exploit the compositionality assumption as a way to address data sparsity.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.104.pdf"
    },
    {
        "title": "Can Pretrained Language Models (Yet) Reason Deductively?",
        "authors": [
            "Zhangdie Yuan",
            "Songbo Hu",
            "Ivan Vulić",
            "Anna Korhonen",
            "Zaiqiao Meng"
        ],
        "published": "2023",
        "summary": "Acquiring factual knowledge with Pretrained Language Models (PLMs) has attracted increasing attention, showing promising performance in many knowledge-intensive tasks. Their good performance has led the community to believe that the models do possess a modicum of reasoning competence rather than merely memorising the knowledge. In this paper, we conduct a comprehensive evaluation of the learnable deductive (also known as explicit) reasoning capability of PLMs. Through a series of controlled experiments, we posit two main findings. 1) PLMs inadequately generalise learned logic rules and perform inconsistently against simple adversarial surface form edits. 2) While the deductive reasoning fine-tuning of PLMs does improve their performance on reasoning over unseen knowledge facts, it results in catastrophically forgetting the previously learnt knowledge. Our main results suggest that PLMs cannot yet perform reliable deductive reasoning, demonstrating the importance of controlled examinations and probing of PLMs’ deductive reasoning abilities; we reach beyond (misleading) task performance, revealing that PLMs are still far from robust reasoning capabilities, even for simple deductive tasks.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.106.pdf"
    },
    {
        "title": "Selective In-Context Data Augmentation for Intent Detection using Pointwise V-Information",
        "authors": [
            "Yen-Ting Lin",
            "Alexandros Papangelis",
            "Seokhwan Kim",
            "Sungjin Lee",
            "Devamanyu Hazarika",
            "Mahdi Namazifar",
            "Di Jin",
            "Yang Liu",
            "Dilek Hakkani-Tur"
        ],
        "published": "2023",
        "summary": "This work focuses on in-context data augmentation for intent detection. Having found that augmentation via in-context prompting of large pre-trained language models (PLMs) alone does not improve performance, we introduce a novel approach based on PLMs and pointwise V-information (PVI), a metric that can measure the usefulness of a datapoint for training a model. Our method first fine-tunes a PLM on a small seed of training data and then synthesizes new datapoints - utterances that correspond to given intents. It then employs intent-aware filtering, based on PVI, to remove datapoints that are not helpful to the downstream intent classifier. Our method is thus able to leverage the expressive power of large language models to produce diverse training data. Empirical results demonstrate that our method can produce synthetic training data that achieve state-of-the-art performance on three challenging intent detection datasets under few-shot settings (1.28% absolute improvement in 5-shot and 1.18% absolute in 10-shot, on average) and perform on par with the state-of-the-art in full-shot settings (within 0.01% absolute, on average).",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.107.pdf"
    },
    {
        "title": "The Impacts of Unanswerable Questions on the Robustness of Machine Reading Comprehension Models",
        "authors": [
            "Son Quoc Tran",
            "Phong Nguyen-Thuan Do",
            "Uyen Le",
            "Matt Kretchmar"
        ],
        "published": "2023",
        "summary": "Pretrained language models have achieved super-human performances on many Machine Reading Comprehension (MRC) benchmarks. Nevertheless, their relative inability to defend against adversarial attacks has spurred skepticism about their natural language understanding. In this paper, we ask whether training with unanswerable questions in SQuAD 2.0 can help improve the robustness of MRC models against adversarial attacks. To explore that question, we fine-tune three state-of-the-art language models on either SQuAD 1.1 or SQuAD 2.0 and then evaluate their robustness under adversarial attacks. Our experiments reveal that current models fine-tuned on SQuAD 2.0 do not initially appear to be any more robust than ones fine-tuned on SQuAD 1.1, yet they reveal a measure of hidden robustness that can be leveraged to realize actual performance gains. Furthermore, we find that robustness of models fine-tuned on SQuAD 2.0 extends on additional out-of-domain datasets. Finally, we introduce a new adversarial attack to reveal of SQuAD 2.0 that current MRC models are learning.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.113.pdf"
    },
    {
        "title": "SODAPOP: Open-Ended Discovery of Social Biases in Social Commonsense Reasoning Models",
        "authors": [
            "Haozhe An",
            "Zongxia Li",
            "Jieyu Zhao",
            "Rachel Rudinger"
        ],
        "published": "2023",
        "summary": "A common limitation of diagnostic tests for detecting social biases in NLP models is that they may only detect stereotypic associations that are pre-specified by the designer of the test. Since enumerating all possible problematic associations is infeasible, it is likely these tests fail to detect biases that are present in a model but not pre-specified by the designer. To address this limitation, we propose SODAPOP (SOcial bias Discovery from Answers about PeOPle), an approach for automatic social bias discovery in social commonsense question-answering. The SODAPOP pipeline generates modified instances from the Social IQa dataset (Sap et al., 2019b) by (1) substituting names associated with different demographic groups, and (2) generating many distractor answers from a masked language model. By using a social commonsense model to score the generated distractors, we are able to uncover the model’s stereotypic associations between demographic groups and an open set of words. We also test SODAPOP on debiased models and show the limitations of multiple state-of-the-art debiasing algorithms.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.116.pdf"
    },
    {
        "title": "Augmenting Pre-trained Language Models with QA-Memory for Open-Domain Question Answering",
        "authors": [
            "Wenhu Chen",
            "Pat Verga",
            "Michiel de Jong",
            "John Wieting",
            "William W. Cohen"
        ],
        "published": "2023",
        "summary": "Existing state-of-the-art methods for open-domain question-answering (ODQA) use an open book approach in which information is first retrieved from a large text corpus or knowledge base (KB) and then reasoned over to produce an answer. A recent alternative is to retrieve from a collection of previously-generated question-answer pairs; this has several practical advantages including being more memory and compute-efficient. Question-answer pairs are also appealing in that they can be viewed as an intermediate between text and KB triples: like KB triples, they often concisely express a single relationship, but like text, have much higher coverage than traditional KBs. In this work, we describe a new QA system that augments a text-to-text model with a large memory of question-answer pairs, and a new pre-training task for the latent step of question retrieval. The pre-training task substantially simplifies training and greatly improves performance on smaller QA benchmarks. Unlike prior systems of this sort, our QA system can also answer multi-hop questions that do not explicitly appear in the collection of stored question-answer pairs.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.117.pdf"
    },
    {
        "title": "Enhancing Multi-Document Summarization with Cross-Document Graph-based Information Extraction",
        "authors": [
            "Zixuan Zhang",
            "Heba Elfardy",
            "Markus Dreyer",
            "Kevin Small",
            "Heng Ji",
            "Mohit Bansal"
        ],
        "published": "2023",
        "summary": "Information extraction (IE) and summarization are closely related, both tasked with presenting a subset of the information contained in a natural language text. However, while IE extracts structural representations, summarization aims to abstract the most salient information into a generated text summary – thus potentially encountering the technical limitations of current text generation methods (e.g., hallucination). To mitigate this risk, this work uses structured IE graphs to enhance the abstractive summarization task. Specifically, we focus on improving Multi-Document Summarization (MDS) performance by using cross-document IE output, incorporating two novel components: (1) the use of auxiliary entity and event recognition systems to focus the summary generation model; (2) incorporating an alignment loss between IE nodes and their text spans to reduce inconsistencies between the IE graphs and text representations. Operationally, both the IE nodes and corresponding text spans are projected into the same embedding space and pairwise distance is minimized. Experimental results on multiple MDS benchmarks show that summaries generated by our model are more factually consistent with the source documents than baseline models while maintaining the same level of abstractiveness.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.124.pdf"
    },
    {
        "title": "Multi-Modal Bias: Introducing a Framework for Stereotypical Bias Assessment beyond Gender and Race in Vision–Language Models",
        "authors": [
            "Sepehr Janghorbani",
            "Gerard De Melo"
        ],
        "published": "2023",
        "summary": "Recent breakthroughs in self-supervised training have led to a new class of pretrained vision–language models. While there have been investigations of bias in multimodal models, they have mostly focused on gender and racial bias, giving much less attention to other relevant groups, such as minorities with regard to religion, nationality, sexual orientation, or disabilities. This is mainly due to lack of suitable benchmarks for such groups. We seek to address this gap by providing a visual and textual bias benchmark called MMBias, consisting of around 3,800 images and phrases covering 14 population subgroups. We utilize this dataset to assess bias in several prominent self-supervised multimodal models, including CLIP, ALBEF, and ViLT. Our results show that these models demonstrate meaningful bias favoring certain groups. Finally, we introduce a debiasing method designed specifically for such large pretrained models that can be applied as a post-processing step to mitigate bias, while preserving the remaining accuracy of the model.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.126.pdf"
    },
    {
        "title": "Fiction-Writing Mode: An Effective Control for Human-Machine Collaborative Writing",
        "authors": [
            "Wenjie Zhong",
            "Jason Naradowsky",
            "Hiroya Takamura",
            "Ichiro Kobayashi",
            "Yusuke Miyao"
        ],
        "published": "2023",
        "summary": "We explore the idea of incorporating concepts from writing skills curricula into human-machine collaborative writing scenarios, focusing on adding writing modes as a control for text generation models. Using crowd-sourced workers, we annotate a corpus of narrative text paragraphs with writing mode labels. Classifiers trained on this data achieve an average accuracy of ~87% on held-out data. We fine-tune a set of large language models to condition on writing mode labels, and show that the generated text is recognized as belonging to the specified mode with high accuracy. To study the ability of writing modes to provide fine-grained control over generated text, we devise a novel turn-based text reconstruction game to evaluate the difference between the generated text and the author’s intention. We show that authors prefer text suggestions made by writing mode-controlled models on average 61.1% of the time, with satisfaction scores 0.5 higher on a 5-point ordinal scale. When evaluated by humans, stories generated via collaboration with writing mode-controlled models achieve high similarity with the professionally written target story. We conclude by identifying the most common mistakes found in the generated stories.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.128.pdf"
    },
    {
        "title": "Robustness Challenges in Model Distillation and Pruning for Natural Language Understanding",
        "authors": [
            "Mengnan Du",
            "Subhabrata Mukherjee",
            "Yu Cheng",
            "Milad Shokouhi",
            "Xia Hu",
            "Ahmed Hassan Awadallah"
        ],
        "published": "2023",
        "summary": "Recent work has focused on compressing pre-trained language models (PLMs) like BERT where the major focus has been to improve the in-distribution performance for downstream tasks. However, very few of these studies have analyzed the impact of compression on the generalizability and robustness of compressed models for out-of-distribution (OOD) data. Towards this end, we study two popular model compression techniques including knowledge distillation and pruning and show that the compressed models are significantly less robust than their PLM counterparts on OOD test sets although they obtain similar performance on in-distribution development sets for a task. Further analysis indicates that the compressed models overfit on the shortcut samples and generalize poorly on the hard ones. We further leverage this observation to develop a regularization strategy for robust model compression based on sample uncertainty.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.129.pdf"
    },
    {
        "title": "Unified Neural Topic Model via Contrastive Learning and Term Weighting",
        "authors": [
            "Sungwon Han",
            "Mingi Shin",
            "Sungkyu Park",
            "Changwook Jung",
            "Meeyoung Cha"
        ],
        "published": "2023",
        "summary": "Two types of topic modeling predominate: generative methods that employ probabilistic latent models and clustering methods that identify semantically coherent groups. This paper newly presents UTopic (Unified neural Topic model via contrastive learning and term weighting) that combines the advantages of these two types. UTopic uses contrastive learning and term weighting to learn knowledge from a pretrained language model and discover influential terms from semantically coherent clusters. Experiments show that the generated topics have a high-quality topic-word distribution in terms of topic coherence, outperforming existing baselines across multiple topic coherence measures. We demonstrate how our model can be used as an add-on to existing topic models and improve their performance.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.132.pdf"
    },
    {
        "title": "The Devil is in the Details: On Models and Training Regimes for Few-Shot Intent Classification",
        "authors": [
            "Mohsen Mesgar",
            "Thy Thy Tran",
            "Goran Glavaš",
            "Iryna Gurevych"
        ],
        "published": "2023",
        "summary": "In task-oriented dialog (ToD) new intents emerge on regular basis, with a handful of available utterances at best. This renders effective Few-Shot Intent Classification (FSIC) a central challenge for modular ToD systems. Recent FSIC methods appear to be similar: they use pretrained language models (PLMs) to encode utterances and predominantly resort to nearest-neighbor-based inference. However, they also differ in major components: they start from different PLMs, use different encoding architectures and utterance similarity functions, and adopt different training regimes. Coupling of these vital components together with the lack of informative ablations prevents the identification of factors that drive the (reported) FSIC performance. We propose a unified framework to evaluate these components along the following key dimensions:(1) Encoding architectures: Cross-Encoder vs Bi-Encoders;(2) Similarity function: Parameterized (i.e., trainable) vs non-parameterized; (3) Training regimes: Episodic meta-learning vs conventional (i.e., non-episodic) training. Our experimental results on seven FSIC benchmarks reveal three new important findings. First, the unexplored combination of cross-encoder architecture and episodic meta-learning consistently yields the best FSIC performance. Second, episodic training substantially outperforms its non-episodic counterpart. Finally, we show that splitting episodes into support and query sets has a limited and inconsistent effect on performance. Our findings show the importance of ablations and fair comparisons in FSIC. We publicly release our code and data.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.135.pdf"
    },
    {
        "title": "Synthesizing Human Gaze Feedback for Improved NLP Performance",
        "authors": [
            "Varun Khurana",
            "Yaman Kumar",
            "Nora Hollenstein",
            "Rajesh Kumar",
            "Balaji Krishnamurthy"
        ],
        "published": "2023",
        "summary": "Integrating human feedback in models can improve the performance of natural language processing (NLP) models. Feedback can be either explicit (e.g. ranking used in training language models) or implicit (e.g. using human cognitive signals in the form of eyetracking). Prior eye tracking and NLP research reveal that cognitive processes, such as human scanpaths, gleaned from human gaze patterns aid in the understanding and performance of NLP models. However, the collection of real eyetracking data for NLP tasks is challenging due to the requirement of expensive and precise equipment coupled with privacy invasion issues. To address this challenge, we propose ScanTextGAN, a novel model for generating human scanpaths over text. We show that ScanTextGAN-generated scanpaths can approximate meaningful cognitive signals in human gaze patterns. We include synthetically generated scanpaths in four popular NLP tasks spanning six different datasets as proof of concept and show that the models augmented with generated scanpaths improve the performance of all downstream NLP tasks.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.139.pdf"
    },
    {
        "title": "Extracting Victim Counts from Text",
        "authors": [
            "Mian Zhong",
            "Shehzaad Dhuliawala",
            "Niklas Stoehr"
        ],
        "published": "2023",
        "summary": "Decision-makers in the humanitarian sector rely on timely and exact information during crisis events. Knowing how many civilians were injured during an earthquake is vital to allocate aids properly. Information about such victim counts are however often only available within full-text event descriptions from newspapers and other reports. Extracting numbers from text is challenging: numbers have different formats and may require numeric reasoning. This renders purely tagging approaches insufficient. As a consequence, fine-grained counts of injured, displaced, or abused victims beyond fatalities are often not extracted and remain unseen. We cast victim count extraction as a question answering (QA) task with a regression or classification objective. We compare tagging approaches: regex, dependency parsing, semantic role labeling, and advanced text-to-text models. Beyond model accuracy, we analyze extraction reliability and robustness which are key for this sensitive task. In particular, we discuss model calibration and investigate out-of-distribution and few-shot performance. Ultimately, we make a comprehensive recommendation on which model to select for different desiderata and data domains. Our work is among the first to apply numeracy-focused large language models in a real-world use case with a positive impact.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.141.pdf"
    },
    {
        "title": "Task and Sentiment Adaptation for Appraisal Tagging",
        "authors": [
            "Lin Tian",
            "Xiuzhen Zhang",
            "Myung Hee Kim",
            "Jennifer Biggs"
        ],
        "published": "2023",
        "summary": "The Appraisal framework in linguistics defines the framework for fine-grained evaluations and opinions and has contributed to sentiment analysis and opinion mining. As developing appraisal-annotated resources requires tagging of several dimensions with distinct semantic taxonomies, it has been primarily conducted manually by human experts through expensive and time-consuming processes. In this paper, we study how to automatically identify and annotate text segments for appraisal. We formulate the problem as a sequence tagging problem and propose novel task and sentiment adapters based on language models for appraisal tagging. Our model, named Adaptive Appraisal (Aˆ2), achieves superior performance than baseline adapter-based models and other neural classification models, especially for cross-domain and cross-language settings. Source code for Aˆ2 is available at: https://github.com/ltian678/AA-code.git",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.144.pdf"
    },
    {
        "title": "Step by Step Loss Goes Very Far: Multi-Step Quantization for Adversarial Text Attacks",
        "authors": [
            "Piotr Gaiński",
            "Klaudia Bałazy"
        ],
        "published": "2023",
        "summary": "We propose a novel gradient-based attack against transformer-based language models that searches for an adversarial example in a continuous space of tokens probabilities. Our algorithm mitigates the gap between adversarial loss for continuous and discrete text representations by performing multi-step quantization in a quantization-compensation loop. Experiments show that our method significantly outperforms other approaches on various natural language processing (NLP) tasks.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.149.pdf"
    },
    {
        "title": "ZELDA: A Comprehensive Benchmark for Supervised Entity Disambiguation",
        "authors": [
            "Marcel Milich",
            "Alan Akbik"
        ],
        "published": "2023",
        "summary": "Entity disambiguation (ED) is the task of disambiguating named entity mentions in text to unique entries in a knowledge base. Due to its industrial relevance, as well as current progress in leveraging pre-trained language models, a multitude of ED approaches have been proposed in recent years. However, we observe a severe lack of uniformity across experimental setups in current ED work,rendering a direct comparison of approaches based solely on reported numbers impossible: Current approaches widely differ in the data set used to train, the size of the covered entity vocabulary, and the usage of additional signals such as candidate lists. To address this issue, we present ZELDA , a novel entity disambiguation benchmark that includes a unified training data set, entity vocabulary, candidate lists, as well as challenging evaluation splits covering 8 different domains. We illustrate its design and construction, and present experiments in which we train and compare current state-of-the-art approaches on our benchmark. To encourage greater direct comparability in the entity disambiguation domain, we make our benchmark publicly available to the research community.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.151.pdf"
    },
    {
        "title": "GLADIS: A General and Large Acronym Disambiguation Benchmark",
        "authors": [
            "Lihu Chen",
            "Gael Varoquaux",
            "Fabian M. Suchanek"
        ],
        "published": "2023",
        "summary": "Acronym Disambiguation (AD) is crucial for natural language understanding on various sources, including biomedical reports, scientific papers, and search engine queries. However, existing acronym disambiguationbenchmarks and tools are limited to specific domains, and the size of prior benchmarks is rather small. To accelerate the research on acronym disambiguation, we construct a new benchmark with three components: (1) a much larger acronym dictionary with 1.5M acronyms and 6.4M long forms; (2) a pre-training corpus with 160 million sentences;(3) three datasets that cover thegeneral, scientific, and biomedical domains. We then pre-train a language model, AcroBERT, on our constructed corpus for general acronym disambiguation, and show the challenges and values of our new benchmark.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.152.pdf"
    },
    {
        "title": "Probing Cross-Lingual Lexical Knowledge from Multilingual Sentence Encoders",
        "authors": [
            "Ivan Vulić",
            "Goran Glavaš",
            "Fangyu Liu",
            "Nigel Collier",
            "Edoardo Maria Ponti",
            "Anna Korhonen"
        ],
        "published": "2023",
        "summary": "Pretrained multilingual language models (LMs) can be successfully transformed into multilingual sentence encoders (SEs; e.g., LaBSE, xMPNet) via additional fine-tuning or model distillation with parallel data. However, it remains unclear how to best leverage them to represent sub-sentence lexical items (i.e., words and phrases) in cross-lingual lexical tasks. In this work, we probe SEs for the amount of cross-lingual lexical knowledge stored in their parameters, and compare them against the original multilingual LMs. We also devise a simple yet efficient method for exposing the cross-lingual lexical knowledge by means of additional fine-tuning through inexpensive contrastive learning that requires only a small amount of word translation pairs. Using bilingual lexical induction (BLI), cross-lingual lexical semantic similarity, and cross-lingual entity linking as lexical probing tasks, we report substantial gains on standard benchmarks (e.g., +10 Precision@1 points in BLI). The results indicate that the SEs such as LaBSE can be ‘rewired’ into effective cross-lingual lexical encoders via the contrastive learning procedure, and that it is possible to expose more cross-lingual lexical knowledge compared to using them as off-the-shelf SEs. This way, we also provide an effective tool for harnessing ‘covert’ multilingual lexical knowledge hidden in multilingual sentence encoders.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.153.pdf"
    },
    {
        "title": "Plausible May Not Be Faithful: Probing Object Hallucination in Vision-Language Pre-training",
        "authors": [
            "Wenliang Dai",
            "Zihan Liu",
            "Ziwei Ji",
            "Dan Su",
            "Pascale Fung"
        ],
        "published": "2023",
        "summary": "Large-scale vision-language pre-trained (VLP) models are prone to hallucinate non-existent visual objects when generating text based on visual information. In this paper, we systematically study the object hallucination problem from three aspects. First, we examine recent state-of-the-art VLP models, showing that they still hallucinate frequently and models achieving better scores on standard metrics (e.g., CIDEr) could be more unfaithful. Second, we investigate how different types of image encoding in VLP influence hallucination, including region-based, grid-based, and patch-based. Surprisingly, we find that patch-based features perform the best and smaller patch resolution yields a non-trivial reduction in object hallucination. Third, we decouple various VLP objectives and demonstrate that token-level image-text alignment and controlled generation are crucial to reducing hallucination. Based on that, we propose a simple yet effective VLP loss named ObjMLM to further mitigate object hallucination. Results show that it reduces object hallucination by up to 17.4% when tested on two benchmarks (COCO Caption for in-domain and NoCaps for out-of-domain evaluation).",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.156.pdf"
    },
    {
        "title": "Measuring Normative and Descriptive Biases in Language Models Using Census Data",
        "authors": [
            "Samia Touileb",
            "Lilja Øvrelid",
            "Erik Velldal"
        ],
        "published": "2023",
        "summary": "We investigate in this paper how distributions of occupations with respect to gender is reflected in pre-trained language models. Such distributions are not always aligned to normative ideals, nor do they necessarily reflect a descriptive assessment of reality. In this paper, we introduce an approach for measuring to what degree pre-trained language models are aligned to normative and descriptive occupational distributions. To this end, we use official demographic information about gender–occupation distributions provided by the national statistics agencies of France, Norway, United Kingdom, and the United States. We manually generate template-based sentences combining gendered pronouns and nouns with occupations, and subsequently probe a selection of ten language models covering the English, French, and Norwegian languages. The scoring system we introduce in this work is language independent, and can be used on any combination of template-based sentences, occupations, and languages. The approach could also be extended to other dimensions of national census data and other demographic variables.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.164.pdf"
    },
    {
        "title": "UDAPTER - Efficient Domain Adaptation Using Adapters",
        "authors": [
            "Bhavitvya Malik",
            "Abhinav Ramesh Kashyap",
            "Min-Yen Kan",
            "Soujanya Poria"
        ],
        "published": "2023",
        "summary": "We propose two methods to make unsupervised domain adaptation (UDA) more parameter efficient using adapters – small bottleneck layers interspersed with every layer of the large-scale pre-trained language model (PLM). The first method deconstructs UDA into a two-step process: first by adding a domain adapter to learn domain-invariant information and then by adding a task adapter that uses domain-invariant information to learn task representations in the source domain. The second method jointly learns a supervised classifier while reducing the divergence measure. Compared to strong baselines, our simple methods perform well in natural language inference (MNLI) and the cross-domain sentiment classification task. We even outperform unsupervised domain adaptation methods such as DANN and DSN in sentiment classification, and we are within 0.85% F1 for natural language inference task, by fine-tuning only a fraction of the full model parameters. We release our code at this URL.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.165.pdf"
    },
    {
        "title": "Exploring Category Structure with Contextual Language Models and Lexical Semantic Networks",
        "authors": [
            "Joseph Renner",
            "Pascal Denis",
            "Remi Gilleron",
            "Angèle Brunellière"
        ],
        "published": "2023",
        "summary": "The psychological plausibility of word embeddings has been studied through different tasks such as word similarity, semantic priming, and lexical entailment. Recent work on predicting category structure with word embeddings report low correlations with human ratings. (Heyman and Heyman, 2019) showed that static word embeddings fail at predicting typicality using cosine similarity between category and exemplar words, while (Misra et al., 2021)obtain equally modest results for various contextual language models (CLMs) using a Cloze task formulation over hand-crafted taxonomic sentences. In this work, we test a wider array of methods for probing CLMs for predicting typicality scores. Our experiments, using BERT (Devlin et al., 2018), show the importance of using the right type of CLM probes, as our best BERT-based typicality prediction methods improve on previous works. Second, our results highlight the importance of polysemy in this task, as our best results are obtained when contextualization is paired with a disambiguation mechanism as in (Chronis and Erk, 2020). Finally, additional experiments and analyses reveal that Information Content-based WordNet (Miller, 1995) similarities with disambiguation match the performance of the best BERT-based method, and in fact capture complementary information, and when combined with BERT allow for enhanced typicality predictions.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.167.pdf"
    },
    {
        "title": "An Empirical Study of Clinical Note Generation from Doctor-Patient Encounters",
        "authors": [
            "Asma Ben Abacha",
            "Wen-wai Yim",
            "Yadan Fan",
            "Thomas Lin"
        ],
        "published": "2023",
        "summary": "Medical doctors spend on average 52 to 102 minutes per day writing clinical notes from their patient encounters (Hripcsak et al., 2011). Reducing this workload calls for relevant and efficient summarization methods. In this paper, we introduce new resources and empirical investigations for the automatic summarization of doctor-patient conversations in a clinical setting. In particular, we introduce the MTS-Dialog dataset; a new collection of 1,700 doctor-patient dialogues and corresponding clinical notes. We use this new dataset to investigate the feasibility of this task and the relevance of existing language models, data augmentation, and guided summarization techniques. We compare standard evaluation metrics based on n-gram matching, contextual embeddings, and Fact Extraction to assess the accuracy and the factual consistency of the generated summaries. To ground these results, we perform an expert-based evaluation using relevant natural language generation criteria and task-specific criteria such as critical omissions, and study the correlation between the automatic metrics and expert judgments. To the best of our knowledge, this study is the first attempt to introduce an open dataset of doctor-patient conversations and clinical notes, with detailed automated and manual evaluations of clinical note generation.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.168.pdf"
    },
    {
        "title": "Opportunities and Challenges in Neural Dialog Tutoring",
        "authors": [
            "Jakub Macina",
            "Nico Daheim",
            "Lingzhi Wang",
            "Tanmay Sinha",
            "Manu Kapur",
            "Iryna Gurevych",
            "Mrinmaya Sachan"
        ],
        "published": "2023",
        "summary": "Designing dialog tutors has been challenging as it involves modeling the diverse and complex pedagogical strategies employed by human tutors. Although there have been significant recent advances in neural conversational systems using large language models and growth in available dialog corpora, dialog tutoring has largely remained unaffected by these advances. In this paper, we rigorously analyze various generative language models on two dialog tutoring datasets for language learning using automatic and human evaluations to understand the new opportunities brought by these advances as well as the challenges we must overcome to build models that would be usable in real educational settings. We find that although current approaches can model tutoring in constrained learning scenarios when the number of concepts to be taught and possible teacher strategies are small, they perform poorly in less constrained scenarios. Our human quality evaluation shows that both models and ground-truth annotations exhibit low performance in terms of equitable tutoring, which measures learning opportunities for students and how engaging the dialog is. To understand the behavior of our models in a real tutoring setting, we conduct a user study using expert annotators and find a significantly large number of model reasoning errors in 45% of conversations. Finally, we connect our findings to outline future work.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.173.pdf"
    },
    {
        "title": "Evaluating the Robustness of Discrete Prompts",
        "authors": [
            "Yoichi Ishibashi",
            "Danushka Bollegala",
            "Katsuhito Sudoh",
            "Satoshi Nakamura"
        ],
        "published": "2023",
        "summary": "Discrete prompts have been used for fine-tuning Pre-trained Language Models for diverse NLP tasks. In particular, automatic methods that generate discrete prompts from a small set of training instances have reported superior performance. However, a closer look at the learnt prompts reveals that they contain noisy and counter-intuitive lexical constructs that would not be encountered in manually-written prompts. This raises an important yet understudied question regarding the robustness of automatically learnt discrete prompts when used in downstream tasks. To address this question, we conduct a systematic study of the robustness of discrete prompts by applying carefully designed perturbations into an application using AutoPrompt and then measure their performance in two Natural Language Inference (NLI) datasets. Our experimental results show that although the discrete prompt-based method remains relatively robust against perturbations to NLI inputs, they are highly sensitive to other types of perturbations such as shuffling and deletion of prompt tokens. Moreover, they generalize poorly across different NLI datasets. We hope our findings will inspire future work on robust discrete prompt learning.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.174.pdf"
    },
    {
        "title": "Assessing Out-of-Domain Language Model Performance from Few Examples",
        "authors": [
            "Prasann Singhal",
            "Jarad Forristal",
            "Xi Ye",
            "Greg Durrett"
        ],
        "published": "2023",
        "summary": "While pretrained language models have exhibited impressive generalization capabilities, they still behave unpredictably under certain domain shifts. In particular, a model may learn a reasoning process on in-domain training data that does not hold for out-of-domain test data. We address the task of predicting out-of-domain (OOD) performance in a few-shot fashion: given a few target-domain examples and a set of models with similar training performance, can we understand how these models will perform on OOD test data? We benchmark the performance on this task when looking at model accuracy on the few-shot examples, then investigate how to incorporate analysis of the models’ behavior using feature attributions to better tackle this problem. Specifically, we explore a set of factors designed to reveal model agreement with certain pathological heuristics that may indicate worse generalization capabilities. On textual entailment, paraphrase recognition, and a synthetic classification task, we show that attribution-based factors can help rank relative model OOD performance. However, accuracy on a few-shot test set is a surprisingly strong baseline, particularly when the system designer does not have in-depth prior knowledge about the domain shift.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.175.pdf"
    },
    {
        "title": "Mind the Labels: Describing Relations in Knowledge Graphs With Pretrained Models",
        "authors": [
            "Zdeněk Kasner",
            "Ioannis Konstas",
            "Ondrej Dusek"
        ],
        "published": "2023",
        "summary": "Pretrained language models (PLMs) for data-to-text (D2T) generation can use human-readable data labels such as column headings, keys, or relation names to generalize to out-of-domain examples. However, the models are well-known in producing semantically inaccurate outputs if these labels are ambiguous or incomplete, which is often the case in D2T datasets. In this paper, we expose this issue on the task of descibing a relation between two entities. For our experiments, we collect a novel dataset for verbalizing a diverse set of 1,522 unique relations from three large-scale knowledge graphs (Wikidata, DBPedia, YAGO). We find that although PLMs for D2T generation expectedly fail on unclear cases, models trained with a large variety of relation labels are surprisingly robust in verbalizing novel, unseen relations. We argue that using data with a diverse set of clear and meaningful labels is key to training D2T generation systems capable of generalizing to novel domains.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.176.pdf"
    },
    {
        "title": "Bootstrapping Multilingual Semantic Parsers using Large Language Models",
        "authors": [
            "Abhijeet Awasthi",
            "Nitish Gupta",
            "Bidisha Samanta",
            "Shachi Dave",
            "Sunita Sarawagi",
            "Partha Talukdar"
        ],
        "published": "2023",
        "summary": "Despite cross-lingual generalization demonstrated by pre-trained multilingual models, the translate-train paradigm of transferring English datasets across multiple languages remains to be a key mechanism for training task-specific multilingual models. However, for many low-resource languages, the availability of a reliable translation service entails significant amounts of costly human-annotated translation pairs. Further, translation services may continue to be brittle due to domain mismatch between task-specific input text and general-purpose text used for training translation models. For multilingual semantic parsing, we demonstrate the effectiveness and flexibility offered by large language models (LLMs) for translating English datasets into several languages via few-shot prompting. Through extensive comparisons on two public datasets, MTOP and MASSIVE, spanning 50 languages and several domains, we show that our method of translating data using LLMs outperforms a strong translate-train baseline on 41 out of 50 languages. We study the key design choices that enable more effective multilingual data translation via prompted LLMs.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.180.pdf"
    },
    {
        "title": "MAPL: Parameter-Efficient Adaptation of Unimodal Pre-Trained Models for Vision-Language Few-Shot Prompting",
        "authors": [
            "Oscar Mañas",
            "Pau Rodriguez Lopez",
            "Saba Ahmadi",
            "Aida Nematzadeh",
            "Yash Goyal",
            "Aishwarya Agrawal"
        ],
        "published": "2023",
        "summary": "Large pre-trained models have proved to be remarkable zero- and (prompt-based) few-shot learners in unimodal vision and language tasks. We propose MAPL, a simple and parameter-efficient method that reuses frozen pre-trained unimodal models and leverages their strong generalization capabilities in multimodal vision-language (VL) settings. MAPL learns a lightweight mapping between the representation spaces of unimodal models using aligned image-text data, and can generalize to unseen VL tasks from just a few in-context examples. The small number of trainable parameters makes MAPL effective at low-data and in-domain learning. Moreover, MAPL’s modularity enables easy extension to other pre-trained models. Extensive experiments on several visual question answering and image captioning benchmarks show that MAPL achieves superior or competitive performance compared to similar methods while training orders of magnitude fewer parameters. MAPL can be trained in just a few hours using modest computational resources and public datasets. We release our code and pre-trained model weights at https://github.com/oscmansan/mapl.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.185.pdf"
    },
    {
        "title": "Towards preserving word order importance through Forced Invalidation",
        "authors": [
            "Hadeel Al-Negheimish",
            "Pranava Madhyastha",
            "Alessandra Russo"
        ],
        "published": "2023",
        "summary": "Large pre-trained language models such as BERT have been widely used as a framework for natural language understanding (NLU) tasks. However, recent findings have revealed that pre-trained language models are insensitive to word order. The performance on NLU tasks remains unchanged even after randomly permuting the word of a sentence, where crucial syntactic information is destroyed. To help preserve the importance of word order, we propose a simple approach called Forced Invalidation (FI): forcing the model to identify permuted sequences as invalid samples. We perform an extensive evaluation of our approach on various English NLU and QA based tasks over BERT-based and attention-based models over word embeddings. Our experiments demonstrate that FI significantly improves the sensitivity of the models to word order.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.187.pdf"
    },
    {
        "title": "Penguins Don’t Fly: Reasoning about Generics through Instantiations and Exceptions",
        "authors": [
            "Emily Allaway",
            "Jena D. Hwang",
            "Chandra Bhagavatula",
            "Kathleen McKeown",
            "Doug Downey",
            "Yejin Choi"
        ],
        "published": "2023",
        "summary": "Generics express generalizations about the world (e.g., birds can fly) that are not universally true (e.g., newborn birds and penguins cannot fly). Commonsense knowledge bases, used extensively in NLP, encode some generic knowledge but rarely enumerate such exceptions and knowing when a generic statement holds or does not hold true is crucial for developing a comprehensive understanding of generics. We present a novel framework informed by linguistic theory to generate exemplars—specific cases when a generic holds true or false. We generate ~19k exemplars for ~650 generics and show that our framework outperforms a strong GPT-3 baseline by 12.8 precision points. Our analysis highlights the importance of linguistic theory-based controllability for generating exemplars, the insufficiency of knowledge bases as a source of exemplars, and the challenges exemplars pose for the task of natural language inference.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.192.pdf"
    },
    {
        "title": "Adding Instructions during Pretraining: Effective way of Controlling Toxicity in Language Models",
        "authors": [
            "Shrimai Prabhumoye",
            "Mostofa Patwary",
            "Mohammad Shoeybi",
            "Bryan Catanzaro"
        ],
        "published": "2023",
        "summary": "Pretrained large language models have become indispensable for solving various natural language processing (NLP) tasks. However, safely deploying them in real world applications is challenging because they generate toxic content. To address this challenge, we propose two novel pretraining data augmentation strategies that significantly reduce model toxicity without compromising its utility. Our two strategies are: (1) MEDA: adds raw toxicity score as meta-data to the pretraining samples, and (2) INST: adds instructions to those samples indicating their toxicity. Our results indicate that our best performing strategy (INST) substantially reduces the toxicity probability up to 61% while preserving the accuracy on five benchmark NLP tasks as well as improving AUC scores on four bias detection tasks by 1.3%. We also demonstrate the generalizability of our techniques by scaling the number of training samples and the number of model parameters.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.193.pdf"
    },
    {
        "title": "SwitchPrompt: Learning Domain-Specific Gated Soft Prompts for Classification in Low-Resource Domains",
        "authors": [
            "Koustava Goswami",
            "Lukas Lange",
            "Jun Araki",
            "Heike Adel"
        ],
        "published": "2023",
        "summary": "Prompting pre-trained language models leads to promising results across natural language processing tasks but is less effective when applied in low-resource domains, due to the domain gap between the pre-training data and the downstream task. In this work, we bridge this gap with a novel and lightweight prompting methodology called SwitchPrompt for the adaptation of language models trained on datasets from the general domain to diverse low-resource domains. Using domain-specific keywords with a trainable gated prompt, SwitchPrompt offers domain-oriented prompting, that is, effective guidance on the target domains for general-domain language models. Our few-shot experiments on three text classification benchmarks demonstrate the efficacy of the general-domain pre-trained language models when used with SwitchPrompt. They often even outperform their domain-specific counterparts trained with baseline state-of-the-art prompting methods by up to 10.7% performance increase in accuracy. This result indicates that SwitchPrompt effectively reduces the need for domain-specific language model pre-training.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.197.pdf"
    },
    {
        "title": "Do dialogue representations align with perception? An empirical study",
        "authors": [
            "Sarenne Wallbridge",
            "Peter Bell",
            "Catherine Lai"
        ],
        "published": "2023",
        "summary": "There has been a surge of interest regarding the alignment of large-scale language models with human language comprehension behaviour. The majority of this research investigates comprehension behaviours from reading isolated, written sentences. We propose studying the perception of dialogue, focusing on an intrinsic form of language use: spoken conversations. Using the task of predicting upcoming dialogue turns, we ask whether turn plausibility scores produced by state-of-the-art language models correlate with human judgements. We find a strong correlation for some but not all models: masked language models produce stronger correlations than auto-regressive models. In doing so, we quantify human performance on the response selection task for open-domain spoken conversation. To the best of our knowledge, this is the first such quantification. We find that response selection performance can be used as a coarse proxy for the strength of correlation with human judgements, however humans and models make different response selection mistakes. The model which produces the strongest correlation also outperforms human response selection performance. Through ablation studies, we show that pre-trained language models provide a useful basis for turn representations; however, fine-grained contextualisation, inclusion of dialogue structure information, and fine-tuning towards response selection all boost response selection accuracy by over 30 absolute points.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.198.pdf"
    },
    {
        "title": "Methods for Measuring, Updating, and Visualizing Factual Beliefs in Language Models",
        "authors": [
            "Peter Hase",
            "Mona Diab",
            "Asli Celikyilmaz",
            "Xian Li",
            "Zornitsa Kozareva",
            "Veselin Stoyanov",
            "Mohit Bansal",
            "Srinivasan Iyer"
        ],
        "published": "2023",
        "summary": "Language models can memorize a considerable amount of factual information during pretraining that can be elicited through prompting or finetuning models on tasks like question answering. In this paper, we discuss approaches to measuring model factual beliefs, updating incorrect factual beliefs in models, and visualizing graphical relationships between factual beliefs. Our main contributions include: (1) new metrics for evaluating belief-updating methods focusing on the logical consistency of beliefs, (2) a training objective for Sequential, Local, and Generalizing updates (SLAG) that improves the performance of existing hypernetwork approaches, and (3) the introduction of the belief graph, a new form of visualization for language models that shows relationships between stored model beliefs. Our experiments suggest that models show only limited consistency between factual beliefs, but update methods can both fix incorrect model beliefs and greatly improve their consistency. Although off-the-shelf optimizers are surprisingly strong belief-updating baselines, our learned optimizers can outperform them in more difficult settings than have been considered in past work.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.199.pdf"
    },
    {
        "title": "Parameter-efficient Modularised Bias Mitigation via AdapterFusion",
        "authors": [
            "Deepak Kumar",
            "Oleg Lesota",
            "George Zerveas",
            "Daniel Cohen",
            "Carsten Eickhoff",
            "Markus Schedl",
            "Navid Rekabsaz"
        ],
        "published": "2023",
        "summary": "Large pre-trained language models contain societal biases and carry along these biases to downstream tasks. Current in-processing bias mitigation approaches (like adversarial training) impose debiasing by updating a model’s parameters, effectively transferring the model to a new, irreversible debiased state. In this work, we propose a novel approach to develop stand-alone debiasing functionalities separate from the model, which can be integrated into the model on-demand, while keeping the core model untouched. Drawing from the concept of AdapterFusion in multi-task learning, we introduce DAM (Debiasing with Adapter Modules) – a debiasing approach to first encapsulate arbitrary bias mitigation functionalities into separate adapters, and then add them to the model on-demand in order to deliver fairness qualities. We conduct a large set of experiments on three classification tasks with gender, race, and age as protected attributes. Our results show that DAM improves or maintains the effectiveness of bias mitigation, avoids catastrophic forgetting in a multi-attribute scenario, and maintains on-par task performance, while granting parameter-efficiency and easy switching between the original and debiased models.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.201.pdf"
    },
    {
        "title": "Behavior Cloned Transformers are Neurosymbolic Reasoners",
        "authors": [
            "Ruoyao Wang",
            "Peter Jansen",
            "Marc-Alexandre Côté",
            "Prithviraj Ammanabrolu"
        ],
        "published": "2023",
        "summary": "In this work, we explore techniques for augmenting interactive agents with information from symbolic modules, much like humans use tools like calculators and GPS systems to assist with arithmetic and navigation. We test our agent’s abilities in text games – challenging benchmarks for evaluating the multi-step reasoning abilities of game agents in grounded, language-based environments. Our experimental study indicates that injecting the actions from these symbolic modules into the action space of a behavior cloned transformer agent increases performance on four text game benchmarks that test arithmetic, navigation, sorting, and common sense reasoning by an average of 22%, allowing an agent to reach the highest possible performance on unseen games. This action injection technique is easily extended to new agents, environments, and symbolic modules.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.204.pdf"
    },
    {
        "title": "The StatCan Dialogue Dataset: Retrieving Data Tables through Conversations with Genuine Intents",
        "authors": [
            "Xing Han Lu",
            "Siva Reddy",
            "Harm de Vries"
        ],
        "published": "2023",
        "summary": "We introduce the StatCan Dialogue Dataset consisting of 19,379 conversation turns between agents working at Statistics Canada and online users looking for published data tables. The conversations stem from genuine intents, are held in English or French, and lead to agents retrieving one of over 5000 complex data tables. Based on this dataset, we propose two tasks: (1) automatic retrieval of relevant tables based on a on-going conversation, and (2) automatic generation of appropriate agent responses at each turn. We investigate the difficulty of each task by establishing strong baselines. Our experiments on a temporal data split reveal that all models struggle to generalize to future conversations, as we observe a significant drop in performance across both tasks when we move from the validation to the test set. In addition, we find that response generation models struggle to decide when to return a table. Considering that the tasks pose significant challenges to existing models, we encourage the community to develop models for our task, which can be directly used to help knowledge workers find relevant tables for live chat users.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.206.pdf"
    },
    {
        "title": "StyLEx: Explaining Style Using Human Lexical Annotations",
        "authors": [
            "Shirley Anugrah Hayati",
            "Kyumin Park",
            "Dheeraj Rajagopal",
            "Lyle Ungar",
            "Dongyeop Kang"
        ],
        "published": "2023",
        "summary": "Large pre-trained language models have achieved impressive results on various style classification tasks, but they often learn spurious domain-specific words to make predictions (Hayati et al., 2021). While human explanation highlights stylistic tokens as important features for this task, we observe that model explanations often do not align with them. To tackle this issue, we introduce StyLEx, a model that learns from human annotated explanations of stylistic features and jointly learns to perform the task and predict these features as model explanations. Our experiments show that StyLEx can provide human like stylistic lexical explanations without sacrificing the performance of sentence-level style prediction on both in-domain and out-of-domain datasets. Explanations from StyLEx show significant improvements in explanation metrics (sufficiency, plausibility) and when evaluated with human annotations. They are also more understandable by human judges compared to the widely-used saliency-based explanation baseline.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.208.pdf"
    },
    {
        "title": "Comparing Intrinsic Gender Bias Evaluation Measures without using Human Annotated Examples",
        "authors": [
            "Masahiro Kaneko",
            "Danushka Bollegala",
            "Naoaki Okazaki"
        ],
        "published": "2023",
        "summary": "Numerous types of social biases have been identified in pre-trained language models (PLMs), and various intrinsic bias evaluation measures have been proposed for quantifying those social biases. Prior works have relied on human annotated examples to compare existing intrinsic bias evaluation measures. However, this approach is not easily adaptable to different languages nor amenable to large scale evaluations due to the costs and difficulties when recruiting human annotators. To overcome this limitation, we propose a method to compare intrinsic gender bias evaluation measures without relying on human-annotated examples. Specifically, we create multiple bias-controlled versions of PLMs using varying amounts of male vs. female gendered sentences, mined automatically from an unannotated corpus using gender-related word lists. Next, each bias-controlled PLM is evaluated using an intrinsic bias evaluation measure, and the rank correlation between the computed bias scores and the gender proportions used to fine-tune the PLMs is computed. Experiments on multiple corpora and PLMs repeatedly show that the correlations reported by our proposed method that does not require human annotated examples are comparable to those computed using human annotated examples in prior work.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.209.pdf"
    },
    {
        "title": "Dynamic Benchmarking of Masked Language Models on Temporal Concept Drift with Multiple Views",
        "authors": [
            "Katerina Margatina",
            "Shuai Wang",
            "Yogarshi Vyas",
            "Neha Anna John",
            "Yassine Benajiba",
            "Miguel Ballesteros"
        ],
        "published": "2023",
        "summary": "Temporal concept drift refers to the problem of data changing over time. In the field of NLP, that would entail that language (e.g. new expressions, meaning shifts) and factual knowledge (e.g. new concepts, updated facts) evolve over time. Focusing on the latter, we benchmark 11 pretrained masked language models (MLMs) on a series of tests designed to evaluate the effect of temporal concept drift, as it is crucial that widely used language models remain up-to-date with the ever-evolving factual updates of the real world. Specifically, we provide a holistic framework that (1) dynamically creates temporal test sets of any time granularity (e.g. month, quarter, year) of factual data from Wikidata, (2) constructs fine-grained splits of tests (e.g. updated, new, unchanged facts) to ensure comprehensive analysis, and (3) evaluates MLMs in three distinct ways (single-token probing, multi-token generation, MLM scoring). In contrast to prior work, our framework aims to unveil how robust an MLM is over time and thus to provide a signal in case it has become outdated, by leveraging multiple views of evaluation.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.211.pdf"
    },
    {
        "title": "Real-Time Visual Feedback to Guide Benchmark Creation: A Human-and-Metric-in-the-Loop Workflow",
        "authors": [
            "Anjana Arunkumar",
            "Swaroop Mishra",
            "Bhavdeep Singh Sachdeva",
            "Chitta Baral",
            "Chris Bryan"
        ],
        "published": "2023",
        "summary": "Recent research has shown that language models exploit ‘artifacts’ in benchmarks to solve tasks, rather than truly learning them, leading to inflated model performance. In pursuit of creating better benchmarks, we propose VAIDA, a novel benchmark creation paradigm for NLP, that focuses on guiding crowdworkers, an under-explored facet of addressing benchmark idiosyncrasies. VAIDA facilitates sample correction by providing realtime visual feedback and recommendations to improve sample quality. Our approach is domain, model, task, and metric agnostic, and constitutes a paradigm shift for robust, validated, and dynamic benchmark creation via human-and-metric-in-the-loop workflows. We evaluate via expert review and a user study with NASA TLX. We find that VAIDA decreases effort, frustration, mental, and temporal demands of crowdworkers and analysts, simultaneously increasing the performance of both user groups with a 45.8% decrease in the level of artifacts in created samples. As a by product of our user study, we observe that created samples are adversarial across models, leading to decreases of 31.3% (BERT), 22.5% (RoBERTa), 14.98% (GPT-3 fewshot) in performance.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.212.pdf"
    },
    {
        "title": "COMPS: Conceptual Minimal Pair Sentences for testing Robust Property Knowledge and its Inheritance in Pre-trained Language Models",
        "authors": [
            "Kanishka Misra",
            "Julia Rayz",
            "Allyson Ettinger"
        ],
        "published": "2023",
        "summary": "A characteristic feature of human semantic cognition is its ability to not only store and retrieve the properties of concepts observed through experience, but to also facilitate the inheritance of properties (can breathe) from superordinate concepts (animal) to their subordinates (dog)—i.e. demonstrate property inheritance. In this paper, we present COMPS, a collection of minimal pair sentences that jointly tests pre-trained language models (PLMs) on their ability to attribute properties to concepts and their ability to demonstrate property inheritance behavior. Analyses of 22 different PLMs on COMPS reveal that they can easily distinguish between concepts on the basis of a property when they are trivially different, but find it relatively difficult when concepts are related on the basis of nuanced knowledge representations. Furthermore, we find that PLMs can show behaviors suggesting successful property inheritance in simple contexts, but fail in the presence of distracting information, which decreases the performance of many models sometimes even below chance. This lack of robustness in demonstrating simple reasoning raises important questions about PLMs’ capacity to make correct inferences even when they appear to possess the prerequisite knowledge.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.213.pdf"
    },
    {
        "title": "Unsupervised Improvement of Factual Knowledge in Language Models",
        "authors": [
            "Nafis Sadeq",
            "Byungkyu Kang",
            "Prarit Lamba",
            "Julian McAuley"
        ],
        "published": "2023",
        "summary": "Masked language modeling (MLM) plays a key role in pretraining large language models. But the MLM objective is often dominated by high-frequency words that are sub-optimal for learning factual knowledge. In this work, we propose an approach for influencing MLM pretraining in a way that can improve language model performance on a variety of knowledge-intensive tasks. We force the language model to prioritize informative words in a fully unsupervised way. Experiments demonstrate that the proposed approach can significantly improve the performance of pretrained language models on tasks such as factual recall, question answering, sentiment analysis, and natural language inference in a closed-book setting.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.215.pdf"
    },
    {
        "title": "Should You Mask 15% in Masked Language Modeling?",
        "authors": [
            "Alexander Wettig",
            "Tianyu Gao",
            "Zexuan Zhong",
            "Danqi Chen"
        ],
        "published": "2023",
        "summary": "Masked language models (MLMs) conventionally mask 15% of tokens due to the belief that more masking would leave insufficient context to learn good representations; this masking rate has been widely used, regardless of model sizes or masking strategies. In this work, we revisit this important choice of MLM pre-training. We first establish that 15% is not universally optimal, and larger models should adopt a higher masking rate. Specifically, we find that masking 40% outperforms 15% for BERT-large size models on GLUE and SQuAD. Interestingly, an extremely high masking rate of 80% can still preserve 95% fine-tuning performance and most of the accuracy in linguistic probing, challenging the conventional wisdom about the role of the masking rate. We then examine the interplay between masking rates and masking strategies and find that uniform masking requires a higher masking rate compared to sophisticated masking strategies such as span or PMI masking. Finally, we argue that increasing the masking rate has two distinct effects: it leads to more corruption, which makes the prediction task more difficult; it also enables more predictions, which benefits optimization. Using this framework, we revisit BERT’s 80-10-10 corruption strategy. Together, our results contribute to a better understanding of MLM pre-training.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.217.pdf"
    },
    {
        "title": "Incorporating Task-Specific Concept Knowledge into Script Learning",
        "authors": [
            "Chenkai Sun",
            "Tie Xu",
            "ChengXiang Zhai",
            "Heng Ji"
        ],
        "published": "2023",
        "summary": "In this paper, we present Tetris, a new task of Goal-Oriented Script Completion. Unlike previous work, it considers a more realistic and general setting, where the input includes not only the goal but also additional user context, including preferences and history. To address this problem, we propose a novel approach, which uses two techniques to improve performance: (1) concept prompting, and (2) script-oriented contrastive learning that addresses step repetition and hallucination problems. On our WikiHow-based dataset, we find that both methods improve performance.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.220.pdf"
    },
    {
        "title": "Salient Span Masking for Temporal Understanding",
        "authors": [
            "Jeremy R. Cole",
            "Aditi Chaudhary",
            "Bhuwan Dhingra",
            "Partha Talukdar"
        ],
        "published": "2023",
        "summary": "Salient Span Masking (SSM) has shown itself to be an effective strategy to improve closed-book question answering performance. SSM extends general masked language model pretraining by creating additional unsupervised training sentences that mask a single entity or date span, thus oversampling factual information. Despite the success of this paradigm, the span types and sampling strategies are relatively arbitrary and not widely studied for other tasks. Thus, we investigate SSM from the perspective of temporal tasks, where learning a good representation of various temporal expressions is important. To that end, we introduce Temporal Span Masking (TSM) intermediate training. First, we find that SSM alone improves the downstream performance on three temporal tasks by an avg. +5.8 points. Further, we are able to achieve additional improvements (avg. +0.29 points) by adding the TSM task. These comprise the new best reported results on the targeted tasks. Our analysis suggests that the effectiveness of SSM stems from the sentences chosen in the training data rather than the mask choice: sentences with entities frequently also contain temporal expressions. Nonetheless, the additional targeted spans of TSM can still improve performance, especially in a zero-shot context.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.222.pdf"
    },
    {
        "title": "Contextual Dynamic Prompting for Response Generation in Task-oriented Dialog Systems",
        "authors": [
            "Sandesh Swamy",
            "Narges Tabari",
            "Chacha Chen",
            "Rashmi Gangadharaiah"
        ],
        "published": "2023",
        "summary": "Response generation is one of the critical components in task-oriented dialog systems. Existing studies have shown that large pre-trained language models can be adapted to this task. The typical paradigm of adapting such extremely large language models would be by fine-tuning on the downstream tasks which is not only time-consuming but also involves significant resources and access to fine-tuning data. Prompting (Schick and Schütze, 2020) has been an alternative to fine-tuning in many NLP tasks. In our work, we explore the idea of using prompting for response generation in task-oriented dialog systems. Specifically, we propose an approach that performs contextual dynamic prompting where the prompts are learnt from dialog contexts. We aim to distill useful prompting signals from the dialog context. On experiments with MultiWOZ 2.2 dataset (Zang et al., 2020), we show that contextual dynamic prompts improve response generation in terms of combined score (Mehri et al., 2019) by 3 absolute points, and an additional 17 points when dialog states are incorporated. Furthermore, we carried out human annotation on these conversations and found that agents which incorporate context are preferred over agents with vanilla prefix-tuning.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.226.pdf"
    },
    {
        "title": "Path Spuriousness-aware Reinforcement Learning for Multi-Hop Knowledge Graph Reasoning",
        "authors": [
            "Chunyang Jiang",
            "Tianchen Zhu",
            "Haoyi Zhou",
            "Chang Liu",
            "Ting Deng",
            "Chunming Hu",
            "Jianxin Li"
        ],
        "published": "2023",
        "summary": "Multi-hop reasoning, a prevalent approach for query answering, aims at inferring new facts along reasonable paths over a knowledge graph. Reinforcement learning methods can be adopted by formulating the problem into a Markov decision process. However, common suffering within RL-based reasoning models is that the agent can be biased to spurious paths which coincidentally lead to the correct answer with poor explanation. In this work, we take a deep dive into this phenomenon and define a metric named Path Spuriousness (PS), to quantitatively estimate to what extent a path is spurious. Guided by the definition of PS, we design a model with a new reward that considers both answer accuracy and path reasonableness. We test our method on four datasets and experiments reveal that our method considerably enhances the agent’s capacity to prevent spurious paths while keeping comparable to state-of-the-art performance.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.232.pdf"
    },
    {
        "title": "When Do Pre-Training Biases Propagate to Downstream Tasks? A Case Study in Text Summarization",
        "authors": [
            "Faisal Ladhak",
            "Esin Durmus",
            "Mirac Suzgun",
            "Tianyi Zhang",
            "Dan Jurafsky",
            "Kathleen McKeown",
            "Tatsunori Hashimoto"
        ],
        "published": "2023",
        "summary": "Large language models (LLMs) are subject to sociocultural and other biases previously identified using intrinsic evaluations. However, when and how these intrinsic biases in pre-trained LM representations propagate to downstream, fine-tuned NLP tasks like summarization is not well understood. In this work, we investigate one type of bias—name-nationality bias—and trace it from the pre-training stage to a downstream summarization task across multiple summarization modeling choices. We show that these biases manifest themselves as hallucinations in summarization, leading to factually incorrect summaries. We also find that this propagation of biases is algorithm-dependent: more abstractive models allow biases to propagate more directly to downstream tasks as hallucinated facts. Building on these observations, we further analyze how changes to the adaptation method and fine-tuning data set affect name nationality biases and show that while they can reduce the overall rate of hallucinations, they do not change the types of biases that do appear.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.234.pdf"
    },
    {
        "title": "BERT Shows Garden Path Effects",
        "authors": [
            "Tovah Irwin",
            "Kyra Wilson",
            "Alec Marantz"
        ],
        "published": "2023",
        "summary": "Garden path sentences (i.e. “the horse raced past the barn fell”) are sentences that readers initially incorrectly parse, requiring partial or total re-analysis of the sentence structure. Given human difficulty in parsing garden paths, we aim to compare transformer language models’ performance on these sentences. We assess a selection of models from the BERT family which have been fine-tuned on the question-answering task, and evaluate each model’s performance on comprehension questions based on garden path and control sentences. We then further investigate the semantic roles assigned to arguments of verbs in garden path and control sentences by utilizing a probe task to directly assess which semantic role(s) the model assigns. We find that the models have relatively low performance in certain instances of question answering based on garden path contexts, and the model incorrectly assigns semantic roles, aligning for the most part with human performance.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.235.pdf"
    },
    {
        "title": "DyLoRA: Parameter-Efficient Tuning of Pre-trained Models using Dynamic Search-Free Low-Rank Adaptation",
        "authors": [
            "Mojtaba Valipour",
            "Mehdi Rezagholizadeh",
            "Ivan Kobyzev",
            "Ali Ghodsi"
        ],
        "published": "2023",
        "summary": "With the ever-growing size of pretrained models (PMs), fine-tuning them has become more expensive and resource-hungry. As a remedy, low-rank adapters (LoRA) keep the main pretrained weights of the model frozen and just introduce some learnable truncated SVD modules (so-called LoRA blocks) to the model. While LoRA blocks are parameter-efficient, they suffer from two major problems: first, the size of these blocks is fixed and cannot be modified after training (for example, if we need to change the rank of LoRA blocks, then we need to re-train them from scratch); second, optimizing their rank requires an exhaustive search and effort. In this work, we introduce a dynamic low-rank adaptation (DyLoRA) technique to address these two problems together. Our DyLoRA method trains LoRA blocks for a range of ranks instead of a single rank by sorting the representation learned by the adapter module at different ranks during training. We evaluate our solution on different natural language understanding (GLUE benchmark) and language generation tasks (E2E, DART and WebNLG) using different pretrained models such as RoBERTa and GPT with different sizes. Our results show that we can train dynamic search-free models with DyLoRA at least 4 to 7 times (depending to the task) faster than LoRA without significantly compromising performance. Moreover, our models can perform consistently well on a much larger range of ranks compared to LoRA.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.239.pdf"
    },
    {
        "title": "Language Generation Models Can Cause Harm: So What Can We Do About It? An Actionable Survey",
        "authors": [
            "Sachin Kumar",
            "Vidhisha Balachandran",
            "Lucille Njoo",
            "Antonios Anastasopoulos",
            "Yulia Tsvetkov"
        ],
        "published": "2023",
        "summary": "Recent advances in the capacity of large language models to generate human-like text have resulted in their increased adoption in user-facing settings. In parallel, these improvements have prompted a heated discourse around the risks of societal harms they introduce, whether inadvertent or malicious. Several studies have explored these harms and called for their mitigation via development of safer, fairer models. Going beyond enumerating the risks of harms, this work provides a survey of practical methods for addressing potential threats and societal harms from language generation models. We draw on several prior works’ taxonomies of language model risks to present a structured overview of strategies for detecting and ameliorating different kinds of risks/harms of language generators. Bridging diverse strands of research, this survey aims to serve as a practical guide for both LM researchers and practitioners, with explanations of different strategies’ motivations, their limitations, and open problems for future research.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.241.pdf"
    },
    {
        "title": "How Far Can It Go? On Intrinsic Gender Bias Mitigation for Text Classification",
        "authors": [
            "Ewoenam Kwaku Tokpo",
            "Pieter Delobelle",
            "Bettina Berendt",
            "Toon Calders"
        ],
        "published": "2023",
        "summary": "To mitigate gender bias in contextualized language models, different intrinsic mitigation strategies have been proposed, alongside many bias metrics. Considering that the end use of these language models is for downstream tasks like text classification, it is important to understand how these intrinsic bias mitigation strategies actually translate to fairness in downstream tasks and the extent of this. In this work, we design a probe to investigate the effects that some of the major intrinsic gender bias mitigation strategies have on downstream text classification tasks. We discover that instead of resolving gender bias, intrinsic mitigation techniques and metrics are able to hide it in such a way that significant gender information is retained in the embeddings. Furthermore, we show that each mitigation technique is able to hide the bias from some of the intrinsic bias measures but not all, and each intrinsic bias measure can be fooled by some mitigation techniques, but not all. We confirm experimentally, that none of the intrinsic mitigation techniques used without any other fairness intervention is able to consistently impact extrinsic bias. We recommend that intrinsic bias mitigation techniques should be combined with other fairness interventions for downstream tasks.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.248.pdf"
    },
    {
        "title": "Semantic Specialization for Knowledge-based Word Sense Disambiguation",
        "authors": [
            "Sakae Mizuki",
            "Naoaki Okazaki"
        ],
        "published": "2023",
        "summary": "A promising approach for knowledge-based Word Sense Disambiguation (WSD) is to select the sense whose contextualized embeddings computed for its definition sentence are closest to those computed for a target word in a given sentence. This approach relies on the similarity of the sense and context embeddings computed by a pre-trained language model. We propose a semantic specialization for WSD where contextualized embeddings are adapted to the WSD task using solely lexical knowledge. The key idea is, for a given sense, to bring semantically related senses and contexts closer and send different/unrelated senses farther away. We realize this idea as the joint optimization of the Attract-Repel objective for sense pairs and the self-training objective for context-sense pairs while controlling deviations from the original embeddings. The proposed method outperformed previous studies that adapt contextualized embeddings. It achieved state-of-the-art performance on knowledge-based WSD when combined with the reranking heuristic that uses the sense inventory. We found that the similarity characteristics of specialized embeddings conform to the key idea. We also found that the (dis)similarity of embeddings between the related/different/unrelated senses correlates well with the performance of WSD.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.251.pdf"
    },
    {
        "title": "RPTCS: A Reinforced Persona-aware Topic-guiding Conversational System",
        "authors": [
            "Zishan Ahmad",
            "Kshitij Mishra",
            "Asif Ekbal",
            "Pushpak Bhattacharyya"
        ],
        "published": "2023",
        "summary": "Although there has been a plethora of work on open-domain conversational systems, most of the systems lack the mechanism of controlling the concept transitions in a dialogue. For activities like switching from casual chit-chat to task-oriented conversation, an agent with the ability to manage the flow of concepts in a conversation might be helpful. The user would find the dialogue more engaging and be more receptive to such transitions if these concept transitions were made while taking into account the user’s persona. Focusing on persona-aware concept transitions, we propose a Reinforced Persona-aware Topic-guiding Conversational System (RPTCS). Due to the lack of a persona-aware topic transition dataset, we propose a novel conversation dataset creation mechanism in which the conversational agent leads the discourse to drift to a set of target concepts depending on the persona of the speaker and the context of the conversation. To avoid scarcely available expensive human resource, the entire data-creation process is mostly automatic with human-in-loop only for quality checks. This created conversational dataset named PTCD is used to develop the RPTCS in two steps. First, a maximum likelihood estimation loss-based conversational model is trained on PTCD. Then this trained model is fine-tuned in a Reinforcement Learning (RL) framework by employing novel reward functions to assure persona, topic, and context consistency with non-repetitiveness in generated responses. Our experimental results demonstrate the strength of the proposed system with respect to strong baselines.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.253.pdf"
    },
    {
        "title": "End-to-end Case-Based Reasoning for Commonsense Knowledge Base Completion",
        "authors": [
            "Zonglin Yang",
            "Xinya Du",
            "Erik Cambria",
            "Claire Cardie"
        ],
        "published": "2023",
        "summary": "Pretrained language models have been shown to store knowledge in their parameters and have achieved reasonable performance in commonsense knowledge base completion (CKBC) tasks. However, CKBC is knowledge-intensive and it is reported that pretrained language models’ performance in knowledge-intensive tasks are limited because of their incapability of accessing and manipulating knowledge. As a result, we hypothesize that providing retrieved passages that contain relevant knowledge as additional input to the CKBC task will improve performance. In particular, we draw insights from Case-Based Reasoning (CBR) – which aims to solve a new problem by reasoning with retrieved relevant cases, and investigate the direct application of it to CKBC. On two benchmark datasets, we demonstrate through automatic and human evaluations that our End-to-end Case-Based Reasoning Framework (ECBRF) generates more valid, informative, and novel knowledge than the state-of-the-art COMET model for CKBC in both the fully supervised and few-shot settings. We provide insights on why previous retrieval-based methods only achieve merely the same performance with COMET. From the perspective of CBR, our framework addresses a fundamental question on whether CBR methodology can be utilized to improve deep learning models.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.255.pdf"
    },
    {
        "title": "MetaQA: Combining Expert Agents for Multi-Skill Question Answering",
        "authors": [
            "Haritz Puerto",
            "Gözde Şahin",
            "Iryna Gurevych"
        ],
        "published": "2023",
        "summary": "The recent explosion of question-answering (QA) datasets and models has increased the interest in the generalization of models across multiple domains and formats by either training on multiple datasets or combining multiple models. Despite the promising results of multi-dataset models, some domains or QA formats may require specific architectures, and thus the adaptability of these models might be limited. In addition, current approaches for combining models disregard cues such as question-answer compatibility. In this work, we propose to combine expert agents with a novel, flexible, and training-efficient architecture that considers questions, answer predictions, and answer-prediction confidence scores to select the best answer among a list of answer predictions. Through quantitative and qualitative experiments, we show that our model i) creates a collaboration between agents that outperforms previous multi-agent and multi-dataset approaches, ii) is highly data-efficient to train, and iii) can be adapted to any QA format. We release our code and a dataset of answer predictions from expert agents for 16 QA datasets to foster future research of multi-agent systems.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.259.pdf"
    },
    {
        "title": "BERT Is Not The Count: Learning to Match Mathematical Statements with Proofs",
        "authors": [
            "Weixian Waylon Li",
            "Yftah Ziser",
            "Maximin Coavoux",
            "Shay B. Cohen"
        ],
        "published": "2023",
        "summary": "We introduce a task consisting in matching a proof to a given mathematical statement. The task fits well within current research on Mathematical Information Retrieval and, more generally, mathematical article analysis (Mathematical Sciences, 2014). We present a dataset for the task (the MATcH dataset) consisting of over 180k statement-proof pairs extracted from modern mathematical research articles. We find this dataset highly representative of our task, as it consists of relatively new findings useful to mathematicians. We propose a bilinear similarity model and two decoding methods to match statements to proofs effectively. While the first decoding method matches a proof to a statement without being aware of other statements or proofs, the second method treats the task as a global matching problem. Through a symbol replacement procedure, we analyze the “insights” that pre-trained language models have in such mathematical article analysis and show that while these models perform well on this task with the best performing mean reciprocal rank of 73.7, they follow a relatively shallow symbolic analysis and matching to achieve that performance.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.260.pdf"
    },
    {
        "title": "Contrastive Learning with Keyword-based Data Augmentation for Code Search and Code Question Answering",
        "authors": [
            "Shinwoo Park",
            "Youngwook Kim",
            "Yo-Sub Han"
        ],
        "published": "2023",
        "summary": "The semantic code search is to find code snippets from the collection of candidate code snippets with respect to a user query that describes functionality. Recent work on code search proposes data augmentation of queries for contrastive learning. This data augmentation approach modifies random words in queries. When a user web query for searching code snippet is too brief, the important word that represents the search intent of the query could be undesirably modified. A code snippet has informative components such as function name and documentation that describe its functionality. We propose to utilize these code components to identify important words and preserve them in the data augmentation step. We present KeyDAC (Keyword-based Data Augmentation for Contrastive learning) that identifies important words for code search from queries and code components based on term matching. KeyDAC augments query-code pairs while preserving keywords, and then leverages generated training instances for contrastive learning. We use KeyDAC to fine-tune various pre-trained language models and evaluate the performance of code search and code question answering via CoSQA and WebQueryTest. The experimental results confirm that KeyDAC substantially outperforms the current state-of-the-art performance, and achieves the new state-of-the-arts for both tasks.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.262.pdf"
    },
    {
        "title": "In-Depth Look at Word Filling Societal Bias Measures",
        "authors": [
            "Matúš Pikuliak",
            "Ivana Beňová",
            "Viktor Bachratý"
        ],
        "published": "2023",
        "summary": "Many measures of societal bias in language models have been proposed in recent years. A popular approach is to use a set of word filling prompts to evaluate the behavior of the language models. In this work, we analyze the validity of two such measures – StereoSet and CrowS-Pairs. We show that these measures produce unexpected and illogical results when appropriate control group samples are constructed. Based on this, we believe that they are problematic and using them in the future should be reconsidered. We propose a way forward with an improved testing protocol. Finally, we also introduce a new gender bias dataset for Slovak.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.265.pdf"
    },
    {
        "title": "Social Commonsense for Explanation and Cultural Bias Discovery",
        "authors": [
            "Lisa Bauer",
            "Hanna Tischer",
            "Mohit Bansal"
        ],
        "published": "2023",
        "summary": "Social commonsense contains many human biases due to social and cultural influence (Sap et al., 2020; Emelin et al., 2020). We focus on identifying cultural biases in data, specifically causal assumptions and commonsense implications, that strongly influence model decisions for a variety of tasks designed for social impact. This enables us to examine data for bias by making explicit the causal (if-then, inferential) relations in social commonsense knowledge used for decision making, furthering interpretable commonsense reasoning from a dataset perspective. We apply our methods on 2 social tasks: emotion detection and perceived value detection. We identify influential social commonsense knowledge to explain model behavior in the following ways. First, we augment large-scale language models with social knowledge and show improvements for the tasks, indicating the implicit assumptions a model requires to be successful on each dataset. Second, we identify influential events in the datasets by using social knowledge to cluster data and demonstrate the influence that these events have on model behavior via leave-K-out experiments. This allows us to gain a dataset-level understanding of the events and causal commonsense relationships that strongly influence predictions. We then analyze these relationships to detect influential cultural bias in each dataset. Finally, we use our influential event identification for detecting mislabeled examples and improve training and performance through their removal. We support our findings with manual analysis.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.271.pdf"
    },
    {
        "title": "Counter-GAP: Counterfactual Bias Evaluation through Gendered Ambiguous Pronouns",
        "authors": [
            "Zhongbin Xie",
            "Vid Kocijan",
            "Thomas Lukasiewicz",
            "Oana-Maria Camburu"
        ],
        "published": "2023",
        "summary": "Bias-measuring datasets play a critical role in detecting biased behavior of language models and in evaluating progress of bias mitigation methods. In this work, we focus on evaluating gender bias through coreference resolution, where previous datasets are either hand-crafted or fail to reliably measure an explicitly defined bias. To overcome these shortcomings, we propose a novel method to collect diverse, natural, and minimally distant text pairs via counterfactual generation, and construct Counter-GAP, an annotated dataset consisting of 4008 instances grouped into 1002 quadruples. We further identify a bias cancellation problem in previous group-level metrics on Counter-GAP, and propose to use the difference between inconsistency across genders and within genders to measure bias at a quadruple level. Our results show that four pre-trained language models are significantly more inconsistent across different gender groups than within each group, and that a name-based counterfactual data augmentation method is more effective to mitigate such bias than an anonymization-based method.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.272.pdf"
    },
    {
        "title": "GrIPS: Gradient-free, Edit-based Instruction Search for Prompting Large Language Models",
        "authors": [
            "Archiki Prasad",
            "Peter Hase",
            "Xiang Zhou",
            "Mohit Bansal"
        ],
        "published": "2023",
        "summary": "Providing natural language instructions in prompts is a useful new paradigm for improving task performance of large language models in a zero-shot setting. Recent work has aimed to improve such prompts via manual rewriting or gradient-based tuning. However, manual rewriting is time-consuming and requires subjective interpretation, while gradient-based tuning can be extremely computationally demanding for large models and may not be feasible for API-based models. In this work, we introduce Gradient-free Instructional Prompt Search (GrIPS), a gradient-free, edit-based search approach for improving task instructions for large language models. GrIPS takes in instructions designed for humans and automatically returns an improved, edited prompt, while allowing for API-based tuning. With InstructGPT models, GrIPS improves the average task performance by up to 4.30 percentage points on eight classification tasks from the Natural Instructions dataset (with similar improvements for OPT, BLOOM, and FLAN-T5). We see improvements for both instruction-only prompts and instruction + k-shot examples prompts. Notably, GrIPS outperforms manual rewriting and purely example-based prompts while controlling for the available compute and data budget. Further, performance of GrIPS is comparable to select gradient-based tuning approaches. Qualitatively, we show our edits can simplify instructions and at times make them incoherent but nonetheless improve accuracy.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.277.pdf"
    },
    {
        "title": "Know your audience: specializing grounded language models with listener subtraction",
        "authors": [
            "Aaditya K Singh",
            "David Ding",
            "Andrew Saxe",
            "Felix Hill",
            "Andrew Lampinen"
        ],
        "published": "2023",
        "summary": "Effective communication requires adapting to the idiosyncrasies of each communicative context—such as the common ground shared with each partner. Humans demonstrate this ability to specialize to their audience in many contexts, such as the popular game Dixit. We take inspiration from Dixit to formulate a multi-agent image reference game where a (trained) speaker model is rewarded for describing a target image such that one (pretrained) listener model can correctly identify it among distractors, but another listener cannot. To adapt, the speaker must exploit differences in the knowledge it shares with the different listeners. We show that finetuning an attention-based adapter between a CLIP vision encoder and a large language model in this contrastive, multi-agent setting gives rise to context-dependent natural language specialization from rewards only, without direct supervision. Through controlled experiments, we show that training a speaker with two listeners that perceive differently, using our method, allows the speaker to adapt to the idiosyncracies of the listeners. Furthermore, we show zero-shot transfer of the specialization to real-world data. Our experiments demonstrate a method for specializing grounded language models without direct supervision and highlight the interesting research challenges posed by complex multi-agent communication.",
        "pdf_link": "https://aclanthology.org/2023.eacl-main.279.pdf"
    },
    {
        "title": "Improving Numeracy by Input Reframing and Quantitative Pre-Finetuning Task",
        "authors": [
            "Chung-Chi Chen",
            "Hiroya Takamura",
            "Ichiro Kobayashi",
            "Yusuke Miyao"
        ],
        "published": "2023",
        "summary": "Numbers have unique characteristics to words. Teaching models to understand numbers in text is an open-ended research question. Instead of discussing the required calculation skills, this paper focuses on a more fundamental topic: understanding numerals. We point out that innumeracy—the inability to handle basic numeral concepts—exists in most pretrained language models (LMs), and we propose a method to solve this issue by exploring the notation of numbers. Further, we discuss whether changing notation and pre-finetuning along with the comparing-number task can improve performance in three benchmark datasets containing quantitative-related tasks. The results of this study indicate that input reframing and the proposed pre-finetuning task is useful for RoBERTa.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.4.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Visualize Before You Write: Imagination-Guided Open-Ended Text Generation",
        "authors": [
            "Wanrong Zhu",
            "An Yan",
            "Yujie Lu",
            "Wenda Xu",
            "Xin Wang",
            "Miguel Eckstein",
            "William Yang Wang"
        ],
        "published": "2023",
        "summary": "Recent advances in text-to-image synthesis make it possible to visualize machine imaginations for a given context. On the other hand, when generating text, human writers are gifted at creative visualization, which enhances their writings by forming imaginations as blueprints before putting down the stories in words. Inspired by such a cognitive process, we ask the natural question of whether we can endow machines with the same ability to utilize visual information and construct a general picture of the context to guide text generation. In this work, we propose iNLG that uses machine-generated images to guide language models (LM) in open-ended text generation. The experiments and analyses demonstrate the effectiveness of iNLG on open-ended text generation tasks, including text completion, story generation, and concept-to-text generation in both few-shot and full-data scenarios. Both automatic metrics and human evaluations verify that the text snippets generated by our iNLG are coherent and informative while displaying minor degeneration.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.5.pdf",
        "source": "eacl2023"
    },
    {
        "title": "CIKQA: Learning Commonsense Inference with a Unified Knowledge-in-the-loop QA Paradigm",
        "authors": [
            "Hongming Zhang",
            "Yintong Huo",
            "Yanai Elazar",
            "Yangqiu Song",
            "Yoav Goldberg",
            "Dan Roth"
        ],
        "published": "2023",
        "summary": "We propose a new commonsense reasoning benchmark to motivate commonsense reasoning progress from two perspectives: (1) Evaluating whether models can distinguish knowledge quality by predicting if the knowledge is enough to answer the question; (2) Evaluating whether models can develop commonsense inference capabilities that generalize across tasks. We first extract supporting knowledge for each question and ask humans to annotate whether the auto-extracted knowledge is enough to answer the question or not. After that, we convert different tasks into a unified question-answering format to evaluate the models’ generalization capabilities. We name the benchmark Commonsense Inference with Knowledge-in-the-loop Question Answering (\\name). Experiments show that with our learning paradigm, models demonstrate encouraging generalization capabilities. At the same time, we also notice that distinguishing knowledge quality remains challenging for current commonsense reasoning models.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.8.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Learning the Effects of Physical Actions in a Multi-modal Environment",
        "authors": [
            "Gautier Dagan",
            "Frank Keller",
            "Alex Lascarides"
        ],
        "published": "2023",
        "summary": "Large Language Models (LLMs) handle physical commonsense information inadequately. As a result of being trained in a disembodied setting, LLMs often fail to predict an action’s outcome in a given environment. However, predicting the effects of an action before it is executed is crucial in planning, where coherent sequences of actions are often needed to achieve a goal. Therefore, we introduce the multi-modal task of predicting the outcomes of actions solely from realistic sensory inputs (images and text). Next, we extend an LLM to model latent representations of objects to better predict action outcomes in an environment. We show that multi-modal models can capture physical commonsense when augmented with visual information. Finally, we evaluate our model’s performance on novel actions and objects and find that combining modalities help models to generalize and learn physical commonsense reasoning better.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.10.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Revisiting Intermediate Layer Distillation for Compressing Language Models: An Overfitting Perspective",
        "authors": [
            "Jongwoo Ko",
            "Seungjoon Park",
            "Minchan Jeong",
            "Sukjin Hong",
            "Euijai Ahn",
            "Du-Seong Chang",
            "Se-Young Yun"
        ],
        "published": "2023",
        "summary": "Knowledge distillation (KD) is a highly promising method for mitigating the computational problems of pre-trained language models (PLMs). Among various KD approaches, Intermediate Layer Distillation (ILD) has been a de facto standard KD method with its performance efficacy in the NLP field. In this paper, we find that existing ILD methods are prone to overfitting to training datasets, although these methods transfer more information than the original KD. Next, we present the simple observations to mitigate the overfitting of ILD: distilling only the last Transformer layer and conducting ILD on supplementary tasks. Based on our two findings, we propose a simple yet effective consistency-regularized ILD (CR-ILD), which prevents the student model from overfitting the training dataset. Substantial experiments on distilling BERT on the GLUE benchmark and several synthetic datasets demonstrate that our proposed ILD method outperforms other KD techniques. Our code is available at https://github.com/jongwooko/CR-ILD.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.12.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Implicit Temporal Reasoning for Evidence-Based Fact-Checking",
        "authors": [
            "Liesbeth Allein",
            "Marlon Saelens",
            "Ruben Cartuyvels",
            "Marie-Francine Moens"
        ],
        "published": "2023",
        "summary": "Leveraging contextual knowledge has become standard practice in automated claim verification, yet the impact of temporal reasoning has been largely overlooked. Our study demonstrates that time positively influences the claim verification process of evidence-based fact-checking. The temporal aspects and relations between claims and evidence are first established through grounding on shared timelines, which are constructed using publication dates and time expressions extracted from their text. Temporal information is then provided to RNN-based and Transformer-based classifiers before or after claim and evidence encoding. Our time-aware fact-checking models surpass base models by up to 9% Micro F1 (64.17%) and 15% Macro F1 (47.43%) on the MultiFC dataset. They also outperform prior methods that explicitly model temporal relations between evidence. Our findings show that the presence of temporal information and the manner in which timelines are constructed greatly influence how fact-checking models determine the relevance and supporting or refuting character of evidence documents.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.13.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Active PETs: Active Data Annotation Prioritisation for Few-Shot Claim Verification with Pattern Exploiting Training",
        "authors": [
            "Xia Zeng",
            "Arkaitz Zubiaga"
        ],
        "published": "2023",
        "summary": "To mitigate the impact of the scarcity of labelled data on fact-checking systems, we focus on few-shot claim verification. Despite recent work on few-shot classification by proposing advanced language models, there is a dearth of research in data annotation prioritisation that improves the selection of the few shots to be labelled for optimal model performance. We propose Active PETs, a novel weighted approach that utilises an ensemble of Pattern Exploiting Training (PET) models based on various language models, to actively select unlabelled data as candidates for annotation. Using Active PETs for few-shot data selection shows consistent improvement over the baseline methods, on two technical fact-checking datasets and using six different pretrained language models. We show further improvement with Active PETs-o, which further integrates an oversampling strategy. Our approach enables effective selection of instances to be labelled where unlabelled data is abundant but resources for labelling are limited, leading to consistently improved few-shot claim verification performance. Our code is available.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.14.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Augmenting pre-trained language models with audio feature embedding for argumentation mining in political debates",
        "authors": [
            "Rafael Mestre",
            "Stuart E. Middleton",
            "Matt Ryan",
            "Masood Gheasi",
            "Timothy Norman",
            "Jiatong Zhu"
        ],
        "published": "2023",
        "summary": "The integration of multimodality in natural language processing (NLP) tasks seeks to exploit the complementary information contained in two or more modalities, such as text, audio and video. This paper investigates the integration of often under-researched audio features with text, using the task of argumentation mining (AM) as a case study. We take a previously reported dataset and present an audio-enhanced version (the Multimodal USElecDeb60To16 dataset). We report the performance of two text models based on BERT and GloVe embeddings, one audio model (based on CNN and Bi-LSTM) and multimodal combinations, on a dataset of 28,850 utterances. The results show that multimodal models do not outperform text-based models when using the full dataset. However, we show that audio features add value in fully supervised scenarios with limited data. We find that when data is scarce (e.g. with 10% of the original dataset) multimodal models yield improved performance, whereas text models based on BERT considerably decrease performance. Finally, we conduct a study with artificially generated voices and an ablation study to investigate the importance of different audio features in the audio models.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.21.pdf",
        "source": "eacl2023"
    },
    {
        "title": "CALM-Bench: A Multi-task Benchmark for Evaluating Causality-Aware Language Models",
        "authors": [
            "Dhairya Dalal",
            "Paul Buitelaar",
            "Mihael Arcan"
        ],
        "published": "2023",
        "summary": "Causal reasoning is a critical component of human cognition and is required across a range of question-answering (QA) tasks (such as abductive reasoning, commonsense QA, and procedural reasoning). Research on causal QA has been underdefined, task-specific, and limited in complexity. Recent advances in foundation language models (such as BERT, ERNIE, and T5) have shown the efficacy of pre-trained models across diverse QA tasks. However, there is limited research exploring the causal reasoning capabilities of those language models and no standard evaluation benchmark. To unify causal QA research, we propose CALM-Bench, a multi-task benchmark for evaluating causality-aware language models (CALM). We present a standardized definition of causal QA tasks and show empirically that causal reasoning can be generalized and transferred across different QA tasks. Additionally, we share a strong multi-task baseline model which outperforms single-task fine-tuned models on the CALM-Bench tasks.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.23.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Bridging the Gap between Pre-Training and Fine-Tuning for Commonsense Generation",
        "authors": [
            "Haoran Yang",
            "Yan Wang",
            "Piji Li",
            "Wei Bi",
            "Wai Lam",
            "Chen Xu"
        ],
        "published": "2023",
        "summary": "Commonsense generation aims to generate a plausible sentence containing all given unordered concept words. Previous methods focusing on this task usually directly concatenate these words as the input of a pre-trained language model (PLM). However, in PLMs’ pre-training process, the inputs are often corrupted sentences with correct word order. This input distribution discrepancy between pre-training and fine-tuning makes the model difficult to fully utilize the knowledge of PLMs. In this paper, we propose a two-stage framework to alleviate this issue. Firstly, in pre-training stage, we design a new format of input to endow PLMs the ability to deal with masked sentences with incorrect word order. Secondly, during fine-tuning, we insert the special token [MASK] between two consecutive concept words to make the input distribution more similar to the input distribution in pre-training. We conduct extensive experiments and provide thorough analysis to demonstrate the effectiveness of our proposed method.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.28.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Causal Reasoning of Entities and Events in Procedural Texts",
        "authors": [
            "Li Zhang",
            "Hainiu Xu",
            "Yue Yang",
            "Shuyan Zhou",
            "Weiqiu You",
            "Manni Arora",
            "Chris Callison-Burch"
        ],
        "published": "2023",
        "summary": "Entities and events are crucial to natural language reasoning and common in procedural texts. Existing work has focused either exclusively on entity state tracking (e.g., whether a pan is hot) or on event reasoning (e.g., whether one would burn themselves by touching the pan), while these two tasks are often causally related. We propose CREPE, the first benchmark on causal reasoning of event plausibility and entity states. We show that most language models, including GPT-3, perform close to chance at .35 F1, lagging far behind human at .87 F1. We boost model performance to .59 F1 by creatively representing events as programming languages while prompting language models pretrained on code. By injecting the causal relations between entities and events as intermediate reasoning steps in our representation, we further boost the performance to .67 F1. Our findings indicate not only the challenge that CREPE brings for language models, but also the efficacy of code-like prompting combined with chain-of-thought prompting for multihop event reasoning.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.31.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Transfer Knowledge from Natural Language to Electrocardiography: Can We Detect Cardiovascular Disease Through Language Models?",
        "authors": [
            "Jielin Qiu",
            "William Han",
            "Jiacheng Zhu",
            "Mengdi Xu",
            "Michael Rosenberg",
            "Emerson Liu",
            "Douglas Weber",
            "Ding Zhao"
        ],
        "published": "2023",
        "summary": "Recent advancements in Large Language Models (LLMs) have drawn increasing attention since the learned embeddings pretrained on large-scale datasets have shown powerful ability in various downstream applications. However, whether the learned knowledge by LLMs can be transferred to clinical cardiology remains unknown. In this work, we aim to bridge this gap by transferring the knowledge of LLMs to clinical Electrocardiography (ECG). We propose an approach for cardiovascular disease diagnosis and automatic ECG diagnosis report generation. We also introduce an additional loss function by Optimal Transport (OT) to align the distribution between ECG and language embedding. The learned embeddings are evaluated on two downstream tasks: (1) automatic ECG diagnosis report generation, and (2) zero-shot cardiovascular disease detection. Our approach is able to generate high-quality cardiac diagnosis reports and also achieves competitive zero-shot classification performance even compared with supervised baselines, which proves the feasibility of transferring knowledge from LLMs to the cardiac domain.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.33.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Practical Takes on Federated Learning with Pretrained Language Models",
        "authors": [
            "Ankur Agarwal",
            "Mehdi Rezagholizadeh",
            "Prasanna Parthasarathi"
        ],
        "published": "2023",
        "summary": "Real-world applications of language models entail data privacy constraints when learning from diverse data domains. Federated learning with pretrained language models for language tasks has been gaining attention lately but there are definite confounders that warrants a careful study. Specifically, understanding the limits of federated NLP applications through varying the effects of different aspects (such as data heterogeneity, the trade-off between training time and performance, the effect of different data, and client distributions and sensitivity of the shared model to learning local distributions) is necessary to evaluate whether language models indeed learn to generalize by adapting to the different domains. Towards that, we elaborate different hypotheses over the components in federated NLP architectures and study them in detail with relevant experiments over three tasks: Stanford Sentiment Treebank-2, OntoNotes-5.0 and GigaWord. The experiments with different Transformer inductive biases on the variety of tasks provide a glimpse at the understanding of federated learning at NLP tasks. Specifically, the analysis suggests that regularization due to the ensembling effect may be masquerading as domain adaptation of federated learning in NLP with pre-trained language models.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.34.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Lexical Semantics with Large Language Models: A Case Study of English “break”",
        "authors": [
            "Erika Petersen",
            "Christopher Potts"
        ],
        "published": "2023",
        "summary": "Large neural language models (LLMs) can be powerful tools for research in lexical semantics. We illustrate this potential using the English verb “break”, which has numerous senses and appears in a wide range of syntactic frames. We show that LLMs capture known sense distinctions and can be used to identify informative new sense combinations for further analysis. More generally, we argue that LLMs are aligned with lexical semantic theories in providing high-dimensional, contextually modulated representations, but LLMs’ lack of discrete features and dependence on usage-based data offer a genuinely new perspective on traditional problems in lexical semantics.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.36.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Bag of Tricks for In-Distribution Calibration of Pretrained Transformers",
        "authors": [
            "Jaeyoung Kim",
            "Dongbin Na",
            "Sungchul Choi",
            "Sungbin Lim"
        ],
        "published": "2023",
        "summary": "While pre-trained language models (PLMs) have become a de-facto standard promoting the accuracy of text classification tasks, recent studies find that PLMs often predict over-confidently. Although calibration methods have been proposed, such as ensemble learning and data augmentation, most of the methods have been verified in computer vision benchmarks rather than in PLM-based text classification tasks. In this paper, we present an empirical study on confidence calibration for PLMs, addressing three categories, including confidence penalty losses, data augmentations, and ensemble methods. We find that the ensemble model overfitted to the training set shows sub-par calibration performance and also observe that PLMs trained with confidence penalty loss have a trade-off between calibration and accuracy. Building on these observations, we propose the Calibrated PLM (CALL), a combination of calibration techniques. The CALL complements shortcomings that may occur when utilizing a calibration method individually and boosts both classification and calibration accuracy. Design choices in CALL’s training procedures are extensively studied, and we provide a detailed analysis of how calibration techniques affect the calibration performance of PLMs.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.40.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Fine-Tuning Deteriorates General Textual Out-of-Distribution Detection by Distorting Task-Agnostic Features",
        "authors": [
            "Sishuo Chen",
            "Wenkai Yang",
            "Xiaohan Bi",
            "Xu Sun"
        ],
        "published": "2023",
        "summary": "Detecting out-of-distribution (OOD) inputs is crucial for the safe deployment of natural language processing (NLP) models. Though existing methods, especially those based on the statistics in the feature space of fine-tuned pre-trained language models (PLMs), are claimed to be effective, their effectiveness on different types of distribution shifts remains underexplored. In this work, we take the first step to comprehensively evaluate the mainstream textual OOD detection methods for detecting semantic and non-semantic shifts. We find that: (1) no existing method behaves well in both settings; (2) fine-tuning PLMs on in-distribution data benefits detecting semantic shifts but severely deteriorates detecting non-semantic shifts, which can be attributed to the distortion of task-agnostic features. To alleviate the issue, we present a simple yet effective general OOD score named GNOME that integrates the confidence scores derived from the task-agnostic and task-specific representations. Experiments show that GNOME works well in both semantic and non-semantic shift scenarios, and further brings significant improvement on two cross-task benchmarks where both kinds of shifts simultaneously take place. Our code is available at https://github.com/lancopku/GNOME.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.41.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Task-specific Compression for Multi-task Language Models using Attribution-based Pruning",
        "authors": [
            "Nakyeong Yang",
            "Yunah Jang",
            "Hwanhee Lee",
            "Seohyeong Jeong",
            "Kyomin Jung"
        ],
        "published": "2023",
        "summary": "Multi-task language models show outstanding performance for various natural language understanding tasks with only a single model. However, these language models inevitably utilize an unnecessarily large number of model parameters, even when used only for a specific task. In this paper, we propose a novel training-free compression method for multi-task language models using pruning method. Specifically, we use an attribution method to determine which neurons are essential for performing a specific task. We task-specifically prune unimportant neurons and leave only task-specific parameters. Furthermore, we extend our method to be applicable in both low-resource and unsupervised settings. Since our compression method is training-free, it uses little computing resources and does not update the pre-trained parameters of language models, reducing storage space usage. Experimental results on the six widely-used datasets show that our proposed pruning method significantly outperforms baseline pruning methods. In addition, we demonstrate that our method preserves performance even in an unseen domain setting.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.43.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Abstractive Document Summarization with Summary-length Prediction",
        "authors": [
            "Jingun Kwon",
            "Hidetaka Kamigaito",
            "Manabu Okumura"
        ],
        "published": "2023",
        "summary": "Recently, we can obtain a practical abstractive document summarization model by fine-tuning a pre-trained language model (PLM). Since the pre-training for PLMs does not consider summarization-specific information such as the target summary length, there is a gap between the pre-training and fine-tuning for PLMs in summarization tasks. To fill the gap, we propose a method for enabling the model to understand the summarization-specific information by predicting the summary length in the encoder and generating a summary of the predicted length in the decoder in fine-tuning. Experimental results on the WikiHow, NYT, and CNN/DM datasets showed that our methods improve ROUGE scores from BART by generating summaries of appropriate lengths. Further, we observed about 3.0, 1,5, and 3.1 point improvements for ROUGE-1, -2, and -L, respectively, from GSum on the WikiHow dataset. Human evaluation results also showed that our methods improve the informativeness and conciseness of summaries.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.45.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Cross-Lingual Transfer of Cognitive Processing Complexity",
        "authors": [
            "Charlotte Pouw",
            "Nora Hollenstein",
            "Lisa Beinborn"
        ],
        "published": "2023",
        "summary": "When humans read a text, their eye movements are influenced by the structural complexity of the input sentences. This cognitive phenomenon holds across languages and recent studies indicate that multilingual language models utilize structural similarities between languages to facilitate cross-lingual transfer. We use sentence-level eye-tracking patterns as a cognitive indicator for structural complexity and show that the multilingual model XLM-RoBERTa can successfully predict varied patterns for 13 typologically diverse languages, despite being fine-tuned only on English data. We quantify the sensitivity of the model to structural complexity and distinguish a range of complexity characteristics. Our results indicate that the model develops a meaningful bias towards sentence length but also integrates cross-lingual differences. We conduct a control experiment with randomized word order and find that the model seems to additionally capture more complex structural information.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.49.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Does Transliteration Help Multilingual Language Modeling?",
        "authors": [
            "Ibraheem Muhammad Moosa",
            "Mahmud Elahi Akhter",
            "Ashfia Binte Habib"
        ],
        "published": "2023",
        "summary": "Script diversity presents a challenge to Multilingual Language Models (MLLM) by reducing lexical overlap among closely related languages. Therefore, transliterating closely related languages that use different writing scripts to a common script may improve the downstream task performance of MLLMs. We empirically measure the effect of transliteration on MLLMs in this context. We specifically focus on the Indic languages, which have the highest script diversity in the world, and we evaluate our models on the IndicGLUE benchmark. We perform the Mann-Whitney U test to rigorously verify whether the effect of transliteration is significant or not. We find that transliteration benefits the low-resource languages without negatively affecting the comparatively high-resource languages. We also measure the cross-lingual representation similarity of the models using centered kernel alignment on parallel sentences from the FLORES-101 dataset. We find that for parallel sentences across different languages, the transliteration-based model learns sentence representations that are more similar.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.50.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Zero-Shot On-the-Fly Event Schema Induction",
        "authors": [
            "Rotem Dror",
            "Haoyu Wang",
            "Dan Roth"
        ],
        "published": "2023",
        "summary": "What are the events involved in a pandemic outbreak? What steps should be taken when planning a wedding? The answers to these questions can be found by collecting many documents on the complex event of interest, extracting relevant information, and analyzing it. We present a new approach in which large language models are utilized to generate source documents that allow predicting, given a high-level event definition, the specific events, arguments, and relations between them to construct a schema that describes the complex event in its entirety. Using our model, complete schemas on any topic can be generated on-the-fly without any manual data collection, i.e., in a zero-shot manner. Moreover, we develop efficient methods to extract pertinent information from texts and demonstrate in a series of experiments that these schemas are considered to be more complete than human-curated ones in the majority of examined scenarios. Finally, we show that this framework is comparable in performance with previous supervised schema induction methods that rely on collecting real texts and even reaching the best score in the prediction task.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.53.pdf",
        "source": "eacl2023"
    },
    {
        "title": "BanglaNLG and BanglaT5: Benchmarks and Resources for Evaluating Low-Resource Natural Language Generation in Bangla",
        "authors": [
            "Abhik Bhattacharjee",
            "Tahmid Hasan",
            "Wasi Uddin Ahmad",
            "Rifat Shahriyar"
        ],
        "published": "2023",
        "summary": "This work presents ‘BanglaNLG,’ a comprehensive benchmark for evaluating natural language generation (NLG) models in Bangla, a widely spoken yet low-resource language. We aggregate six challenging conditional text generation tasks under the BanglaNLG benchmark, introducing a new dataset on dialogue generation in the process. Furthermore, using a clean corpus of 27.5 GB of Bangla data, we pretrain ‘BanglaT5’, a sequence-to-sequence Transformer language model for Bangla. BanglaT5 achieves state-of-the-art performance in all of these tasks, outperforming several multilingual models by up to 9% absolute gain and 32% relative gain. We are making the new dialogue dataset and the BanglaT5 model publicly available at https://github.com/csebuetnlp/BanglaNLG in the hope of advancing future research on Bangla NLG.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.54.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Bridging the Gap between Native Text and Translated Text through Adversarial Learning: A Case Study on Cross-Lingual Event Extraction",
        "authors": [
            "Pengfei Yu",
            "Jonathan May",
            "Heng Ji"
        ],
        "published": "2023",
        "summary": "Recent research in cross-lingual learning has found that combining large-scale pretrained multilingual language models with machine translation can yield good performance. We explore this idea for cross-lingual event extraction with a new model architecture that jointly encodes a source language input sentence with its translation to the target language during training, and takes a target language sentence with its translation back to the source language as input during evaluation. However, we observe significant representational gap between the native source language texts during training and the texts translated into source language during evaluation, as well as the texts translated into target language during training and the native target language texts during evaluation. This representational gap undermines the effectiveness of cross-lingual transfer learning for event extraction with machine-translated data. In order to mitigate this problem, we propose an adversarial training framework that encourages the language model to produce more similar representations for the translated text and the native text. To be specific, we train the language model such that its hidden representations are able to fool a jointly trained discriminator that distinguishes translated texts’ representations from native texts’ representations. We conduct experiments on cross-lingual for event extraction across three languages. Results demonstrate that our proposed adversarial training can effectively incorporate machine translation to improve event extraction, while simply adding machine-translated data yields unstable performance due to the representational gap.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.57.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Scalable Prompt Generation for Semi-supervised Learning with Language Models",
        "authors": [
            "Yuhang Zhou",
            "Suraj Maharjan",
            "Beiye Liu"
        ],
        "published": "2023",
        "summary": "Prompt-based learning methods in semi-supervised learning (SSL) settings have been shown to be effective on multiple natural language understanding (NLU) datasets and tasks in the literature. However, manually designing multiple prompts and verbalizers requires domain knowledge and human effort, making it difficult and expensive to scale across different datasets. In this paper, we propose two methods to automatically design multiple prompts and integrate automatic verbalizer in SSL settings without sacrificing performance. The first method uses various demonstration examples with learnable continuous prompt tokens to create diverse prompt models. The second method uses a varying number of soft prompt tokens to encourage language models to learn different prompts. For the verbalizer, we use the prototypical verbalizer to replace the manual one. In summary, we obtained the best average accuracy of 71.5% (a relative improvement of 0.99% over even the previous state-of-the-art SSL method with manual prompts and verbalizers) in different few-shot learning settings.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.58.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Context Generation Improves Open Domain Question Answering",
        "authors": [
            "Dan Su",
            "Mostofa Patwary",
            "Shrimai Prabhumoye",
            "Peng Xu",
            "Ryan Prenger",
            "Mohammad Shoeybi",
            "Pascale Fung",
            "Anima Anandkumar",
            "Bryan Catanzaro"
        ],
        "published": "2023",
        "summary": "Closed-book question answering (QA) requires a model to directly answer an open-domain question without access to any external knowledge. Prior work on closed-book QA either directly finetunes or prompts a pretrained language model (LM) to leverage the stored knowledge. However, they do not fully exploit the parameterized knowledge. To address this inefficiency, we propose a two-stage, closed-book QA framework which employs a coarse-to-fine approach to extract the relevant knowledge and answer a question. We first generate a related context for a given question by prompting a pretrained LM. We then prompt the same LM to generate an answer using the generated context and the question. Additionally, we marginalize over the generated contexts to improve the accuracies and reduce context uncertainty. Experimental results on three QA benchmarks show that our method significantly outperforms previous closed-book QA methods. For example on TriviaQA, our method improves exact match accuracy from 55.3% to 68.6%, and is on par with open-book QA methods (68.6% vs. 68.0%). Our results show that our new methodology is able to better exploit the stored knowledge in pretrained LMs without adding extra learnable parameters or needing finetuning, and paves the way for hybrid models that integrate pretrained LMs with external knowledge.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.60.pdf",
        "source": "eacl2023"
    },
    {
        "title": "PLACES: Prompting Language Models for Social Conversation Synthesis",
        "authors": [
            "Maximillian Chen",
            "Alexandros Papangelis",
            "Chenyang Tao",
            "Seokhwan Kim",
            "Andy Rosenbaum",
            "Yang Liu",
            "Zhou Yu",
            "Dilek Hakkani-Tur"
        ],
        "published": "2023",
        "summary": "Collecting high quality conversational data can be very expensive for most applications and infeasible for others due to privacy, ethical, or similar concerns. A promising direction to tackle this problem is to generate synthetic dialogues by prompting large language models. In this work, we use a small set of expert-written conversations as in-context examples to synthesize a social conversation dataset using prompting. We perform several thorough evaluations of our synthetic conversations compared to human-collected conversations. This includes various dimensions of conversation quality with human evaluation directly on the synthesized conversations, and interactive human evaluation of chatbots fine-tuned on the synthetically generated dataset. We additionally demonstrate that this prompting approach is generalizable to multi-party conversations, providing potential to create new synthetic data for multi-party tasks. Our synthetic multi-party conversations were rated more favorably across all measured dimensions compared to conversation excerpts sampled from a human-collected multi-party dataset.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.63.pdf",
        "source": "eacl2023"
    },
    {
        "title": "MLASK: Multimodal Summarization of Video-based News Articles",
        "authors": [
            "Mateusz Krubiński",
            "Pavel Pecina"
        ],
        "published": "2023",
        "summary": "In recent years, the pattern of news consumption has been changing. The most popular multimedia news formats are now multimodal - the reader is often presented not only with a textual article but also with a short, vivid video. To draw the attention of the reader, such video-based articles are usually presented as a short textual summary paired with an image thumbnail. In this paper, we introduce MLASK (MultimodaL Article Summarization Kit) - a new dataset of video-based news articles paired with a textual summary and a cover picture, all obtained by automatically crawling several news websites. We demonstrate how the proposed dataset can be used to model the task of multimodal summarization by training a Transformer-based neural model. We also examine the effects of pre-training when the usage of generative pre-trained language models helps to improve the model performance, but (additional) pre-training on the simpler task of text summarization yields even better results. Our experiments suggest that the benefits of pre-training and using additional modalities in the input are not orthogonal.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.67.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Going beyond research datasets: Novel intent discovery in the industry setting",
        "authors": [
            "Aleksandra Chrabrowa",
            "Tsimur Hadeliya",
            "Dariusz Kajtoch",
            "Robert Mroczkowski",
            "Piotr Rybak"
        ],
        "published": "2023",
        "summary": "Novel intent discovery automates the process of grouping similar messages (questions) to identify previously unknown intents. However, current research focuses on publicly available datasets which have only the question field and significantly differ from real-life datasets. This paper proposes methods to improve the intent discovery pipeline deployed in a large e-commerce platform. We show the benefit of pre-training language models on in-domain data: both self-supervised and with weak supervision. We also devise the best method to utilize the conversational structure (i.e., question and answer) of real-life datasets during fine-tuning for clustering tasks, which we call Conv. All our methods combined to fully utilize real-life datasets give up to 33pp performance boost over state-of-the-art Constrained Deep Adaptive Clustering (CDAC) model for question only. By comparison CDAC model for the question data only gives only up to 13pp performance boost over the naive baseline.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.68.pdf",
        "source": "eacl2023"
    },
    {
        "title": "DATScore: Evaluating Translation with Data Augmented Translations",
        "authors": [
            "Moussa Kamal Eddine",
            "Guokan Shang",
            "Michalis Vazirgiannis"
        ],
        "published": "2023",
        "summary": "The rapid development of large pretrained language models has revolutionized not only the field of Natural Language Generation (NLG) but also its evaluation. Inspired by the recent work of BARTScore: a metric leveraging the BART language model to evaluate the quality of generated text from various aspects, we introduce DATScore. DATScore uses data augmentation techniques to improve the evaluation of machine translation. Our main finding is that introducing data augmented translations of the source and reference texts is greatly helpful in evaluating the quality of the generated translation. We also propose two novel score averaging and term weighting strategies to improve the original score computing process of BARTScore. Experimental results on WMT show that DATScore correlates better with human meta-evaluations than the other recent state-of-the-art metrics, especially for low-resource languages. Ablation studies demonstrate the value added by our new scoring strategies. Moreover, we report in our extended experiments the performance of DATScore on 3 NLG tasks other than translation.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.69.pdf",
        "source": "eacl2023"
    },
    {
        "title": "How do decoding algorithms distribute information in dialogue responses?",
        "authors": [
            "Saranya Venkatraman",
            "He He",
            "David Reitter"
        ],
        "published": "2023",
        "summary": "Humans tend to follow the Uniform Information Density (UID) principle by distributing information evenly in utterances. We study if decoding algorithms implicitly follow this UID principle, and under what conditions adherence to UID might be desirable for dialogue generation. We generate responses using different decoding algorithms with GPT-2 on the Persona-Chat dataset and collect human judgments on their quality using Amazon Mechanical Turk. We find that (i) surprisingly, model-generated responses follow the UID principle to a greater extent than human responses, and (ii) decoding algorithms that promote UID do not generate higher-quality responses. Instead, when we control for surprisal, non-uniformity of information density correlates with the quality of responses with very low/high surprisal. Our findings indicate that encouraging non-uniform responses is a potential solution to the “likelihood trap” problem (quality degradation in very high-likelihood text). Our dataset containing multiple candidate responses per dialog history along with human-annotated quality ratings is available at: https://huggingface.co/datasets/saranya132/dialog_uid_gpt2.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.70.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Benchmarking Long-tail Generalization with Likelihood Splits",
        "authors": [
            "Ameya Godbole",
            "Robin Jia"
        ],
        "published": "2023",
        "summary": "In order to reliably process natural language, NLP systems must generalize to the long tail of rare utterances. We propose a method to create challenging benchmarks that require generalizing to the tail of the distribution by re-splitting existing datasets. We create ‘Likelihood Splits’ where examples that are assigned lower likelihood by a pre-trained language model (LM) are placed in the test set, and more likely examples are in the training set. This simple approach can be customized to construct meaningful train-test splits for a wide range of tasks. Likelihood Splits surface more challenges than random splits: relative error rates of state-of-the-art models increase by 59% for semantic parsing on Spider, 93% for natural language inference on SNLI, and 33% for yes/no question answering on BoolQ, on our splits compared with the corresponding random splits. Moreover, Likelihood Splits create fairer benchmarks than adversarial filtering; when the LM used to create the splits is also employed as the task model, our splits do not unfairly penalize the LM.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.71.pdf",
        "source": "eacl2023"
    },
    {
        "title": "How Many Data Samples is an Additional Instruction Worth?",
        "authors": [
            "Ravsehaj Singh Puri",
            "Swaroop Mishra",
            "Mihir Parmar",
            "Chitta Baral"
        ],
        "published": "2023",
        "summary": "Recently introduced instruction-paradigm empowers non-expert users to leverage NLP resources by defining a new task in natural language. Instruction-tuned models have significantly outperformed multitask learning models (without instruction); however they are far from state-of-the-art task-specific models. Conventional approaches to improve model performance via creating datasets with large number of task instances or architectural changes in the model may not be feasible for non-expert users. However, they can write alternate instructions to represent an instruction task. Is Instruction-augmentation helpful? We augment a subset of tasks in the expanded version of NATURAL INSTRUCTIONS with additional instructions and find that it significantly improves model performance (up to 35%), especially in the low-data regime. Our results indicate that an additional instruction can be equivalent to ~200 data samples on average across tasks.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.77.pdf",
        "source": "eacl2023"
    },
    {
        "title": "ViDeBERTa: A powerful pre-trained language model for Vietnamese",
        "authors": [
            "Cong Dao Tran",
            "Nhut Huy Pham",
            "Anh Tuan Nguyen",
            "Truong Son Hy",
            "Tu Vu"
        ],
        "published": "2023",
        "summary": "This paper presents ViDeBERTa, a new pre-trained monolingual language model for Vietnamese, with three versions - ViDeBERTa_xsmall, ViDeBERTa_base, and ViDeBERTa_large, which are pre-trained on a large-scale corpus of high-quality and diverse Vietnamese texts using DeBERTa architecture. Although many successful pre-trained language models based on Transformer have been widely proposed for the English language, there are still few pre-trained models for Vietnamese, a low-resource language, that perform good results on downstream tasks, especially Question answering. We fine-tune and evaluate our model on three important natural language downstream tasks, Part-of-speech tagging, Named-entity recognition, and Question answering. The empirical results demonstrate that ViDeBERTa with far fewer parameters surpasses the previous state-of-the-art models on multiple Vietnamese-specific natural language understanding tasks. Notably, ViDeBERTa_base with 86M parameters, which is only about 23% of PhoBERT_large with 370M parameters, still performs the same or better results than the previous state-of-the-art model. Our ViDeBERTa models are available at: https://github.com/HySonLab/ViDeBERTa.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.79.pdf",
        "source": "eacl2023"
    },
    {
        "title": "NapSS: Paragraph-level Medical Text Simplification via Narrative Prompting and Sentence-matching Summarization",
        "authors": [
            "Junru Lu",
            "Jiazheng Li",
            "Byron Wallace",
            "Yulan He",
            "Gabriele Pergola"
        ],
        "published": "2023",
        "summary": "Accessing medical literature is difficult for laypeople as the content is written for specialists and contains medical jargon. Automated text simplification methods offer a potential means to address this issue. In this work, we propose a summarize-then-simplify two-stage strategy, which we call NapSS, identifying the relevant content to simplify while ensuring that the original narrative flow is preserved. In this approach, we first generate reference summaries via sentence matching between the original and the simplified abstracts. These summaries are then used to train an extractive summarizer, learning the most relevant content to be simplified. Then, to ensure the narrative consistency of the simplified text, we synthesize auxiliary narrative prompts combining key phrases derived from the syntactical analyses of the original text. Our model achieves results significantly better than the seq2seq baseline on an English medical corpus, yielding 3% 4% absolute improvements in terms of lexical similarity, and providing a further 1.1% improvement of SARI score when combined with the baseline. We also highlight shortcomings of existing evaluation methods, and introduce new metrics that take into account both lexical and high-level semantic similarity. A human evaluation conducted on a random sample of the test set further establishes the effectiveness of the proposed approach. Codes and models are released here: https://github.com/LuJunru/NapSS.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.80.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Large Language Models are few(1)-shot Table Reasoners",
        "authors": [
            "Wenhu Chen"
        ],
        "published": "2023",
        "summary": "Recent literature has shown that large language models (LLMs) are generally excellent few-shot reasoners to solve text reasoning tasks. However, the capability of LLMs on table reasoning tasks is yet to be explored. In this paper, we aim at understanding how well LLMs can perform table-related tasks with few-shot in-context learning. Specifically, we evaluated LLMs on popular table QA and fact verification datasets like WikiTableQuestion, FetaQA, TabFact, and FEVEROUS and found that LLMs are competent at complex reasoning over table structures, though these models are not pre-trained on any table corpus. When combined with ‘chain of thoughts’ prompting, LLMs can achieve very strong performance with only a 1-shot demonstration, even on par with some SoTA models. We show that LLMs are even more competent at generating comprehensive long-form answers on FetaQA than tuned T5-large. We further manually studied the reasoning chains elicited from LLMs and found that these reasoning chains are highly consistent with the underlying semantic form. We believe that LLMs can serve as a simple yet generic baseline for future research. The code and data are released in https://github.com/wenhuchen/TableCoT.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.83.pdf",
        "source": "eacl2023"
    },
    {
        "title": "“Why do I feel offended?” - Korean Dataset for Offensive Language Identification",
        "authors": [
            "San-Hee Park",
            "Kang-Min Kim",
            "O-Joun Lee",
            "Youjin Kang",
            "Jaewon Lee",
            "Su-Min Lee",
            "SangKeun Lee"
        ],
        "published": "2023",
        "summary": "Warning: This paper contains some offensive expressions. Offensive content is an unavoidable issue on social media. Most existing offensive language identification methods rely on the compilation of labeled datasets. However, existing methods rarely consider low-resource languages that have relatively less data available for training (e.g., Korean). To address these issues, we construct a novel KOrean Dataset for Offensive Language Identification (KODOLI). KODOLI comprises more fine-grained offensiveness categories (i.e., not offensive, likely offensive, and offensive) than existing ones. A likely offensive language refers to texts with implicit offensiveness or abusive language without offensive intentions. In addition, we propose two auxiliary tasks to help identify offensive languages: abusive language detection and sentiment analysis. We provide experimental results for baselines on KODOLI and observe that language models suffer from identifying “LIKELY” offensive statements. Quantitative results and qualitative analysis demonstrate that jointly learning offensive language, abusive language and sentiment information improves the performance of offensive language identification.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.85.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Multilingual BERT has an accent: Evaluating English influences on fluency in multilingual models",
        "authors": [
            "Isabel Papadimitriou",
            "Kezia Lopez",
            "Dan Jurafsky"
        ],
        "published": "2023",
        "summary": "While multilingual language models can improve NLP performance on low-resource languages by leveraging higher-resource languages, they also reduce average performance on all languages (the ‘curse of multilinguality’). Here we show another problem with multilingual models: grammatical structures in higher-resource languages bleed into lower-resource languages, a phenomenon we call grammatical structure bias. We show this bias via a novel method for comparing the fluency of multilingual models to the fluency of monolingual Spanish and Greek models: testing their preference for two carefully-chosen variable grammatical structures (optional pronoun-drop in Spanish and optional Subject-Verb ordering in Greek). We find that multilingual BERT is biased toward the English-like setting (explicit pronouns and Subject-Verb-Object ordering) as compared to our monolingual control language model. With our case studies, we hope to bring to light the fine-grained ways in which multilingual models can be biased, and encourage more linguistically-aware fluency evaluation.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.89.pdf",
        "source": "eacl2023"
    },
    {
        "title": "SharPT: Shared Latent Space Prompt Tuning",
        "authors": [
            "Bo Pang",
            "Semih Yavuz",
            "Caiming Xiong",
            "Yingbo Zhou"
        ],
        "published": "2023",
        "summary": "Prompt tuning is an efficient method for adapting large language models, and Soft Prompt Transfer (SPoT) further narrows the gap between prompt tuning and full model tuning by transferring prompts learned from source tasks to target tasks. It is nevertheless difficult and expensive to identify the source task that provides optimal prompts. In this work, we propose to learn a shared latent space which captures a set of basis skills from a mixture of source tasks. Given an instance, its embedding queries the latent space, yielding a basis skill vector. This vector generates soft prompts, via a lightweight prompt generator, which modulates a frozen model. The latent space and prompt transformation are learned end-to-end by training on source tasks. Transfer learning from source tasks to a target task simply amounts to finetuning the prompt generator, accounting for roughly 0.3% parameters of the frozen backbone model, while the shared latent space is also frozen in finetuning. Our approach outperforms prior soft prompt methods by a significant margin on a variety of tasks such as NLI, sentence completion, QA, conference resolution, word sense disambiguation. We also find, on various model scales, our method achieves competitive performance compared to finetuning the full model.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.92.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Mini But Mighty: Efficient Multilingual Pretraining with Linguistically-Informed Data Selection",
        "authors": [
            "Tolulope Ogunremi",
            "Dan Jurafsky",
            "Christopher Manning"
        ],
        "published": "2023",
        "summary": "With the prominence of large pretrained language models, low-resource languages are rarely modelled monolingually and become victims of the “curse of multilinguality” in massively multilingual models. Recently, AfriBERTa showed that training transformer models from scratch on 1GB of data from many unrelated African languages outperforms massively multilingual models on downstream NLP tasks. Here we extend this direction, focusing on the use of related languages. We propose that training on smaller amounts of data but from related languages could match the performance of models trained on large, unrelated data. We test our hypothesis on the Niger-Congo family and its Bantu and Volta-Niger sub-families, pretraining models with data solely from Niger-Congo languages and finetuning on 4 downstream tasks: NER, part-of-speech tagging, sentiment analysis and text classification. We find that models trained on genetically related languages achieve equal performance on downstream tasks in low-resource languages despite using less training data. We recommend selecting training data based on language-relatedness when pretraining language models for low-resource languages.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.93.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Long Document Summarization with Top-down and Bottom-up Inference",
        "authors": [
            "Bo Pang",
            "Erik Nijkamp",
            "Wojciech Kryscinski",
            "Silvio Savarese",
            "Yingbo Zhou",
            "Caiming Xiong"
        ],
        "published": "2023",
        "summary": "Text summarization aims to condense long documents and retain key information. Critical to the success of a summarization model is the faithful inference of latent representations of words or tokens in the source documents. Most recent models infer the latent representations with a transformer encoder, which is purely bottom-up and thus does not capture long-distance context well. Also, self-attention-based models face the challenge of quadratic complexity with respect to sequence length. We propose a method to improve summarization models on these two aspects. Our method assumes a hierarchical latent structure of a document where the top-level captures the long range dependency at a coarser time scale and the bottom token level preserves the details. Critically, our method enables token representations to be updated in both a bottom-up and top-down manner. In the bottom-up pass, token representations are inferred with local self-attention to leverage its efficiency. Top-down correction is then applied to allow tokens to capture global context. We demonstrate the effectiveness on a diverse set of summarization datasets, including narrative, conversational, scientific documents and news. Our model achieves state-of-the-art performance on a wide range of long document summarization benchmarks, compared to recent efficient transformers. We show that our model can summarize an entire book and achieve competitive performance using 0.27% parameters and much less training data, compared to a recent GPT-3-based model. These results indicate the general applicability and benefits of the framework.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.94.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Spelling convention sensitivity in neural language models",
        "authors": [
            "Elizabeth Nielsen",
            "Christo Kirov",
            "Brian Roark"
        ],
        "published": "2023",
        "summary": "We examine whether large neural language models, trained on very large collections of varied English text, learn the potentially long-distance dependency of British versus American spelling conventions, i.e., whether spelling is consistently one or the other within model-generated strings. In contrast to long-distance dependencies in non-surface underlying structure (e.g., syntax), spelling consistency is easier to measure both in LMs and the text corpora used to train them, which can provide additional insight into certain observed model behaviors. Using a set of probe words unique to either British or American English, we first establish that training corpora exhibit substantial (though not total) consistency. A large T5 language model does appear to internalize this consistency, though only with respect to observed lexical items (not nonce words with British/American spelling patterns). We further experiment with correcting for biases in the training data by fine-tuning T5 on synthetic data that has been debiased, and find that finetuned T5 remains only somewhat sensitive to spelling consistency. Further experiments show GPT2 to be similarly limited.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.98.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Distinguishability Calibration to In-Context Learning",
        "authors": [
            "Hongjing Li",
            "Hanqi Yan",
            "Yanran Li",
            "Li Qian",
            "Yulan He",
            "Lin Gui"
        ],
        "published": "2023",
        "summary": "Recent years have witnessed increasing interests in prompt-based learning in which models can be trained on only a few annotated instances, making them suitable in low-resource settings. It is even challenging in fine-grained classification as the pre-trained language models tend to generate similar output embedding which makes it difficult to discriminate for the prompt-based classifier. In this work, we alleviate this information diffusion issue by proposing a calibration method based on a transformation which rotates the embedding feature into a new metric space where we adapt the ratio of each dimension to a uniform distribution to guarantee the distinguishability of learned embeddings. Furthermore, we take the advantage of hyperbolic embedding to capture the relation between dimensions by a coarse-fine metric learning strategy to enhance interpretability. Extensive experiments on the three datasets under various settings demonstrate the effectiveness of our approach.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.102.pdf",
        "source": "eacl2023"
    },
    {
        "title": "More Robust Schema-Guided Dialogue State Tracking via Tree-Based Paraphrase Ranking",
        "authors": [
            "Alexandru Coca",
            "Bo-Hsiang Tseng",
            "Weizhe Lin",
            "Bill Byrne"
        ],
        "published": "2023",
        "summary": "The schema-guided paradigm overcomes scalability issues inherent in building task-oriented dialogue (TOD) agents with static ontologies. Rather than operating on dialogue context alone, agents have access to hierarchical schemas containing task-relevant natural language descriptions. Fine-tuned language models excel at schema-guided dialogue state tracking (DST) but are sensitive to the writing style of the schemas. We explore methods for improving the robustness of DST models. We propose a framework for generating synthetic schemas which uses tree-based ranking to jointly optimise lexical diversity and semantic faithfulness. The robust generalisation of strong baselines is improved when augmenting their training data with prompts generated by our framework, as demonstrated by marked improvements in average Joint Goal Accuracy (JGA) and schema sensitivity (SS) on the SGD-X benchmark.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.106.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Language Model Decoding as Likelihood–Utility Alignment",
        "authors": [
            "Martin Josifoski",
            "Maxime Peyrard",
            "Frano Rajič",
            "Jiheng Wei",
            "Debjit Paul",
            "Valentin Hartmann",
            "Barun Patra",
            "Vishrav Chaudhary",
            "Emre Kiciman",
            "Boi Faltings"
        ],
        "published": "2023",
        "summary": "A critical component of a successful language generation pipeline is the decoding algorithm. However, the general principles that should guide the choice of a decoding algorithm remain unclear. Previous works only compare decoding algorithms in narrow scenarios, and their findings do not generalize across tasks. We argue that the misalignment between the model’s likelihood and the task-specific notion of utility is the key factor in understanding the effectiveness of decoding algorithms. To structure the discussion, we introduce a taxonomy of misalignment mitigation strategies (MMSs), providing a unifying view of decoding as a tool for alignment. The MMS taxonomy groups decoding algorithms based on their implicit assumptions about likelihood–utility misalignment, yielding general statements about their applicability across tasks. Specifically, by analyzing the correlation between the likelihood and the utility of predictions across a diverse set of tasks, we provide empirical evidence supporting the proposed taxonomy and a set of principles to structure reasoning when choosing a decoding algorithm. Crucially, our analysis is the first to relate likelihood-based decoding algorithms with algorithms that rely on external information, such as value-guided methods and prompting, and covers the most diverse set of tasks to date. Code, data, and models are available at https://github.com/epfl-dlab/understanding-decoding.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.107.pdf",
        "source": "eacl2023"
    },
    {
        "title": "On the Generalization Ability of Retrieval-Enhanced Transformers",
        "authors": [
            "Tobias Norlund",
            "Ehsan Doostmohammadi",
            "Richard Johansson",
            "Marco Kuhlmann"
        ],
        "published": "2023",
        "summary": "Recent work on the Retrieval-Enhanced Transformer (RETRO) model has shown impressive results: off-loading memory from trainable weights to a retrieval database can significantly improve language modeling and match the performance of non-retrieval models that are an order of magnitude larger in size. It has been suggested that at least some of this performance gain is due to non-trivial generalization based on both model weights and retrieval. In this paper, we try to better understand the relative contributions of these two components. We find that the performance gains from retrieval to a very large extent originate from overlapping tokens between the database and the test data, suggesting less of non-trivial generalization than previously assumed. More generally, our results point to the challenges of evaluating the generalization of retrieval-augmented language models such as RETRO, as even limited token overlap may significantly decrease test-time loss. We release our code and model at https://github.com/TobiasNorlund/retro",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.109.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Assessing Monotonicity Reasoning in Dutch through Natural Language Inference",
        "authors": [
            "Gijs Wijnholds"
        ],
        "published": "2023",
        "summary": "In this paper we investigate monotonicity reasoning in Dutch, through a novel Natural Language Inference dataset. Monotonicity reasoning shows to be highly challenging for Transformer-based language models in English and here, we corroborate those findings using a parallel Dutch dataset, obtained by translating the Monotonicity Entailment Dataset of Yanaka et al. (2019). After fine-tuning two Dutch language models BERTje and RobBERT on the Dutch NLI dataset SICK-NL, we find that performance severely drops on the monotonicity reasoning dataset, indicating poor generalization capacity of the models. We provide a detailed analysis of the test results by means of the linguistic annotations in the dataset. We find that models struggle with downward entailing contexts, and argue that this is due to a poor understanding of negation. Additionally, we find that the choice of monotonicity context affects model performance on conjunction and disjunction. We hope that this new resource paves the way for further research in generalization of neural reasoning models in Dutch, and contributes to the development of better language technology for Natural Language Inference, specifically for Dutch.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.110.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Exploring Data Augmentation for Code Generation Tasks",
        "authors": [
            "Pinzhen Chen",
            "Gerasimos Lampouras"
        ],
        "published": "2023",
        "summary": "Advances in natural language processing, such as transfer learning from pre-trained language models, have impacted how models are trained for programming language tasks too. Previous research primarily explored code pre-training and expanded it through multi-modality and multi-tasking, yet the data for downstream tasks remain modest in size. Focusing on data utilization for downstream tasks, we propose and adapt augmentation methods that yield consistent improvements in code translation and summarization by up to 6.9% and 7.5% respectively. Further analysis suggests that our methods work orthogonally and show benefits in output code style and numeric consistency. We also discuss test data imperfections.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.114.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Stabilized In-Context Learning with Pre-trained Language Models for Few Shot Dialogue State Tracking",
        "authors": [
            "Derek Chen",
            "Kun Qian",
            "Zhou Yu"
        ],
        "published": "2023",
        "summary": "Prompt-based methods with large pre-trained language models (PLMs) have shown impressive unaided performance across many NLP tasks. These models improve even further with the addition of a few labeled in-context exemplars to guide output generation. However, for more complex tasks such as dialogue state tracking (DST), designing prompts that reliably convey the desired intent is nontrivial, leading to unstable results. Furthermore, building in-context exemplars for dialogue tasks is difficult because conversational contexts are long while model input lengths are relatively short. To overcome these issues we first adapt a meta-learning scheme to the dialogue domain which stabilizes the ability of the model to perform well under various prompts. We additionally design a novel training method to improve upon vanilla retrieval mechanisms to find ideal in-context examples. Finally, we introduce a saliency model to limit dialogue text length, allowing us to include more exemplars per query. In effect, we are able to achieve highly competitive results for few-shot DST on MultiWOZ.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.115.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Can Demographic Factors Improve Text Classification? Revisiting Demographic Adaptation in the Age of Transformers",
        "authors": [
            "Chia-Chien Hung",
            "Anne Lauscher",
            "Dirk Hovy",
            "Simone Paolo Ponzetto",
            "Goran Glavaš"
        ],
        "published": "2023",
        "summary": "Demographic factors (e.g., gender or age) shape our language. Previous work showed that incorporating demographic factors can consistently improve performance for various NLP tasks with traditional NLP models. In this work, we investigate whether these previous findings still hold with state-of-the-art pretrained Transformer-based language models (PLMs). We use three common specialization methods proven effective for incorporating external knowledge into pretrained Transformers (e.g., domain-specific or geographic knowledge). We adapt the language representations for the demographic dimensions of gender and age, using continuous language modeling and dynamic multi-task learning for adaptation, where we couple language modeling objectives with the prediction of demographic classes. Our results, when employing a multilingual PLM, show substantial gains in task performance across four languages (English, German, French, and Danish), which is consistent with the results of previous work. However, controlling for confounding factors – primarily domain and language proficiency of Transformer-based PLMs – shows that downstream performance gains from our demographic adaptation do not actually stem from demographic knowledge. Our results indicate that demographic specialization of PLMs, while holding promise for positive societal impact, still represents an unsolved problem for (modern) NLP.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.116.pdf",
        "source": "eacl2023"
    },
    {
        "title": "JBLiMP: Japanese Benchmark of Linguistic Minimal Pairs",
        "authors": [
            "Taiga Someya",
            "Yohei Oseki"
        ],
        "published": "2023",
        "summary": "In this paper, we introduce JBLiMP (Japanese Benchmark of Linguistic Minimal Pairs), a novel dataset for targeted syntactic evaluations of language models in Japanese. JBLiMP consists of 331 minimal pairs, which are created based on acceptability judgments extracted from journal articles in theoretical linguistics. These minimal pairs are grouped into 11 categories, each covering a different linguistic phenomenon. JBLiMP is unique in that it successfully combines two important features independently observed in existing datasets: (i) coverage of complex linguistic phenomena (cf. CoLA) and (ii) presentation of sentences as minimal pairs (cf. BLiMP). In addition, JBLiMP is the first dataset for targeted syntactic evaluations of language models in Japanese, thus allowing the comparison of syntactic knowledge of language models across different languages. We then evaluate the syntactic knowledge of several language models on JBLiMP: GPT-2, LSTM, and n-gram language models. The results demonstrated that all the architectures achieved comparable overall accuracies around 75%. Error analyses by linguistic phenomenon further revealed that these language models successfully captured local dependencies like nominal structures, but not long-distance dependencies such as verbal agreement and binding.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.117.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Model-Agnostic Bias Measurement in Link Prediction",
        "authors": [
            "Lena Schwertmann",
            "Manoj Prabhakar Kannan Ravi",
            "Gerard de Melo"
        ],
        "published": "2023",
        "summary": "Link prediction models based on factual knowledge graphs are commonly used in applications such as search and question answering. However, work investigating social bias in these models has been limited. Previous work focused on knowledge graph embeddings, so more recent classes of models achieving superior results by fine-tuning Transformers have not yet been investigated. We therefore present a model-agnostic approach for bias measurement leveraging fairness metrics to compare bias in knowledge graph embedding-based predictions (KG only) with models that use pre-trained, Transformer-based language models (KG+LM). We further create a dataset to measure gender bias in occupation predictions and assess whether the KG+LM models are more or less biased than KG only models. We find that gender bias tends to be higher for the KG+LM models and analyze potential connections to the accuracy of the models and the data bias inherent in our dataset. Finally, we discuss the limitations and ethical considerations of our work. The repository containing the source code and the data set is publicly available at https://github.com/lena-schwert/comparing-bias-in-KG-models.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.121.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Divergence-Based Domain Transferability for Zero-Shot Classification",
        "authors": [
            "Alexander Pugantsov",
            "Richard McCreadie"
        ],
        "published": "2023",
        "summary": "Transferring learned patterns from pretrained neural language models has been shown to significantly improve effectiveness across a variety of language-based tasks, meanwhile further tuning on intermediate tasks has been demonstrated to provide additional performance benefits, provided the intermediate task is sufficiently related to the target task. However, how to identify related tasks is an open problem, and brute-force searching effective task combinations is prohibitively expensive. Hence, the question arises, are we able to improve the effectiveness and efficiency of tasks with no training examples through selective fine-tuning? In this paper, we explore statistical measures that approximate the divergence between domain representations as a means to estimate whether tuning using one task pair will exhibit performance benefits over tuning another. This estimation can then be used to reduce the number of task pairs that need to be tested by eliminating pairs that are unlikely to provide benefits. Through experimentation over 58 tasks and over 6,600 task pair combinations, we demonstrate that statistical measures can distinguish effective task pairs, and the resulting estimates can reduce end-to-end runtime by up to 40%.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.122.pdf",
        "source": "eacl2023"
    },
    {
        "title": "“Chère maison” or “maison chère”? Transformer-based prediction of adjective placement in French",
        "authors": [
            "Eleni Metheniti",
            "Tim Van de Cruys",
            "Wissam Kerkri",
            "Juliette Thuilier",
            "Nabil Hathout"
        ],
        "published": "2023",
        "summary": "In French, the placement of the adjective within a noun phrase is subject to variation: it can appear either before or after the noun. We conduct experiments to assess whether transformer-based language models are able to learn the adjective position in noun phrases in French –a position which depends on several linguistic factors. Prior findings have shown that transformer models are insensitive to permutated word order, but in this work, we show that finetuned models are successful at learning and selecting the correct position of the adjective. However, this success can be attributed to the process of finetuning rather than the linguistic knowledge acquired during pretraining, as evidenced by the low accuracy of experiments of classification that make use of pretrained embeddings. Comparing the finetuned models to the choices of native speakers (with a questionnaire), we notice that the models favor context and global syntactic roles, and are weaker with complex structures and fixed expressions.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.124.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Joint Reasoning on Hybrid-knowledge sources for Task-Oriented Dialog",
        "authors": [
            "Mayank Mishra",
            "Danish Contractor",
            "Dinesh Raghu"
        ],
        "published": "2023",
        "summary": "Traditional systems designed for task oriented dialog utilize knowledge present only in structured knowledge sources to generate responses. However, relevant information required to generate responses may also reside in unstructured sources, such as documents. Recent state of the art models such as HyKnow (Gao et al., 2021b) and SEKNOW (Gao et al., 2021a) aimed at overcoming these challenges make limiting assumptions about the knowledge sources. For instance, these systems assume that certain types of information, such as a phone number, is always present in a structured knowledge base (KB) while information about aspects such as entrance ticket prices, would always be available in documents. In this paper, we create a modified version of the MutliWOZ-based dataset prepared by (Gao et al., 2021a) to demonstrate how current methods have significant degradation in performance when strict assumptions about the source of information are removed. Then, in line with recent work exploiting pre-trained language models, we fine-tune a BART (Lewiset al., 2020) based model using prompts (Brown et al., 2020; Sun et al., 2021) for the tasks of querying knowledge sources, as well as, for response generation, without makingassumptions about the information present in each knowledge source. Through a series of experiments, we demonstrate that our model is robust to perturbations to knowledge modality (source of information), and that it can fuse information from structured as well as unstructured knowledge to generate responses.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.132.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Revisiting Offline Compression: Going Beyond Factorization-based Methods for Transformer Language Models",
        "authors": [
            "Mohammadreza Banaei",
            "Klaudia Bałazy",
            "Artur Kasymov",
            "Rémi Lebret",
            "Jacek Tabor",
            "Karl Aberer"
        ],
        "published": "2023",
        "summary": "Recent transformer language models achieve outstanding results in many natural language processing (NLP) tasks. However, their enormous size often makes them impractical on memory-constrained devices, requiring practitioners to compress them to smaller networks. In this paper, we explore offline compression methods, meaning computationally-cheap approaches that do not require further fine-tuning of the compressed model. We challenge the classical matrix factorization methods by proposing a novel, better-performing autoencoder-based framework. We perform a comprehensive ablation study of our approach, examining its different aspects over a diverse set of evaluation settings. Moreover, we show that enabling collaboration between modules across layers by compressing certain modules together positively impacts the final model performance. Experiments on various NLP tasks demonstrate that our approach significantly outperforms commonly used factorization-based offline compression methods.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.133.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Best Practices in the Creation and Use of Emotion Lexicons",
        "authors": [
            "Saif Mohammad"
        ],
        "published": "2023",
        "summary": "Words play a central role in how we express ourselves. Lexicons of word–emotion associations are widely used in research and real-world applications for sentiment analysis, tracking emotions associated with products and policies, studying health disorders, tracking emotional arcs of stories, and so on. However, inappropriate and incorrect use of these lexicons can lead to not just sub-optimal results, but also inferences that are directly harmful to people. This paper brings together ideas from Affective Computing and AI Ethics to present, some of the practical and ethical considerations involved in the creation and use of emotion lexicons – best practices. The goal is to provide a comprehensive set of relevant considerations, so that readers (especially those new to work with emotions) can find relevant information in one place. We hope this work will facilitate more thoughtfulness when one is deciding on what emotions to work on, how to create an emotion lexicon, how to use an emotion lexicon, how to draw meaningful inferences, and how to judge success.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.136.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Crawling The Internal Knowledge-Base of Language Models",
        "authors": [
            "Roi Cohen",
            "Mor Geva",
            "Jonathan Berant",
            "Amir Globerson"
        ],
        "published": "2023",
        "summary": "Language models are trained on large volumes of text, and as a result their parameters might contain a significant body of factual knowledge. Any downstream task performed by these models implicitly builds on these facts, and thus it is highly desirable to have means for representing this body of knowledge in an interpretable way. However, there is currently no mechanism for such a representation. Here, we propose to address this goal by extracting a knowledge-graph of facts from a given language model. We describe a procedure for “crawling” the internal knowledge-base of a language model. Specifically, given a seed entity, we expand a knowledge-graph around it. The crawling procedure is decomposed into sub-tasks, realized through specially designed prompts that control for both precision (i.e., that no wrong facts are generated) and recall (i.e., the number of facts generated). We evaluate our approach on graphs crawled starting from dozens of seed entities, and show it yields high precision graphs (82-92%), while emitting a reasonable number of facts per entity.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.139.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Intent Identification and Entity Extraction for Healthcare Queries in Indic Languages",
        "authors": [
            "Ankan Mullick",
            "Ishani Mondal",
            "Sourjyadip Ray",
            "Raghav R",
            "G Chaitanya",
            "Pawan Goyal"
        ],
        "published": "2023",
        "summary": "Scarcity of data and technological limitations for resource-poor languages in developing countries like India poses a threat to the development of sophisticated NLU systems for healthcare. To assess the current status of various state-of-the-art language models in healthcare, this paper studies the problem by initially proposing two different Healthcare datasets, Indian Healthcare Query Intent-WebMD and 1mg (IHQID-WebMD and IHQID-1mg) and one real world Indian hospital query data in English and multiple Indic languages (Hindi, Bengali, Tamil, Telugu, Marathi and Gujarati) which are annotated with the query intents as well as entities. Our aim is to detect query intents and corresponding entities. We perform extensive experiments on a set of models which in various realistic settings and explore two scenarios based on the access to English data only (less costly) and access to target language data (more expensive). We analyze context specific practical relevancy through empirical analysis. The results, expressed in terms of overall F-score show that our approach is practically useful to identify intents and entities.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.140.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Text-Derived Knowledge Helps Vision: A Simple Cross-modal Distillation for Video-based Action Anticipation",
        "authors": [
            "Sayontan Ghosh",
            "Tanvi Aggarwal",
            "Minh Hoai",
            "Niranjan Balasubramanian"
        ],
        "published": "2023",
        "summary": "Anticipating future actions in a video is useful for many autonomous and assistive technologies. Prior action anticipation work mostly treat this as a vision modality problem, where the models learn the task information primarily from the video features in the action anticipation datasets. However, knowledge about action sequences can also be obtained from external textual data. In this work, we show how knowledge in pretrained language models can be adapted and distilled into vision based action anticipation models. We show that a simple distillation technique can achieve effective knowledge transfer and provide consistent gains on a strong vision model (Anticipative Vision Transformer) for two action anticipation datasets (3.5% relative gain on EGTEA-GAZE+ and 7.2% relative gain on EPIC-KITCHEN 55), giving a new state-of-the-art result.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.141.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Towards Fine-tuning Pre-trained Language Models with Integer Forward and Backward Propagation",
        "authors": [
            "Mohammadreza Tayaranian Hosseini",
            "Alireza Ghaffari",
            "Marzieh S. Tahaei",
            "Mehdi Rezagholizadeh",
            "Masoud Asgharian",
            "Vahid Partovi Nia"
        ],
        "published": "2023",
        "summary": "The large number of parameters of some prominent language models, such as BERT, makes their fine-tuning on downstream tasks computationally intensive and energy hungry. Previously researchers were focused on lower bit-width integer data types for the forward propagation of language models to save memory and computation. As for the backward propagation, however, only 16-bit floating-point data type has been used for the fine-tuning of BERT.In this work, we use integer arithmetic for both forward and back propagation in the fine-tuning of BERT.We study the effects of varying the integer bit-width on the model’s metric performance. Our integer fine-tuning uses integer arithmetic to perform forward propagation and gradient computation of linear, layer-norm, and embedding layers of BERT.We fine-tune BERT using our integer training method on SQuAD v1.1 and SQuAD v2., and GLUE benchmark. We demonstrate that metric performance of fine-tuning 16-bit integer BERT matches both 16-bit and 32-bit floating-point baselines. Furthermore, using the faster and more memory efficient 8-bit integer data type, integer fine-tuning of BERT loses an average of 3.1 points compared to the FP32 baseline.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.143.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Data Augmentation for Radiology Report Simplification",
        "authors": [
            "Ziyu Yang",
            "Santhosh Cherian",
            "Slobodan Vucetic"
        ],
        "published": "2023",
        "summary": "This work considers the development of a text simplification model to help patients better understand their radiology reports. This paper proposes a data augmentation approach to address the data scarcity issue caused by the high cost of manual simplification. It prompts a large foundational pre-trained language model to generate simplifications of unlabeled radiology sentences. In addition, it uses paraphrasing of labeled radiology sentences. Experimental results show that the proposed data augmentation approach enables the training of a significantly more accurate simplification model than the baselines.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.144.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Embedding Recycling for Language Models",
        "authors": [
            "Jon Saad-Falcon",
            "Amanpreet Singh",
            "Luca Soldaini",
            "Mike D’Arcy",
            "Arman Cohan",
            "Doug Downey"
        ],
        "published": "2023",
        "summary": "Real-world applications of neural language models often involve running many different models over the same corpus. The high computational cost of these runs has led to interest in techniques that can reuse the contextualized embeddings produced in previous runs to speed training and inference of future ones. We refer to this approach as embedding recycling (ER). While multiple ER techniques have been proposed, their practical effectiveness is still unknown because existing evaluations consider very few models and do not adequately account for overhead costs. We perform an extensive evaluation of ER across eight different models (17 to 900 million parameters) and fourteen tasks in English. We show how a simple ER technique that caches activations from an intermediate layer of a pretrained model, and learns task-specific adapters on the later layers, is broadly effective. For the best-performing baseline in our experiments (DeBERTa-v2 XL), adding a precomputed cache results in a 90% speedup during training and 87-91% speedup for inference, with negligible impact on accuracy. Our analysis reveals important areas of future work.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.145.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Trained on 100 million words and still in shape: BERT meets British National Corpus",
        "authors": [
            "David Samuel",
            "Andrey Kutuzov",
            "Lilja Øvrelid",
            "Erik Velldal"
        ],
        "published": "2023",
        "summary": "While modern masked language models (LMs) are trained on ever larger corpora, we here explore the effects of down-scaling training to a modestly-sized but representative, well-balanced, and publicly available English text source – the British National Corpus. We show that pre-training on this carefully curated corpus can reach better performance than the original BERT model. We argue that this type of corpora has great potential as a language modeling benchmark. To showcase this potential, we present fair, reproducible and data-efficient comparative studies of LMs, in which we evaluate several training objectives and model architectures and replicate previous empirical results in a systematic way. We propose an optimized LM architecture called LTG-BERT.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.146.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints",
        "authors": [
            "Albert Lu",
            "Hongxin Zhang",
            "Yanzhe Zhang",
            "Xuezhi Wang",
            "Diyi Yang"
        ],
        "published": "2023",
        "summary": "The limits of open-ended generative models are unclear, yet increasingly important. What causes them to succeed and what causes them to fail? In this paper, we take a prompt-centric approach to analyzing and bounding the abilities of open-ended generative models. We present a generic methodology of analysis with two challenging prompt constraint types: structural and stylistic. These constraint types are categorized into a set of well-defined constraints that are analyzable by a single prompt. We then systematically create a diverse set of simple, natural, and useful prompts to robustly analyze each individual constraint. Using the GPT-3 text-davinci-002 model as a case study, we generate outputs from our collection of prompts and analyze the model’s generative failures. We also show the generalizability of our proposed method on other large models like BLOOM and OPT. Our results and our in-context mitigation strategies reveal open challenges for future research.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.148.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Selective-LAMA: Selective Prediction for Confidence-Aware Evaluation of Language Models",
        "authors": [
            "Hiyori Yoshikawa",
            "Naoaki Okazaki"
        ],
        "published": "2023",
        "summary": "Recent studies have suggested that neural language models learn and store a large amount of facts and commonsense knowledge from training data. The ability of language models to restore such knowledge is often evaluated via zero-shot cloze-style QA tasks. However, such evaluations rely only on prediction accuracy without punishing the systems for their mistakes, e.g., simply guessing or hallucinating likely answers. Selective prediction is a more informative evaluation framework that takes the confidence of predictions into account. Under the selective prediction setting, a model is evaluated not only by the number of correct predictions, but also by the ability to filter out dubious predictions by estimating the confidence of individual predictions. Such confidence-aware evaluation is crucial for determining whether to trust zero-shot predictions of language models. In this paper, we apply the selective prediction setting to an existing benchmark, LAMA probe, and conduct extensive experiments with recent neural language models and different confidence functions. We empirically show that our Selective-LAMA evaluation is more robust to the effect of simple guesses than the conventional accuracy-based evaluation. Our evaluation reveals the importance of the choice of confidence functions by showing that simply relying on token probabilities is not always the best choice. Further analysis shows that various confidence functions exhibit different preferences over predicted tokens for a given context.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.150.pdf",
        "source": "eacl2023"
    },
    {
        "title": "AdapterSoup: Weight Averaging to Improve Generalization of Pretrained Language Models",
        "authors": [
            "Alexandra Chronopoulou",
            "Matthew Peters",
            "Alexander Fraser",
            "Jesse Dodge"
        ],
        "published": "2023",
        "summary": "Pretrained language models (PLMs) are trained on massive corpora, but often need to specialize to specific domains. A parameter-efficient adaptation method suggests training an adapter for each domain on the task of language modeling. This leads to good in-domain scores but can be impractical for domain- or resource-restricted settings. A solution is to use a related-domain adapter for the novel domain at test time. In this paper, we introduce AdapterSoup, an approach that performs weight-space averaging of adapters trained on different domains. Our approach is embarrassingly parallel: first, we train a set of domain-specific adapters; then, for each novel domain, we determine which adapters should be averaged at test time. We present extensive experiments showing that AdapterSoup consistently improves performance to new domains without extra training. We also explore weight averaging of adapters trained on the same domain with different hyper-parameters, and show that it preserves the performance of a PLM on new domains while obtaining strong in-domain results. We explore various approaches for choosing which adapters to combine, such as text clustering and semantic similarity. We find that using clustering leads to the most competitive results on novel domains.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.153.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Fairness in Language Models Beyond English: Gaps and Challenges",
        "authors": [
            "Krithika Ramesh",
            "Sunayana Sitaram",
            "Monojit Choudhury"
        ],
        "published": "2023",
        "summary": "With language models becoming increasingly ubiquitous, it has become essential to address their inequitable treatment of diverse demographic groups and factors. Most research on evaluating and mitigating fairness harms has been concentrated on English, while multilingual models and non-English languages have received comparatively little attention. In this paper, we survey different aspects of fairness in languages beyond English and multilingual contexts. This paper presents a survey of fairness in multilingual and non-English contexts, highlighting the shortcomings of current research and the difficulties faced by methods designed for English. We contend that the multitude of diverse cultures and languages across the world makes it infeasible to achieve comprehensive coverage in terms of constructing fairness datasets. Thus, the measurement and mitigation of biases must evolve beyond the current dataset-driven practices that are narrowly focused on specific dimensions and types of biases and, therefore, impossible to scale across languages and cultures.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.157.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Global-Local Modeling with Prompt-Based Knowledge Enhancement for Emotion Inference in Conversation",
        "authors": [
            "Renxi Wang",
            "Shi Feng"
        ],
        "published": "2023",
        "summary": "The ability to recognize emotions in conversations is necessary and important for the online chatbot to do tasks such as empathetic response generation and emotional support. Present researches mainly focus on recognizing emotions through a speaker’s utterance, while research on emotion inference predicts emotions of addressees through previous utterances. Because of the lack of the addressee’s utterance, emotion inference is more challenging than emotion recognition. In this paper, we propose a global-local modeling method based on recurrent neural networks (RNN) and pre-trained language models (PLM) to do emotion inference, which utilizes the sequence modeling ability of RNNs and abundant knowledge from PLMs. Moreover, we take the whole dialogue history as input of PLM to generate knowledge by in-context learning. Experimental results show that our model with knoledge enhancement achieves state-of-the-art performance on all three datasets.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.158.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Decipherment as Regression: Solving Historical Substitution Ciphers by Learning Symbol Recurrence Relations",
        "authors": [
            "Nishant Kambhatla",
            "Logan Born",
            "Anoop Sarkar"
        ],
        "published": "2023",
        "summary": "Solving substitution ciphers involves mapping sequences of cipher symbols to fluent text in a target language. This has conventionally been formulated as a search problem, to find the decipherment key using a character-level language model to constrain the search space. This work instead frames decipherment as a sequence prediction task, using a Transformer-based causal language model to learn recurrences between characters in a ciphertext. We introduce a novel technique for transcribing arbitrary substitution ciphers into a common recurrence encoding. By leveraging this technique, we (i) create a large synthetic dataset of homophonic ciphers using random keys, and (ii) train a decipherment model that predicts the plaintext sequence given a recurrence-encoded ciphertext. Our method achieves strong results on synthetic 1:1 and homophonic ciphers, and cracks several real historic homophonic ciphers. Our analysis shows that the model learns recurrence relations between cipher symbols and recovers decipherment keys in its self-attention.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.160.pdf",
        "source": "eacl2023"
    },
    {
        "title": "A Survey on Recent Advances in Keyphrase Extraction from Pre-trained Language Models",
        "authors": [
            "Mingyang Song",
            "Yi Feng",
            "Liping Jing"
        ],
        "published": "2023",
        "summary": "Keyphrase Extraction (KE) is a critical component in Natural Language Processing (NLP) systems for selecting a set of phrases from the document that could summarize the important information discussed in the document. Typically, a keyphrase extraction system can significantly accelerate the speed of information retrieval and help people get first-hand information from a long document quickly and accurately. Specifically, keyphrases are capable of providing semantic metadata characterizing documents and producing an overview of the content of a document. In this paper, we introduce keyphrase extraction, present a review of the recent studies based on pre-trained language models, offer interesting insights on the different approaches, highlight open issues, and give a comparative experimental study of popular supervised as well as unsupervised techniques on several datasets. To encourage more instantiations, we release the related files mentioned in this paper.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.161.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Prompting for explanations improves Adversarial NLI. Is this true? {Yes} it is {true} because {it weakens superficial cues}",
        "authors": [
            "Pride Kavumba",
            "Ana Brassard",
            "Benjamin Heinzerling",
            "Kentaro Inui"
        ],
        "published": "2023",
        "summary": "Explanation prompts ask language models to not only assign a particular label to a giveninput, such as true, entailment, or contradiction in the case of natural language inference but also to generate a free-text explanation that supports this label. For example: “This is label because explanation.” While this type of prompt was originally introduced with the aim of improving model interpretability, we showhere that explanation prompts also improve robustness to adversarial perturbations in naturallanguage inference benchmarks. Compared to prompting for labels only, explanation prompting consistently yields stronger performance on adversarial benchmarks, outperforming the state of the art on Adversarial Natural Language Inference, Counterfactually-Augmented Natural Language Inference, and SNLI-Hard datasets. We argue that the increase in robustness is due to the fact that prompting for explanations weakens superficial cues. Specifically, single tokens that are highly predictive of the correct answer in the label-only setting become uninformative when the model also has to generate explanations.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.162.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Does Masked Language Model Pre-training with Artificial Data Improve Low-resource Neural Machine Translation?",
        "authors": [
            "Hiroto Tamura",
            "Tosho Hirasawa",
            "Hwichan Kim",
            "Mamoru Komachi"
        ],
        "published": "2023",
        "summary": "Pre-training masked language models (MLMs) with artificial data has been proven beneficial for several natural language processing tasks such as natural language understanding and summarization; however, it has been less explored for neural machine translation (NMT).A previous study revealed the benefit of transfer learning for NMT in a limited setup, which differs from MLM.In this study, we prepared two kinds of artificial data and compared the translation performance of NMT when pre-trained with MLM.In addition to the random sequences, we created artificial data mimicking token frequency information from the real world. Our results showed that pre-training the models with artificial data by MLM improves translation performance in low-resource situations. Additionally, we found that pre-training on artificial data created considering token frequency information facilitates improved performance.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.166.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Performance and Risk Trade-offs for Multi-word Text Prediction at Scale",
        "authors": [
            "Aniket Vashishtha",
            "S Sai Prasad",
            "Payal Bajaj",
            "Vishrav Chaudhary",
            "Kate Cook",
            "Sandipan Dandapat",
            "Sunayana Sitaram",
            "Monojit Choudhury"
        ],
        "published": "2023",
        "summary": "Large Language Models such as GPT-3 are well-suited for text prediction tasks, which can help and delight users during text composition. LLMs are known to generate ethically inappropriate predictions even for seemingly innocuous contexts. Toxicity detection followed by filtering is a common strategy for mitigating the harm from such predictions. However, as we shall argue in this paper, in the context of text prediction, it is not sufficient to detect and filter toxic content. One also needs to ensure factual correctness and group-level fairness of the predictions; failing to do so can make the system ineffective and nonsensical at best, and unfair and detrimental to the users at worst. We discuss the gaps and challenges of toxicity detection approaches - from blocklist-based approaches to sophisticated state-of-the-art neural classifiers - by evaluating them on the text prediction task for English against a manually crafted CheckList of harms targeted at different groups and different levels of severity.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.167.pdf",
        "source": "eacl2023"
    },
    {
        "title": "How Much Syntactic Supervision is “Good Enough”?",
        "authors": [
            "Hiroshi Noji",
            "Yohei Oseki"
        ],
        "published": "2023",
        "summary": "In this paper, we explore how much syntactic supervision is “good enough” to make language models (LMs) more human-like. Specifically, we propose the new method called syntactic ablation, where syntactic LMs, namely Recurrent Neural Network Grammars (RNNGs), are gradually ablated from full syntactic supervision to zero syntactic supervision (≈ unidirectional LSTM) by preserving NP, VP, PP, SBAR nonterminal symbols and the combinations thereof. The 17 ablated grammars are then evaluated via targeted syntactic evaluation on the SyntaxGym benchmark. The results of our syntactic ablation demonstrated that (i) the RNNG with zero syntactic supervision underperformed the RNNGs with some syntactic supervision, (ii) the RNNG with full syntactic supervision underperformed the RNNGs with less syntactic supervision, and (iii) the RNNG with mild syntactic supervision achieved the best performance comparable to the state-of-the-art GPT-2-XL. Those results may suggest that the “good enough” approach to language processing seems to make LMs more human-like.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.173.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Better Pre-Training by Reducing Representation Confusion",
        "authors": [
            "Haojie Zhang",
            "Mingfei Liang",
            "Ruobing Xie",
            "Zhenlong Sun",
            "Bo Zhang",
            "Leyu Lin"
        ],
        "published": "2023",
        "summary": "In this work, we revisit the Transformer-based pre-trained language models and identify two different types of information confusion in position encoding and model representations, respectively. Firstly, we show that in the relative position encoding, the joint modeling about relative distances and directions brings confusion between two heterogeneous information. It may make the model unable to capture the associative semantics of the same distance and the opposite directions, which in turn affects the performance of downstream tasks. Secondly, we notice the BERT with Mask Language Modeling (MLM) pre-training objective outputs similar token representations (last hidden states of different tokens) and head representations (attention weightsof different heads), which may make the diversity of information expressed by different tokens and heads limited. Motivated by the above investigation, we propose two novel techniques to improve pre-trained language models: Decoupled Directional Relative Position (DDRP) encoding and MTH pre-training objective. DDRP decouples the relative distance features and the directional features in classical relative position encoding. MTH applies two novel auxiliary regularizers besides MLM to enlarge the dissimilarities between (a) last hidden states of different tokens, and (b) attention weights of different heads. These designs allow the model to capture different categories of information more clearly, as a way to alleviate information confusion in representation learning for better optimization. Extensive experiments and ablation studies on GLUE benchmark demonstrate the effectiveness of our proposed methods.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.176.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Simple and Effective Multi-Token Completion from Masked Language Models",
        "authors": [
            "Oren Kalinsky",
            "Guy Kushilevitz",
            "Alexander Libov",
            "Yoav Goldberg"
        ],
        "published": "2023",
        "summary": "Pre-trained neural masked language models are often used for predicting a replacement token for a given sequence position, in a cloze-like task. However, this usage is restricted to predicting a single token, from a relatively small pre-trained vocabulary. Recent Sequence2Sequence pre-trained LMs like T5 do allow predicting multi-token completions, but are more expensive to train and run. We show that pre-trained masked language models can be adapted to produce multi-token completions, with only a modest addition to their parameter count. We propose two simple adaptation approaches, trading parameter counts for accuracy. The first method generates multi-token completions from a conditioned RNN. It has a very low parameter count and achieves competitive results. The second method is even simpler: it adds items corresponding to multi-token units to the output prediction matrix. While being higher in parameter count than the RNN method, it also surpasses current state-of-the-art multi-token completion models, including T5-3B, while being significantly more parameter efficient. We demonstrate that our approach is flexible to different vocabularies and domains and can effectively leverage existing pre-trained models available in different domains. Finally, a human evaluation further validates our results and shows that our solution regularly provides valid completions, as well as reasonable correctness for factual-sentence completions.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.179.pdf",
        "source": "eacl2023"
    },
    {
        "title": "A Survey on Dynamic Neural Networks for Natural Language Processing",
        "authors": [
            "Canwen Xu",
            "Julian McAuley"
        ],
        "published": "2023",
        "summary": "Effectively scaling large Transformer models is a main driver of recent advances in natural language processing. Dynamic neural networks, as an emerging research direction, are capable of scaling up neural networks with sub-linear increases in computation and time by dynamically adjusting their computational path based on the input. Dynamic neural networks could be a promising solution to the growing parameter numbers of pretrained language models, allowing both model pretraining with trillions of parameters and faster inference on mobile devices. In this survey, we summarize the progress of three types of dynamic neural networks in NLP: skimming, mixture of experts, and early exit. We also highlight current challenges in dynamic neural networks and directions for future research.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.180.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Transformers with Learnable Activation Functions",
        "authors": [
            "Haishuo Fang",
            "Ji-Ung Lee",
            "Nafise Sadat Moosavi",
            "Iryna Gurevych"
        ],
        "published": "2023",
        "summary": "Activation functions can have a significant impact on reducing the topological complexity of input data and therefore, improving a model’s performance. However, the choice of activation functions is seldom discussed or explored in Transformer-based language models. As a common practice, commonly used activation functions like Gaussian Error Linear Unit (GELU) are chosen beforehand and then remain fixed from pre-training to fine-tuning. In this paper, we investigate the impact of activation functions on Transformer-based models by utilizing rational activation functions (RAFs). In contrast to fixed activation functions (FAF), RAFs are capable of learning the optimal activation functions from data. Our experiments show that the RAF-based Transformer model (RAFT) achieves a better performance than its FAF-based counterpart (). For instance, we find that RAFT outperforms on the GLUE benchmark by 5.71 points when using only 100 training examples and by 2.05 points on SQuAD with all available data. Analyzing the shapes of the learned RAFs further unveils that they vary across different layers and different tasks; opening a promising way to better analyze and understand large, pre-trained language models.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.181.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Reliable Gradient-free and Likelihood-free Prompt Tuning",
        "authors": [
            "Maohao Shen",
            "Soumya Ghosh",
            "Prasanna Sattigeri",
            "Subhro Das",
            "Yuheng Bu",
            "Gregory Wornell"
        ],
        "published": "2023",
        "summary": "Due to privacy or commercial constraints, large pre-trained language models (PLMs) are often offered as black-box APIs. Fine-tuning such models to downstream tasks is challenging because one can neither access the model’s internal representations nor propagate gradients through it. This paper addresses these challenges by developing techniques for adapting PLMs with only API access. Building on recent work on soft prompt tuning, we develop methods to tune the soft prompts without requiring gradient computation. Further, we develop extensions that in addition to not requiring gradients also do not need to access any internal representation of the PLM beyond the input embeddings. Moreover, instead of learning a single prompt, our methods learn a distribution over prompts allowing us to quantify predictive uncertainty. Ours is the first work to consider uncertainty in prompts when only having API access to the PLM. Finally, through extensive experiments, we carefully vet the proposed methods and find them competitive with (and sometimes even improving on) gradient-based approaches with full access to the PLM.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.183.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Combining Psychological Theory with Language Models for Suicide Risk Detection",
        "authors": [
            "Daniel Izmaylov",
            "Avi Segal",
            "Kobi Gal",
            "Meytal Grimland",
            "Yossi Levi-Belz"
        ],
        "published": "2023",
        "summary": "With the increased awareness of situations of mental crisis and their societal impact, online services providing emergency support are becoming commonplace in many countries. Computational models, trained on discussions between help-seekers and providers, can support suicide prevention by identifying at-risk individuals. However, the lack of domain-specific models, especially in low-resource languages, poses a significant challenge for the automatic detection of suicide risk. We propose a model that combines pre-trained language models (PLM) with a fixed set of manually crafted (and clinically approved) set of suicidal cues, followed by a two-stage fine-tuning process. Our model achieves 0.91 ROC-AUC and an F2-score of 0.55, significantly outperforming an array of strong baselines even early on in the conversation, which is critical for real-time detection in the field. Moreover, the model performs well across genders and age groups.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.184.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Cross-Lingual Question Answering over Knowledge Base as Reading Comprehension",
        "authors": [
            "Chen Zhang",
            "Yuxuan Lai",
            "Yansong Feng",
            "Xingyu Shen",
            "Haowei Du",
            "Dongyan Zhao"
        ],
        "published": "2023",
        "summary": "Although many large-scale knowledge bases (KBs) claim to contain multilingual information, their support for many non-English languages is often incomplete. This incompleteness gives birth to the task of cross-lingual question answering over knowledge base (xKBQA), which aims to answer questions in languages different from that of the provided KB. One of the major challenges facing xKBQA is the high cost of data annotation, leading to limited resources available for further exploration. Another challenge is mapping KB schemas and natural language expressions in the questions under cross-lingual settings. In this paper, we propose a novel approach for xKBQA in a reading comprehension paradigm. We convert KB subgraphs into passages to narrow the gap between KB schemas and questions, which enables our model to benefit from recent advances in multilingual pre-trained language models (MPLMs) and cross-lingual machine reading comprehension (xMRC). Specifically, we use MPLMs, with considerable knowledge of cross-lingual mappings, for cross-lingual reading comprehension. Existing high-quality xMRC datasets can be further utilized to finetune our model, greatly alleviating the data scarcity issue in xKBQA. Extensive experiments on two xKBQA datasets in 12 languages show that our approach outperforms various baselines and achieves strong few-shot and zero-shot performance. Our dataset and code are released for further research.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.185.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Interventional Probing in High Dimensions: An NLI Case Study",
        "authors": [
            "Julia Rozanova",
            "Marco Valentino",
            "Lucas Cordeiro",
            "André Freitas"
        ],
        "published": "2023",
        "summary": "Probing strategies have been shown to detect the presence of various linguistic features in large language models; in particular, semantic features intermediate to the “natural logic” fragment of the Natural Language Inference task (NLI). In the case of natural logic, the relation between the intermediate features and the entailment label is explicitly known: as such, this provides a ripe setting for interventional studies on the NLI models’ representations, allowing for stronger causal conjectures and a deeper critical analysis of interventional probing methods. In this work, we carry out new and existing representation-level interventions to investigate the effect of these semantic features on NLI classification: we perform amnesic probing (which removes features as directed by learned linear probes) and introduce the mnestic probing variation (which forgets all dimensions except the probe-selected ones). Furthermore, we delve into the limitations of these methods and outline some pitfalls have been obscuring the effectivity of interventional probing studies.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.188.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Program Synthesis for Complex QA on Charts via Probabilistic Grammar Based Filtered Iterative Back-Translation",
        "authors": [
            "Shabbirhussain Bhaisaheb",
            "Shubham Paliwal",
            "Rajaswa Patil",
            "Manasi Patwardhan",
            "Lovekesh Vig",
            "Gautam Shroff"
        ],
        "published": "2023",
        "summary": "Answering complex reasoning questions from chart images is a challenging problem requiring a combination of natural language understanding, fine-grained perception, and analytical reasoning. Current chart-based Question Answering (QA) approaches largely address structural, visual or simple data retrieval-type questions with fixed-vocabulary answers and perform poorly on reasoning queries. We focus on answering realistic, complex, reasoning-based questions where the answer needs to be computed and not selected from a fixed set of choices. Our approach employs a neural semantic parser to transform Natural Language (NL) questions into SQL programs and execute them on a standardized schema populated from the extracted chart contents. In the absence of program annotations, i.e., in a weak supervision setting, we obtain initial SQL predictions from a pre-trained CodeT5 semantic parser and employ Filtered Iterative Back-Translation (FIBT) for iteratively augmenting our NL-SQL training set. The forward (neural semantic parser) and backward (language model) models are initially trained with an external NL-SQL dataset. We iteratively move towards the NL query distribution by generating NL questions from the synthesized SQL programs using a Probabilistic Context-Free Grammar (PCFG) where the production rule probabilities are induced to be inversely proportional to the probabilities in the training data. We filter out the generated NL queries with mismatched structures and compositions. Our FIBT approach achieves State-of-the-Art (SOTA) results on reasoning-based queries in the PlotQA dataset yielding a test accuracy of 60.44%, superseding the previous baselines by a large margin.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.189.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Exploiting Language Characteristics for Legal Domain-Specific Language Model Pretraining",
        "authors": [
            "Inderjeet Nair",
            "Natwar Modani"
        ],
        "published": "2023",
        "summary": "Pretraining large language models has resulted in tremendous performance improvement for many natural language processing (NLP) tasks. While for non-domain specific tasks, such models can be used directly, a common strategy to achieve better performance for specific domains involves pretraining these language models over domain specific data using objectives like Masked Language Modelling (MLM), Autoregressive Language Modelling, etc. While such pretraining addresses the change in vocabulary and style of language for the domain, it is otherwise a domain agnostic approach. In this work, we investigate the effect of incorporating pretraining objectives that explicitly tries to exploit the domain specific language characteristics in addition to such MLM based pretraining. Particularly, we examine two distinct characteristics associated with the legal domain and propose pretraining objectives modelling these characteristics. The proposed objectives target improvement of token-level feature representation, as well as aim to incorporate sentence level semantics. We demonstrate superiority in the performance of the models pretrained using our objectives against those trained using domain-agnostic objectives over several legal downstream tasks.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.190.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Global Constraints with Prompting for Zero-Shot Event Argument Classification",
        "authors": [
            "Zizheng Lin",
            "Hongming Zhang",
            "Yangqiu Song"
        ],
        "published": "2023",
        "summary": "Determining the role of event arguments is a crucial subtask of event extraction. Most previous supervised models leverage costly annotations, which is not practical for open-domain applications. In this work, we propose to use global constraints with prompting to effectively tackles event argument classification without any annotation and task-specific training. Specifically, given an event and its associated passage, the model first creates several new passages by prefix prompts and cloze prompts, where prefix prompts indicate event type and trigger span, and cloze prompts connect each candidate role with the target argument span. Then, a pre-trained language model scores the new passages, making the initial prediction. Our novel prompt templates can easily adapt to all events and argument types without manual effort. Next, the model regularizes the prediction by global constraints exploiting cross-task, cross-argument, and cross-event relations. Extensive experiments demonstrate our model’s effectiveness: it outperforms the best zero-shot baselines by 12.5% and 10.9% F1 on ACE and ERE with given argument spans and by 4.3% and 3.3% F1, respectively, without given argument spans. We have made our code publicly available.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.191.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Distillation of encoder-decoder transformers for sequence labelling",
        "authors": [
            "Marco Farina",
            "Duccio Pappadopulo",
            "Anant Gupta",
            "Leslie Huang",
            "Ozan Irsoy",
            "Thamar Solorio"
        ],
        "published": "2023",
        "summary": "Driven by encouraging results on a wide range of tasks, the field of NLP is experiencing an accelerated race to develop bigger language models. This race for bigger models has also underscored the need to continue the pursuit of practical distillation approaches that can leverage the knowledge acquired by these big models in a compute-efficient manner. Having this goal in mind, we build on recent work to propose a hallucination-free framework for sequence tagging that is especially suited for distillation. We show empirical results of new state-of-the-art performance across multiple sequence labelling datasets and validate the usefulness of this framework for distilling a large model in a few-shot learning scenario.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.192.pdf",
        "source": "eacl2023"
    },
    {
        "title": "Discourse Structure Extraction from Pre-Trained and Fine-Tuned Language Models in Dialogues",
        "authors": [
            "Chuyuan Li",
            "Patrick Huber",
            "Wen Xiao",
            "Maxime Amblard",
            "Chloe Braud",
            "Giuseppe Carenini"
        ],
        "published": "2023",
        "summary": "Discourse processing suffers from data sparsity, especially for dialogues. As a result, we explore approaches to infer latent discourse structures for dialogues, based on attention matrices from Pre-trained Language Models (PLMs). We investigate multiple auxiliary tasks for fine-tuning and show that the dialogue-tailored Sentence Ordering task performs best. To locate and exploit discourse information in PLMs, we propose an unsupervised and a semi-supervised method. Our proposals thereby achieve encouraging results on the STAC corpus, with F1 scores of 57.2 and 59.3 for the unsupervised and semi-supervised methods, respectively. When restricted to projective trees, our scores improved to 63.3 and 68.1.",
        "pdf_link": "https://aclanthology.org/2023.findings-eacl.194.pdf",
        "source": "eacl2023"
    }
]