[
    {
        "title": "Learning Natural Language Generation with Truncated Reinforcement Learning",
        "authors": [
            "Alice Martin",
            "Guillaume Quispe",
            "Charles Ollion",
            "Sylvain Le Corff",
            "Florian Strub",
            "Olivier Pietquin"
        ],
        "published": "2022",
        "summary": "This paper introduces TRUncated ReinForcement Learning for Language (TrufLL), an original approach to train conditional languagemodels without a supervised learning phase, by only using reinforcement learning (RL). As RL methods unsuccessfully scale to large action spaces, we dynamically truncate the vocabulary space using a generic language model. TrufLL thus enables to train a language agent by solely interacting with its environment without any task-specific prior knowledge; it is only guided with a task-agnostic language model. Interestingly, this approach avoids the dependency to labelled datasets and inherently reduces pretrained policy flaws such as language or exposure biases. We evaluate TrufLL on two visual question generation tasks, for which we report positive results over performance and language metrics, which we then corroborate with a human evaluation. To our knowledge, it is the first approach that successfully learns a language generation policy without pre-training, using only reinforcement learning.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.2.pdf"
    },
    {
        "title": "Language Model Augmented Monotonic Attention for Simultaneous Translation",
        "authors": [
            "Sathish Reddy Indurthi",
            "Mohd Abbas Zaidi",
            "Beomseok Lee",
            "Nikhil Kumar Lakumarapu",
            "Sangha Kim"
        ],
        "published": "2022",
        "summary": "The state-of-the-art adaptive policies for Simultaneous Neural Machine Translation (SNMT) use monotonic attention to perform read/write decisions based on the partial source and target sequences. The lack of sufficient information might cause the monotonic attention to take poor read/write decisions, which in turn negatively affects the performance of the SNMT model. On the other hand, human translators make better read/write decisions since they can anticipate the immediate future words using linguistic information and domain knowledge. In this work, we propose a framework to aid monotonic attention with an external language model to improve its decisions. Experiments on MuST-C English-German and English-French speech-to-text translation tasks show the future information from the language model improves the state-of-the-art monotonic multi-head attention model further.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.3.pdf"
    },
    {
        "title": "LEA: Meta Knowledge-Driven Self-Attentive Document Embedding for Few-Shot Text Classification",
        "authors": [
            "S. K. Hong",
            "Tae Young Jang"
        ],
        "published": "2022",
        "summary": "Text classification has achieved great success with the prosperity of deep learning and pre-trained language models. However, we often encounter labeled data deficiency problems in real-world text-classification tasks. To overcome such challenging scenarios, interest in few-shot learning has increased, whereas most few-shot text classification studies suffer from a difficulty of utilizing pre-trained language models. In the study, we propose a novel learning method for learning how to attend, called LEA, through which meta-level attention aspects are derived based on our meta-learning strategy. This enables the generation of task-specific document embedding with leveraging pre-trained language models even though a few labeled data instances are given. We evaluate our proposed learning method on five benchmark datasets. The results show that the novel method robustly provides the competitive performance compared to recent few-shot learning methods for all the datasets.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.7.pdf"
    },
    {
        "title": "Enhancing Self-Attention with Knowledge-Assisted Attention Maps",
        "authors": [
            "Jiangang Bai",
            "Yujing Wang",
            "Hong Sun",
            "Ruonan Wu",
            "Tianmeng Yang",
            "Pengfei Tang",
            "Defu Cao",
            "Mingliang Zhang1",
            "Yunhai Tong",
            "Yaming Yang",
            "Jing Bai",
            "Ruofei Zhang",
            "Hao Sun",
            "Wei Shen"
        ],
        "published": "2022",
        "summary": "Large-scale pre-trained language models have attracted extensive attentions in the research community and shown promising results on various tasks of natural language processing. However, the attention maps, which record the attention scores between tokens in self-attention mechanism, are sometimes ineffective as they are learned implicitly without the guidance of explicit semantic knowledge. Thus, we aim to infuse explicit external knowledge into pre-trained language models to further boost their performance. Existing works of knowledge infusion largely depend on multi-task learning frameworks, which are inefficient and require large-scale re-training when new knowledge is considered. In this paper, we propose a novel and generic solution, KAM-BERT, which directly incorporates knowledge-generated attention maps into the self-attention mechanism. It requires only a few extra parameters and supports efficient fine-tuning once new knowledge is added. KAM-BERT achieves consistent improvements on various academic datasets for natural language understanding. It also outperforms other state-of-the-art methods which conduct knowledge infusion into transformer-based architectures. Moreover, we apply our model to an industry-scale ad relevance application and show its advantages in the real-world scenario.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.8.pdf"
    },
    {
        "title": "Knowledge-Grounded Dialogue Generation with a Unified Knowledge Representation",
        "authors": [
            "Yu Li",
            "Baolin Peng",
            "Yelong Shen",
            "Yi Mao",
            "Lars Liden",
            "Zhou Yu",
            "Jianfeng Gao"
        ],
        "published": "2022",
        "summary": "Knowledge-grounded dialogue systems are challenging to build due to the lack of training data and heterogeneous knowledge sources. Existing systems perform poorly on unseen topics due to limited topics covered in the training data. In addition, it is challenging to generalize to the domains that require different types of knowledge sources. To address the above challenges, we present PLUG, a language model that homogenizes different knowledge sources to a unified knowledge representation for knowledge-grounded dialogue generation tasks. We first retrieve relevant information from heterogeneous knowledge sources (e.g., wiki, dictionary, or knowledge graph); Then the retrieved knowledge is transformed into text and concatenated with dialogue history to feed into the language model for generating responses. PLUG is pre-trained on a large-scale knowledge-grounded dialogue corpus. The empirical evaluation on two benchmarks shows that PLUG generalizes well across different knowledge-grounded dialogue tasks. It achieves comparable performance with state-of-the-art methods in the fully-supervised setting and significantly outperforms other approaches in zero-shot and few-shot settings.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.15.pdf"
    },
    {
        "title": "Cooperative Self-training of Machine Reading Comprehension",
        "authors": [
            "Hongyin Luo",
            "Shang-Wen Li",
            "Mingye Gao",
            "Seunghak Yu",
            "James Glass"
        ],
        "published": "2022",
        "summary": "Pretrained language models have significantly improved the performance of downstream language understanding tasks, including extractive question answering, by providing high-quality contextualized word embeddings. However, training question answering models still requires large amounts of annotated data for specific domains. In this work, we propose a cooperative self-training framework, RGX, for automatically generating more non-trivial question-answer pairs to improve model performance. RGX is built upon a masked answer extraction task with an interactive learning environment containing an answer entity Recognizer, a question Generator, and an answer eXtractor. Given a passage with a masked entity, the generator generates a question around the entity, and the extractor is trained to extract the masked entity with the generated question and raw texts. The framework allows the training of question generation and answering models on any text corpora without annotation. We further leverage a self-training technique to improve the performance of both question generation and answer extraction models. Experiment results show that RGX outperforms the state-of-the-art (SOTA) pretrained language models and transfer learning approaches on standard question-answering benchmarks, and yields the new SOTA performance under given model size and transfer learning settings.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.18.pdf"
    },
    {
        "title": "Seed-Guided Topic Discovery with Out-of-Vocabulary Seeds",
        "authors": [
            "Yu Zhang",
            "Yu Meng",
            "Xuan Wang",
            "Sheng Wang",
            "Jiawei Han"
        ],
        "published": "2022",
        "summary": "Discovering latent topics from text corpora has been studied for decades. Many existing topic models adopt a fully unsupervised setting, and their discovered topics may not cater to users’ particular interests due to their inability of leveraging user guidance. Although there exist seed-guided topic discovery approaches that leverage user-provided seeds to discover topic-representative terms, they are less concerned with two factors: (1) the existence of out-of-vocabulary seeds and (2) the power of pre-trained language models (PLMs). In this paper, we generalize the task of seed-guided topic discovery to allow out-of-vocabulary seeds. We propose a novel framework, named SeeTopic, wherein the general knowledge of PLMs and the local semantics learned from the input corpus can mutually benefit each other. Experiments on three real datasets from different domains demonstrate the effectiveness of SeeTopic in terms of topic coherence, accuracy, and diversity.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.21.pdf"
    },
    {
        "title": "SwahBERT: Language Model of Swahili",
        "authors": [
            "Gati Martin",
            "Medard Edmund Mswahili",
            "Young-Seob Jeong",
            "Jiyoung Woo"
        ],
        "published": "2022",
        "summary": "The rapid development of social networks, electronic commerce, mobile Internet, and other technologies, has influenced the growth of Web data. Social media and Internet forums are valuable sources of citizens’ opinions, which can be analyzed for community development and user behavior analysis. Unfortunately, the scarcity of resources (i.e., datasets or language models) become a barrier to the development of natural language processing applications in low-resource languages. Thanks to the recent growth of online forums and news platforms of Swahili, we introduce two datasets of Swahili in this paper: a pre-training dataset of approximately 105MB with 16M words and annotated dataset of 13K instances for the emotion classification task. The emotion classification dataset is manually annotated by two native Swahili speakers. We pre-trained a new monolingual language model for Swahili, namely SwahBERT, using our collected pre-training data, and tested it with four downstream tasks including emotion classification. We found that SwahBERT outperforms multilingual BERT, a well-known existing language model, in almost all downstream tasks.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.23.pdf"
    },
    {
        "title": "Understand before Answer: Improve Temporal Reading Comprehension via Precise Question Understanding",
        "authors": [
            "Hao Huang",
            "Xiubo Geng",
            "Guodong Long",
            "Daxin Jiang"
        ],
        "published": "2022",
        "summary": "This work studies temporal reading comprehension (TRC), which reads a free-text passage and answers temporal ordering questions. Precise question understanding is critical for temporal reading comprehension. For example, the question “What happened before the victory” and “What happened after the victory” share almost all words except one, while their answers are totally different. Moreover, even if two questions query about similar temporal relations, different varieties might also lead to various answers. For example, although both the question “What usually happened during the press release?” and “What might happen during the press release” query events which happen after “the press release”, they convey divergent semantics. To this end, we propose a novel reading comprehension approach with precise question understanding. Specifically, a temporal ordering question is embedded into two vectors to capture the referred event and the temporal relation. Then we evaluate the temporal relation between candidate events and the referred event based on that. Such fine-grained representations offer two benefits. First, it enables a better understanding of the question by focusing on different elements of a question. Second, it provides good interpretability when evaluating temporal relations. Furthermore, we also harness an auxiliary contrastive loss for representation learning of temporal relations, which aims to distinguish relations with subtle but critical changes. The proposed approach outperforms strong baselines and achieves state-of-the-art performance on the TORQUE dataset. It also increases the accuracy of four pre-trained language models (BERT base, BERT large, RoBERTa base, and RoBETRa large), demonstrating its generic effectiveness on divergent models.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.28.pdf"
    },
    {
        "title": "Fine-tuning Pre-trained Language Models for Few-shot Intent Detection: Supervised Pre-training and Isotropization",
        "authors": [
            "Haode Zhang",
            "Haowen Liang",
            "Yuwei Zhang",
            "Liming Zhan",
            "Xiaolei Lu",
            "Albert Lam",
            "Xiao-Ming Wu"
        ],
        "published": "2022",
        "summary": "It is challenging to train a good intent classifier for a task-oriented dialogue system with only a few annotations. Recent studies have shown that fine-tuning pre-trained language models with a small set of labeled utterances from public benchmarks in a supervised manner is extremely helpful. However, we find that supervised pre-training yields an anisotropic feature space, which may suppress the expressive power of the semantic representations. Inspired by recent research in isotropization, we propose to improve supervised pre-training by regularizing the feature space towards isotropy. We propose two regularizers based on contrastive learning and correlation matrix respectively, and demonstrate their effectiveness through extensive experiments. Our main finding is that it is promising to regularize supervised pre-training with isotropization to further improve the performance of few-shot intent detection. The source code can be found at https://github.com/fanolabs/isoIntentBert-main.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.39.pdf"
    },
    {
        "title": "Machine-in-the-Loop Rewriting for Creative Image Captioning",
        "authors": [
            "Vishakh Padmakumar",
            "He He"
        ],
        "published": "2022",
        "summary": "Machine-in-the-loop writing aims to build models that assist humans to accomplish their writing tasks more effectively. Prior work has found that providing users a machine-written draft or sentence-level continuations has limited success since the generated text tends to deviate from users’ intention. To allow the user to retain control over the content, we train a rewriting model that, when prompted, modifies specified spans of text within the user’s original draft to introduce descriptive and figurative elements in the text. We evaluate the model on its ability to collaborate with humans on the task of creative image captioning. On a user study through Amazon Mechanical Turk, our model is rated to be more helpful by users than a baseline infilling language model. In addition, third-party evaluation shows that users write more descriptive and figurative captions when collaborating with our model compared to completing the task alone. However, the improvement is not uniform across user groups: the model is more helpful to skilled users, which risks widening the gap between skilled and novice users, highlighting a need for careful, user-centric evaluation of interactive systems.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.42.pdf"
    },
    {
        "title": "Reframing Human-AI Collaboration for Generating Free-Text Explanations",
        "authors": [
            "Sarah Wiegreffe",
            "Jack Hessel",
            "Swabha Swayamdipta",
            "Mark Riedl",
            "Yejin Choi"
        ],
        "published": "2022",
        "summary": "Large language models are increasingly capable of generating fluent-appearing text with relatively little task-specific supervision. But can these models accurately explain classification decisions? We consider the task of generating free-text explanations using human-written examples in a few-shot manner. We find that (1) authoring higher quality prompts results in higher quality generations; and (2) surprisingly, in a head-to-head comparison, crowdworkers often prefer explanations generated by GPT-3 to crowdsourced explanations in existing datasets. Our human studies also show, however, that while models often produce factual, grammatical, and sufficient explanations, they have room to improve along axes such as providing novel information and supporting the label. We create a pipeline that combines GPT-3 with a supervised filter that incorporates binary acceptability judgments from humans in the loop. Despite the intrinsic subjectivity of acceptability judgments, we demonstrate that acceptability is partially correlated with various fine-grained attributes of explanations. Our approach is able to consistently filter GPT-3-generated explanations deemed acceptable by humans.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.47.pdf"
    },
    {
        "title": "Fuse It More Deeply! A Variational Transformer with Layer-Wise Latent Variable Inference for Text Generation",
        "authors": [
            "Jinyi Hu",
            "Xiaoyuan Yi",
            "Wenhao Li",
            "Maosong Sun",
            "Xing Xie"
        ],
        "published": "2022",
        "summary": "The past several years have witnessed Variational Auto-Encoder’s superiority in various text generation tasks. However, due to the sequential nature of the text, auto-regressive decoders tend to ignore latent variables and then reduce to simple language models, known as the KL vanishing problem, which would further deteriorate when VAE is combined with Transformer-based structures. To ameliorate this problem, we propose Della, a novel variational Transformer framework. Della learns a series of layer-wise latent variables with each inferred from those of lower layers and tightly coupled with the hidden states by low-rank tensor product. In this way, Della forces these posterior latent variables to be fused deeply with the whole computation path and hence incorporate more information. We theoretically demonstrate that our method can be regarded as entangling latent variables to avoid posterior information decrease through layers, enabling Della to get higher non-zero KL values even without any annealing or thresholding tricks. Experiments on four unconditional and three conditional generation tasks show that Della could better alleviate KL vanishing and improve both quality and diversity compared to several strong baselines.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.51.pdf"
    },
    {
        "title": "NeuroLogic A*esque Decoding: Constrained Text Generation with Lookahead Heuristics",
        "authors": [
            "Ximing Lu",
            "Sean Welleck",
            "Peter West",
            "Liwei Jiang",
            "Jungo Kasai",
            "Daniel Khashabi",
            "Ronan Le Bras",
            "Lianhui Qin",
            "Youngjae Yu",
            "Rowan Zellers",
            "Noah A. Smith",
            "Yejin Choi"
        ],
        "published": "2022",
        "summary": "The dominant paradigm for neural text generation is left-to-right decoding from autoregressive language models. Constrained or controllable generation under complex lexical constraints, however, requires foresight to plan ahead feasible future paths. Drawing inspiration from the A* search algorithm, we propose NeuroLogic A*esque, a decoding algorithm that incorporates heuristic estimates of future cost. We develop lookahead heuristics that are efficient for large-scale language models, making our method a drop-in replacement for common techniques such as beam search and top-k sampling. To enable constrained generation, we build on NeuroLogic decoding (Lu et al., 2021), combining its flexibility in incorporating logical constraints with A*esque estimates of future constraint satisfaction. Our approach outperforms competitive baselines on five generation tasks, and achieves new state-of-the-art performance on table-to-text generation, constrained machine translation, and keyword-constrained generation. The improvements are particularly notable on tasks that require complex constraint satisfaction or in few-shot or zero-shot settings. NeuroLogic A*esque illustrates the power of decoding for improving and enabling new capabilities of large-scale language models.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.57.pdf"
    },
    {
        "title": "GRAM: Fast Fine-tuning of Pre-trained Language Models for Content-based Collaborative Filtering",
        "authors": [
            "Yoonseok Yang",
            "Kyu Seok Kim",
            "Minsam Kim",
            "Juneyoung Park"
        ],
        "published": "2022",
        "summary": "Content-based collaborative filtering (CCF) predicts user-item interactions based on both users’ interaction history and items’ content information. Recently, pre-trained language models (PLM) have been used to extract high-quality item encodings for CCF. However, it is resource-intensive to train a PLM-based CCF model in an end-to-end (E2E) manner, since optimization involves back-propagating through every content encoding within a given user interaction sequence. To tackle this issue, we propose GRAM (GRadient Accumulation for Multi-modality in CCF), which exploits the fact that a given item often appears multiple times within a batch of interaction histories. Specifically, Single-step GRAM aggregates each item encoding’s gradients for back-propagation, with theoretic equivalence to the standard E2E training. As an extension of Single-step GRAM, we propose Multi-step GRAM, which increases the gradient update latency, achieving a further speedup with drastically less GPU memory. GRAM significantly improves training efficiency (up to 146x) on five datasets from two task domains of Knowledge Tracing and News Recommendation. Our code is available at https://github.com/yoonseok312/GRAM.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.61.pdf"
    },
    {
        "title": "Generating Repetitions with Appropriate Repeated Words",
        "authors": [
            "Toshiki Kawamoto",
            "Hidetaka Kamigaito",
            "Kotaro Funakoshi",
            "Manabu Okumura"
        ],
        "published": "2022",
        "summary": "A repetition is a response that repeats words in the previous speaker’s utterance in a dialogue. Repetitions are essential in communication to build trust with others, as investigated in linguistic studies. In this work, we focus on repetition generation. To the best of our knowledge, this is the first neural approach to address repetition generation. We propose Weighted Label Smoothing, a smoothing method for explicitly learning which words to repeat during fine-tuning, and a repetition scoring method that can output more appropriate repetitions during decoding. We conducted automatic and human evaluations involving applying these methods to the pre-trained language model T5 for generating repetitions. The experimental results indicate that our methods outperformed baselines in both evaluations.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.62.pdf"
    },
    {
        "title": "CoSIm: Commonsense Reasoning for Counterfactual Scene Imagination",
        "authors": [
            "Hyounghun Kim",
            "Abhay Zala",
            "Mohit Bansal"
        ],
        "published": "2022",
        "summary": "As humans, we can modify our assumptions about a scene by imagining alternative objects or concepts in our minds. For example, we can easily anticipate the implications of the sun being overcast by rain clouds (e.g., the street will get wet) and accordingly prepare for that. In this paper, we introduce a new dataset called Commonsense Reasoning for Counterfactual Scene Imagination (CoSIm) which is designed to evaluate the ability of AI systems to reason about scene change imagination. To be specific, in this multimodal task/dataset, models are given an image and an initial question-response pair about the image. Next, a counterfactual imagined scene change (in textual form) is applied, and the model has to predict the new response to the initial question based on this scene change. We collect 3.5K high-quality and challenging data instances, with each instance consisting of an image, a commonsense question with a response, a description of a counterfactual change, a new response to the question, and three distractor responses. Our dataset contains various complex scene change types (such as object addition/removal/state change, event description, environment change, etc.) that require models to imagine many different scenarios and reason about the changed scenes. We present a baseline model based on a vision-language Transformer (i.e., LXMERT) and ablation studies. Through human evaluation, we demonstrate a large human-model performance gap, suggesting room for promising future work on this challenging, counterfactual multimodal task.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.66.pdf"
    },
    {
        "title": "Provably Confidential Language Modelling",
        "authors": [
            "Xuandong Zhao",
            "Lei Li",
            "Yu-Xiang Wang"
        ],
        "published": "2022",
        "summary": "Large language models are shown to memorize privacy information such as social security numbers in training data. Given the sheer scale of the training corpus, it is challenging to screen and filter these privacy data, either manually or automatically. In this paper, we propose Confidentially Redacted Training (CRT), a method to train language generation models while protecting the confidential segments. We borrow ideas from differential privacy (which solves a related but distinct problem) and show that our method is able to provably prevent unintended memorization by randomizing parts of the training process. Moreover, we show that redaction with an approximately correct screening policy amplifies the confidentiality guarantee. We implement the method for both LSTM and GPT language models. Our experimental results show that the models trained by CRT obtain almost the same perplexity while preserving strong confidentiality.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.69.pdf"
    },
    {
        "title": "When a sentence does not introduce a discourse entity, Transformer-based models still sometimes refer to it",
        "authors": [
            "Sebastian Schuster",
            "Tal Linzen"
        ],
        "published": "2022",
        "summary": "Understanding longer narratives or participating in conversations requires tracking of discourse entities that have been mentioned. Indefinite noun phrases (NPs), such as ‘a dog’, frequently introduce discourse entities but this behavior is modulated by sentential operators such as negation. For example, ‘a dog’ in ‘Arthur doesn’t own a dog’ does not introduce a discourse entity due to the presence of negation. In this work, we adapt the psycholinguistic assessment of language models paradigm to higher-level linguistic phenomena and introduce an English evaluation suite that targets the knowledge of the interactions between sentential operators and indefinite NPs. We use this evaluation suite for a fine-grained investigation of the entity tracking abilities of the Transformer-based models GPT-2 and GPT-3. We find that while the models are to a certain extent sensitive to the interactions we investigate, they are all challenged by the presence of multiple NPs and their behavior is not systematic, which suggests that even models at the scale of GPT-3 do not fully acquire basic entity tracking abilities.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.71.pdf"
    },
    {
        "title": "On Curriculum Learning for Commonsense Reasoning",
        "authors": [
            "Adyasha Maharana",
            "Mohit Bansal"
        ],
        "published": "2022",
        "summary": "Commonsense reasoning tasks follow a standard paradigm of finetuning pretrained language models on the target task data, where samples are introduced to the model in a random order during training. However, recent research suggests that data order can have a significant impact on the performance of finetuned models for natural language understanding. Hence, we examine the effect of a human-like easy-to-difficult curriculum during finetuning of language models for commonsense reasoning tasks. We use paced curriculum learning to rank data and sample training mini-batches with increasing levels of difficulty from the ranked dataset during finetuning. Further, we investigate the effect of an adaptive curriculum, i.e., the data ranking is dynamically updated during training based on the current state of the learner model. We use a teacher model to measure difficulty of each sample and experiment with three measures based on question answering probability, variability and out-of-distribution. To understand the effectiveness of curriculum learning in various scenarios, we apply it on full model fine-tuning as well as parameter-efficient prompt-tuning settings. Our results show that fixed as well as adaptive curriculum learning significantly improve performance for five commonsense reasoning tasks, i.e., SocialIQA, CosmosQA, CODAH, HellaSwag, WinoGrande in both tuning settings. Further, we find that prioritizing the difficult samples in the tail end of training improves generalization to unseen in-domain data as well as out-of-domain data. Our work provides evidence and encourages research into curriculum learning for commonsense reasoning.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.72.pdf"
    },
    {
        "title": "FactPEGASUS: Factuality-Aware Pre-training and Fine-tuning for Abstractive Summarization",
        "authors": [
            "David Wan",
            "Mohit Bansal"
        ],
        "published": "2022",
        "summary": "We present FactPEGASUS, an abstractive summarization model that addresses the problem of factuality during pre-training and fine-tuning: (1) We augment the sentence selection strategy of PEGASUS’s (Zhang et al., 2019) pre-training objective to create pseudo-summaries that are both important and factual; (2) We introduce three complementary components for fine-tuning. The corrector removes hallucinations present in the reference summary, the contrastor uses contrastive learning to better differentiate nonfactual summaries from factual ones, and the connector bridges the gap between the pre-training and fine-tuning for better transfer of knowledge. Experiments on three downstream tasks demonstrate that FactPEGASUS substantially improves factuality evaluated by multiple automatic metrics and humans. Our thorough analysis suggests that FactPEGASUS is more factual than using the original pre-training objective in zero-shot and few-shot settings, retains factual behavior more robustly than strong baselines, and does not rely entirely on becoming more extractive to improve factuality.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.74.pdf"
    },
    {
        "title": "Masked Part-Of-Speech Model: Does Modeling Long Context Help Unsupervised POS-tagging?",
        "authors": [
            "Xiang Zhou",
            "Shiyue Zhang",
            "Mohit Bansal"
        ],
        "published": "2022",
        "summary": "Previous Part-Of-Speech (POS) induction models usually assume certain independence assumptions (e.g., Markov, unidirectional, local dependency) that do not hold in real languages. For example, the subject-verb agreement can be both long-term and bidirectional. To facilitate flexible dependency modeling, we propose a Masked Part-of-Speech Model (MPoSM), inspired by the recent success of Masked Language Models (MLM). MPoSM can model arbitrary tag dependency and perform POS induction through the objective of masked POS reconstruction. We achieve competitive results on both the English Penn WSJ dataset as well as the universal treebank containing 10 diverse languages. Though modeling the long-term dependency should ideally help this task, our ablation study shows mixed trends in different languages. To better understand this phenomenon, we design a novel synthetic experiment that can specifically diagnose the model’s ability to learn tag agreement. Surprisingly, we find that even strong baselines fail to solve this problem consistently in a very simplified setting: the agreement between adjacent words. Nonetheless, MPoSM achieves overall better performance. Lastly, we conduct a detailed error analysis to shed light on other remaining challenges.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.81.pdf"
    },
    {
        "title": "DREAM: Improving Situational QA by First Elaborating the Situation",
        "authors": [
            "Yuling Gu",
            "Bhavana Dalvi",
            "Peter Clark"
        ],
        "published": "2022",
        "summary": "When people answer questions about a specific situation, e.g., “I cheated on my mid-term exam last week. Was that wrong?”, cognitive science suggests that they form a mental picture of that situation before answering. While we do not know how language models (LMs) answer such questions, we conjecture that they may answer more accurately if they are also provided with additional details about the question situation, elaborating the “scene”. To test this conjecture, we train a new model, DREAM, to answer questions that elaborate the scenes that situated questions are about, and then provide those elaborations as additional context to a question-answering (QA) model. We find that DREAM is able to create better scene elaborations (more accurate, useful, and consistent) than a representative state-of-the-art, zero-shot model (Macaw). We also find that using the scene elaborations as additional context improves the answer accuracy of a downstream QA system, including beyond that obtainable by simply further fine-tuning the QA system on DREAM’s training data. These results suggest that adding focused elaborations about a situation can improve a system’s reasoning about it, and may serve as an effective way of injecting new scenario-based knowledge into QA models. Finally, our approach is dataset-neutral; we observe improved QA performance across different models, with even bigger gains on models with fewer parameters.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.82.pdf"
    },
    {
        "title": "CoSe-Co: Text Conditioned Generative CommonSense Contextualizer",
        "authors": [
            "Rachit Bansal",
            "Milan Aggarwal",
            "Sumit Bhatia",
            "Jivat Kaur",
            "Balaji Krishnamurthy"
        ],
        "published": "2022",
        "summary": "Pre-trained Language Models (PTLMs) have been shown to perform well on natural language tasks. Many prior works have leveraged structured commonsense present in the form of entities linked through labeled relations in Knowledge Graphs (KGs) to assist PTLMs. Retrieval approaches use KG as a separate static module which limits coverage since KGs contain finite knowledge. Generative methods train PTLMs on KG triples to improve the scale at which knowledge can be obtained. However, training on symbolic KG entities limits their applicability in tasks involving natural language text where they ignore overall context. To mitigate this, we propose a CommonSense Contextualizer (CoSe-Co) conditioned on sentences as input to make it generically usable in tasks for generating knowledge relevant to the overall context of input text. To train CoSe-Co, we propose a novel dataset comprising of sentence and commonsense knowledge pairs. The knowledge inferred by CoSe-Co is diverse and contain novel entities not present in the underlying KG. We augment generated knowledge in Multi-Choice QA and Open-ended CommonSense Reasoning tasks leading to improvements over current best methods on CSQA, ARC, QASC and OBQA datasets. We also demonstrate its applicability in improving performance of a baseline model for paraphrase generation task.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.83.pdf"
    },
    {
        "title": "Probing via Prompting",
        "authors": [
            "Jiaoda Li",
            "Ryan Cotterell",
            "Mrinmaya Sachan"
        ],
        "published": "2022",
        "summary": "Probing is a popular approach to understand what linguistic information is contained in the representations of pre-trained language models. However, the mechanism of selecting the probe model has recently been subject to intense debate, as it is not clear if the probes are merely extracting information or modelling the linguistic property themselves. To address this challenge, this paper introduces a novel model-free approach to probing via prompting, which formulates probing as a prompting task. We conduct experiments on five probing tasks and show that PP is comparable or better at extracting information than diagnostic probes while learning much less on its own. We further combine the probing via prompting approach with pruning to analyze where the model stores the linguistic information in its architecture. Finally, we apply the probing via prompting approach to examine the usefulness of a linguistic property for pre-training by removing the heads that are essential to it and evaluating the resulting model’s performance on language modeling.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.84.pdf"
    },
    {
        "title": "Unsupervised Slot Schema Induction for Task-oriented Dialog",
        "authors": [
            "Dian Yu",
            "Mingqiu Wang",
            "Yuan Cao",
            "Izhak Shafran",
            "Laurent Shafey",
            "Hagen Soltau"
        ],
        "published": "2022",
        "summary": "Carefully-designed schemas describing how to collect and annotate dialog corpora are a prerequisite towards building task-oriented dialog systems. In practical applications, manually designing schemas can be error-prone, laborious, iterative, and slow, especially when the schema is complicated. To alleviate this expensive and time consuming process, we propose an unsupervised approach for slot schema induction from unlabeled dialog corpora. Leveraging in-domain language models and unsupervised parsing structures, our data-driven approach extracts candidate slots without constraints, followed by coarse-to-fine clustering to induce slot types. We compare our method against several strong supervised baselines, and show significant performance improvement in slot schema induction on MultiWoz and SGD datasets. We also demonstrate the effectiveness of induced schemas on downstream applications including dialog state tracking and response generation.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.86.pdf"
    },
    {
        "title": "Towards a Progression-Aware Autonomous Dialogue Agent",
        "authors": [
            "Abraham Sanders",
            "Tomek Strzalkowski",
            "Mei Si",
            "Albert Chang",
            "Deepanshu Dey",
            "Jonas Braasch",
            "Dakuo Wang"
        ],
        "published": "2022",
        "summary": "Recent advances in large-scale language modeling and generation have enabled the creation of dialogue agents that exhibit human-like responses in a wide range of conversational scenarios spanning a diverse set of tasks, from general chit-chat to focused goal-oriented discourse. While these agents excel at generating high-quality responses that are relevant to prior context, they suffer from a lack of awareness of the overall direction in which the conversation is headed, and the likelihood of task success inherent therein. Thus, we propose a framework in which dialogue agents can evaluate the progression of a conversation toward or away from desired outcomes, and use this signal to inform planning for subsequent responses. Our framework is composed of three key elements: (1) the notion of a “global” dialogue state (GDS) space, (2) a task-specific progression function (PF) computed in terms of a conversation’s trajectory through this space, and (3) a planning mechanism based on dialogue rollouts by which an agent may use progression signals to select its next response.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.87.pdf"
    },
    {
        "title": "Cross-Domain Detection of GPT-2-Generated Technical Text",
        "authors": [
            "Juan Diego Rodriguez",
            "Todd Hay",
            "David Gros",
            "Zain Shamsi",
            "Ravi Srinivasan"
        ],
        "published": "2022",
        "summary": "Machine-generated text presents a potential threat not only to the public sphere, but also to the scientific enterprise, whereby genuine research is undermined by convincing, synthetic text. In this paper we examine the problem of detecting GPT-2-generated technical research text. We first consider the realistic scenario where the defender does not have full information about the adversary’s text generation pipeline, but is able to label small amounts of in-domain genuine and synthetic text in order to adapt to the target distribution. Even in the extreme scenario of adapting a physics-domain detector to a biomedical detector, we find that only a few hundred labels are sufficient for good performance. Finally, we show that paragraph-level detectors can be used to detect the tampering of full-length documents under a variety of threat models.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.88.pdf"
    },
    {
        "title": "Context-Aware Abbreviation Expansion Using Large Language Models",
        "authors": [
            "Shanqing Cai",
            "Subhashini Venugopalan",
            "Katrin Tomanek",
            "Ajit Narayanan",
            "Meredith Morris",
            "Michael Brenner"
        ],
        "published": "2022",
        "summary": "Motivated by the need for accelerating text entry in augmentative and alternative communication (AAC) for people with severe motor impairments, we propose a paradigm in which phrases are abbreviated aggressively as primarily word-initial letters. Our approach is to expand the abbreviations into full-phrase options by leveraging conversation context with the power of pretrained large language models (LLMs). Through zero-shot, few-shot, and fine-tuning experiments on four public conversation datasets, we show that for replies to the initial turn of a dialog, an LLM with 64B parameters is able to exactly expand over 70% of phrases with abbreviation length up to 10, leading to an effective keystroke saving rate of up to about 77% on these exact expansions. Including a small amount of context in the form of a single conversation turn more than doubles abbreviation expansion accuracies compared to having no context, an effect that is more pronounced for longer phrases. Additionally, the robustness of models against typo noise can be enhanced through fine-tuning on noisy data.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.91.pdf"
    },
    {
        "title": "Theory-Grounded Measurement of U.S. Social Stereotypes in English Language Models",
        "authors": [
            "Yang Trista Cao",
            "Anna Sotnikova",
            "Hal Daumé III",
            "Rachel Rudinger",
            "Linda Zou"
        ],
        "published": "2022",
        "summary": "NLP models trained on text have been shown to reproduce human stereotypes, which can magnify harms to marginalized groups when systems are deployed at scale. We adapt the Agency-Belief-Communion (ABC) stereotype model of Koch et al. (2016) from social psychology as a framework for the systematic study and discovery of stereotypic group-trait associations in language models (LMs). We introduce the sensitivity test (SeT) for measuring stereotypical associations from language models. To evaluate SeT and other measures using the ABC model, we collect group-trait judgments from U.S.-based subjects to compare with English LM stereotypes. Finally, we extend this framework to measure LM stereotyping of intersectional identities.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.92.pdf"
    },
    {
        "title": "Sort by Structure: Language Model Ranking as Dependency Probing",
        "authors": [
            "Max Müller-Eberstein",
            "Rob van der Goot",
            "Barbara Plank"
        ],
        "published": "2022",
        "summary": "Making an informed choice of pre-trained language model (LM) is critical for performance, yet environmentally costly, and as such widely underexplored. The field of Computer Vision has begun to tackle encoder ranking, with promising forays into Natural Language Processing, however they lack coverage of linguistic tasks such as structured prediction. We propose probing to rank LMs, specifically for parsing dependencies in a given language, by measuring the degree to which labeled trees are recoverable from an LM’s contextualized embeddings. Across 46 typologically and architecturally diverse LM-language pairs, our probing approach predicts the best LM choice 79% of the time using orders of magnitude less compute than training a full parser. Within this study, we identify and analyze one recently proposed decoupled LM—RemBERT—and find it strikingly contains less inherent dependency information, but often yields the best parser after full fine-tuning. Without this outlier our approach identifies the best LM in 89% of cases.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.93.pdf"
    },
    {
        "title": "Efficient Hierarchical Domain Adaptation for Pretrained Language Models",
        "authors": [
            "Alexandra Chronopoulou",
            "Matthew Peters",
            "Jesse Dodge"
        ],
        "published": "2022",
        "summary": "The remarkable success of large language models has been driven by dense models trained on massive unlabeled, unstructured corpora. These corpora typically contain text from diverse, heterogeneous sources, but information about the source of the text is rarely used during training. Transferring their knowledge to a target domain is typically done by continuing training in-domain. In this paper, we introduce a method to permit domain adaptation to many diverse domains using a computationally efficient adapter approach. Our method is based on the observation that textual domains are partially overlapping, and we represent domains as a hierarchical tree structure where each node in the tree is associated with a set of adapter weights. When combined with a frozen pretrained language model, this approach enables parameter sharing among related domains, while avoiding negative interference between unrelated ones. Experimental results with GPT-2 and a large fraction of the 100 most represented websites in C4 show across-the-board improvements in-domain. We additionally provide an inference time algorithm for a held-out domain and show that averaging over multiple paths through the tree enables further gains in generalization, while adding only a marginal cost to inference.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.96.pdf"
    },
    {
        "title": "On the Economics of Multilingual Few-shot Learning: Modeling the Cost-Performance Trade-offs of Machine Translated and Manual Data",
        "authors": [
            "Kabir Ahuja",
            "Monojit Choudhury",
            "Sandipan Dandapat"
        ],
        "published": "2022",
        "summary": "Borrowing ideas from Production functions in micro-economics, in this paper we introduce a framework to systematically evaluate the performance and cost trade-offs between machine-translated and manually-created labelled data for task-specific fine-tuning of massively multilingual language models. We illustrate the effectiveness of our framework through a case-study on the TyDIQA-GoldP dataset. One of the interesting conclusion of the study is that if the cost of machine translation is greater than zero, the optimal performance at least cost is always achieved with at least some or only manually-created data. To our knowledge, this is the first attempt towards extending the concept of production functions to study data collection strategies for training multilingual models, and can serve as a valuable tool for other similar cost vs data trade-offs in NLP.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.98.pdf"
    },
    {
        "title": "AcTune: Uncertainty-Based Active Self-Training for Active Fine-Tuning of Pretrained Language Models",
        "authors": [
            "Yue Yu",
            "Lingkai Kong",
            "Jieyu Zhang",
            "Rongzhi Zhang",
            "Chao Zhang"
        ],
        "published": "2022",
        "summary": "Although fine-tuning pre-trained language models (PLMs) renders strong performance in many NLP tasks, it relies on excessive labeled data. Recently, researchers have resorted to active fine-tuning for enhancing the label efficiency of PLM fine-tuning, but existing methods of this type usually ignore the potential of unlabeled data. We develop AcTune, a new framework that improves the label efficiency of active PLM fine-tuning by unleashing the power of unlabeled data via self-training. AcTune switches between data annotation and model self-training based on uncertainty: the unlabeled samples of high-uncertainty are selected for annotation, while the ones from low-uncertainty regions are used for model self-training. Additionally, we design (1) a region-aware sampling strategy to avoid redundant samples when querying annotations and (2) a momentum-based memory bank to dynamically aggregate the model’s pseudo labels to suppress label noise in self-training. Experiments on 6 text classification datasets show that AcTune outperforms the strongest active learning and self-training baselines and improves the label efficiency of PLM fine-tuning by 56.2% on average. Our implementation is available at https://github.com/yueyu1030/actune.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.102.pdf"
    },
    {
        "title": "Label Anchored Contrastive Learning for Language Understanding",
        "authors": [
            "Zhenyu Zhang",
            "Yuming Zhao",
            "Meng Chen",
            "Xiaodong He"
        ],
        "published": "2022",
        "summary": "Contrastive learning (CL) has achieved astonishing progress in computer vision, speech, and natural language processing fields recently with self-supervised learning. However, CL approach to the supervised setting is not fully explored, especially for the natural language understanding classification task. Intuitively, the class label itself has the intrinsic ability to perform hard positive/negative mining, which is crucial for CL. Motivated by this, we propose a novel label anchored contrastive learning approach (denoted as LaCon) for language understanding. Specifically, three contrastive objectives are devised, including a multi-head instance-centered contrastive loss (ICL), a label-centered contrastive loss (LCL), and a label embedding regularizer (LER). Our approach does not require any specialized network architecture or any extra data augmentation, thus it can be easily plugged into existing powerful pre-trained language models. Compared to the state-of-the-art baselines, LaCon obtains up to 4.1% improvement on the popular datasets of GLUE and CLUE benchmarks. Besides, LaCon also demonstrates significant advantages under the few-shot and data imbalance settings, which obtains up to 9.4% improvement on the FewGLUE and FewCLUE benchmarking tasks.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.103.pdf"
    },
    {
        "title": "Forecasting COVID-19 Caseloads Using Unsupervised Embedding Clusters of Social Media Posts",
        "authors": [
            "Felix Drinkall",
            "Stefan Zohren",
            "Janet Pierrehumbert"
        ],
        "published": "2022",
        "summary": "We present a novel approach incorporating transformer-based language models into infectious disease modelling. Text-derived features are quantified by tracking high-density clusters of sentence-level representations of Reddit posts within specific US states’ COVID-19 subreddits. We benchmark these clustered embedding features against features extracted from other high-quality datasets. In a threshold-classification task, we show that they outperform all other feature types at predicting upward trend signals, a significant result for infectious disease modelling in areas where epidemiological data is unreliable. Subsequently, in a time-series forecasting task, we fully utilise the predictive power of the caseload and compare the relative strengths of using different supplementary datasets as covariate feature sets in a transformer-based time-series model.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.105.pdf"
    },
    {
        "title": "Disentangled Learning of Stance and Aspect Topics for Vaccine Attitude Detection in Social Media",
        "authors": [
            "Lixing Zhu",
            "Zheng Fang",
            "Gabriele Pergola",
            "Robert Procter",
            "Yulan He"
        ],
        "published": "2022",
        "summary": "Building models to detect vaccine attitudes on social media is challenging because of the composite, often intricate aspects involved, and the limited availability of annotated data. Existing approaches have relied heavily on supervised training that requires abundant annotations and pre-defined aspect categories. Instead, with the aim of leveraging the large amount of unannotated data now available on vaccination, we propose a novel semi-supervised approach for vaccine attitude detection, called VADet. A variational autoencoding architecture based on language models is employed to learn from unlabelled data the topical information of the domain. Then, the model is fine-tuned with a few manually annotated examples of user attitudes. We validate the effectiveness of VADet on our annotated data and also on an existing vaccination corpus annotated with opinions on vaccines. Our results show that VADet is able to learn disentangled stance and aspect topics, and outperforms existing aspect-based sentiment analysis models on both stance detection and tweet clustering.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.112.pdf"
    },
    {
        "title": "SKILL: Structured Knowledge Infusion for Large Language Models",
        "authors": [
            "Fedor Moiseev",
            "Zhe Dong",
            "Enrique Alfonseca",
            "Martin Jaggi"
        ],
        "published": "2022",
        "summary": "Large language models (LLMs) have demonstrated human-level performance on a vast spectrum of natural language tasks. However, it is largely unexplored whether they can better internalize knowledge from a structured data, such as a knowledge graph, or from text. In this work, we propose a method to infuse structured knowledge into LLMs, by directly training T5 models on factual triples of knowledge graphs (KGs). We show that models pre-trained on Wikidata KG with our method outperform the T5 baselines on FreebaseQA and WikiHop, as well as the Wikidata-answerable subset of TriviaQA and NaturalQuestions. The models pre-trained on factual triples compare competitively with the ones on natural language sentences that contain the same knowledge. Trained on a smaller size KG, WikiMovies, we saw 3x improvement of exact match score on MetaQA task. The proposed method has an advantage that no alignment between the knowledge graph and text corpus is required in curating training data. This makes our method particularly useful when working with industry-scale knowledge graphs.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.113.pdf"
    },
    {
        "title": "Aspect Is Not You Need: No-aspect Differential Sentiment Framework for Aspect-based Sentiment Analysis",
        "authors": [
            "Jiahao Cao",
            "Rui Liu",
            "Huailiang Peng",
            "Lei Jiang",
            "Xu Bai"
        ],
        "published": "2022",
        "summary": "Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment classification task. Most recent efforts adopt pre-trained model to classify the sentences with aspects. However, the aspect sentiment bias from pre-trained model brings some noise to the ABSA task. Besides, traditional methods using cross-entropy loss are hard to find the potential associations between sentiment polarities. In this work, we analyze the ABSA task from a novel cognition perspective: humans can often judge the sentiment of an aspect even if they do not know what the aspect is. Moreover, it is easier to distinguish positive and negative sentiments than others for human beings because positive and negative are two opposite sentiments. To this end, we propose a no-aspect differential sentiment (NADS) framework for the ABSA task. We first design a no-aspect template by replacing the aspect with a special unbiased character to eliminate the sentiment bias and obtain a stronger representation. To better get the benefits from the template, we adopt contrastive learning between the no-aspect template and the original sentence. Then we propose a differential sentiment loss instead of the cross-entropy loss to better classify the sentiments by distinguishing the different distances between sentiments. Our proposed model is a general framework and can be combined with almost all traditional ABSA methods. Experiments on SemEval 2014 show that our framework is still able to predict the sentiment of the aspect even we don’t konw what the aspect is. Moreover, our NADS framework boosts three typical ABSA methods and achieves state-of-the-art performance.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.115.pdf"
    },
    {
        "title": "MoEBERT: from BERT to Mixture-of-Experts via Importance-Guided Adaptation",
        "authors": [
            "Simiao Zuo",
            "Qingru Zhang",
            "Chen Liang",
            "Pengcheng He",
            "Tuo Zhao",
            "Weizhu Chen"
        ],
        "published": "2022",
        "summary": "Pre-trained language models have demonstrated superior performance in various natural language processing tasks. However, these models usually contain hundreds of millions of parameters, which limits their practicality because of latency requirements in real-world applications. Existing methods train small compressed models via knowledge distillation. However, performance of these small models drops significantly compared with the pre-trained models due to their reduced model capacity. We propose MoEBERT, which uses a Mixture-of-Experts structure to increase model capacity and inference speed. We initialize MoEBERT by adapting the feed-forward neural networks in a pre-trained model into multiple experts. As such, representation power of the pre-trained model is largely retained. During inference, only one of the experts is activated, such that speed can be improved. We also propose a layer-wise distillation method to train MoEBERT. We validate the efficiency and efficacy of MoEBERT on natural language understanding and question answering tasks. Results show that the proposed method outperforms existing task-specific distillation algorithms. For example, our method outperforms previous approaches by over 2% on the MNLI (mismatched) dataset. Our code is publicly available at https://github.com/SimiaoZuo/MoEBERT.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.116.pdf"
    },
    {
        "title": "Improving Multi-Document Summarization through Referenced Flexible Extraction with Credit-Awareness",
        "authors": [
            "Yun-Zhu Song",
            "Yi-Syuan Chen",
            "Hong-Han Shuai"
        ],
        "published": "2022",
        "summary": "A notable challenge in Multi-Document Summarization (MDS) is the extremely-long length of the input. In this paper, we present an extract-then-abstract Transformer framework to overcome the problem. Specifically, we leverage pre-trained language models to construct a hierarchical extractor for salient sentence selection across documents and an abstractor for rewriting the selected contents as summaries. However, learning such a framework is challenging since the optimal contents for the abstractor are generally unknown. Previous works typically create pseudo extraction oracle to enable the supervised learning for both the extractor and the abstractor. Nevertheless, we argue that the performance of such methods could be restricted due to the insufficient information for prediction and inconsistent objectives between training and testing. To this end, we propose a loss weighting mechanism that makes the model aware of the unequal importance for the sentences not in the pseudo extraction oracle, and leverage the fine-tuned abstractor to generate summary references as auxiliary signals for learning the extractor. Moreover, we propose a reinforcement learning method that can efficiently apply to the extractor for harmonizing the optimization between training and testing. Experiment results show that our framework substantially outperforms strong baselines with comparable model sizes and achieves the best results on the Multi-News, Multi-XScience, and WikiCatSum corpora.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.120.pdf"
    },
    {
        "title": "Measuring Fairness with Biased Rulers: A Comparative Study on Bias Metrics for Pre-trained Language Models",
        "authors": [
            "Pieter Delobelle",
            "Ewoenam Tokpo",
            "Toon Calders",
            "Bettina Berendt"
        ],
        "published": "2022",
        "summary": "An increasing awareness of biased patterns in natural language processing resources such as BERT has motivated many metrics to quantify ‘bias’ and ‘fairness’ in these resources. However, comparing the results of different metrics and the works that evaluate with such metrics remains difficult, if not outright impossible. We survey the literature on fairness metrics for pre-trained language models and experimentally evaluate compatibility, including both biases in language models and in their downstream tasks. We do this by combining traditional literature survey, correlation analysis and empirical evaluations. We find that many metrics are not compatible with each other and highly depend on (i) templates, (ii) attribute and target seeds and (iii) the choice of embeddings. We also see no tangible evidence of intrinsic bias relating to extrinsic bias. These results indicate that fairness or bias evaluation remains challenging for contextualized language models, among other reasons because these choices remain subjective. To improve future comparisons and fairness evaluations, we recommend to avoid embedding-based metrics and focus on fairness evaluations in downstream tasks.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.122.pdf"
    },
    {
        "title": "Representation Learning for Conversational Data using Discourse Mutual Information Maximization",
        "authors": [
            "Bishal Santra",
            "Sumegh Roychowdhury",
            "Aishik Mandal",
            "Vasu Gurram",
            "Atharva Naik",
            "Manish Gupta",
            "Pawan Goyal"
        ],
        "published": "2022",
        "summary": "Although many pretrained models exist for text or images, there have been relatively fewer attempts to train representations specifically for dialog understanding. Prior works usually relied on finetuned representations based on generic text representation models like BERT or GPT-2. But such language modeling pretraining objectives do not take the structural information of conversational text into consideration. Although generative dialog models can learn structural features too, we argue that the structure-unaware word-by-word generation is not suitable for effective conversation modeling. We empirically demonstrate that such representations do not perform consistently across various dialog understanding tasks. Hence, we propose a structure-aware Mutual Information based loss-function DMI (Discourse Mutual Information) for training dialog-representation models, that additionally captures the inherent uncertainty in response prediction. Extensive evaluation on nine diverse dialog modeling tasks shows that our proposed DMI-based models outperform strong baselines by significant margins.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.124.pdf"
    },
    {
        "title": "ValCAT: Variable-Length Contextualized Adversarial Transformations Using Encoder-Decoder Language Model",
        "authors": [
            "Chuyun Deng",
            "Mingxuan Liu",
            "Yue Qin",
            "Jia Zhang",
            "Hai-Xin Duan",
            "Donghong Sun"
        ],
        "published": "2022",
        "summary": "Adversarial texts help explore vulnerabilities in language models, improve model robustness, and explain their working mechanisms. However, existing word-level attack methods trap in a one-to-one attack pattern, i.e., only a single word can be modified in one transformation round, and they ignore the interactions between several consecutive words. In this paper, we propose ValCAT, a black-box attack framework that misleads the language model by applying variable-length contextualized transformations to the original text. Compared to word-level methods, ValCAT expands the basic units of perturbation from single words to spans composed of multiple consecutive words, enhancing the perturbation capability. Experiments show that our method outperforms state-of-the-art methods in terms of attack success rate, perplexity, and semantic similarity on several classification tasks and inference tasks. The comprehensive human evaluation demonstrates that ValCAT has a significant advantage in ensuring the fluency of the adversarial examples and achieves better semantic consistency. We release the code at https://github.com/linerxliner/ValCAT.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.125.pdf"
    },
    {
        "title": "TIE: Topological Information Enhanced Structural Reading Comprehension on Web Pages",
        "authors": [
            "Zihan Zhao",
            "Lu Chen",
            "Ruisheng Cao",
            "Hongshen Xu",
            "Xingyu Chen",
            "Kai Yu"
        ],
        "published": "2022",
        "summary": "Recently, the structural reading comprehension (SRC) task on web pages has attracted increasing research interests. Although previous SRC work has leveraged extra information such as HTML tags or XPaths, the informative topology of web pages is not effectively exploited. In this work, we propose a Topological Information Enhanced model (TIE), which transforms the token-level task into a tag-level task by introducing a two-stage process (i.e. node locating and answer refining). Based on that, TIE integrates Graph Attention Network (GAT) and Pre-trained Language Model (PLM) to leverage the topological information of both logical structures and spatial structures. Experimental results demonstrate that our model outperforms strong baselines and achieves state-of-the-art performances on the web-based SRC benchmark WebSRC at the time of writing. The code of TIE will be publicly available at https://github.com/X-LANCE/TIE.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.132.pdf"
    },
    {
        "title": "RSTGen: Imbuing Fine-Grained Interpretable Control into Long-FormText Generators",
        "authors": [
            "Rilwan Adewoyin",
            "Ritabrata Dutta",
            "Yulan He"
        ],
        "published": "2022",
        "summary": "In this paper, we study the task of improving the cohesion and coherence of long-form text generated by language models. To this end, we propose RSTGen, a framework that utilises Rhetorical Structure Theory (RST), a classical language theory, to control the discourse structure, semantics and topics of generated text. Firstly, we demonstrate our model’s ability to control structural discourse and semantic features of generated text in open generation evaluation. Then we experiment on the two challenging long-form text tasks of argument generation and story generation. Evaluation using automated metrics and a metric with high correlation to human evaluation, shows that our model performs competitively against existing models, while offering significantly more controls over generated text than alternative methods.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.133.pdf"
    },
    {
        "title": "Bridging the Gap between Language Models and Cross-Lingual Sequence Labeling",
        "authors": [
            "Nuo Chen",
            "Linjun Shou",
            "Ming Gong",
            "Jian Pei",
            "Daxin Jiang"
        ],
        "published": "2022",
        "summary": "Large-scale cross-lingual pre-trained language models (xPLMs) have shown effective in cross-lingual sequence labeling tasks (xSL), such as machine reading comprehension (xMRC) by transferring knowledge from a high-resource language to low-resource languages. Despite the great success, we draw an empirical observation that there is an training objective gap between pre-training and fine-tuning stages: e.g., mask language modeling objective requires local understanding of the masked token and the span-extraction objective requires understanding and reasoning of the global input passage/paragraph and question, leading to the discrepancy between pre-training and xMRC. In this paper, we first design a pre-training task tailored for xSL named Cross-lingual Language Informative Span Masking (CLISM) to eliminate the objective gap in a self-supervised manner. Second, we present ContrAstive-Consistency Regularization (CACR), which utilizes contrastive learning to encourage the consistency between representations of input parallel sequences via unsupervised cross-lingual instance-wise training signals during pre-training. By these means, our methods not only bridge the gap between pretrain-finetune, but also enhance PLMs to better capture the alignment between different languages. Extensive experiments prove that our method achieves clearly superior results on multiple xSL benchmarks with limited pre-training data. Our methods also surpass the previous state-of-the-art methods by a large margin in few-shot data setting, where only a few hundred training examples are available.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.139.pdf"
    },
    {
        "title": "Simple Local Attentions Remain Competitive for Long-Context Tasks",
        "authors": [
            "Wenhan Xiong",
            "Barlas Oguz",
            "Anchit Gupta",
            "Xilun Chen",
            "Diana Liskovich",
            "Omer Levy",
            "Scott Yih",
            "Yashar Mehdad"
        ],
        "published": "2022",
        "summary": "Many NLP tasks require processing long contexts beyond the length limit of pretrained models. In order to scale these models to longer text sequences, many efficient long-range attention variants have been proposed. Despite the abundance of research along this direction, it is still difficult to gauge the relative effectiveness of these models in practical use cases, e.g., if we apply these models following the pretrain-and-finetune paradigm. In this work, we aim to conduct a thorough analysis of these emerging models with large-scale and controlled experiments. For each attention variant, we pretrain large-size models using the same long-doc corpus and then finetune these models for real-world long-context tasks. Our findings reveal pitfalls of an existing widely-used long-range benchmark and show none of the tested efficient attentions can beat a simple local window attention under standard pretraining paradigms. Further analysis on local attention variants suggests that even the commonly used attention-window overlap is not necessary to achieve good downstream results — using disjoint local attentions, we are able to build a simpler and more efficient long-doc QA model that matches the performance of Longformer with half of its pretraining compute.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.144.pdf"
    },
    {
        "title": "CS1QA: A Dataset for Assisting Code-based Question Answering in an Introductory Programming Course",
        "authors": [
            "Changyoon Lee",
            "Yeon Seonwoo",
            "Alice Oh"
        ],
        "published": "2022",
        "summary": "We introduce CS1QA, a dataset for code-based question answering in the programming education domain. CS1QA consists of 9,237 question-answer pairs gathered from chat logs in an introductory programming class using Python, and 17,698 unannotated chat data with code. Each question is accompanied with the student’s code, and the portion of the code relevant to answering the question. We carefully design the annotation process to construct CS1QA, and analyze the collected dataset in detail. The tasks for CS1QA are to predict the question type, the relevant code snippet given the question and the code and retrieving an answer from the annotated corpus. Results for the experiments on several baseline models are reported and thoroughly analyzed. The tasks for CS1QA challenge models to understand both the code and natural language. This unique dataset can be used as a benchmark for source code comprehension and question answering in the educational setting.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.148.pdf"
    },
    {
        "title": "Don’t Take It Literally: An Edit-Invariant Sequence Loss for Text Generation",
        "authors": [
            "Guangyi Liu",
            "Zichao Yang",
            "Tianhua Tao",
            "Xiaodan Liang",
            "Junwei Bao",
            "Zhen Li",
            "Xiaodong He",
            "Shuguang Cui",
            "Zhiting Hu"
        ],
        "published": "2022",
        "summary": "Neural text generation models are typically trained by maximizing log-likelihood with the sequence cross entropy (CE) loss, which encourages an exact token-by-token match between a target sequence with a generated sequence. Such training objective is sub-optimal when the target sequence is not perfect, e.g., when the target sequence is corrupted with noises, or when only weak sequence supervision is available. To address the challenge, we propose a novel Edit-Invariant Sequence Loss (EISL), which computes the matching loss of a target n-gram with all n-grams in the generated sequence. EISL is designed to be robust to various noises and edits in the target sequences. Moreover, the EISL computation is essentially an approximate convolution operation with target n-grams as kernels, which is easy to implement and efficient to compute with existing libraries. To demonstrate the effectiveness of EISL, we conduct experiments on a wide range of tasks, including machine translation with noisy target sequences, unsupervised text style transfer with only weak training signals, and non-autoregressive generation with non-predefined generation order. Experimental results show our method significantly outperforms the common CE loss and other strong baselines on all the tasks. EISL has a simple API that can be used as a drop-in replacement of the CE loss: https://github.com/guangyliu/EISL.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.150.pdf"
    },
    {
        "title": "Modeling Exemplification in Long-form Question Answering via Retrieval",
        "authors": [
            "Shufan Wang",
            "Fangyuan Xu",
            "Laure Thompson",
            "Eunsol Choi",
            "Mohit Iyyer"
        ],
        "published": "2022",
        "summary": "Exemplification is a process by which writers explain or clarify a concept by providing an example. While common in all forms of writing, exemplification is particularly useful in the task of long-form question answering (LFQA), where a complicated answer can be made more understandable through simple examples. In this paper, we provide the first computational study of exemplification in QA, performing a fine-grained annotation of different types of examples (e.g., hypotheticals, anecdotes) in three corpora. We show that not only do state-of-the-art LFQA models struggle to generate relevant examples, but also that standard evaluation metrics such as ROUGE are insufficient to judge exemplification quality. We propose to treat exemplification as a retrieval problem in which a partially-written answer is used to query a large set of human-written examples extracted from a corpus. Our approach allows a reliable ranking-type automatic metrics that correlates well with human evaluation. A human evaluation shows that our model’s retrieved examples are more relevant than examples generated from a state-of-the-art LFQA model.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.151.pdf"
    },
    {
        "title": "Reference-free Summarization Evaluation via Semantic Correlation and Compression Ratio",
        "authors": [
            "Yizhu Liu",
            "Qi Jia",
            "Kenny Zhu"
        ],
        "published": "2022",
        "summary": "A document can be summarized in a number of ways. Reference-based evaluation of summarization has been criticized for its inflexibility. The more sufficient the number of abstracts, the more accurate the evaluation results. However, it is difficult to collect sufficient reference summaries. In this paper, we propose a new automatic reference-free evaluation metric that compares semantic distribution between source document and summary by pretrained language models and considers summary compression ratio. The experiments show that this metric is more consistent with human evaluation in terms of coherence, consistency, relevance and fluency.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.153.pdf"
    },
    {
        "title": "KroneckerBERT: Significant Compression of Pre-trained Language Models Through Kronecker Decomposition and Knowledge Distillation",
        "authors": [
            "Marzieh Tahaei",
            "Ella Charlaix",
            "Vahid Nia",
            "Ali Ghodsi",
            "Mehdi Rezagholizadeh"
        ],
        "published": "2022",
        "summary": "The development of over-parameterized pre-trained language models has made a significant contribution toward the success of natural language processing. While over-parameterization of these models is the key to their generalization power, it makes them unsuitable for deployment on low-capacity devices. We push the limits of state-of-the-art Transformer-based pre-trained language model compression using Kronecker decomposition. We present our KroneckerBERT, a compressed version of the BERT_BASE model obtained by compressing the embedding layer and the linear mappings in the multi-head attention, and the feed-forward network modules in the Transformer layers. Our KroneckerBERT is trained via a very efficient two-stage knowledge distillation scheme using far fewer data samples than state-of-the-art models like MobileBERT and TinyBERT. We evaluate the performance of KroneckerBERT on well-known NLP benchmarks. We show that our KroneckerBERT with compression factors of 7.7x and 21x outperforms state-of-the-art compression methods on the GLUE and SQuAD benchmarks. In particular, using only 13% of the teacher model parameters, it retain more than 99% of the accuracy on the majority of GLUE tasks.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.154.pdf"
    },
    {
        "title": "Building a Role Specified Open-Domain Dialogue System Leveraging Large-Scale Language Models",
        "authors": [
            "Sanghwan Bae",
            "Donghyun Kwak",
            "Sungdong Kim",
            "Donghoon Ham",
            "Soyoung Kang",
            "Sang-Woo Lee",
            "Woomyoung Park"
        ],
        "published": "2022",
        "summary": "Recent open-domain dialogue models have brought numerous breakthroughs. However, building a chat system is not scalable since it often requires a considerable volume of human-human dialogue data, especially when enforcing features such as persona, style, or safety. In this work, we study the challenge of imposing roles on open-domain dialogue systems, with the goal of making the systems maintain consistent roles while conversing naturally with humans. To accomplish this, the system must satisfy a role specification that includes certain conditions on the stated features as well as a system policy on whether or not certain types of utterances are allowed. For this, we propose an efficient data collection framework leveraging in-context few-shot learning of large-scale language models for building role-satisfying dialogue dataset from scratch. We then compare various architectures for open-domain dialogue systems in terms of meeting role specifications while maintaining conversational abilities. Automatic and human evaluations show that our models return few out-of-bounds utterances, keeping competitive performance on general metrics. We release a Korean dialogue dataset we built for further research.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.155.pdf"
    },
    {
        "title": "Locally Aggregated Feature Attribution on Natural Language Model Understanding",
        "authors": [
            "Sheng Zhang",
            "Jin Wang",
            "Haitao Jiang",
            "Rui Song"
        ],
        "published": "2022",
        "summary": "With the growing popularity of deep-learning models, model understanding becomes more important. Much effort has been devoted to demystify deep neural networks for better explainability. Some feature attribution methods have shown promising results in computer vision, especially the gradient-based methods where effectively smoothing the gradients with reference data is the key to a robust and faithful result. However, direct application of these gradient-based methods to NLP tasks is not trivial due to the fact that the input consists of discrete tokens and the “reference” tokens are not explicitly defined. In this work, we propose Locally Aggregated Feature Attribution (LAFA), a novel gradient-based feature attribution method for NLP models. Instead of relying on obscure reference tokens, it smooths gradients by aggregating similar reference texts derived from language model embeddings. For evaluation purpose, we also design experiments on different NLP tasks including Entity Recognition and Sentiment Analysis on public datasets and key words detection on constructed Amazon catalogue dataset. The superior performance of the proposed method is demonstrated through experiments.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.159.pdf"
    },
    {
        "title": "Evidentiality-guided Generation for Knowledge-Intensive NLP Tasks",
        "authors": [
            "Akari Asai",
            "Matt Gardner",
            "Hannaneh Hajishirzi"
        ],
        "published": "2022",
        "summary": "Retrieval-augmented generation models have shown state-of-the-art performance across many knowledge-intensive NLP tasks such as open-domain question answering and fact verification. These models are trained to generate a final output given retrieved passages that can be irrelevant to an input query, leading to learning spurious cues or memorization. This work introduces a method to incorporate evidentiality of passages—whether a passage contains correct evidence to support the output—into training the generator. We introduce a multi-task learning framework to jointly generate the final output and predict the evidentiality of each passage. Furthermore, we introduce a new task-agnostic method for obtaining high-quality silver evidentiality labels, addressing the issues of gold evidentiality labels being unavailable in most domains. Our experiments on five datasets across three knowledge-intensive tasks show that our new evidentiality-guided generator significantly outperforms its direct counterpart on all of them, and advances the state of the art on three of them. Our analysis shows that multi-task learning and silver evidentiality mining play key roles. Our code is available at https://github.com/AkariAsai/evidentiality_qa",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.162.pdf"
    },
    {
        "title": "Modularized Transfer Learning with Multiple Knowledge Graphs for Zero-shot Commonsense Reasoning",
        "authors": [
            "Yu Jin Kim",
            "Beong-woo Kwak",
            "Youngwook Kim",
            "Reinald Kim Amplayo",
            "Seung-won Hwang",
            "Jinyoung Yeo"
        ],
        "published": "2022",
        "summary": "Commonsense reasoning systems should be able to generalize to diverse reasoning cases. However, most state-of-the-art approaches depend on expensive data annotations and overfit to a specific benchmark without learning how to perform general semantic reasoning. To overcome these drawbacks, zero-shot QA systems have shown promise as a robust learning scheme by transforming a commonsense knowledge graph (KG) into synthetic QA-form samples for model training. Considering the increasing type of different commonsense KGs, this paper aims to extend the zero-shot transfer learning scenario into multiple-source settings, where different KGs can be utilized synergetically. Towards this goal, we propose to mitigate the loss of knowledge from the interference among the different knowledge sources, by developing a modular variant of the knowledge aggregation as a new zero-shot commonsense reasoning framework. Results on five commonsense reasoning benchmarks demonstrate the efficacy of our framework, improving the performance with multiple KGs.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.163.pdf"
    },
    {
        "title": "Do Prompt-Based Models Really Understand the Meaning of Their Prompts?",
        "authors": [
            "Albert Webson",
            "Ellie Pavlick"
        ],
        "published": "2022",
        "summary": "Recently, a boom of papers has shown extraordinary progress in zero-shot and few-shot learning with various prompt-based models. It is commonly argued that prompts help models to learn faster in the same way that humans learn faster when provided with task instructions expressed in natural language. In this study, we experiment with over 30 prompts manually written for natural language inference (NLI). We find that models can learn just as fast with many prompts that are intentionally irrelevant or even pathologically misleading as they do with instructively “good” prompts. Further, such patterns hold even for models as large as 175 billion parameters (Brown et al., 2020) as well as the recently proposed instruction-tuned models which are trained on hundreds of prompts (Sanh et al., 2021). That is, instruction-tuned models often produce good predictions with irrelevant and misleading prompts even at zero shots. In sum, notwithstanding prompt-based models’ impressive improvement, we find evidence of serious limitations that question the degree to which such improvement is derived from models understanding task instructions in ways analogous to humans’ use of task instructions.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.167.pdf"
    },
    {
        "title": "Towards Understanding Large-Scale Discourse Structures in Pre-Trained and Fine-Tuned Language Models",
        "authors": [
            "Patrick Huber",
            "Giuseppe Carenini"
        ],
        "published": "2022",
        "summary": "In this paper, we extend the line of BERTology work by focusing on the important, yet less explored, alignment of pre-trained and fine-tuned PLMs with large-scale discourse structures. We propose a novel approach to infer discourse information for arbitrarily long documents. In our experiments, we find that the captured discourse information is local and general, even across a collection of fine-tuning tasks. We compare the inferred discourse trees with supervised, distantly supervised and simple baselines to explore the structural overlap, finding that constituency discourse trees align well with supervised models, however, contain complementary discourse information. Lastly, we individually explore self-attention matrices to analyze the information redundancy. We find that similar discourse information is consistently captured in the same heads.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.170.pdf"
    },
    {
        "title": "Combating the Curse of Multilinguality in Cross-Lingual WSD by Aligning Sparse Contextualized Word Representations",
        "authors": [
            "Gábor Berend"
        ],
        "published": "2022",
        "summary": "In this paper, we advocate for using large pre-trained monolingual language models in cross lingual zero-shot word sense disambiguation (WSD) coupled with a contextualized mapping mechanism. We also report rigorous experiments that illustrate the effectiveness of employing sparse contextualized word representations obtained via a dictionary learning procedure. Our experimental results demonstrate that the above modifications yield a significant improvement of nearly 6.5 points of increase in the average F-score (from 62.0 to 68.5) over a collection of 17 typologically diverse set of target languages. We release our source code for replicating our experiments at https://github.com/begab/sparsity_makes_sense.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.176.pdf"
    },
    {
        "title": "What do tokens know about their characters and how do they know it?",
        "authors": [
            "Ayush Kaushal",
            "Kyle Mahowald"
        ],
        "published": "2022",
        "summary": "Pre-trained language models (PLMs) that use subword tokenization schemes can succeed at a variety of language tasks that require character-level information, despite lacking explicit access to the character composition of tokens. Here, studying a range of models (e.g., GPT- J, BERT, RoBERTa, GloVe), we probe what word pieces encode about character-level information by training classifiers to predict the presence or absence of a particular alphabetical character in a token, based on its embedding (e.g., probing whether the model embedding for “cat” encodes that it contains the character “a”). We find that these models robustly encode character-level information and, in general, larger models perform better at the task. We show that these results generalize to characters from non-Latin alphabets (Arabic, Devanagari, and Cyrillic). Then, through a series of experiments and analyses, we investigate the mechanisms through which PLMs acquire English-language character information during training and argue that this knowledge is acquired through multiple phenomena, including a systematic relationship between particular characters and particular parts of speech, as well as natural variability in the tokenization of related strings.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.179.pdf"
    },
    {
        "title": "Data Augmentation with Dual Training for Offensive Span Detection",
        "authors": [
            "Nasim Nouri"
        ],
        "published": "2022",
        "summary": "Recognizing offensive text is an important requirement for every content management system, especially for social networks. While the majority of the prior work formulate this problem as text classification, i.e., if a text excerpt is offensive or not, in this work we propose a novel model for offensive span detection (OSD), whose goal is to identify the spans responsible for the offensive tone of the text. One of the challenges to train a model for this novel setting is the lack of enough training data. To address this limitation, in this work we propose a novel method in which the large-scale pre-trained language model GPT-2 is employed to generate synthetic training data for OSD. In particular, we propose to train the GPT-2 model in a dual-training setting using the REINFORCE algorithm to generate in-domain, natural and diverse training samples. Extensive experiments on the benchmark dataset for OSD reveal the effectiveness of the proposed method.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.185.pdf"
    },
    {
        "title": "Learning To Retrieve Prompts for In-Context Learning",
        "authors": [
            "Ohad Rubin",
            "Jonathan Herzig",
            "Jonathan Berant"
        ],
        "published": "2022",
        "summary": "In-context learning is a recent paradigm in natural language understanding, where a large pre-trained language model (LM) observes a test instance and a few training examples as its input, and directly decodes the output without any update to its parameters. However, performance has been shown to strongly depend on the selected training examples (termed prompts). In this work, we propose an efficient method for retrieving prompts for in-context learning using annotated data and an LM. Given an input-output pair, we estimate the probability of the output given the input and a candidate training example as the prompt, and label training examples as positive or negative based on this probability. We then train an efficient dense retriever from this data, which is used to retrieve training examples as prompts at test time. We evaluate our approach on three sequence-to-sequence tasks where language utterances are mapped to meaning representations, and find that it substantially outperforms prior work and multiple baselines across the board.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.191.pdf"
    },
    {
        "title": "Re2G: Retrieve, Rerank, Generate",
        "authors": [
            "Michael Glass",
            "Gaetano Rossiello",
            "Md Faisal Mahbub Chowdhury",
            "Ankita Naik",
            "Pengshan Cai",
            "Alfio Gliozzo"
        ],
        "published": "2022",
        "summary": "As demonstrated by GPT-3 and T5, transformers grow in capability as parameter spaces become larger and larger. However, for tasks that require a large amount of knowledge, non-parametric memory allows models to grow dramatically with a sub-linear increase in computational cost and GPU memory requirements. Recent models such as RAG and REALM have introduced retrieval into conditional generation. These models incorporate neural initial retrieval from a corpus of passages. We build on this line of research, proposing Re2G, which combines both neural initial retrieval and reranking into a BART-based sequence-to-sequence generation. Our reranking approach also permits merging retrieval results from sources with incomparable scores, enabling an ensemble of BM25 and neural initial retrieval. To train our system end-to-end, we introduce a novel variation of knowledge distillation to train the initial retrieval, reranker and generation using only ground truth on the target sequence output. We find large gains in four diverse tasks: zero-shot slot filling, question answering, fact checking and dialog, with relative gains of 9% to 34% over the previous state-of-the-art on the KILT leaderboard. We make our code available as open source.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.194.pdf"
    },
    {
        "title": "Gender Bias in Masked Language Models for Multiple Languages",
        "authors": [
            "Masahiro Kaneko",
            "Aizhan Imankulova",
            "Danushka Bollegala",
            "Naoaki Okazaki"
        ],
        "published": "2022",
        "summary": "Masked Language Models (MLMs) pre-trained by predicting masked tokens on large corpora have been used successfully in natural language processing tasks for a variety of languages. Unfortunately, it was reported that MLMs also learn discriminative biases regarding attributes such as gender and race. Because most studies have focused on MLMs in English, the bias of MLMs in other languages has rarely been investigated. Manual annotation of evaluation data for languages other than English has been challenging due to the cost and difficulty in recruiting annotators. Moreover, the existing bias evaluation methods require the stereotypical sentence pairs consisting of the same context with attribute words (e.g. He/She is a nurse).We propose Multilingual Bias Evaluation (MBE) score, to evaluate bias in various languages using only English attribute word lists and parallel corpora between the target language and English without requiring manually annotated data. We evaluated MLMs in eight languages using the MBE and confirmed that gender-related biases are encoded in MLMs for all those languages. We manually created datasets for gender bias in Japanese and Russian to evaluate the validity of the MBE.The results show that the bias scores reported by the MBE significantly correlates with that computed from the above manually created datasets and the existing English datasets for gender bias.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.197.pdf"
    },
    {
        "title": "MetaICL: Learning to Learn In Context",
        "authors": [
            "Sewon Min",
            "Mike Lewis",
            "Luke Zettlemoyer",
            "Hannaneh Hajishirzi"
        ],
        "published": "2022",
        "summary": "We introduce MetaICL (Meta-training for In-Context Learning), a new meta-training framework for few-shot learning where a pretrained language model is tuned to do in-context learning on a large set of training tasks. This meta-training enables the model to more effectively learn a new task in context at test time, by simply conditioning on a few training examples with no parameter updates or task-specific templates. We experiment on a large, diverse collection of tasks consisting of 142 NLP datasets including classification, question answering, natural language inference, paraphrase detection and more, across seven different meta-training/target splits. MetaICL outperforms a range of baselines including in-context learning without meta-training and multi-task learning followed by zero-shot transfer. We find that the gains are particularly significant for target tasks that have domain shifts from the meta-training tasks, and that using a diverse set of the meta-training tasks is key to improvements. We also show that MetaICL approaches (and sometimes beats) the performance of models fully finetuned on the target task training data, and outperforms much bigger models with nearly 8x parameters.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.201.pdf"
    },
    {
        "title": "Using Natural Sentence Prompts for Understanding Biases in Language Models",
        "authors": [
            "Sarah Alnegheimish",
            "Alicia Guo",
            "Yi Sun"
        ],
        "published": "2022",
        "summary": "Evaluation of biases in language models is often limited to synthetically generated datasets. This dependence traces back to the need of prompt-style dataset to trigger specific behaviors of language models. In this paper, we address this gap by creating a prompt dataset with respect to occupations collected from real-world natural sentences present in Wikipedia.We aim to understand the differences between using template-based prompts and natural sentence prompts when studying gender-occupation biases in language models. We find bias evaluations are very sensitiveto the design choices of template prompts, and we propose using natural sentence prompts as a way of more systematically using real-world sentences to move away from design decisions that may bias the results.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.203.pdf"
    },
    {
        "title": "Robust Conversational Agents against Imperceptible Toxicity Triggers",
        "authors": [
            "Ninareh Mehrabi",
            "Ahmad Beirami",
            "Fred Morstatter",
            "Aram Galstyan"
        ],
        "published": "2022",
        "summary": "Warning: this paper contains content that maybe offensive or upsetting. Recent research in Natural Language Processing (NLP) has advanced the development of various toxicity detection models with the intention of identifying and mitigating toxic language from existing systems. Despite the abundance of research in this area, less attention has been given to adversarial attacks that force the system to generate toxic language and the defense against them. Existing work to generate such attacks is either based on human-generated attacks which is costly and not scalable or, in case of automatic attacks, the attack vector does not conform to human-like language, which can be detected using a language model loss. In this work, we propose attacks against conversational agents that are imperceptible, i.e., they fit the conversation in terms of coherency, relevancy, and fluency, while they are effective and scalable, i.e., they can automatically trigger the system into generating toxic language. We then propose a defense mechanism against such attacks which not only mitigates the attack but also attempts to maintain the conversational flow. Through automatic and human evaluations, we show that our defense is effective at avoiding toxic language generation even against imperceptible toxicity triggers while the generated language fits the conversation in terms of coherency and relevancy. Lastly, we establish the generalizability of such a defense mechanism on language generation models beyond conversational agents.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.204.pdf"
    },
    {
        "title": "Selective Differential Privacy for Language Modeling",
        "authors": [
            "Weiyan Shi",
            "Aiqi Cui",
            "Evan Li",
            "Ruoxi Jia",
            "Zhou Yu"
        ],
        "published": "2022",
        "summary": "With the increasing applications of language models, it has become crucial to protect these models from leaking private information. Previous work has attempted to tackle this challenge by training RNN-based language models with differential privacy guarantees. However, applying classical differential privacy to language models leads to poor model performance as the underlying privacy notion is over-pessimistic and provides undifferentiated protection for all tokens in the data. Given that the private information in natural language is sparse (for example, the bulk of an email might not carry personally identifiable information), we propose a new privacy notion, selective differential privacy, to provide rigorous privacy guarantees on the sensitive portion of the data to improve model utility. To realize such a new notion, we develop a corresponding privacy mechanism, Selective-DPSGD, for RNN-based language models. Besides language modeling, we also apply the method to a more concrete application – dialog systems. Experiments on both language modeling and dialog system building show that the proposed privacy-preserving mechanism achieves better utilities while remaining safe under various privacy attacks compared to the baselines. The data and code are released at https://github.com/wyshi/lm_privacy to facilitate future research.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.205.pdf"
    },
    {
        "title": "Do Trajectories Encode Verb Meaning?",
        "authors": [
            "Dylan Ebert",
            "Chen Sun",
            "Ellie Pavlick"
        ],
        "published": "2022",
        "summary": "Distributional models learn representations of words from text, but are criticized for their lack of grounding, or the linking of text to the non-linguistic world. Grounded language models have had success in learning to connect concrete categories like nouns and adjectives to the world via images and videos, but can struggle to isolate the meaning of the verbs themselves from the context in which they typically occur. In this paper, we investigate the extent to which trajectories (i.e. the position and rotation of objects over time) naturally encode verb semantics. We build a procedurally generated agent-object-interaction dataset, obtain human annotations for the verbs that occur in this data, and compare several methods for representation learning given the trajectories. We find that trajectories correlate as-is with some verbs (e.g., fall), and that additional abstraction via self-supervised pretraining can further capture nuanced differences in verb meaning (e.g., roll and slide).",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.206.pdf"
    },
    {
        "title": "Long Context Question Answering via Supervised Contrastive Learning",
        "authors": [
            "Avi Caciularu",
            "Ido Dagan",
            "Jacob Goldberger",
            "Arman Cohan"
        ],
        "published": "2022",
        "summary": "Long-context question answering (QA) tasks require reasoning over a long document or multiple documents. Addressing these tasks often benefits from identifying a set of evidence spans (e.g., sentences), which provide supporting evidence for answering the question. In this work, we propose a novel method for equipping long-context QA models with an additional sequence-level objective for better identification of the supporting evidence. We achieve this via an additional contrastive supervision signal in finetuning, where the model is encouraged to explicitly discriminate supporting evidence sentences from negative ones by maximizing question-evidence similarity. The proposed additional loss exhibits consistent improvements on three different strong long-context transformer models, across two challenging question answering benchmarks – HotpotQA and QAsper.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.207.pdf"
    },
    {
        "title": "Modal Dependency Parsing via Language Model Priming",
        "authors": [
            "Jiarui Yao",
            "Nianwen Xue",
            "Bonan Min"
        ],
        "published": "2022",
        "summary": "The task of modal dependency parsing aims to parse a text into its modal dependency structure, which is a representation for the factuality of events in the text. We design a modal dependency parser that is based on priming pre-trained language models, and evaluate the parser on two data sets. Compared to baselines, we show an improvement of 2.6% in F-score for English and 4.6% for Chinese. To the best of our knowledge, this is also the first work on Chinese modal dependency parsing.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.211.pdf"
    },
    {
        "title": "PPL-MCTS: Constrained Textual Generation Through Discriminator-Guided MCTS Decoding",
        "authors": [
            "Antoine Chaffin",
            "Vincent Claveau",
            "Ewa Kijak"
        ],
        "published": "2022",
        "summary": "Large language models (LM) based on Transformers allow to generate plausible long texts. In this paper, we explore how this generation can be further controlled at decoding time to satisfy certain constraints (e.g. being non-toxic, conveying certain emotions, using a specific writing style, etc.) without fine-tuning the LM.Precisely, we formalize constrained generation as a tree exploration process guided by a discriminator that indicates how well the associated sequence respects the constraint. This approach, in addition to being easier and cheaper to train than fine-tuning the LM, allows to apply the constraint more finely and dynamically. We propose several original methods to search this generation tree, notably the Monte Carlo Tree Search (MCTS) which provides theoretical guarantees on the search efficiency, but also simpler methods based on re-ranking a pool of diverse sequences using the discriminator scores. These methods are evaluated, with automatic and human-based metrics, on two types of constraints and languages: review polarity and emotion control in French and English. We show that discriminator-guided MCTS decoding achieves state-of-the-art results without having to tune the language model, in both tasks and languages. We also demonstrate that other proposed decoding methods based on re-ranking can be really effective when diversity among the generated propositions is encouraged.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.215.pdf"
    },
    {
        "title": "Progressive Class Semantic Matching for Semi-supervised Text Classification",
        "authors": [
            "Haiming Xu",
            "Lingqiao Liu",
            "Ehsan Abbasnejad"
        ],
        "published": "2022",
        "summary": "Semi-supervised learning is a promising way to reduce the annotation cost for text-classification. Combining with pre-trained language models (PLMs), e.g., BERT, recent semi-supervised learning methods achieved impressive performance. In this work, we further investigate the marriage between semi-supervised learning and a pre-trained language model. Unlike existing approaches that utilize PLMs only for model parameter initialization, we explore the inherent topic matching capability inside PLMs for building a more powerful semi-supervised learning approach. Specifically, we propose a joint semi-supervised learning process that can progressively build a standard K-way classifier and a matching network for the input text and the Class Semantic Representation (CSR). The CSR will be initialized from the given labeled sentences and progressively updated through the training process. By means of extensive experiments, we show that our method can not only bring remarkable improvement to baselines, but also overall be more stable, and achieves state-of-the-art performance in semi-supervised text classification.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.219.pdf"
    },
    {
        "title": "Low Resource Style Transfer via Domain Adaptive Meta Learning",
        "authors": [
            "Xiangyang Li",
            "Xiang Long",
            "Yu Xia",
            "Sujian Li"
        ],
        "published": "2022",
        "summary": "Text style transfer (TST) without parallel data has achieved some practical success. However, most of the existing unsupervised text style transfer methods suffer from (i) requiring massive amounts of non-parallel data to guide transferring different text styles. (ii) colossal performance degradation when fine-tuning the model in new domains. In this work, we propose DAML-ATM (Domain Adaptive Meta-Learning with Adversarial Transfer Model), which consists of two parts: DAML and ATM. DAML is a domain adaptive meta-learning approach to learn general knowledge in multiple heterogeneous source domains, capable of adapting to new unseen domains with a small amount of data. Moreover, we propose a new unsupervised TST approach Adversarial Transfer Model (ATM), composed of a sequence-to-sequence pre-trained language model and uses adversarial style training for better content preservation and style transfer. Results on multi-domain datasets demonstrate that our approach generalizes well on unseen low-resource domains, achieving state-of-the-art results against ten strong baselines.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.220.pdf"
    },
    {
        "title": "A Few Thousand Translations Go a Long Way! Leveraging Pre-trained Models for African News Translation",
        "authors": [
            "David Adelani",
            "Jesujoba Alabi",
            "Angela Fan",
            "Julia Kreutzer",
            "Xiaoyu Shen",
            "Machel Reid",
            "Dana Ruiter",
            "Dietrich Klakow",
            "Peter Nabende",
            "Ernie Chang",
            "Tajuddeen Gwadabe",
            "Freshia Sackey",
            "Bonaventure F. P. Dossou",
            "Chris Emezue",
            "Colin Leong",
            "Michael Beukman",
            "Shamsuddeen Muhammad",
            "Guyo Jarso",
            "Oreen Yousuf",
            "Andre Niyongabo Rubungo",
            "Gilles Hacheme",
            "Eric Peter Wairagala",
            "Muhammad Umair Nasir",
            "Benjamin Ajibade",
            "Tunde Ajayi",
            "Yvonne Gitau",
            "Jade Abbott",
            "Mohamed Ahmed",
            "Millicent Ochieng",
            "Anuoluwapo Aremu",
            "Perez Ogayo",
            "Jonathan Mukiibi",
            "Fatoumata Ouoba Kabore",
            "Godson Kalipe",
            "Derguene Mbaye",
            "Allahsera Auguste Tapo",
            "Victoire Memdjokam Koagne",
            "Edwin Munkoh-Buabeng",
            "Valencia Wagner",
            "Idris Abdulmumin",
            "Ayodele Awokoya",
            "Happy Buzaaba",
            "Blessing Sibanda",
            "Andiswa Bukula",
            "Sam Manthalu"
        ],
        "published": "2022",
        "summary": "Recent advances in the pre-training for language models leverage large-scale datasets to create multilingual models. However, low-resource languages are mostly left out in these datasets. This is primarily because many widely spoken languages that are not well represented on the web and therefore excluded from the large-scale crawls for datasets. Furthermore, downstream users of these models are restricted to the selection of languages originally chosen for pre-training. This work investigates how to optimally leverage existing pre-trained models to create low-resource translation systems for 16 African languages. We focus on two questions: 1) How can pre-trained models be used for languages not included in the initial pretraining? and 2) How can the resulting translation models effectively transfer to new domains? To answer these questions, we create a novel African news corpus covering 16 languages, of which eight languages are not part of any existing evaluation dataset. We demonstrate that the most effective strategy for transferring both additional languages and additional domains is to leverage small quantities of high-quality translation data to fine-tune large pre-trained models.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.223.pdf"
    },
    {
        "title": "Analyzing Encoded Concepts in Transformer Language Models",
        "authors": [
            "Hassan Sajjad",
            "Nadir Durrani",
            "Fahim Dalvi",
            "Firoj Alam",
            "Abdul Khan",
            "Jia Xu"
        ],
        "published": "2022",
        "summary": "We propose a novel framework ConceptX, to analyze how latent concepts are encoded in representations learned within pre-trained lan-guage models. It uses clustering to discover the encoded concepts and explains them by aligning with a large set of human-defined concepts. Our analysis on seven transformer language models reveal interesting insights: i) the latent space within the learned representations overlap with different linguistic concepts to a varying degree, ii) the lower layers in the model are dominated by lexical concepts (e.g., affixation) and linguistic ontologies (e.g. Word-Net), whereas the core-linguistic concepts (e.g., morphology, syntactic relations) are better represented in the middle and higher layers, iii) some encoded concepts are multi-faceted and cannot be adequately explained using the existing human-defined concepts.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.225.pdf"
    },
    {
        "title": "MuCGEC: a Multi-Reference Multi-Source Evaluation Dataset for Chinese Grammatical Error Correction",
        "authors": [
            "Yue Zhang",
            "Zhenghua Li",
            "Zuyi Bao",
            "Jiacheng Li",
            "Bo Zhang",
            "Chen Li",
            "Fei Huang",
            "Min Zhang"
        ],
        "published": "2022",
        "summary": "This paper presents MuCGEC, a multi-reference multi-source evaluation dataset for Chinese Grammatical Error Correction (CGEC), consisting of 7,063 sentences collected from three Chinese-as-a-Second-Language (CSL) learner sources. Each sentence is corrected by three annotators, and their corrections are carefully reviewed by a senior annotator, resulting in 2.3 references per sentence. We conduct experiments with two mainstream CGEC models, i.e., the sequence-to-sequence model and the sequence-to-edit model, both enhanced with large pretrained language models, achieving competitive benchmark performance on previous and our datasets. We also discuss CGEC evaluation methodologies, including the effect of multiple references and using a char-based metric. Our annotation guidelines, data, and code are available at https://github.com/HillZhang1999/MuCGEC.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.227.pdf"
    },
    {
        "title": "Enhance Incomplete Utterance Restoration by Joint Learning Token Extraction and Text Generation",
        "authors": [
            "Shumpei Inoue",
            "Tsungwei Liu",
            "Son Nguyen",
            "Minh-Tien Nguyen"
        ],
        "published": "2022",
        "summary": "This paper introduces a model for incomplete utterance restoration (IUR) called JET (Joint learning token Extraction and Text generation). Different from prior studies that only work on extraction or abstraction datasets, we design a simple but effective model, working for both scenarios of IUR. Our design simulates the nature of IUR, where omitted tokens from the context contribute to restoration. From this, we construct a Picker that identifies the omitted tokens. To support the picker, we design two label creation methods (soft and hard labels), which can work in cases of no annotation data for the omitted tokens. The restoration is done by using a Generator with the help of the Picker on joint learning. Promising results on four benchmark datasets in extraction and abstraction scenarios show that our model is better than the pretrained T5 and non-generative language model methods in both rich and limited training data settings.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.229.pdf"
    },
    {
        "title": "Curriculum: A Broad-Coverage Benchmark for Linguistic Phenomena in Natural Language Understanding",
        "authors": [
            "Zeming Chen",
            "Qiyue Gao"
        ],
        "published": "2022",
        "summary": "In the age of large transformer language models, linguistic evaluation play an important role in diagnosing models’ abilities and limitations on natural language understanding. However, current evaluation methods show some significant shortcomings. In particular, they do not provide insight into how well a language model captures distinct linguistic skills essential for language understanding and reasoning. Thus they fail to effectively map out the aspects of language understanding that remain challenging to existing models, which makes it hard to discover potential limitations in models and datasets. In this paper, we introduce Curriculum as a new format of NLI benchmark for evaluation of broad-coverage linguistic phenomena. Curriculum contains a collection of datasets that covers 36 types of major linguistic phenomena and an evaluation procedure for diagnosing how well a language model captures reasoning skills for distinct types of linguistic phenomena. We show that this linguistic-phenomena-driven benchmark can serve as an effective tool for diagnosing model behavior and verifying model learning quality. In addition, our experiments provide insight into the limitation of existing benchmark datasets and state-of-the-art models that may encourage future research on re-designing datasets, model architectures, and learning objectives.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.234.pdf"
    },
    {
        "title": "Neural Language Taskonomy: Which NLP Tasks are the most Predictive of fMRI Brain Activity?",
        "authors": [
            "Subba Reddy Oota",
            "Jashn Arora",
            "Veeral Agarwal",
            "Mounika Marreddy",
            "Manish Gupta",
            "Bapi Surampudi"
        ],
        "published": "2022",
        "summary": "Several popular Transformer based language models have been found to be successful for text-driven brain encoding. However, existing literature leverages only pretrained text Transformer models and has not explored the efficacy of task-specific learned Transformer representations. In this work, we explore transfer learning from representations learned for ten popular natural language processing tasks (two syntactic and eight semantic) for predicting brain responses from two diverse datasets: Pereira (subjects reading sentences from paragraphs) and Narratives (subjects listening to the spoken stories). Encoding models based on task features are used to predict activity in different regions across the whole brain. Features from coreference resolution, NER, and shallow syntax parsing explain greater variance for the reading activity. On the other hand, for the listening activity, tasks such as paraphrase generation, summarization, and natural language inference show better encoding performance. Experiments across all 10 task representations provide the following cognitive insights: (i) language left hemisphere has higher predictive brain activity versus language right hemisphere, (ii) posterior medial cortex, temporo-parieto-occipital junction, dorsal frontal lobe have higher correlation versus early auditory and auditory association cortex, (iii) syntactic and semantic tasks display a good predictive performance across brain regions for reading and listening stimuli resp.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.235.pdf"
    },
    {
        "title": "Unsupervised Paraphrasability Prediction for Compound Nominalizations",
        "authors": [
            "John Sie Yuen Lee",
            "Ho Hung Lim",
            "Carol Webster"
        ],
        "published": "2022",
        "summary": "Commonly found in academic and formal texts, a nominalization uses a deverbal noun to describe an event associated with its corresponding verb. Nominalizations can be difficult to interpret because of ambiguous semantic relations between the deverbal noun and its arguments. Automatic generation of clausal paraphrases for nominalizations can help disambiguate their meaning. However, previous work has not identified cases where it is awkward or impossible to paraphrase a compound nominalization. This paper investigates unsupervised prediction of paraphrasability, which determines whether the prenominal modifier of a nominalization can be re-written as a noun or adverb in a clausal paraphrase. We adopt the approach of overgenerating candidate paraphrases followed by candidate ranking with a neural language model. In experiments on an English dataset, we show that features from an Abstract Meaning Representation graph lead to statistically significant improvement in both paraphrasability prediction and paraphrase generation.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.237.pdf"
    },
    {
        "title": "Towards Efficient NLP: A Standard Evaluation and A Strong Baseline",
        "authors": [
            "Xiangyang Liu",
            "Tianxiang Sun",
            "Junliang He",
            "Jiawen Wu",
            "Lingling Wu",
            "Xinyu Zhang",
            "Hao Jiang",
            "Zhao Cao",
            "Xuanjing Huang",
            "Xipeng Qiu"
        ],
        "published": "2022",
        "summary": "Supersized pre-trained language models have pushed the accuracy of various natural language processing (NLP) tasks to a new state-of-the-art (SOTA). Rather than pursuing the reachless SOTA accuracy, more and more researchers start paying attention to model efficiency and usability. Different from accuracy, the metric for efficiency varies across different studies, making them hard to be fairly compared. To that end, this work presents ELUE (Efficient Language Understanding Evaluation), a standard evaluation, and a public leaderboard for efficient NLP models. ELUE is dedicated to depicting the Pareto Frontier for various language understanding tasks, such that it can tell whether and how much a method achieves Pareto improvement. Along with the benchmark, we also release a strong baseline, ElasticBERT, which allows BERT to exit at any layer in both static and dynamic ways. We demonstrate the ElasticBERT, despite its simplicity, outperforms or performs on par with SOTA compressed and early exiting models. With ElasticBERT, the proposed ELUE has a strong Pareto Frontier and makes a better evaluation for efficient NLP models.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.240.pdf"
    },
    {
        "title": "Learning to Transfer Prompts for Text Generation",
        "authors": [
            "Junyi Li",
            "Tianyi Tang",
            "Jian-Yun Nie",
            "Ji-Rong Wen",
            "Xin Zhao"
        ],
        "published": "2022",
        "summary": "Pretrained language models (PLMs) have made remarkable progress in text generation tasks via fine-tuning. While, it is challenging to fine-tune PLMs in a data-scarce situation. Therefore, it is non-trivial to develop a general and lightweight model that can adapt to various text generation tasks based on PLMs. To fulfill this purpose, the recent prompt-based learning offers a potential solution. In this paper, we improve this technique and propose a novel prompt-based method (PTG) for text generation in a transferable setting. First, PTG learns a set of source prompts for various source generation tasks and then transfers these prompts as target prompts to perform target generation tasks. To consider both task- and instance-level information, we design an adaptive attention mechanism to derive the target prompts. For each data instance, PTG learns a specific target prompt by attending to highly relevant source prompts. In extensive experiments, PTG yields competitive or better results than fine-tuning methods. We release our source prompts as an open resource, where users can add or reuse them to improve new text generation tasks for future research. Code and data can be available at https://github.com/RUCAIBox/Transfer-Prompts-for-Text-Generation.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.257.pdf"
    },
    {
        "title": "ElitePLM: An Empirical Study on General Language Ability Evaluation of Pretrained Language Models",
        "authors": [
            "Junyi Li",
            "Tianyi Tang",
            "Zheng Gong",
            "Lixin Yang",
            "Zhuohao Yu",
            "Zhipeng Chen",
            "Jingyuan Wang",
            "Xin Zhao",
            "Ji-Rong Wen"
        ],
        "published": "2022",
        "summary": "Nowadays, pretrained language models (PLMs) have dominated the majority of NLP tasks. While, little research has been conducted on systematically evaluating the language abilities of PLMs. In this paper, we present a large-scale empirical study on general language ability evaluation of PLMs (ElitePLM). In our study, we design four evaluation dimensions, memory, comprehension, reasoning, and composition, to measure ten widely-used PLMs within five categories. Our empirical results demonstrate that: (1) PLMs with varying training objectives and strategies are good at different ability tests; (2) fine-tuning PLMs in downstream tasks is usually sensitive to the data size and distribution; (3) PLMs have excellent transferability between similar tasks. Moreover, the prediction results of PLMs in our experiments are released as an open resource for more deep and detailed analysis on the language abilities of PLMs. This paper can guide the future work to select, apply, and design PLMs for specific tasks. We have made all the details of experiments publicly available at https://github.com/RUCAIBox/ElitePLM.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.258.pdf"
    },
    {
        "title": "Exposing the Limits of Video-Text Models through Contrast Sets",
        "authors": [
            "Jae Sung Park",
            "Sheng Shen",
            "Ali Farhadi",
            "Trevor Darrell",
            "Yejin Choi",
            "Anna Rohrbach"
        ],
        "published": "2022",
        "summary": "Recent video-text models can retrieve relevant videos based on text with a high accuracy, but to what extent do they comprehend the semantics of the text? Can they discriminate between similar entities and actions? To answer this, we propose an evaluation framework that probes video-text models with hard negatives. We automatically build contrast sets, where true textual descriptions are manipulated in ways that change their semantics while maintaining plausibility. Specifically, we leverage a pre-trained language model and a set of heuristics to create verb and person entity focused contrast sets. We apply these in the multiple choice video to-text classification setting. We test the robustness of recent methods on the proposed automatic contrast sets, and compare them to additionally collected human-generated counterparts, to assess their effectiveness. We see that model performance suffers across all methods, erasing the gap between recent CLIP-based methods vs. the earlier methods.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.261.pdf"
    },
    {
        "title": "Benchmarking Intersectional Biases in NLP",
        "authors": [
            "John Lalor",
            "Yi Yang",
            "Kendall Smith",
            "Nicole Forsgren",
            "Ahmed Abbasi"
        ],
        "published": "2022",
        "summary": "There has been a recent wave of work assessing the fairness of machine learning models in general, and more specifically, on natural language processing (NLP) models built using machine learning techniques. While much work has highlighted biases embedded in state-of-the-art language models, and more recent efforts have focused on how to debias, research assessing the fairness and performance of biased/debiased models on downstream prediction tasks has been limited. Moreover, most prior work has emphasized bias along a single dimension such as gender or race. In this work, we benchmark multiple NLP models with regards to their fairness and predictive performance across a variety of NLP tasks. In particular, we assess intersectional bias - fairness across multiple demographic dimensions. The results show that while current debiasing strategies fare well in terms of the fairness-accuracy trade-off (generally preserving predictive power in debiased models), they are unable to effectively alleviate bias in downstream tasks. Furthermore, this bias is often amplified across dimensions (i.e., intersections). We conclude by highlighting possible causes and making recommendations for future NLP debiasing research.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.263.pdf"
    },
    {
        "title": "When is BERT Multilingual? Isolating Crucial Ingredients for Cross-lingual Transfer",
        "authors": [
            "Ameet Deshpande",
            "Partha Talukdar",
            "Karthik Narasimhan"
        ],
        "published": "2022",
        "summary": "While recent work on multilingual language models has demonstrated their capacity for cross-lingual zero-shot transfer on downstream tasks, there is a lack of consensus in the community as to what shared properties between languages enable such transfer. Analyses involving pairs of natural languages are often inconclusive and contradictory since languages simultaneously differ in many linguistic aspects. In this paper, we perform a large-scale empirical study to isolate the effects of various linguistic properties by measuring zero-shot transfer between four diverse natural languages and their counterparts constructed by modifying aspects such as the script, word order, and syntax. Among other things, our experiments show that the absence of sub-word overlap significantly affects zero-shot transfer when languages differ in their word order, and there is a strong correlation between transfer performance and word embedding alignment between languages (e.g., 𝜌s=0.94 on the task of NLI). Our results call for focus in multilingual models on explicitly improving word embedding alignment between languages rather than relying on its implicit emergence.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.264.pdf"
    },
    {
        "title": "How Conservative are Language Models? Adapting to the Introduction of Gender-Neutral Pronouns",
        "authors": [
            "Stephanie Brandl",
            "Ruixiang Cui",
            "Anders Søgaard"
        ],
        "published": "2022",
        "summary": "Gender-neutral pronouns have recently been introduced in many languages to a) include non-binary people and b) as a generic singular. Recent results from psycholinguistics suggest that gender-neutral pronouns (in Swedish) are not associated with human processing difficulties. This, we show, is in sharp contrast with automated processing. We show that gender-neutral pronouns in Danish, English, and Swedish are associated with higher perplexity, more dispersed attention patterns, and worse downstream performance. We argue that such conservativity in language models may limit widespread adoption of gender-neutral pronouns and must therefore be resolved.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.265.pdf"
    },
    {
        "title": "Prompt Waywardness: The Curious Case of Discretized Interpretation of Continuous Prompts",
        "authors": [
            "Daniel Khashabi",
            "Xinxi Lyu",
            "Sewon Min",
            "Lianhui Qin",
            "Kyle Richardson",
            "Sean Welleck",
            "Hannaneh Hajishirzi",
            "Tushar Khot",
            "Ashish Sabharwal",
            "Sameer Singh",
            "Yejin Choi"
        ],
        "published": "2022",
        "summary": "Fine-tuning continuous prompts for target tasks has recently emerged as a compact alternative to full model fine-tuning. Motivated by these promising results, we investigate the feasibility of extracting a discrete (textual) interpretation of continuous prompts that is faithful to the problem they solve. In practice, we observe a “wayward” behavior between the task solved by continuous prompts and their nearest neighbor discrete projections: We can find continuous prompts that solve a task while being projected to an arbitrary text (e.g., definition of a different or even a contradictory task), while being within a very small (2%) margin of the best continuous prompt of the same size for the task. We provide intuitions behind this odd and surprising behavior, as well as extensive empirical analyses quantifying the effect of various parameters. For instance, for larger model sizes we observe higher waywardness, i.e, we can find prompts that more closely map to any arbitrary text with a smaller drop in accuracy. These findings have important implications relating to the difficulty of faithfully interpreting continuous prompts and their generalization across models and tasks, providing guidance for future progress in prompting language models.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.266.pdf"
    },
    {
        "title": "Multi2WOZ: A Robust Multilingual Dataset and Conversational Pretraining for Task-Oriented Dialog",
        "authors": [
            "Chia-Chien Hung",
            "Anne Lauscher",
            "Ivan Vulić",
            "Simone Ponzetto",
            "Goran Glavaš"
        ],
        "published": "2022",
        "summary": "Research on (multi-domain) task-oriented dialog (TOD) has predominantly focused on the English language, primarily due to the shortage of robust TOD datasets in other languages, preventing the systematic investigation of cross-lingual transfer for this crucial NLP application area. In this work, we introduce Multi2WOZ, a new multilingual multi-domain TOD dataset, derived from the well-established English dataset MultiWOZ, that spans four typologically diverse languages: Chinese, German, Arabic, and Russian. In contrast to concurrent efforts, Multi2WOZ contains gold-standard dialogs in target languages that are directly comparable with development and test portions of the English dataset, enabling reliable and comparative estimates of cross-lingual transfer performance for TOD. We then introduce a new framework for multilingual conversational specialization of pretrained language models (PrLMs) that aims to facilitate cross-lingual transfer for arbitrary downstream TOD tasks. Using such conversational PrLMs specialized for concrete target languages, we systematically benchmark a number of zero-shot and few-shot cross-lingual transfer approaches on two standard TOD tasks: Dialog State Tracking and Response Retrieval. Our experiments show that, in most setups, the best performance entails the combination of (i) conversational specialization in the target language and (ii) few-shot transfer for the concrete TOD task. Most importantly, we show that our conversational specialization in the target language allows for an exceptionally sample-efficient few-shot transfer for downstream TOD tasks.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.270.pdf"
    },
    {
        "title": "ChapterBreak: A Challenge Dataset for Long-Range Language Models",
        "authors": [
            "Simeng Sun",
            "Katherine Thai",
            "Mohit Iyyer"
        ],
        "published": "2022",
        "summary": "While numerous architectures for long-range language models (LRLMs) have recently been proposed, a meaningful evaluation of their discourse-level language understanding capabilities has not yet followed. To this end, we introduce ChapterBreak, a challenge dataset that provides an LRLM with a long segment from a narrative that ends at a chapter boundary and asks it to distinguish the beginning of the ground-truth next chapter from a set of negative segments sampled from the same narrative. A fine-grained human annotation reveals that our dataset contains many complex types of chapter transitions (e.g., parallel narratives, cliffhanger endings) that require processing global context to comprehend. Experiments on ChapterBreak show that existing LRLMs fail to effectively leverage long-range context, substantially underperforming a segment-level model trained directly for this task. We publicly release our ChapterBreak dataset to spur more principled future research into LRLMs.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.271.pdf"
    },
    {
        "title": "Knowledge Inheritance for Pre-trained Language Models",
        "authors": [
            "Yujia Qin",
            "Yankai Lin",
            "Jing Yi",
            "Jiajie Zhang",
            "Xu Han",
            "Zhengyan Zhang",
            "Yusheng Su",
            "Zhiyuan Liu",
            "Peng Li",
            "Maosong Sun",
            "Jie Zhou"
        ],
        "published": "2022",
        "summary": "Recent explorations of large-scale pre-trained language models (PLMs) have revealed the power of PLMs with huge amounts of parameters, setting off a wave of training ever-larger PLMs. However, it requires tremendous computational resources to train a large-scale PLM, which may be practically unaffordable. In addition, existing large-scale PLMs are mainly trained from scratch individually, ignoring that many well-trained PLMs are available. To this end, we explore the question how could existing PLMs benefit training large-scale PLMs in future. Specifically, we introduce a pre-training framework named “knowledge inheritance” (KI) and explore how could knowledge distillation serve as auxiliary supervision during pre-training to efficiently learn larger PLMs. Experimental results demonstrate the superiority of KI in training efficiency. We also conduct empirical analyses to explore the effects of teacher PLMs’ pre-training settings, including model architecture, pre-training data, etc. Finally, we show that KI could be applied to domain adaptation and knowledge transfer.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.288.pdf"
    },
    {
        "title": "On Transferability of Prompt Tuning for Natural Language Processing",
        "authors": [
            "Yusheng Su",
            "Xiaozhi Wang",
            "Yujia Qin",
            "Chi-Min Chan",
            "Yankai Lin",
            "Huadong Wang",
            "Kaiyue Wen",
            "Zhiyuan Liu",
            "Peng Li",
            "Juanzi Li",
            "Lei Hou",
            "Maosong Sun",
            "Jie Zhou"
        ],
        "published": "2022",
        "summary": "Prompt tuning (PT) is a promising parameter-efficient method to utilize extremely large pre-trained language models (PLMs), which can achieve comparable performance to full-parameter fine-tuning by only tuning a few soft prompts. However, PT requires much more training time than fine-tuning. Intuitively, knowledge transfer can help to improve the efficiency. To explore whether we can improve PT via prompt transfer, we empirically investigate the transferability of soft prompts across different downstream tasks and PLMs in this work. We find that (1) in zero-shot setting, trained soft prompts can effectively transfer to similar tasks on the same PLM and also to other PLMs with a cross-model projector trained on similar tasks; (2) when used as initialization, trained soft prompts of similar tasks and projected prompts of other PLMs can significantly accelerate training and also improve the performance of PT. Moreover, to explore what decides prompt transferability, we investigate various transferability indicators and find that the overlapping rate of activated neurons strongly reflects the transferability, which suggests how the prompts stimulate PLMs is essential. Our findings show that prompt transfer is promising for improving PT, and further research shall focus more on prompts’ stimulation to PLMs. The source code can be obtained from https://github.com/thunlp/Prompt-Transferability.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.290.pdf"
    },
    {
        "title": "WECHSEL: Effective initialization of subword embeddings for cross-lingual transfer of monolingual language models",
        "authors": [
            "Benjamin Minixhofer",
            "Fabian Paischer",
            "Navid Rekabsaz"
        ],
        "published": "2022",
        "summary": "Large pretrained language models (LMs) have become the central building block of many NLP applications. Training these models requires ever more computational resources and most of the existing models are trained on English text only. It is exceedingly expensive to train these models in other languages. To alleviate this problem, we introduce a novel method – called WECHSEL – to efficiently and effectively transfer pretrained LMs to new languages. WECHSEL can be applied to any model which uses subword-based tokenization and learns an embedding for each subword. The tokenizer of the source model (in English) is replaced with a tokenizer in the target language and token embeddings are initialized such that they are semantically similar to the English tokens by utilizing multilingual static word embeddings covering English and the target language. We use WECHSEL to transfer the English RoBERTa and GPT-2 models to four languages (French, German, Chinese and Swahili). We also study the benefits of our method on very low-resource languages. WECHSEL improves over proposed methods for cross-lingual parameter transfer and outperforms models of comparable size trained from scratch with up to 64x less training effort. Our method makes training large language models for new languages more accessible and less damaging to the environment. We make our code and models publicly available.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.293.pdf"
    },
    {
        "title": "Improving negation detection with negation-focused pre-training",
        "authors": [
            "Thinh Truong",
            "Timothy Baldwin",
            "Trevor Cohn",
            "Karin Verspoor"
        ],
        "published": "2022",
        "summary": "Negation is a common linguistic feature that is crucial in many language understanding tasks, yet it remains a hard problem due to diversity in its expression in different types of text. Recent works show that state-of-the-art NLP models underperform on samples containing negation in various tasks, and that negation detection models do not transfer well across domains. We propose a new negation-focused pre-training strategy, involving targeted data augmentation and negation masking, to better incorporate negation information into language models. Extensive experiments on common benchmarks show that our proposed approach improves negation detection performance and generalizability over the strong baseline NegBERT (Khandelwal and Sawant, 2020).",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.309.pdf"
    },
    {
        "title": "DiffCSE: Difference-based Contrastive Learning for Sentence Embeddings",
        "authors": [
            "Yung-Sung Chuang",
            "Rumen Dangovski",
            "Hongyin Luo",
            "Yang Zhang",
            "Shiyu Chang",
            "Marin Soljacic",
            "Shang-Wen Li",
            "Scott Yih",
            "Yoon Kim",
            "James Glass"
        ],
        "published": "2022",
        "summary": "We propose DiffCSE, an unsupervised contrastive learning framework for learning sentence embeddings. DiffCSE learns sentence embeddings that are sensitive to the difference between the original sentence and an edited sentence, where the edited sentence is obtained by stochastically masking out the original sentence and then sampling from a masked language model. We show that DiffSCE is an instance of equivariant contrastive learning, which generalizes contrastive learning and learns representations that are insensitive to certain types of augmentations and sensitive to other “harmful” types of augmentations. Our experiments show that DiffCSE achieves state-of-the-art results among unsupervised sentence representation learning methods, outperforming unsupervised SimCSE by 2.3 absolute points on semantic textual similarity tasks.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.311.pdf"
    },
    {
        "title": "A Data Cartography based MixUp for Pre-trained Language Models",
        "authors": [
            "Seo Yeon Park",
            "Cornelia Caragea"
        ],
        "published": "2022",
        "summary": "MixUp is a data augmentation strategy where additional samples are generated during training by combining random pairs of training samples and their labels. However, selecting random pairs is not potentially an optimal choice. In this work, we propose TDMixUp, a novel MixUp strategy that leverages Training Dynamics and allows more informative samples to be combined for generating new data samples. Our proposed TDMixUp first measures confidence, variability, (Swayamdipta et al., 2020), and Area Under the Margin (AUM) (Pleiss et al., 2020) to identify the characteristics of training samples (e.g., as easy-to-learn or ambiguous samples), and then interpolates these characterized samples. We empirically validate that our method not only achieves competitive performance using a smaller subset of the training data compared with strong baselines, but also yields lower expected calibration error on the pre-trained language model, BERT, on both in-domain and out-of-domain settings in a wide range of NLP tasks. We publicly release our code.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.314.pdf"
    },
    {
        "title": "Generating Authentic Adversarial Examples beyond Meaning-preserving with Doubly Round-trip Translation",
        "authors": [
            "Siyu Lai",
            "Zhen Yang",
            "Fandong Meng",
            "Xue Zhang",
            "Yufeng Chen",
            "Jinan Xu",
            "Jie Zhou"
        ],
        "published": "2022",
        "summary": "Generating adversarial examples for Neural Machine Translation (NMT) with single Round-Trip Translation (RTT) has achieved promising results by releasing the meaning-preserving restriction. However, a potential pitfall for this approach is that we cannot decide whether the generated examples are adversarial to the target NMT model or the auxiliary backward one, as the reconstruction error through the RTT can be related to either. To remedy this problem, we propose a new definition for NMT adversarial examples based on the Doubly Round-Trip Translation (DRTT). Specifically, apart from the source-target-source RTT, we also consider the target-source-target one, which is utilized to pick out the authentic adversarial examples for the target NMT model. Additionally, to enhance the robustness of the NMT model, we introduce the masked language models to construct bilingual adversarial pairs based on DRTT, which are used to train the NMT model directly. Extensive experiments on both the clean and noisy test sets (including the artificial and natural noise) show that our approach substantially improves the robustness of NMT models.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.316.pdf"
    },
    {
        "title": "TVShowGuess: Character Comprehension in Stories as Speaker Guessing",
        "authors": [
            "Yisi Sang",
            "Xiangyang Mou",
            "Mo Yu",
            "Shunyu Yao",
            "Jing Li",
            "Jeffrey Stanton"
        ],
        "published": "2022",
        "summary": "We propose a new task for assessing machines’ skills of understanding fictional characters in narrative stories. The task, TVShowGuess, builds on the scripts of TV series and takes the form of guessing the anonymous main characters based on the backgrounds of the scenes and the dialogues. Our human study supports that this form of task covers comprehension of multiple types of character persona, including understanding characters’ personalities, facts and memories of personal experience, which are well aligned with the psychological and literary theories about the theory of mind (ToM) of human beings on understanding fictional characters during reading. We further propose new model architectures to support the contextualized encoding of long scene texts. Experiments show that our proposed approaches significantly outperform baselines, yet still largely lag behind the (nearly perfect) human performance. Our work serves as a first step toward the goal of narrative character comprehension.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.317.pdf"
    },
    {
        "title": "Causal Distillation for Language Models",
        "authors": [
            "Zhengxuan Wu",
            "Atticus Geiger",
            "Joshua Rozner",
            "Elisa Kreiss",
            "Hanson Lu",
            "Thomas Icard",
            "Christopher Potts",
            "Noah Goodman"
        ],
        "published": "2022",
        "summary": "Distillation efforts have led to language models that are more compact and efficient without serious drops in performance. The standard approach to distillation trains a student model against two objectives: a task-specific objective (e.g., language modeling) and an imitation objective that encourages the hidden states of the student model to be similar to those of the larger teacher model. In this paper, we show that it is beneficial to augment distillation with a third objective that encourages the student to imitate the causal dynamics of the teacher through a distillation interchange intervention training objective (DIITO). DIITO pushes the student model to become a causal abstraction of the teacher model – a faithful model with simpler causal structure. DIITO is fully differentiable, easily implemented, and combines flexibly with other objectives. Compared against standard distillation with the same setting, DIITO results in lower perplexity on the WikiText-103M corpus (masked language modeling) and marked improvements on the GLUE benchmark (natural language understanding), SQuAD (question answering), and CoNLL-2003 (named entity recognition).",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.318.pdf"
    },
    {
        "title": "Linguistic Frameworks Go Toe-to-Toe at Neuro-Symbolic Language Modeling",
        "authors": [
            "Jakob Prange",
            "Nathan Schneider",
            "Lingpeng Kong"
        ],
        "published": "2022",
        "summary": "We examine the extent to which, in principle, different syntactic and semantic graph representations can complement and improve neural language modeling. Specifically, by conditioning on a subgraph encapsulating the locally relevant sentence history, can a model make better next-word predictions than a pretrained sequential language model alone? With an ensemble setup consisting of GPT-2 and ground-truth graphs from one of 7 different formalisms, we find that the graph information indeed improves perplexity and other metrics. Moreover, this architecture provides a new way to compare different frameworks of linguistic representation. In our oracle graph setup, training and evaluating on English WSJ, semantic constituency structures prove most useful to language modeling performance—outpacing syntactic constituency structures as well as syntactic and semantic dependency structures.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.325.pdf"
    },
    {
        "title": "Imagination-Augmented Natural Language Understanding",
        "authors": [
            "Yujie Lu",
            "Wanrong Zhu",
            "Xin Wang",
            "Miguel Eckstein",
            "William Yang Wang"
        ],
        "published": "2022",
        "summary": "Human brains integrate linguistic and perceptual information simultaneously to understand natural language, and hold the critical ability to render imaginations. Such abilities enable us to construct new abstract concepts or concrete objects, and are essential in involving practical knowledge to solve problems in low-resource scenarios. However, most existing methods for Natural Language Understanding (NLU) are mainly focused on textual signals. They do not simulate human visual imagination ability, which hinders models from inferring and learning efficiently from limited data samples. Therefore, we introduce an Imagination-Augmented Cross-modal Encoder (iACE) to solve natural language understanding tasks from a novel learning perspective—imagination-augmented cross-modal understanding. iACE enables visual imagination with external knowledge transferred from the powerful generative and pre-trained vision-and-language models. Extensive experiments on GLUE and SWAG show that iACE achieves consistent improvement over visually-supervised pre-trained models. More importantly, results in extreme and normal few-shot settings validate the effectiveness of iACE in low-resource natural language understanding circumstances.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.326.pdf"
    },
    {
        "title": "Testing the Ability of Language Models to Interpret Figurative Language",
        "authors": [
            "Emmy Liu",
            "Chenxuan Cui",
            "Kenneth Zheng",
            "Graham Neubig"
        ],
        "published": "2022",
        "summary": "Figurative and metaphorical language are commonplace in discourse, and figurative expressions play an important role in communication and cognition. However, figurative language has been a relatively under-studied area in NLP, and it remains an open question to what extent modern language models can interpret nonliteral phrases. To address this question, we introduce Fig-QA, a Winograd-style nonliteral language understanding task consisting of correctly interpreting paired figurative phrases with divergent meanings. We evaluate the performance of several state-of-the-art language models on this task, and find that although language models achieve performance significantly over chance, they still fall short of human performance, particularly in zero- or few-shot settings. This suggests that further work is needed to improve the nonliteral reasoning capabilities of language models.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.330.pdf"
    },
    {
        "title": "CHAI: A CHatbot AI for Task-Oriented Dialogue with Offline Reinforcement Learning",
        "authors": [
            "Siddharth Verma",
            "Justin Fu",
            "Sherry Yang",
            "Sergey Levine"
        ],
        "published": "2022",
        "summary": "Conventionally, generation of natural language for dialogue agents may be viewed as a statistical learning problem: determine the patterns in human-provided data and generate appropriate responses with similar statistical properties. However, dialogue can also be regarded as a goal directed process, where speakers attempt to accomplish a specific task. Reinforcement learning (RL) algorithms are designed specifically for solving such goal-directed problems, but the most direct way to apply RL, through trial-and-error learning in human conversations, is costly. In this paper, we study how offline reinforcement learning can instead be used to train dialogue agents entirely using static datasets collected from human speakers. Our experiments show that recently developed offline RL methods can be combined with language models to yield realistic dialogue agents that better accomplish task goals.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.332.pdf"
    },
    {
        "title": "SURF: Semantic-level Unsupervised Reward Function for Machine Translation",
        "authors": [
            "Atijit Anuchitanukul",
            "Julia Ive"
        ],
        "published": "2022",
        "summary": "The performance of Reinforcement Learning (RL) for natural language tasks including Machine Translation (MT) is crucially dependent on the reward formulation. This is due to the intrinsic difficulty of the task in the high-dimensional discrete action space as well as the sparseness of the standard reward functions defined for limited set of ground-truth sequences biased towards singular lexical choices. To address this issue, we formulate SURF, a maximally dense semantic-level unsupervised reward function which mimics human evaluation by considering both sentence fluency and semantic similarity. We demonstrate the strong potential of SURF to leverage a family of Actor-Critic Transformer-based Architectures with synchronous and asynchronous multi-agent variants. To tackle the problem of large action-state spaces, each agent is equipped with unique exploration strategies, promoting diversity during its exploration of the hypothesis space. When BLEU scores are compared, our dense unsupervised reward outperforms the standard sparse reward by 2% on average for in- and out-of-domain settings.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.334.pdf"
    },
    {
        "title": "Disentangling Categorization in Multi-agent Emergent Communication",
        "authors": [
            "Washington Garcia",
            "Hamilton Clouse",
            "Kevin Butler"
        ],
        "published": "2022",
        "summary": "The emergence of language between artificial agents is a recent focus of computational linguistics, as it offers a synthetic substrate for reasoning about human language evolution. From the perspective of cognitive science, sophisticated categorization in humans is thought to enable reasoning about novel observations, and thus compose old information to describe new phenomena. Unfortunately, the literature to date has not managed to isolate the effect of categorization power in artificial agents on their inter-communication ability, particularly on novel, unseen objects. In this work, we propose the use of disentangled representations from representation learning to quantify the categorization power of agents, enabling a differential analysis between combinations of heterogeneous systems, e.g., pairs of agents which learn to communicate despite mismatched concept realization. Through this approach, we observe that agent heterogeneity can cut signaling accuracy by up to 40%, despite encouraging compositionality in the artificial language. We conclude that the reasoning process of agents plays a key role in their communication, with unexpected benefits arising from their mixing, such as better language compositionality.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.335.pdf"
    },
    {
        "title": "Show, Don’t Tell: Demonstrations Outperform Descriptions for Schema-Guided Task-Oriented Dialogue",
        "authors": [
            "Raghav Gupta",
            "Harrison Lee",
            "Jeffrey Zhao",
            "Yuan Cao",
            "Abhinav Rastogi",
            "Yonghui Wu"
        ],
        "published": "2022",
        "summary": "Building universal dialogue systems that operate across multiple domains/APIs and generalize to new ones with minimal overhead is a critical challenge. Recent works have leveraged natural language descriptions of schema elements to enable such systems; however, descriptions only indirectly convey schema semantics. In this work, we propose Show, Don’t Tell, which prompts seq2seq models with a labeled example dialogue to show the semantics of schema elements rather than tell the model through descriptions. While requiring similar effort from service developers as generating descriptions, we show that using short examples as schema representations with large language models results in state-of-the-art performance on two popular dialogue state tracking benchmarks designed to measure zero-shot generalization - the Schema-Guided Dialogue dataset and the MultiWOZ leave-one-out benchmark.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.336.pdf"
    },
    {
        "title": "Does Pre-training Induce Systematic Inference? How Masked Language Models Acquire Commonsense Knowledge",
        "authors": [
            "Ian Porada",
            "Alessandro Sordoni",
            "Jackie Cheung"
        ],
        "published": "2022",
        "summary": "Transformer models pre-trained with a masked-language-modeling objective (e.g., BERT) encode commonsense knowledge as evidenced by behavioral probes; however, the extent to which this knowledge is acquired by systematic inference over the semantics of the pre-training corpora is an open question. To answer this question, we selectively inject verbalized knowledge into the pre-training minibatches of BERT and evaluate how well the model generalizes to supported inferences after pre-training on the injected knowledge. We find generalization does not improve over the course of pre-training BERT from scratch, suggesting that commonsense knowledge is acquired from surface-level, co-occurrence patterns rather than induced, systematic reasoning.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.337.pdf"
    },
    {
        "title": "Symbolic Knowledge Distillation: from General Language Models to Commonsense Models",
        "authors": [
            "Peter West",
            "Chandra Bhagavatula",
            "Jack Hessel",
            "Jena Hwang",
            "Liwei Jiang",
            "Ronan Le Bras",
            "Ximing Lu",
            "Sean Welleck",
            "Yejin Choi"
        ],
        "published": "2022",
        "summary": "The common practice for training commonsense models has gone from–human–to–corpus–to–machine: humans author commonsense knowledge graphs in order to train commonsense models. In this work, we investigate an alternative, from–machine–to–corpus–to–machine: general language models author these commonsense knowledge graphs to train commonsense models. Our study leads to a new framework, Symbolic Knowledge Distillation. As with prior art in Knowledge Distillation (Hinton et al. 2015), our approach uses larger models to teach smaller models. A key difference is that we distill knowledge symbolically–as text–in addition to the neural model. We distill only one aspect–the commonsense of a general language model teacher, allowing the student to be a different type, a commonsense model. Altogether, we show that careful prompt engineering and a separately trained critic model allow us to selectively distill high-quality causal commonsense from GPT-3, a general language model. Empirical results demonstrate that, for the first time, a human-authored commonsense knowledge graph is surpassed by our automatically distilled variant in all three criteria: quantity, quality, and diversity. In addition, it results in a neural commonsense model that surpasses the teacher model’s commonsense capabilities despite its 100x smaller size. We apply this to the ATOMIC resource, and will share our new symbolic knowledge graph and commonsense models.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.341.pdf"
    },
    {
        "title": "Quantifying Adaptability in Pre-trained Language Models with 500 Tasks",
        "authors": [
            "Belinda Li",
            "Jane Yu",
            "Madian Khabsa",
            "Luke Zettlemoyer",
            "Alon Halevy",
            "Jacob Andreas"
        ],
        "published": "2022",
        "summary": "When a neural language model (LM) is adapted to perform a new task, what aspects of the task predict the eventual performance of the model? In NLP, systematic features of LM generalization to individual examples are well characterized, but systematic aspects of LM adaptability to new tasks are not nearly as well understood. We present a large-scale empirical study of the features and limits of LM adaptability using a new benchmark, TaskBench500, built from 500 procedurally generated sequence modeling tasks. These tasks combine core aspects of language processing, including lexical semantics, sequence processing, memorization, logical reasoning, and world knowledge. Using TaskBench500, we evaluate three facets of adaptability, finding that: (1) adaptation procedures differ dramatically in their ability to memorize small datasets; (2) within a subset of task types, adaptation procedures exhibit compositional adaptability to complex tasks; and (3) failure to match training label distributions is explained by mismatches in the intrinsic difficulty of predicting individual labels. Our experiments show that adaptability to new tasks, like generalization to new examples, can be systematically described and understood, and we conclude with a discussion of additional aspects of adaptability that could be studied using the new benchmark.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.346.pdf"
    },
    {
        "title": "EPiDA: An Easy Plug-in Data Augmentation Framework for High Performance Text Classification",
        "authors": [
            "Minyi Zhao",
            "Lu Zhang",
            "Yi Xu",
            "Jiandong Ding",
            "Jihong Guan",
            "Shuigeng Zhou"
        ],
        "published": "2022",
        "summary": "Recent works have empirically shown the effectiveness of data augmentation (DA) in NLP tasks, especially for those suffering from data scarcity. Intuitively, given the size of generated data, their diversity and quality are crucial to the performance of targeted tasks. However, to the best of our knowledge, most existing methods consider only either the diversity or the quality of augmented data, thus cannot fully mine the potential of DA for NLP. In this paper, we present an easy and plug-in data augmentation framework EPiDA to support effective text classification. EPiDA employs two mechanisms: relative entropy maximization (REM) and conditional entropy minimization (CEM) to control data generation, where REM is designed to enhance the diversity of augmented data while CEM is exploited to ensure their semantic consistency. EPiDA can support efficient and continuous data generation for effective classifier training. Extensive experiments show that EPiDA outperforms existing SOTA methods in most cases, though not using any agent networks or pre-trained generation networks, and it works well with various DA algorithms and classification models.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.349.pdf"
    },
    {
        "title": "Lifelong Pretraining: Continually Adapting Language Models to Emerging Corpora",
        "authors": [
            "Xisen Jin",
            "Dejiao Zhang",
            "Henghui Zhu",
            "Wei Xiao",
            "Shang-Wen Li",
            "Xiaokai Wei",
            "Andrew Arnold",
            "Xiang Ren"
        ],
        "published": "2022",
        "summary": "Pretrained language models (PTLMs) are typically learned over a large, static corpus and further fine-tuned for various downstream tasks. However, when deployed in the real world, a PTLM-based model must deal with data distributions that deviates from what the PTLM was initially trained on. In this paper, we study a lifelong language model pretraining challenge where a PTLM is continually updated so as to adapt to emerging data. Over a domain-incremental research paper stream and a chronologically-ordered tweet stream, we incrementally pretrain a PTLM with different continual learning algorithms, and keep track of the downstream task performance (after fine-tuning). We evaluate PTLM’s ability to adapt to new corpora while retaining learned knowledge in earlier corpora. Our experiments show distillation-based approaches to be most effective in retaining downstream performance in earlier domains. The algorithms also improve knowledge transfer, allowing models to achieve better downstream performance over latest data, and improve temporal generalization when distribution gaps exist between training and evaluation because of time. We believe our problem formulation, methods, and analysis will inspire future studies towards continual pretraining of language models.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.351.pdf"
    },
    {
        "title": "Learning as Conversation: Dialogue Systems Reinforced for Information Acquisition",
        "authors": [
            "Pengshan Cai",
            "Hui Wan",
            "Fei Liu",
            "Mo Yu",
            "Hong Yu",
            "Sachindra Joshi"
        ],
        "published": "2022",
        "summary": "We propose novel AI-empowered chat bots for learning as conversation where a user does not read a passage but gains information and knowledge through conversation with a teacher bot. Our information acquisition-oriented dialogue system employs a novel adaptation of reinforced self-play so that the system can be transferred to various domains without in-domain dialogue data, and can carry out conversations both informative and attentive to users.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.352.pdf"
    },
    {
        "title": "Generalized Quantifiers as a Source of Error in Multilingual NLU Benchmarks",
        "authors": [
            "Ruixiang Cui",
            "Daniel Hershcovich",
            "Anders Søgaard"
        ],
        "published": "2022",
        "summary": "Logical approaches to representing language have developed and evaluated computational models of quantifier words since the 19th century, but today’s NLU models still struggle to capture their semantics. We rely on Generalized Quantifier Theory for language-independent representations of the semantics of quantifier words, to quantify their contribution to the errors of NLU models. We find that quantifiers are pervasive in NLU benchmarks, and their occurrence at test time is associated with performance drops. Multilingual models also exhibit unsatisfying quantifier reasoning abilities, but not necessarily worse for non-English languages. To facilitate directly-targeted probing, we present an adversarial generalized quantifier NLI task (GQNLI) and show that pre-trained language models have a clear lack of robustness in generalized quantifier reasoning.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.359.pdf"
    },
    {
        "title": "A Balanced Data Approach for Evaluating Cross-Lingual Transfer: Mapping the Linguistic Blood Bank",
        "authors": [
            "Dan Malkin",
            "Tomasz Limisiewicz",
            "Gabriel Stanovsky"
        ],
        "published": "2022",
        "summary": "We show that the choice of pretraining languages affects downstream cross-lingual transfer for BERT-based models. We inspect zero-shot performance in balanced data conditions to mitigate data size confounds, classifying pretraining languages that improve downstream performance as donors, and languages that are improved in zero-shot performance as recipients. We develop a method of quadratic time complexity in the number of languages to estimate these relations, instead of an exponential exhaustive computation of all possible combinations. We find that our method is effective on a diverse set of languages spanning different linguistic features and two downstream tasks. Our findings can inform developers of large-scale multilingual language models in choosing better pretraining configurations.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.361.pdf"
    },
    {
        "title": "Mitigating Toxic Degeneration with Empathetic Data: Exploring the Relationship Between Toxicity and Empathy",
        "authors": [
            "Allison Lahnala",
            "Charles Welch",
            "Béla Neuendorf",
            "Lucie Flek"
        ],
        "published": "2022",
        "summary": "Large pre-trained neural language models have supported the effectiveness of many NLP tasks, yet are still prone to generating toxic language hindering the safety of their use. Using empathetic data, we improve over recent work on controllable text generation that aims to reduce the toxicity of generated text. We find we are able to dramatically reduce the size of fine-tuning data to 7.5-30k samples while at the same time making significant improvements over state-of-the-art toxicity mitigation of up to 3.4% absolute reduction (26% relative) from the original work on 2.3m samples, by strategically sampling data based on empathy scores. We observe that the degree of improvements is subject to specific communication components of empathy. In particular, the more cognitive components of empathy significantly beat the original dataset in almost all experiments, while emotional empathy was tied to less improvement and even underperforming random samples of the original data. This is a particularly implicative insight for NLP work concerning empathy as until recently the research and resources built for it have exclusively considered empathy as an emotional concept.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.363.pdf"
    },
    {
        "title": "SkillSpan: Hard and Soft Skill Extraction from English Job Postings",
        "authors": [
            "Mike Zhang",
            "Kristian Jensen",
            "Sif Sonniks",
            "Barbara Plank"
        ],
        "published": "2022",
        "summary": "Skill Extraction (SE) is an important and widely-studied task useful to gain insights into labor market dynamics. However, there is a lacuna of datasets and annotation guidelines; available datasets are few and contain crowd-sourced labels on the span-level or labels from a predefined skill inventory. To address this gap, we introduce SKILLSPAN, a novel SE dataset consisting of 14.5K sentences and over 12.5K annotated spans. We release its respective guidelines created over three different sources annotated for hard and soft skills by domain experts. We introduce a BERT baseline (Devlin et al., 2019). To improve upon this baseline, we experiment with language models that are optimized for long spans (Joshi et al., 2020; Beltagy et al., 2020), continuous pre-training on the job posting domain (Han and Eisenstein, 2019; Gururangan et al., 2020), and multi-task learning (Caruana, 1997). Our results show that the domain-adapted models significantly outperform their non-adapted counterparts, and single-task outperforms multi-task learning.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.366.pdf"
    },
    {
        "title": "JointLK: Joint Reasoning with Language Models and Knowledge Graphs for Commonsense Question Answering",
        "authors": [
            "Yueqing Sun",
            "Qi Shi",
            "Le Qi",
            "Yu Zhang"
        ],
        "published": "2022",
        "summary": "Existing KG-augmented models for commonsense question answering primarily focus on designing elaborate Graph Neural Networks (GNNs) to model knowledge graphs (KGs). However, they ignore (i) the effectively fusing and reasoning over question context representations and the KG representations, and (ii) automatically selecting relevant nodes from the noisy KGs during reasoning. In this paper, we propose a novel model, JointLK, which solves the above limitations through the joint reasoning of LM and GNN and the dynamic KGs pruning mechanism. Specifically, JointLK performs joint reasoning between LM and GNN through a novel dense bidirectional attention module, in which each question token attends on KG nodes and each KG node attends on question tokens, and the two modal representations fuse and update mutually by multi-step interactions. Then, the dynamic pruning module uses the attention weights generated by joint reasoning to prune irrelevant KG nodes recursively. We evaluate JointLK on the CommonsenseQA and OpenBookQA datasets, and demonstrate its improvements to the existing LM and LM+KG models, as well as its capability to perform interpretable reasoning.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.372.pdf"
    },
    {
        "title": "Models In a Spelling Bee: Language Models Implicitly Learn the Character Composition of Tokens",
        "authors": [
            "Itay Itzhak",
            "Omer Levy"
        ],
        "published": "2022",
        "summary": "Standard pretrained language models operate on sequences of subword tokens without direct access to the characters that compose each token’s string representation. We probe the embedding layer of pretrained language models and show that models learn the internal character composition of whole word and subword tokens to a surprising extent, without ever seeing the characters coupled with the tokens. Our results show that the embedding layers of RoBERTa and GPT2 each hold enough information to accurately spell up to a third of the vocabulary and reach high character ngram overlap across all token types. We further test whether enriching subword models with character information can improve language modeling, and observe that this method has a near-identical learning curve as training without spelling-based enrichment. Overall, our results suggest that language modeling objectives incentivize the model to implicitly learn some notion of spelling, and that explicitly teaching the model how to spell does not appear to enhance its performance on such tasks.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.373.pdf"
    },
    {
        "title": "Meet Your Favorite Character: Open-domain Chatbot Mimicking Fictional Characters with only a Few Utterances",
        "authors": [
            "Seungju Han",
            "Beomsu Kim",
            "Jin Yong Yoo",
            "Seokjun Seo",
            "Sangbum Kim",
            "Enkhbayar Erdenee",
            "Buru Chang"
        ],
        "published": "2022",
        "summary": "In this paper, we consider mimicking fictional characters as a promising direction for building engaging conversation models. To this end, we present a new practical task where only a few utterances of each fictional character are available to generate responses mimicking them. Furthermore, we propose a new method named Pseudo Dialog Prompting (PDP) that generates responses by leveraging the power of large-scale language models with prompts containing the target character’s utterances. To better reflect the style of the character, PDP builds the prompts in the form of dialog that includes the character’s utterances as dialog history. Since only utterances of the characters are available in the proposed task, PDP matches each utterance with an appropriate pseudo-context from a predefined set of context candidates using a retrieval model. Through human and automatic evaluation, we show that PDP generates responses that better reflect the style of fictional characters than baseline methods.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.377.pdf"
    },
    {
        "title": "KALA: Knowledge-Augmented Language Model Adaptation",
        "authors": [
            "Minki Kang",
            "Jinheon Baek",
            "Sung Ju Hwang"
        ],
        "published": "2022",
        "summary": "Pre-trained language models (PLMs) have achieved remarkable success on various natural language understanding tasks. Simple fine-tuning of PLMs, on the other hand, might be suboptimal for domain-specific tasks because they cannot possibly cover knowledge from all domains. While adaptive pre-training of PLMs can help them obtain domain-specific knowledge, it requires a large training cost. Moreover, adaptive pre-training can harm the PLM’s performance on the downstream task by causing catastrophic forgetting of its general knowledge. To overcome such limitations of adaptive pre-training for PLM adaption, we propose a novel domain adaption framework for PLMs coined as Knowledge-Augmented Language model Adaptation (KALA), which modulates the intermediate hidden representations of PLMs with domain knowledge, consisting of entities and their relational facts. We validate the performance of our KALA on question answering and named entity recognition tasks on multiple datasets across various domains. The results show that, despite being computationally efficient, our KALA largely outperforms adaptive pre-training.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.379.pdf"
    },
    {
        "title": "On the Effect of Pretraining Corpora on In-context Learning by a Large-scale Language Model",
        "authors": [
            "Seongjin Shin",
            "Sang-Woo Lee",
            "Hwijeen Ahn",
            "Sungdong Kim",
            "HyoungSeok Kim",
            "Boseop Kim",
            "Kyunghyun Cho",
            "Gichang Lee",
            "Woomyoung Park",
            "Jung-Woo Ha",
            "Nako Sung"
        ],
        "published": "2022",
        "summary": "Many recent studies on large-scale language models have reported successful in-context zero- and few-shot learning ability. However, the in-depth analysis of when in-context learning occurs is still lacking. For example, it is unknown how in-context learning performance changes as the training corpus varies. Here, we investigate the effects of the source and size of the pretraining corpus on in-context learning in HyperCLOVA, a Korean-centric GPT-3 model. From our in-depth investigation, we introduce the following observations: (1) in-context learning performance heavily depends on the corpus domain source, and the size of the pretraining corpus does not necessarily determine the emergence of in-context learning, (2) in-context learning ability can emerge when a language model is trained on a combination of multiple corpora, even when each corpus does not result in in-context learning on its own, (3) pretraining with a corpus related to a downstream task does not always guarantee the competitive in-context learning performance of the downstream task, especially in the few-shot setting, and (4) the relationship between language modeling (measured in perplexity) and in-context learning does not always correlate: e.g., low perplexity does not always imply high in-context few-shot learning performance.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.380.pdf"
    },
    {
        "title": "Dual-Channel Evidence Fusion for Fact Verification over Texts and Tables",
        "authors": [
            "Nan Hu",
            "Zirui Wu",
            "Yuxuan Lai",
            "Xiao Liu",
            "Yansong Feng"
        ],
        "published": "2022",
        "summary": "Different from previous fact extraction and verification tasks that only consider evidence of a single format, FEVEROUS brings further challenges by extending the evidence format to both plain text and tables. Existing works convert all candidate evidence into either sentences or tables, thus often failing to fully capture the rich context in their original format from the converted evidence, let alone the context information lost during conversion. In this paper, we propose a Dual Channel Unified Format fact verification model (DCUF), which unifies various evidence into parallel streams, i.e., natural language sentences and a global evidence table, simultaneously. With carefully-designed evidence conversion and organization methods, DCUF makes the most of pre-trained table/language models to encourage each evidence piece to perform early and thorough interactions with other pieces in its original format. Experiments show that our model can make better use of existing pre-trained models to absorb evidence of two formats, thus outperforming previous works by a large margin. Our code and models are publicly available.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.384.pdf"
    },
    {
        "title": "On the Origin of Hallucinations in Conversational Models: Is it the Datasets or the Models?",
        "authors": [
            "Nouha Dziri",
            "Sivan Milton",
            "Mo Yu",
            "Osmar Zaiane",
            "Siva Reddy"
        ],
        "published": "2022",
        "summary": "Knowledge-grounded conversational models are known to suffer from producing factually invalid statements, a phenomenon commonly called hallucination. In this work, we investigate the underlying causes of this phenomenon: is hallucination due to the training data, or to the models? We conduct a comprehensive human study on both existing knowledge-grounded conversational benchmarks and several state-of-the-art models. Our study reveals that the standard benchmarks consist of > 60% hallucinated responses, leading to models that not only hallucinate but even amplify hallucinations. Our findings raise important questions on the quality of existing datasets and models trained using them. We make our annotations publicly available for future research.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.387.pdf"
    },
    {
        "title": "Is “My Favorite New Movie” My Favorite Movie? Probing the Understanding of Recursive Noun Phrases",
        "authors": [
            "Qing Lyu",
            "Zheng Hua",
            "Daoxin Li",
            "Li Zhang",
            "Marianna Apidianaki",
            "Chris Callison-Burch"
        ],
        "published": "2022",
        "summary": "Recursive noun phrases (NPs) have interesting semantic properties. For example, “my favorite new movie” is not necessarily my favorite movie, whereas “my new favorite movie” is. This is common sense to humans, yet it is unknown whether language models have such knowledge. We introduce the Recursive Noun Phrase Challenge (RNPC), a dataset of three textual inference tasks involving textual entailment and event plausibility comparison, precisely targeting the understanding of recursive NPs. When evaluated on RNPC, state-of-the-art Transformer models only perform around chance. Still, we show that such knowledge is learnable with appropriate data. We further probe the models for relevant linguistic features that can be learned from our tasks, including modifier semantic category and modifier scope. Finally, models trained on RNPC achieve strong zero-shot performance on an extrinsic Harm Detection evaluation task, showing the usefulness of the understanding of recursive NPs in downstream applications.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.388.pdf"
    },
    {
        "title": "When Does Syntax Mediate Neural Language Model Performance? Evidence from Dropout Probes",
        "authors": [
            "Mycal Tucker",
            "Tiwalayo Eisape",
            "Peng Qian",
            "Roger Levy",
            "Julie Shah"
        ],
        "published": "2022",
        "summary": "Recent causal probing literature reveals when language models and syntactic probes use similar representations. Such techniques may yield “false negative” causality results: models may use representations of syntax, but probes may have learned to use redundant encodings of the same syntactic information. We demonstrate that models do encode syntactic information redundantly and introduce a new probe design that guides probes to consider all syntactic information present in embeddings. Using these probes, we find evidence for the use of syntax in models where prior methods did not, allowing us to boost model performance by injecting syntactic information into representations.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.394.pdf"
    },
    {
        "title": "Few-Shot Semantic Parsing with Language Models Trained on Code",
        "authors": [
            "Richard Shin",
            "Benjamin Van Durme"
        ],
        "published": "2022",
        "summary": "Large language models can perform semantic parsing with little training data, when prompted with in-context examples. It has been shown that this can be improved by formulating the problem as paraphrasing into canonical utterances, which casts the underlying meaning representation into a controlled natural language-like representation. Intuitively, such models can more easily output canonical utterances as they are closer to the natural language used for pre-training. Recently, models also pre-trained on code, like OpenAI Codex, have risen in prominence. For semantic parsing tasks where we map natural language into code, such models may prove more adept at it. In this paper, we test this hypothesis and find that Codex performs better on such tasks than equivalent GPT-3 models. We evaluate on Overnight and SMCalFlow and find that unlike GPT-3, Codex performs similarly when targeting meaning representations directly, perhaps because meaning representations are structured similar to code in these datasets.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.396.pdf"
    },
    {
        "title": "ConfliBERT: A Pre-trained Language Model for Political Conflict and Violence",
        "authors": [
            "Yibo Hu",
            "MohammadSaleh Hosseini",
            "Erick Skorupa Parolin",
            "Javier Osorio",
            "Latifur Khan",
            "Patrick Brandt",
            "Vito D’Orazio"
        ],
        "published": "2022",
        "summary": "Analyzing conflicts and political violence around the world is a persistent challenge in the political science and policy communities due in large part to the vast volumes of specialized text needed to monitor conflict and violence on a global scale. To help advance research in political science, we introduce ConfliBERT, a domain-specific pre-trained language model for conflict and political violence. We first gather a large domain-specific text corpus for language modeling from various sources. We then build ConfliBERT using two approaches: pre-training from scratch and continual pre-training. To evaluate ConfliBERT, we collect 12 datasets and implement 18 tasks to assess the models’ practical application in conflict research. Finally, we evaluate several versions of ConfliBERT in multiple experiments. Results consistently show that ConfliBERT outperforms BERT when analyzing political violence and conflict.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.400.pdf"
    },
    {
        "title": "Automatic Multi-Label Prompting: Simple and Interpretable Few-Shot Classification",
        "authors": [
            "Han Wang",
            "Canwen Xu",
            "Julian McAuley"
        ],
        "published": "2022",
        "summary": "Prompt-based learning (i.e., prompting) is an emerging paradigm for exploiting knowledge learned by a pretrained language model. In this paper, we propose Automatic Multi-Label Prompting (AMuLaP), a simple yet effective method to automatically select label mappings for few-shot text classification with prompting. Our method exploits one-to-many label mappings and a statistics-based algorithm to select label mappings given a prompt template. Our experiments demonstrate that AMuLaP achieves competitive performance on the GLUE benchmark without human effort or external resources.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.401.pdf"
    },
    {
        "title": "Few-shot Subgoal Planning with Language Models",
        "authors": [
            "Lajanugen Logeswaran",
            "Yao Fu",
            "Moontae Lee",
            "Honglak Lee"
        ],
        "published": "2022",
        "summary": "Pre-trained language models have shown successful progress in many text understanding benchmarks. This work explores the capability of these models to predict actionable plans in real-world environments. Given a text instruction, we show that language priors encoded in pre-trained models allow us to infer fine-grained subgoal sequences. In contrast to recent methods which make strong assumptions about subgoal supervision, our experiments show that language models can infer detailed subgoal sequences from few training sequences without any fine-tuning. We further propose a simple strategy to re-rank language model predictions based on interaction and feedback from the environment. Combined with pre-trained navigation and visual reasoning components, our approach demonstrates competitive performance on subgoal prediction and task completion in the ALFRED benchmark compared to prior methods that assume more subgoal supervision.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.402.pdf"
    },
    {
        "title": "IDPG: An Instance-Dependent Prompt Generation Method",
        "authors": [
            "Zhuofeng Wu",
            "Sinong Wang",
            "Jiatao Gu",
            "Rui Hou",
            "Yuxiao Dong",
            "V.G.Vinod Vydiswaran",
            "Hao Ma"
        ],
        "published": "2022",
        "summary": "Prompt tuning is a new, efficient NLP transfer learning paradigm that adds a task-specific prompt in each input instance during the model training stage. It freezes the pre-trained language model and only optimizes a few task-specific prompts. In this paper, we propose a conditional prompt generation method to generate prompts for each input instance, referred to as the Instance-Dependent Prompt Generation (IDPG). Unlike traditional prompt tuning methods that use a fixed prompt, IDPG introduces a lightweight and trainable component to generate prompts based on each input sentence. Extensive experiments on ten natural language understanding (NLU) tasks show that the proposed strategy consistently outperforms various prompt tuning baselines and is on par with other efficient transfer learning methods such as Compacter while tuning far fewer model parameters.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.403.pdf"
    },
    {
        "title": "Embedding Hallucination for Few-shot Language Fine-tuning",
        "authors": [
            "Yiren Jian",
            "Chongyang Gao",
            "Soroush Vosoughi"
        ],
        "published": "2022",
        "summary": "Few-shot language learners adapt knowledge from a pre-trained model to recognize novel classes from a few-labeled sentences. In such settings, fine-tuning a pre-trained language model can cause severe over-fitting. In this paper, we propose an Embedding Hallucination (EmbedHalluc) method, which generates auxiliary embedding-label pairs to expand the fine-tuning dataset. The hallucinator is trained by playing an adversarial game with the discriminator, such that the hallucinated embedding is indiscriminative to the real ones in the fine-tuning dataset. By training with the extended dataset, the language learner effectively learns from the diverse hallucinated embeddings to overcome the over-fitting issue. Experiments demonstrate that our proposed method is effective in a wide range of language tasks, outperforming current fine-tuning methods. Further, we show that EmbedHalluc outperforms other methods that address this over-fitting problem, such as common data augmentation, semi-supervised pseudo-labeling, and regularization.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.404.pdf"
    },
    {
        "title": "Cryptocurrency Bubble Detection: A New Stock Market Dataset, Financial Task & Hyperbolic Models",
        "authors": [
            "Ramit Sawhney",
            "Shivam Agarwal",
            "Vivek Mittal",
            "Paolo Rosso",
            "Vikram Nanda",
            "Sudheer Chava"
        ],
        "published": "2022",
        "summary": "The rapid spread of information over social media influences quantitative trading and investments. The growing popularity of speculative trading of highly volatile assets such as cryptocurrencies and meme stocks presents a fresh challenge in the financial realm. Investigating such “bubbles” - periods of sudden anomalous behavior of markets are critical in better understanding investor behavior and market dynamics. However, high volatility coupled with massive volumes of chaotic social media texts, especially for underexplored assets like cryptocoins pose a challenge to existing methods. Taking the first step towards NLP for cryptocoins, we present and publicly release CryptoBubbles, a novel multi- span identification task for bubble detection, and a dataset of more than 400 cryptocoins from 9 exchanges over five years spanning over two million tweets. Further, we develop a set of sequence-to-sequence hyperbolic models suited to this multi-span identification task based on the power-law dynamics of cryptocurrencies and user behavior on social media. We further test the effectiveness of our models under zero-shot settings on a test set of Reddit posts pertaining to 29 “meme stocks”, which see an increase in trade volume due to social media hype. Through quantitative, qualitative, and zero-shot analyses on Reddit and Twitter spanning cryptocoins and meme-stocks, we show the practical applicability of CryptoBubbles and hyperbolic models.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.405.pdf"
    },
    {
        "title": "DEMix Layers: Disentangling Domains for Modular Language Modeling",
        "authors": [
            "Suchin Gururangan",
            "Mike Lewis",
            "Ari Holtzman",
            "Noah A. Smith",
            "Luke Zettlemoyer"
        ],
        "published": "2022",
        "summary": "We introduce a new domain expert mixture (DEMix) layer that enables conditioning a language model (LM) on the domain of the input text. A DEMix layer includes a collection of expert feedforward networks, each specialized to a domain, that makes the LM modular: experts can be mixed, added, or removed after initial training. Extensive experiments with autoregressive transformer LMs (up to 1.3B parameters) show that DEMix layers reduce test-time perplexity (especially for out-of-domain data), increase training efficiency, and enable rapid adaptation. Mixing experts during inference, using a parameter-free weighted ensemble, enables better generalization to heterogeneous or unseen domains. We also show it is possible to add experts to adapt to new domains without forgetting older ones, and remove experts to restrict access to unwanted domains. Overall, these results demonstrate benefits of domain modularity in language models.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.407.pdf"
    },
    {
        "title": "Contrastive Learning for Prompt-based Few-shot Language Learners",
        "authors": [
            "Yiren Jian",
            "Chongyang Gao",
            "Soroush Vosoughi"
        ],
        "published": "2022",
        "summary": "The impressive performance of GPT-3 using natural language prompts and in-context learning has inspired work on better fine-tuning of moderately-sized models under this paradigm. Following this line of work, we present a contrastive learning framework that clusters inputs from the same class for better generality of models trained with only limited examples. Specifically, we propose a supervised contrastive framework that clusters inputs from the same class under different augmented “views” and repel the ones from different classes. We create different “views” of an example by appending it with different language prompts and contextual demonstrations. Combining a contrastive loss with the standard masked language modeling (MLM) loss in prompt-based few-shot learners, the experimental results show that our method can improve over the state-of-the-art methods in a diverse set of 15 language tasks. Our framework makes minimal assumptions on the task or the base model, and can be applied to many recent methods with little modification.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.408.pdf"
    },
    {
        "title": "Cross-Lingual Event Detection via Optimized Adversarial Training",
        "authors": [
            "Luis Guzman-Nateras",
            "Minh Van Nguyen",
            "Thien Nguyen"
        ],
        "published": "2022",
        "summary": "In this work, we focus on Cross-Lingual Event Detection where a model is trained on data from a source language but its performance is evaluated on data from a second, target, language. Most recent works in this area have harnessed the language-invariant qualities displayed by pre-trained Multi-lingual Language Models. Their performance, however, reveals there is room for improvement as the cross-lingual setting entails particular challenges. We employ Adversarial Language Adaptation to train a Language Discriminator to discern between the source and target languages using unlabeled data. The discriminator is trained in an adversarial manner so that the encoder learns to produce refined, language-invariant representations that lead to improved performance. More importantly, we optimize the adversarial training process by only presenting the discriminator with the most informative samples. We base our intuition about what makes a sample informative on two disparate metrics: sample similarity and event presence. Thus, we propose leveraging Optimal Transport as a solution to naturally combine these two distinct information sources into the selection process. Extensive experiments on 8 different language pairs, using 4 languages from unrelated families, show the flexibility and effectiveness of our model that achieves state-of-the-art results.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.409.pdf"
    },
    {
        "title": "CONFIT: Toward Faithful Dialogue Summarization with Linguistically-Informed Contrastive Fine-tuning",
        "authors": [
            "Xiangru Tang",
            "Arjun Nair",
            "Borui Wang",
            "Bingyao Wang",
            "Jai Desai",
            "Aaron Wade",
            "Haoran Li",
            "Asli Celikyilmaz",
            "Yashar Mehdad",
            "Dragomir Radev"
        ],
        "published": "2022",
        "summary": "Factual inconsistencies in generated summaries severely limit the practical applications of abstractive dialogue summarization. Although significant progress has been achieved by using pre-trained neural language models, substantial amounts of hallucinated content are found during the human evaluation. In this work, we first devised a typology of factual errors to better understand the types of hallucinations generated by current models and conducted human evaluation on popular dialog summarization dataset. We further propose a training strategy that improves the factual consistency and overall quality of summaries via a novel contrastive fine-tuning, called CONFIT. To tackle top factual errors from our annotation, we introduce additional contrastive loss with carefully designed hard negative samples and self-supervised dialogue-specific loss to capture the key information between speakers. We show that our model significantly reduces all kinds of factual errors on both SAMSum dialogue summarization and AMI meeting summarization. On both datasets, we achieve significant improvements over state-of-the-art baselines using both automatic metrics, ROUGE and BARTScore, and human evaluation.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.415.pdf"
    },
    {
        "title": "CoMPM: Context Modeling with Speaker’s Pre-trained Memory Tracking for Emotion Recognition in Conversation",
        "authors": [
            "Joosung Lee",
            "Wooin Lee"
        ],
        "published": "2022",
        "summary": "As the use of interactive machines grow, the task of Emotion Recognition in Conversation (ERC) became more important. If the machine-generated sentences reflect emotion, more human-like sympathetic conversations are possible. Since emotion recognition in conversation is inaccurate if the previous utterances are not taken into account, many studies reflect the dialogue context to improve the performances. Many recent approaches show performance improvement by combining knowledge into modules learned from external structured data. However, structured data is difficult to access in non-English languages, making it difficult to extend to other languages. Therefore, we extract the pre-trained memory using the pre-trained language model as an extractor of external knowledge. We introduce CoMPM, which combines the speaker’s pre-trained memory with the context model, and find that the pre-trained memory significantly improves the performance of the context model. CoMPM achieves the first or second performance on all data and is state-of-the-art among systems that do not leverage structured data. In addition, our method shows that it can be extended to other languages because structured knowledge is not required, unlike previous methods. Our code is available on github .",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.416.pdf"
    },
    {
        "title": "What do Toothbrushes do in the Kitchen? How Transformers Think our World is Structured",
        "authors": [
            "Alexander Henlein",
            "Alexander Mehler"
        ],
        "published": "2022",
        "summary": "Transformer-based models are now predominant in NLP.They outperform approaches based on static models in many respects. This success has in turn prompted research that reveals a number of biases in the language models generated by transformers. In this paper we utilize this research on biases to investigate to what extent transformer-based language models allow for extracting knowledge about object relations (X occurs in Y; X consists of Z; action A involves using X).To this end, we compare contextualized models with their static counterparts. We make this comparison dependent on the application of a number of similarity measures and classifiers. Our results are threefold:Firstly, we show that the models combined with the different similarity measures differ greatly in terms of the amount of knowledge they allow for extracting. Secondly, our results suggest that similarity measures perform much worse than classifier-based approaches. Thirdly, we show that, surprisingly, static models perform almost as well as contextualized models – in some cases even better.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.425.pdf"
    },
    {
        "title": "Learning to Win Lottery Tickets in BERT Transfer via Task-agnostic Mask Training",
        "authors": [
            "Yuanxin Liu",
            "Fandong Meng",
            "Zheng Lin",
            "Peng Fu",
            "Yanan Cao",
            "Weiping Wang",
            "Jie Zhou"
        ],
        "published": "2022",
        "summary": "Recent studies on the lottery ticket hypothesis (LTH) show that pre-trained language models (PLMs) like BERT contain matching subnetworks that have similar transfer learning performance as the original PLM. These subnetworks are found using magnitude-based pruning. In this paper, we find that the BERT subnetworks have even more potential than these studies have shown. Firstly, we discover that the success of magnitude pruning can be attributed to the preserved pre-training performance, which correlates with the downstream transferability. Inspired by this, we propose to directly optimize the subnetwork structure towards the pre-training objectives, which can better preserve the pre-training performance. Specifically, we train binary masks over model weights on the pre-training tasks, with the aim of preserving the universal transferability of the subnetwork, which is agnostic to any specific downstream tasks. We then fine-tune the subnetworks on the GLUE benchmark and the SQuAD dataset. The results show that, compared with magnitude pruning, mask training can effectively find BERT subnetworks with improved overall performance on downstream tasks. Moreover, our method is also more efficient in searching subnetworks and more advantageous when fine-tuning within a certain range of data scarcity. Our code is available at https://github.com/llyx97/TAMT.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.428.pdf"
    },
    {
        "title": "You Don’t Know My Favorite Color: Preventing Dialogue Representations from Revealing Speakers’ Private Personas",
        "authors": [
            "Haoran Li",
            "Yangqiu Song",
            "Lixin Fan"
        ],
        "published": "2022",
        "summary": "Social chatbots, also known as chit-chat chatbots, evolve rapidly with large pretrained language models. Despite the huge progress, privacy concerns have arisen recently: training data of large language models can be extracted via model inversion attacks. On the other hand, the datasets used for training chatbots contain many private conversations between two individuals. In this work, we further investigate the privacy leakage of the hidden states of chatbots trained by language modeling which has not been well studied yet. We show that speakers’ personas can be inferred through a simple neural network with high accuracy. To this end, we propose effective defense objectives to protect persona leakage from hidden states. We conduct extensive experiments to demonstrate that our proposed defense objectives can greatly reduce the attack accuracy from 37.6% to 0.5%. Meanwhile, the proposed objectives preserve language models’ powerful generation ability.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.429.pdf"
    },
    {
        "title": "Diagnosing Vision-and-Language Navigation: What Really Matters",
        "authors": [
            "Wanrong Zhu",
            "Yuankai Qi",
            "Pradyumna Narayana",
            "Kazoo Sone",
            "Sugato Basu",
            "Xin Wang",
            "Qi Wu",
            "Miguel Eckstein",
            "William Yang Wang"
        ],
        "published": "2022",
        "summary": "Vision-and-language navigation (VLN) is a multimodal task where an agent follows natural language instructions and navigates in visual environments. Multiple setups have been proposed, and researchers apply new model architectures or training techniques to boost navigation performance. However, there still exist non-negligible gaps between machines’ performance and human benchmarks. Moreover, the agents’ inner mechanisms for navigation decisions remain unclear. To the best of our knowledge, how the agents perceive the multimodal input is under-studied and needs investigation. In this work, we conduct a series of diagnostic experiments to unveil agents’ focus during navigation. Results show that indoor navigation agents refer to both object and direction tokens when making decisions. In contrast, outdoor navigation agents heavily rely on direction tokens and poorly understand the object tokens. Transformer-based agents acquire a better cross-modal understanding of objects and display strong numerical reasoning ability than non-Transformer-based agents. When it comes to vision-and-language alignments, many models claim that they can align object tokens with specific visual targets. We find unbalanced attention on the vision and text input and doubt the reliability of such cross-modal alignments.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.438.pdf"
    },
    {
        "title": "Aligning to Social Norms and Values in Interactive Narratives",
        "authors": [
            "Prithviraj Ammanabrolu",
            "Liwei Jiang",
            "Maarten Sap",
            "Hannaneh Hajishirzi",
            "Yejin Choi"
        ],
        "published": "2022",
        "summary": "We focus on creating agents that act in alignment with socially beneficial norms and values in interactive narratives or text-based games—environments wherein an agent perceives and interacts with a world through natural language. Such interactive agents are often trained via reinforcement learning to optimize task performance, even when such rewards may lead to agent behaviors that violate societal norms—causing harm either to the agent itself or other entities in the environment. Social value alignment refers to creating agents whose behaviors conform to expected moral and social norms for a given context and group of people—in our case, it means agents that behave in a manner that is less harmful and more beneficial for themselves and others. We build on the Jiminy Cricket benchmark (Hendrycks et al. 2021), a set of 25 annotated interactive narratives containing thousands of morally salient scenarios covering everything from theft and bodily harm to altruism. We introduce the GALAD (Game-value ALignment through Action Distillation) agent that uses the social commonsense knowledge present in specially trained language models to contextually restrict its action space to only those actions that are aligned with socially beneficial values. An experimental study shows that the GALAD agent makes decisions efficiently enough to improve state-of-the-art task performance by 4% while reducing the frequency of socially harmful behaviors by 25% compared to strong contemporary value alignment approaches.",
        "pdf_link": "https://aclanthology.org/2022.naacl-main.439.pdf"
    },
    {
        "title": "Masked Measurement Prediction: Learning to Jointly Predict Quantities and Units from Textual Context",
        "authors": [
            "Daniel Spokoyny",
            "Ivan Lee",
            "Zhao Jin",
            "Taylor Berg-Kirkpatrick"
        ],
        "published": "2022",
        "summary": "Physical measurements constitute a large portion of numbers in academic papers, engineering reports, and web tables. Current benchmarks fall short of properly evaluating numeracy of pretrained language models on measurements, hindering research on developing new methods and applying them to numerical tasks. To that end, we introduce a novel task, Masked Measurement Prediction (MMP), where a model learns to reconstruct a number together with its associated unit given masked text. MMP is useful for both training new numerically informed models as well as evaluating numeracy of existing systems. To address this task, we introduce a new Generative Masked Measurement (GeMM) model that jointly learns to predict numbers along with their units. We perform fine-grained analyses comparing our model with various ablations and baselines. We use linear probing of traditional pretrained transformer models (RoBERTa) to show that they significantly underperform jointly trained number-unit models, highlighting the difficulty of this new task and the benefits of our proposed pretraining approach. We hope this framework accelerates the progress towards building more robust numerical reasoning systems in the future.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.2.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Improving Conversational Recommendation Systems’ Quality with Context-Aware Item Meta-Information",
        "authors": [
            "Bowen Yang",
            "Cong Han",
            "Yu Li",
            "Lei Zuo",
            "Zhou Yu"
        ],
        "published": "2022",
        "summary": "A key challenge of Conversational Recommendation Systems (CRS) is to integrate the recommendation function and the dialog generation function smoothly. Previous works employ graph neural networks with external knowledge graphs (KG) to model individual recommendation items and integrate KGs with language models through attention mechanism for response generation. Although previous approaches prove effective, there is still room for improvement. For example, KG-based approaches only rely on entity relations and bag-of-words to recommend items and neglect the information in the conversational context. We propose to improve the usage of dialog context for both recommendation and response generation using an encoding architecture along with the self-attention mechanism of transformers. In this paper, we propose a simple yet effective architecture comprising a pre-trained language model (PLM) and an item metadata encoder to integrate the recommendation and the dialog generation better. The proposed item encoder learns to map item metadata to embeddings reflecting the rich information of the item, which can be matched with dialog context. The PLM then consumes the context-aware item embeddings and dialog context to generate high-quality recommendations and responses. Experimental results on the benchmark dataset ReDial show that our model obtains state-of-the-art results on both recommendation and response generation tasks.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.4.pdf",
        "source": "naacl2022"
    },
    {
        "title": "SEQZERO: Few-shot Compositional Semantic Parsing with Sequential Prompts and Zero-shot Models",
        "authors": [
            "Jingfeng Yang",
            "Haoming Jiang",
            "Qingyu Yin",
            "Danqing Zhang",
            "Bing Yin",
            "Diyi Yang"
        ],
        "published": "2022",
        "summary": "Recent research showed promising results on combining pretrained language models (LMs) with canonical utterance for few-shot semantic parsing. The canonical utterance is often lengthy and complex due to the compositional structure of formal languages. Learning to generate such canonical utterance requires significant amount of data to reach high performance. Fine-tuning with only few-shot samples, the LMs can easily forget pretrained knowledge, overfit spurious biases, and suffer from compositionally out-of-distribution generalization errors. To tackle these issues, we propose a novel few-shot semantic parsing method – SEQZERO. SEQZERO decomposes the problem into a sequence of sub-problems, which corresponds to the sub-clauses of the formal language. Based on the decomposition, the LMs only need to generate short answers using prompts for predicting sub-clauses. Thus, SEQZERO avoids generating a long canonical utterance at once. Moreover, SEQZERO employs not only a few-shot model but also a zero-shot model to alleviate the overfitting.In particular, SEQZERO brings out the merits from both models via ensemble equipped with our proposed constrained rescaling.SEQZERO achieves SOTA performance of BART-based models on GeoQuery and EcommerceQuery, which are two few-shot datasets with compositional data split.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.5.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Self-Supervised Contrastive Learning with Adversarial Perturbations for Defending Word Substitution-based Attacks",
        "authors": [
            "Zhao Meng",
            "Yihan Dong",
            "Mrinmaya Sachan",
            "Roger Wattenhofer"
        ],
        "published": "2022",
        "summary": "In this paper, we present an approach to improve the robustness of BERT language models against word substitution-based adversarial attacks by leveraging adversarial perturbations for self-supervised contrastive learning. We create a word-level adversarial attack generating hard positives on-the-fly as adversarial examples during contrastive learning. In contrast to previous works, our method improves model robustness without using any labeled data. Experimental results show that our method improves robustness of BERT against four different word substitution-based adversarial attacks, and combining our method with adversarial training gives higher robustness than adversarial training alone. As our method improves the robustness of BERT purely with unlabeled data, it opens up the possibility of using large text datasets to train robust language models against word substitution-based adversarial attacks.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.8.pdf",
        "source": "naacl2022"
    },
    {
        "title": "How to Translate Your Samples and Choose Your Shots? Analyzing Translate-train & Few-shot Cross-lingual Transfer",
        "authors": [
            "Iman Jundi",
            "Gabriella Lapesa"
        ],
        "published": "2022",
        "summary": "Translate-train or few-shot cross-lingual transfer can be used to improve the zero-shot performance of multilingual pretrained language models. Few-shot utilizes high-quality low-quantity samples (often manually translated from the English corpus ). Translate-train employs a machine translation of the English corpus, resulting in samples with lower quality that could be scaled to high quantity. Given the lower cost and higher availability of machine translation compared to manual professional translation, it is important to systematically compare few-shot and translate-train, understand when each has an advantage, and investigate how to choose the shots to translate in order to increase the few-shot gain. This work aims to fill this gap: we compare and quantify the performance gain of few-shot vs. translate-train using three different base models and a varying number of samples for three tasks/datasets (XNLI, PAWS-X, XQuAD) spanning 17 languages. We show that scaling up the training data using machine translation gives a larger gain compared to using the small-scale (higher-quality) few-shot data. When few-shot is beneficial, we show that there are random sets of samples that perform better across languages and that the performance on English and on the machine-translation of the samples can both be used to choose the shots to manually translate for an increased few-shot gain.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.11.pdf",
        "source": "naacl2022"
    },
    {
        "title": "FedNLP: Benchmarking Federated Learning Methods for Natural Language Processing Tasks",
        "authors": [
            "Bill Yuchen Lin",
            "Chaoyang He",
            "Zihang Ze",
            "Hulin Wang",
            "Yufen Hua",
            "Christophe Dupuy",
            "Rahul Gupta",
            "Mahdi Soltanolkotabi",
            "Xiang Ren",
            "Salman Avestimehr"
        ],
        "published": "2022",
        "summary": "Increasing concerns and regulations about data privacy and sparsity necessitate the study of privacy-preserving, decentralized learning methods for natural language processing (NLP) tasks. Federated learning (FL) provides promising approaches for a large number of clients (e.g., personal devices or organizations) to collaboratively learn a shared global model to benefit all clients while allowing users to keep their data locally. Despite interest in studying FL methods for NLP tasks, a systematic comparison and analysis is lacking in the literature. Herein, we present the FedNLP, a benchmarking framework for evaluating federated learning methods on four different task formulations: text classification, sequence tagging, question answering, and seq2seq. We propose a universal interface between Transformer-based language models (e.g., BERT, BART) and FL methods (e.g., FedAvg, FedOPT, etc.) under various non-IID partitioning strategies. Our extensive experiments with FedNLP provide empirical comparisons between FL methods and help us better understand the inherent challenges of this direction. The comprehensive analysis points to intriguing and exciting future research aimed at developing FL methods for NLP tasks.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.13.pdf",
        "source": "naacl2022"
    },
    {
        "title": "SemAttack: Natural Textual Attacks via Different Semantic Spaces",
        "authors": [
            "Boxin Wang",
            "Chejian Xu",
            "Xiangyu Liu",
            "Yu Cheng",
            "Bo Li"
        ],
        "published": "2022",
        "summary": "Recent studies show that pre-trained language models (LMs) are vulnerable to textual adversarial attacks. However, existing attack methods either suffer from low attack success rates or fail to search efficiently in the exponentially large perturbation space. We propose an efficient and effective framework SemAttack to generate natural adversarial text by constructing different semantic perturbation functions. In particular, SemAttack optimizes the generated perturbations constrained on generic semantic spaces, including typo space, knowledge space (e.g., WordNet), contextualized semantic space (e.g., the embedding space of BERT clusterings), or the combination of these spaces. Thus, the generated adversarial texts are more semantically close to the original inputs. Extensive experiments reveal that state-of-the-art (SOTA) large-scale LMs (e.g., DeBERTa-v2) and defense strategies (e.g., FreeLB) are still vulnerable to SemAttack. We further demonstrate that SemAttack is general and able to generate natural adversarial texts for different languages (e.g., English and Chinese) with high attack success rates. Human evaluations also confirm that our generated adversarial texts are natural and barely affect human performance. Our code is publicly available at https://github.com/AI-secure/SemAttack.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.14.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Lacuna Reconstruction: Self-Supervised Pre-Training for Low-Resource Historical Document Transcription",
        "authors": [
            "Nikolai Vogler",
            "Jonathan Allen",
            "Matthew Miller",
            "Taylor Berg-Kirkpatrick"
        ],
        "published": "2022",
        "summary": "We present a self-supervised pre-training approach for learning rich visual language representations for both handwritten and printed historical document transcription. After supervised fine-tuning of our pre-trained encoder representations for low-resource document transcription on two languages, (1) a heterogeneous set of handwritten Islamicate manuscript images and (2) early modern English printed documents, we show a meaningful improvement in recognition accuracy over the same supervised model trained from scratch with as few as 30 line image transcriptions for training. Our masked language model-style pre-training strategy, where the model is trained to be able to identify the true masked visual representation from distractors sampled from within the same line, encourages learning robust contextualized language representations invariant to scribal writing style and printing noise present across documents.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.15.pdf",
        "source": "naacl2022"
    },
    {
        "title": "FreeTransfer-X: Safe and Label-Free Cross-Lingual Transfer from Off-the-Shelf Models",
        "authors": [
            "Yinpeng Guo",
            "Liangyou Li",
            "Xin Jiang",
            "Qun Liu"
        ],
        "published": "2022",
        "summary": "Cross-lingual transfer (CLT) is of various applications. However, labeled cross-lingual corpus is expensive or even inaccessible, especially in the fields where labels are private, such as diagnostic results of symptoms in medicine and user profiles in business. Nevertheless, there are off-the-shelf models in these sensitive fields. Instead of pursuing the original labels, a workaround for CLT is to transfer knowledge from the off-the-shelf models without labels. To this end, we define a novel CLT problem named FreeTransfer-X that aims to achieve knowledge transfer from the off-the-shelf models in rich-resource languages. To address the problem, we propose a 2-step knowledge distillation (KD, Hinton et al., 2015) framework based on multilingual pre-trained language models (mPLM). The significant improvement over strong neural machine translation (NMT) baselines demonstrates the effectiveness of the proposed method. In addition to reducing annotation cost and protecting private labels, the proposed method is compatible with different networks and easy to be deployed. Finally, a range of analyses indicate the great potential of the proposed method.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.16.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Aligning Generative Language Models with Human Values",
        "authors": [
            "Ruibo Liu",
            "Ge Zhang",
            "Xinyu Feng",
            "Soroush Vosoughi"
        ],
        "published": "2022",
        "summary": "Although current large-scale generative language models (LMs) can show impressive insights about factual knowledge, they do not exhibit similar success with respect to human values judgements (e.g., whether or not the generations of an LM are moral). Existing methods learn human values either by directly mimicking the behavior of human data, or rigidly constraining the generation space to human-chosen tokens. These methods are inherently limited in that they do not consider the contextual and abstract nature of human values and as a result often fail when dealing with out-of-domain context or sophisticated and abstract human values. This paper proposes SENSEI, a new reinforcement learning based method that can embed human values judgements into each step of language generation. SENSEI deploys an Actor-Critic framework, where the Critic is a reward distributor that simulates the reward assignment procedure of humans, while the Actor guides the generation towards the maximum reward direction. Compared with five existing methods in three human values alignment datasets, SENSEI not only achieves higher alignment performance in terms of both automatic and human evaluations, but also shows improvements on robustness and transfer learning on unseen human values.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.18.pdf",
        "source": "naacl2022"
    },
    {
        "title": "PCEE-BERT: Accelerating BERT Inference via Patient and Confident Early Exiting",
        "authors": [
            "Zhen Zhang",
            "Wei Zhu",
            "Jinfan Zhang",
            "Peng Wang",
            "Rize Jin",
            "Tae-Sun Chung"
        ],
        "published": "2022",
        "summary": "BERT and other pretrained language models (PLMs) are ubiquitous in modern NLP. Even though PLMs are the state-of-the-art (SOTA) models for almost every NLP task (CITATION), the significant latency during inference prohibits wider industrial usage. In this work, we propose Patient and Confident Early Exiting BERT (PCEE-BERT), an off-the-shelf sample-dependent early exiting method that can work with different PLMs and can also work along with popular model compression methods. With a multi-exit BERT as the backbone model, PCEE-BERT will make the early exiting decision if enough numbers (patience parameter) of consecutive intermediate layers are confident about their predictions. The entropy value measures the confidence level of an intermediate layer’s prediction. Experiments on the GLUE benchmark demonstrate that our method outperforms previous SOTA early exiting methods. Ablation studies show that: (a) our method performs consistently well on other PLMs, such as ALBERT and TinyBERT; (b) PCEE-BERT can achieve different speed-up ratios by adjusting the patience parameter and the confidence threshold. The code for PCEE-BERT can be found at https://github.com/michael-wzhu/PCEE-BERT.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.25.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Learning to repair: Repairing model output errors after deployment using a dynamic memory of feedback",
        "authors": [
            "Niket Tandon",
            "Aman Madaan",
            "Peter Clark",
            "Yiming Yang"
        ],
        "published": "2022",
        "summary": "Large language models (LMs), while powerful, are not immune to mistakes, but can be difficult to retrain. Our goal is for an LM to continue to improve after deployment, without retraining, using feedback from the user. Our approach pairs an LM with (i) a growing memory of cases where the user identified an output error and provided general feedback on how to correct it (ii) a corrector model, trained to translate this general feedback into specific edits to repair the model output. Given a new, unseen input, our model can then use feedback from similar, past cases to repair output errors that may occur. We instantiate our approach using an existing, fixed model for script generation, that takes a goal (e.g., “bake a cake”) and generates a partially ordered sequence of actions to achieve that goal, sometimes containing errors. Our memory-enhanced system, , learns to apply user feedback to repair such errors (up to 30 points improvement), while making a start at avoiding similar past mistakes on new, unseen examples (up to 7 points improvement in a controlled setting). This is a first step towards strengthening deployed models, potentially broadening their utility. Our code and data is available at https://github.com/allenai/interscript",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.26.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Few-Shot Self-Rationalization with Natural Language Prompts",
        "authors": [
            "Ana Marasovic",
            "Iz Beltagy",
            "Doug Downey",
            "Matthew Peters"
        ],
        "published": "2022",
        "summary": "Self-rationalization models that predict task labels and generate free-text elaborations for their predictions could enable more intuitive interaction with NLP systems. These models are, however, currently trained with a large amount of human-written free-text explanations for each task which hinders their broader usage. We propose to study a more realistic setting of self-rationalization using few training examples. We present FEB—a standardized collection of four existing English-language datasets and associated metrics. We identify the right prompting approach by extensively exploring natural language prompts on FEB. Then, by using this prompt and scaling the model size, we demonstrate that making progress on few-shot self-rationalization is possible. We show there is still ample room for improvement in this task: the average plausibility of generated explanations assessed by human annotators is at most 51% (with GPT-3), while plausibility of human explanations is 76%. We hope that FEB and our proposed approach will spur the community to take on the few-shot self-rationalization challenge.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.31.pdf",
        "source": "naacl2022"
    },
    {
        "title": "DOCmT5: Document-Level Pretraining of Multilingual Language Models",
        "authors": [
            "Chia-Hsuan Lee",
            "Aditya Siddhant",
            "Viresh Ratnakar",
            "Melvin Johnson"
        ],
        "published": "2022",
        "summary": "In this paper, we introduce DOCmT5, a multilingual sequence-to-sequence language model pretrained with large-scale parallel documents. While previous approaches have focused on leveraging sentence-level parallel data, we try to build a general-purpose pretrained model that can understand and generate long documents. We propose a simple and effective pretraining objective - Document reordering Machine Translation (DrMT), in which the input documents that are shuffled and masked need to be translated. DrMT brings consistent improvements over strong baselines on a variety of document-level generation tasks, including over 12 BLEU points for seen-language pair document-level MT, over 7 BLEU points for unseen-language-pair document-level MT and over 3 ROUGE-1 points for seen-language pair cross-lingual summarization. We achieve state-of-the-art (SOTA) on WMT20 De-En and IWSLT15 Zh-En document translation tasks. We also conduct extensive analysis on various factors for document pretraining, including (1) the effects of pretraining data quality and (2) The effects of combining mono-lingual and cross-lingual pretraining. We plan to make our model checkpoints publicly available.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.32.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Literature-Augmented Clinical Outcome Prediction",
        "authors": [
            "Aakanksha Naik",
            "Sravanthi Parasa",
            "Sergey Feldman",
            "Lucy Lu Wang",
            "Tom Hope"
        ],
        "published": "2022",
        "summary": "We present BEEP (Biomedical Evidence-Enhanced Predictions), a novel approach for clinical outcome prediction that retrieves patient-specific medical literature and incorporates it into predictive models. Based on each individual patient’s clinical notes, we train language models (LMs) to find relevant papers and fuse them with information from notes to predict outcomes such as in-hospital mortality. We develop methods to retrieve literature based on noisy, information-dense patient notes, and to augment existing outcome prediction models with retrieved papers in a manner that maximizes predictive accuracy. Our approach boosts predictive performance on three important clinical tasks in comparison to strong recent LM baselines, increasing F1 by up to 5 points and precision@Top-K by a large margin of over 25%.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.33.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Entailment Tree Explanations via Iterative Retrieval-Generation Reasoner",
        "authors": [
            "Danilo Neves Ribeiro",
            "Shen Wang",
            "Xiaofei Ma",
            "Rui Dong",
            "Xiaokai Wei",
            "Henghui Zhu",
            "Xinchi Chen",
            "Peng Xu",
            "Zhiheng Huang",
            "Andrew Arnold",
            "Dan Roth"
        ],
        "published": "2022",
        "summary": "Large language models have achieved high performance on various question answering (QA) benchmarks, but the explainability of their output remains elusive. Structured explanations, called entailment trees, were recently suggested as a way to explain the reasoning behind a QA system’s answer. In order to better generate such entailment trees, we propose an architecture called Iterative Retrieval-Generation Reasoner (IRGR). Our model is able to explain a given hypothesis by systematically generating a step-by-step explanation from textual premises. The IRGR model iteratively searches for suitable premises, constructing a single entailment step at a time. Contrary to previous approaches, our method combines generation steps and retrieval of premises, allowing the model to leverage intermediate conclusions, and mitigating the input size limit of baseline encoder-decoder models. We conduct experiments using the EntailmentBank dataset, where we outperform existing benchmarks on premise retrieval and entailment tree generation, with around 300% gain in overall correctness.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.35.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Improving the Faithfulness of Abstractive Summarization via Entity Coverage Control",
        "authors": [
            "Haopeng Zhang",
            "Semih Yavuz",
            "Wojciech Kryscinski",
            "Kazuma Hashimoto",
            "Yingbo Zhou"
        ],
        "published": "2022",
        "summary": "Abstractive summarization systems leveraging pre-training language models have achieved superior results on benchmark datasets. However, such models have been shown to be more prone to hallucinate facts that are unfaithful to the input context. In this paper, we propose a method to remedy entity-level extrinsic hallucinations with Entity Coverage Control (ECC). We first compute entity coverage precision and prepend the corresponding control code for each training example, which implicitly guides the model to recognize faithfulness contents in the training phase. We further extend our method via intermediate fine-tuning on large but noisy data extracted from Wikipedia to unlock zero-shot summarization. We show that the proposed method leads to more faithful and salient abstractive summarization in supervised fine-tuning and zero-shot settings according to our experimental results on three benchmark datasets XSum, Pubmed, and SAMSum of very different domains and styles.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.40.pdf",
        "source": "naacl2022"
    },
    {
        "title": "On Measuring Social Biases in Prompt-Based Multi-Task Learning",
        "authors": [
            "Afra Feyza Akyürek",
            "Sejin Paik",
            "Muhammed Kocyigit",
            "Seda Akbiyik",
            "Serife Leman Runyun",
            "Derry Wijaya"
        ],
        "published": "2022",
        "summary": "Large language models trained on a mixture of NLP tasks that are converted into a text-to-text format using prompts, can generalize into novel forms of language and handle novel tasks. A large body of work within prompt engineering attempts to understand the effects of input forms and prompts in achieving superior performance. We consider an alternative measure and inquire whether the way in which an input is encoded affects social biases promoted in outputs. In this paper, we study T0, a large-scale multi-task text-to-text language model trained using prompt-based learning. We consider two different forms of semantically equivalent inputs: question-answer format and premise-hypothesis format. We use an existing bias benchmark for the former BBQ and create the first bias benchmark in natural language inference BBNLI with hand-written hypotheses while also converting each benchmark into the other form. The results on two benchmarks suggest that given two different formulations of essentially the same input, T0 conspicuously acts more biased in question answering form, which is seen during training, compared to premise-hypothesis form which is unlike its training examples. Code and data are released under https://github.com/feyzaakyurek/bbnli.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.42.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Instilling Type Knowledge in Language Models via Multi-Task QA",
        "authors": [
            "Shuyang Li",
            "Mukund Sridhar",
            "Chandana Satya Prakash",
            "Jin Cao",
            "Wael Hamza",
            "Julian McAuley"
        ],
        "published": "2022",
        "summary": "Understanding human language often necessitates understanding entities and their place in a taxonomy of knowledge—their types.Previous methods to learn entity types rely on training classifiers on datasets with coarse, noisy, and incomplete labels. We introduce a method to instill fine-grained type knowledge in language models with text-to-text pre-training on type-centric questions leveraging knowledge base documents and knowledge graphs.We create the WikiWiki dataset: entities and passages from 10M Wikipedia articles linked to the Wikidata knowledge graph with 41K types.Models trained on WikiWiki achieve state-of-the-art performance in zero-shot dialog state tracking benchmarks, accurately infer entity types in Wikipedia articles, and can discover new types deemed useful by human judges.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.45.pdf",
        "source": "naacl2022"
    },
    {
        "title": "StATIK: Structure and Text for Inductive Knowledge Graph Completion",
        "authors": [
            "Elan Markowitz",
            "Keshav Balasubramanian",
            "Mehrnoosh Mirtaheri",
            "Murali Annavaram",
            "Aram Galstyan",
            "Greg Ver Steeg"
        ],
        "published": "2022",
        "summary": "Knowledge graphs (KGs) often represent knowledge bases that are incomplete. Machine learning models can alleviate this by helping automate graph completion. Recently, there has been growing interest in completing knowledge bases that are dynamic, where previously unseen entities may be added to the KG with many missing links. In this paper, we present StATIK–Structure And Text for Inductive Knowledge Completion. StATIK uses Language Models to extract the semantic information from text descriptions, while using Message Passing Neural Networks to capture the structural information. StATIK achieves state of the art results on three challenging inductive baselines. We further analyze our hybrid model through detailed ablation studies.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.46.pdf",
        "source": "naacl2022"
    },
    {
        "title": "CLEAR: Improving Vision-Language Navigation with Cross-Lingual, Environment-Agnostic Representations",
        "authors": [
            "Jialu Li",
            "Hao Tan",
            "Mohit Bansal"
        ],
        "published": "2022",
        "summary": "Vision-and-Language Navigation (VLN) tasks require an agent to navigate through the environment based on language instructions. In this paper, we aim to solve two key challenges in this task: utilizing multilingual instructions for improved instruction-path grounding and navigating through new environments that are unseen during training. To address these challenges, first, our agent learns a shared and visually-aligned cross-lingual language representation for the three languages (English, Hindi and Telugu) in the Room-Across-Room dataset. Our language representation learning is guided by text pairs that are aligned by visual information. Second, our agent learns an environment-agnostic visual representation by maximizing the similarity between semantically-aligned image pairs (with constraints on object-matching) from different environments. Our environment agnostic visual representation can mitigate the environment bias induced by low-level visual information. Empirically, on the Room-Across-Room dataset, we show that our multi-lingual agent gets large improvements in all metrics over the strong baseline model when generalizing to unseen environments with the cross-lingual language representation and the environment-agnostic visual representation. Furthermore, we show that our learned language and visual representations can be successfully transferred to the Room-to-Room and Cooperative Vision-and-Dialogue Navigation task, and present detailed qualitative and quantitative generalization and grounding analysis.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.48.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Language Models for Code-switch Detection of te reo Māori and English in a Low-resource Setting",
        "authors": [
            "Jesin James",
            "Vithya Yogarajan",
            "Isabella Shields",
            "Catherine Watson",
            "Peter Keegan",
            "Keoni Mahelona",
            "Peter-Lucas Jones"
        ],
        "published": "2022",
        "summary": "Te reo Māori, New Zealand’s only indigenous language, is code-switched with English. Māori speakers are atleast bilingual, and the use of Māori is increasing in New Zealand English. Unfortunately, due to the minimal availability of resources, including digital data, Māori is under-represented in technological advances. Cloud-based multilingual systems such as Google and Microsoft Azure support Māori language detection. However, we provide experimental evidence to show that the accuracy of such systems is low when detecting Māori. Hence, with the support of Māori community, we collect Māori and bilingual data to use natural language processing (NLP) to improve Māori language detection. We train bilingual sub-word embeddings and provide evidence to show that our bilingual embeddings improve overall accuracy compared to the publicly-available monolingual embeddings. This improvement has been verified for various NLP tasks using three bilingual databases containing formal transcripts and informal social media data. We also show that BiLSTM with pre-trained Māori-English sub-word embeddings outperforms large-scale contextual language models such as BERT on down streaming tasks of detecting Māori language. However, this research uses large models ‘as is’ for transfer learning, where no further training was done on Māori-English data. The best accuracy of 87% was obtained using BiLSTM with bilingual embeddings to detect Māori-English code-switching points.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.49.pdf",
        "source": "naacl2022"
    },
    {
        "title": "LMTurk: Few-Shot Learners as Crowdsourcing Workers in a Language-Model-as-a-Service Framework",
        "authors": [
            "Mengjie Zhao",
            "Fei Mi",
            "Yasheng Wang",
            "Minglei Li",
            "Xin Jiang",
            "Qun Liu",
            "Hinrich Schuetze"
        ],
        "published": "2022",
        "summary": "Vast efforts have been devoted to creating high-performance few-shot learners, i.e., large-scale pretrained language models (PLMs) that perform well with little downstream task training data. Training PLMs has incurred significant cost, but utilizing the few-shot learners is still challenging due to their enormous size. This work focuses on a crucial question: How to make effective use of these few-shot learners? We propose LMTurk, a novel approach that treats few-shotlearners as crowdsourcing workers. The rationale is that crowdsourcing workers are in fact few-shot learners: They are shown a few illustrative examples to learn about a task and then start annotating. LMTurk employs few-shot learners built upon PLMs as workers. We show that the resulting annotations can be utilized to train models that solve the task well and are small enough to be deployable in practical scenarios. Active learning is integrated into LMTurk to reduce the amount of queries made to PLMs, minimizing the computational cost of running PLM inference passes. Altogether, LMTurk is an important step towards making effective use of current PLMs.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.51.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Entity Cloze By Date: What LMs Know About Unseen Entities",
        "authors": [
            "Yasumasa Onoe",
            "Michael Zhang",
            "Eunsol Choi",
            "Greg Durrett"
        ],
        "published": "2022",
        "summary": "Language models (LMs) are typically trained once on a large-scale corpus and used for years without being updated. However, in a dynamic world, new entities constantly arise. We propose a framework to analyze what LMs can infer about new entities that did not exist when the LMs were pretrained. We derive a dataset of entities indexed by their origination date and paired with their English Wikipedia articles, from which we can find sentences about each entity. We evaluate LMs’ perplexity on masked spans within these sentences. We show that models more informed about the entities, such as those with access to a textual definition of them, achieve lower perplexity on this benchmark. Our experimental results demonstrate that making inferences about new entities remains difficult for LMs. Given its wide coverage on entity knowledge and temporal indexing, our dataset can be used to evaluate LMs and techniques designed to modify or extend their knowledge. Our automatic data collection pipeline can be easily used to continually update our benchmark.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.52.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Data Augmentation for Low-Resource Dialogue Summarization",
        "authors": [
            "Yongtai Liu",
            "Joshua Maynez",
            "Gonçalo Simões",
            "Shashi Narayan"
        ],
        "published": "2022",
        "summary": "We present DADS, a novel Data Augmentation technique for low-resource Dialogue Summarization. Our method generates synthetic examples by replacing sections of text from both the input dialogue and summary while preserving the augmented summary to correspond to a viable summary for the augmented dialogue. We utilize pretrained language models that produce highly likely dialogue alternatives while still being free to generate diverse alternatives. We applied our data augmentation method to the SAMSum dataset in low resource scenarios, mimicking real world problems such as chat, thread, and meeting summarization where large scale supervised datasets with human-written summaries are scarce. Through both automatic and human evaluations, we show that DADS shows strong improvements for low resource scenarios while generating topically diverse summaries without introducing additional hallucinations to the summaries.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.53.pdf",
        "source": "naacl2022"
    },
    {
        "title": "LM-CORE: Language Models with Contextually Relevant External Knowledge",
        "authors": [
            "Jivat Kaur",
            "Sumit Bhatia",
            "Milan Aggarwal",
            "Rachit Bansal",
            "Balaji Krishnamurthy"
        ],
        "published": "2022",
        "summary": "Large transformer-based pre-trained language models have achieved impressive performance on a variety of knowledge-intensive tasks and can capture factual knowledge in their parameters. We argue that storing large amounts of knowledge in the model parameters is sub-optimal given the ever-growing amounts of knowledge and resource requirements. We posit that a more efficient alternative is to provide explicit access to contextually relevant structured knowledge to the model and train it to use that knowledge. We present LM-CORE – a general framework to achieve this– that allows decoupling of the language model training from the external knowledge source and allows the latter to be updated without affecting the already trained model. Experimental results show that LM-CORE, having access to external knowledge, achieves significant and robust outperformance over state-of-the-art knowledge-enhanced language models on knowledge probing tasks; can effectively handle knowledge updates; and performs well on two downstream tasks. We also present a thorough error analysis highlighting the successes and failures of LM-CORE. Our code and model checkpoints are publicly available.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.57.pdf",
        "source": "naacl2022"
    },
    {
        "title": "A Generative Language Model for Few-shot Aspect-Based Sentiment Analysis",
        "authors": [
            "Ehsan Hosseini-Asl",
            "Wenhao Liu",
            "Caiming Xiong"
        ],
        "published": "2022",
        "summary": "Sentiment analysis is an important task in natural language processing. In recent works, pre-trained language models are often used to achieve state-of-the-art results, especially when training data is scarce. It is common to fine-tune on the downstream task, usually by adding task-specific layers on top of the model. In this paper, we focus on aspect-based sentiment analysis, which involves extracting aspect term, category, and predicting their corresponding polarities. In particular, we are interested in few-shot settings. We propose to reformulate the extraction and prediction tasks into the sequence generation task, using a generative language model with unidirectional attention (GPT2 is used unless stated otherwise). This way, the model learns to accomplish the tasks via language generation without the need of training task-specific layers. Our evaluation results on the single-task polarity prediction show that our approach outperforms the previous state-of-the-art (based on BERT) on average performance by a large margins in few-shot and full-shot settings. More importantly, our generative approach significantly reduces the model variance caused by low-resource data. We further demonstrate that the proposed generative language model can handle joint and multi-task settings, unlike previous work. We observe that the proposed sequence generation method achieves further improved performances on polarity prediction when the model is trained via joint and multi-task settings. Further evaluation on similar sentiment analysis datasets, SST-2, SST-5 and OOS intent detection validates the superiority and noise robustness of generative language model in few-shot settings.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.58.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Empathetic Persuasion: Reinforcing Empathy and Persuasiveness in Dialogue Systems",
        "authors": [
            "Azlaan Mustafa Samad",
            "Kshitij Mishra",
            "Mauajama Firdaus",
            "Asif Ekbal"
        ],
        "published": "2022",
        "summary": "Persuasion is an intricate process involving empathetic connection between two individuals. Plain persuasive responses may make a conversation non-engaging. Even the most well-intended and reasoned persuasive conversations can fall through in the absence of empathetic connection between the speaker and listener. In this paper, we propose a novel task of incorporating empathy when generating persuasive responses. We develop an empathetic persuasive dialogue system by fine-tuning a maximum likelihood Estimation (MLE)-based language model in a reinforcement learning (RL) framework. To design feedbacks for our RL-agent, we define an effective and efficient reward function considering consistency, repetitiveness, emotion and persuasion rewards to ensure consistency, non-repetitiveness, empathy and persuasiveness in the generated responses. Due to lack of emotion annotated persuasive data, we first annotate the existing Persuaion For Good dataset with emotions, then build transformer based classifiers to provide emotion based feedbacks to our RL agent. Experimental results confirm that our proposed model increases the rate of generating persuasive responses as compared to the available state-of-the-art dialogue models while making the dialogues empathetically more engaging and retaining the language quality in responses.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.63.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Attention Fusion: a light yet efficient late fusion mechanism for task adaptation in NLU",
        "authors": [
            "Jin Cao",
            "Chandana Satya Prakash",
            "Wael Hamza"
        ],
        "published": "2022",
        "summary": "Fine-tuning a pre-trained language model using annotated data has become the de-facto standard for adapting general-purpose pre-trained models like BERT to downstream tasks. However, given the trend of larger pre-trained models, fine-tuning these models for each downstream task is parameter-inefficient and computationally-expensive deeming this approach sub-optimal for adoption by NLU systems. In recent years, various approaches have been proposed for parameter efficient task adaptation such as Adaptor, Bitfit, Prompt tuning, Prefix tuning etc. However, most of these efforts propose to insert task specific parameters in-between or inside intermediate layers of the pre-trained encoder resulting in higher computational cost due to back-propagation of errors to all layers. To mitigate this issue, we propose a light but efficient, attention based fusion module which computes task-attuned token representations by aggregating intermediate layer representations from a pre-trained network. Our proposed fusion module trains only 0.0009% of total parameters and achieves competitive performance to the standard fine-tuning approach on various tasks. It is also decoupled from the pre-trained network making it efficient during computation and scalable during deployment. Last but not the least, we demonstrate that our proposed attention-fusion mechanism can transfer effectively to different languages for further re-use and expansion.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.64.pdf",
        "source": "naacl2022"
    },
    {
        "title": "The Limits of Word Level Differential Privacy",
        "authors": [
            "Justus Mattern",
            "Benjamin Weggenmann",
            "Florian Kerschbaum"
        ],
        "published": "2022",
        "summary": "As the issues of privacy and trust are receiving increasing attention within the research community, various attempts have been made to anonymize textual data. A significant subset of these approaches incorporate differentially private mechanims to perturb word embeddings, thus replacing individual words in a sentence. While these methods represent very important contributions, have various advantages over other techniques and do show anonymization capabilities,they have several shortcomings. In this paper, we investigate these weaknesses and demonstrate significant mathematical constraints diminishing the theoretical privacy guaranteeas well as major practical shortcomings with regard to the protection against deanonymization attacks, the preservation of content of the original sentences as well as the quality of the language output. Finally, we propose a new method for text anonymization based on transformer based language models fine-tuned for paraphrasing that circumvents most of the identified weaknesses and also offers a formal privacy guarantee. We evaluate the performance of our method via thourough experimentation and demonstrate superior performance over the discussed mechanisms.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.65.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Learning Rich Representation of Keyphrases from Text",
        "authors": [
            "Mayank Kulkarni",
            "Debanjan Mahata",
            "Ravneet Arora",
            "Rajarshi Bhowmik"
        ],
        "published": "2022",
        "summary": "In this work, we explore how to train task-specific language models aimed towards learning rich representation of keyphrases from text documents. We experiment with different masking strategies for pre-training transformer language models (LMs) in discriminative as well as generative settings. In the discriminative setting, we introduce a new pre-training objective - Keyphrase Boundary Infilling with Replacement (KBIR), showing large gains in performance (upto 8.16 points in F1) over SOTA, when the LM pre-trained using KBIR is fine-tuned for the task of keyphrase extraction. In the generative setting, we introduce a new pre-training setup for BART - KeyBART, that reproduces the keyphrases related to the input text in the CatSeq format, instead of the denoised original input. This also led to gains in performance (upto 4.33 points in F1@M) over SOTA for keyphrase generation. Additionally, we also fine-tune the pre-trained language models on named entity recognition (NER), question answering (QA), relation extraction (RE), abstractive summarization and achieve comparable performance with that of the SOTA, showing that learning rich representation of keyphrases is indeed beneficial for many other fundamental NLP tasks.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.67.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Improving Contextual Representation with Gloss Regularized Pre-training",
        "authors": [
            "Yu Lin",
            "Zhecheng An",
            "Peihao Wu",
            "Zejun Ma"
        ],
        "published": "2022",
        "summary": "Though achieving impressive results on many NLP tasks, the BERT-like masked language models (MLM) encounter the discrepancy between pre-training and inference. In light of this gap, we investigate the contextual representation of pre-training and inference from the perspective of word probability distribution. We discover that BERT risks neglecting the contextual word similarity in pre-training. To tackle this issue, we propose an auxiliary gloss regularizer module to BERT pre-training (GR-BERT), to enhance word semantic similarity. By predicting masked words and aligning contextual embeddings to corresponding glosses simultaneously, the word similarity can be explicitly modeled. We design two architectures for GR-BERT and evaluate our model in downstream tasks. Experimental results show that the gloss regularizer benefits BERT in word-level and sentence-level semantic representation. The GR-BERT achieves new state-of-the-art in lexical substitution task and greatly promotes BERT sentence representation in both unsupervised and supervised STS tasks.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.68.pdf",
        "source": "naacl2022"
    },
    {
        "title": "An Information-Theoretic Approach and Dataset for Probing Gender Stereotypes in Multilingual Masked Language Models",
        "authors": [
            "Victor Steinborn",
            "Philipp Dufter",
            "Haris Jabbar",
            "Hinrich Schuetze"
        ],
        "published": "2022",
        "summary": "Bias research in NLP is a rapidly growing and developing field. Similar to CrowS-Pairs (Nangia et al., 2020), we assess gender bias in masked-language models (MLMs) by studying pairs of sentences with gender swapped person references. Most bias research focuses on and often is specific to English.Using a novel methodology for creating sentence pairs that is applicable across languages, we create, based on CrowS-Pairs, a multilingual dataset for English, Finnish, German, Indonesian and Thai.Additionally, we propose SJSD, a new bias measure based on Jensen–Shannon divergence, which we argue retains more information from the model output probabilities than other previously proposed bias measures for MLMs.Using multilingual MLMs, we find that SJSD diagnoses the same systematic biased behavior for non-English that previous studies have found for monolingual English pre-trained MLMs. SJSD outperforms the CrowS-Pairs measure, which struggles to find such biases for smaller non-English datasets.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.69.pdf",
        "source": "naacl2022"
    },
    {
        "title": "QLEVR: A Diagnostic Dataset for Quantificational Language and Elementary Visual Reasoning",
        "authors": [
            "Zechen Li",
            "Anders Søgaard"
        ],
        "published": "2022",
        "summary": "Synthetic datasets have successfully been used to probe visual question-answering datasets for their reasoning abilities. CLEVR (John- son et al., 2017), for example, tests a range of visual reasoning abilities. The questions in CLEVR focus on comparisons of shapes, colors, and sizes, numerical reasoning, and existence claims. This paper introduces a minimally biased, diagnostic visual question-answering dataset, QLEVR, that goes beyond existential and numerical quantification and focus on more complex quantifiers and their combinations, e.g., asking whether there are more than two red balls that are smaller than at least three blue balls in an image. We describe how the dataset was created and present a first evaluation of state-of-the-art visual question-answering models, showing that QLEVR presents a formidable challenge to our current models. Code and Dataset are available at https://github.com/zechenli03/QLEVR",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.73.pdf",
        "source": "naacl2022"
    },
    {
        "title": "MWP-BERT: Numeracy-Augmented Pre-training for Math Word Problem Solving",
        "authors": [
            "Zhenwen Liang",
            "Jipeng Zhang",
            "Lei Wang",
            "Wei Qin",
            "Yunshi Lan",
            "Jie Shao",
            "Xiangliang Zhang"
        ],
        "published": "2022",
        "summary": "Math word problem (MWP) solving faces a dilemma in number representation learning. In order to avoid the number representation issue and reduce the search space of feasible solutions, existing works striving for MWP solving usually replace real numbers with symbolic placeholders to focus on logic reasoning. However, different from common symbolic reasoning tasks like program synthesis and knowledge graph reasoning, MWP solving has extra requirements in numerical reasoning. In other words, instead of the number value itself, it is the reusable numerical property that matters more in numerical reasoning. Therefore, we argue that injecting numerical properties into symbolic placeholders with contextualized representation learning schema can provide a way out of the dilemma in the number representation issue here. In this work, we introduce this idea to the popular pre-training language model (PLM) techniques and build MWP-BERT, an effective contextual number representation PLM. We demonstrate the effectiveness of our MWP-BERT on MWP solving and several MWP-specific understanding tasks on both English and Chinese benchmarks.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.74.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Probing the Role of Positional Information in Vision-Language Models",
        "authors": [
            "Philipp J. Rösch",
            "Jindřich Libovický"
        ],
        "published": "2022",
        "summary": "In most Vision-Language models (VL), the understanding of the image structure is enabled by injecting the position information (PI) about objects in the image. In our case study of LXMERT, a state-of-the-art VL model, we probe the use of the PI in the representation and study its effect on Visual Question Answering. We show that the model is not capable of leveraging the PI for the image-text matching task on a challenge set where only position differs. Yet, our experiments with probing confirm that the PI is indeed present in the representation. We introduce two strategies to tackle this: (i) Positional Information Pre-training and (ii) Contrastive Learning on PI using Cross-Modality Matching. Doing so, the model can correctly classify if images with detailed PI statements match. Additionally to the 2D information from bounding boxes, we introduce the object’s depth as new feature for a better object localization in the space. Even though we were able to improve the model properties as defined by our probes, it only has a negligible effect on the downstream performance. Our results thus highlight an important issue of multimodal modeling: the mere presence of information detectable by a probing classifier is not a guarantee that the information is available in a cross-modal setup.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.77.pdf",
        "source": "naacl2022"
    },
    {
        "title": "”Diversity and Uncertainty in Moderation” are the Key to Data Selection for Multilingual Few-shot Transfer",
        "authors": [
            "Shanu Kumar",
            "Sandipan Dandapat",
            "Monojit Choudhury"
        ],
        "published": "2022",
        "summary": "Few-shot transfer often shows substantial gain over zero-shot transfer (CITATION), which is a practically useful trade-off between fully supervised and unsupervised learning approaches for multilingual pretained model-based systems. This paper explores various strategies for selecting data for annotation that can result in a better few-shot transfer. The proposed approaches rely on multiple measures such as data entropy using n-gram language model, predictive entropy, and gradient embedding. We propose a loss embedding method for sequence labeling tasks, which induces diversity and uncertainty sampling similar to gradient embedding. The proposed data selection strategies are evaluated and compared for POS tagging, NER, and NLI tasks for up to 20 languages. Our experiments show that the gradient and loss embedding-based strategies consistently outperform random data selection baselines, with gains varying with the initial performance of the zero-shot transfer. Furthermore, the proposed method shows similar trends in improvement even when the model is fine-tuned using a lower proportion of the original task-specific labeled training data for zero-shot transfer.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.78.pdf",
        "source": "naacl2022"
    },
    {
        "title": "A Self-supervised Joint Training Framework for Document Reranking",
        "authors": [
            "Xiaozhi Zhu",
            "Tianyong Hao",
            "Sijie Cheng",
            "Fu Lee Wang",
            "Hai Liu"
        ],
        "published": "2022",
        "summary": "Pretrained language models such as BERT have been successfully applied to a wide range of natural language processing tasks and also achieved impressive performance in document reranking tasks. Recent works indicate that further pretraining the language models on the task-specific datasets before fine-tuning helps improve reranking performance. However, the pre-training tasks like masked language model and next sentence prediction were based on the context of documents instead of encouraging the model to understand the content of queries in document reranking task. In this paper, we propose a new self-supervised joint training framework (SJTF) with a self-supervised method called Masked Query Prediction (MQP) to establish semantic relations between given queries and positive documents. The framework randomly masks a token of query and encodes the masked query paired with positive documents, and uses a linear layer as a decoder to predict the masked token. In addition, the MQP is used to jointly optimize the models with supervised ranking objective during fine-tuning stage without an extra further pre-training stage. Extensive experiments on the MS MARCO passage ranking and TREC Robust datasets show that models trained with our framework obtain significant improvements compared to original models.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.79.pdf",
        "source": "naacl2022"
    },
    {
        "title": "RGL: A Simple yet Effective Relation Graph Augmented Prompt-based Tuning Approach for Few-Shot Learning",
        "authors": [
            "Yaqing Wang",
            "Xin Tian",
            "Haoyi Xiong",
            "Yueyang Li",
            "Zeyu Chen",
            "Sheng Guo",
            "Dejing Dou"
        ],
        "published": "2022",
        "summary": "Pre-trained language models (PLMs) can provide a good starting point for downstream applications. However, it is difficult to generalize PLMs to new tasks given a few labeled samples. In this work, we show that Relation Graph augmented Learning (RGL) can improve the performance of few-shot natural language understanding tasks. During learning, RGL constructs a relation graph based on the label consistency between samples in the same batch, and learns to solve the resultant node classification and link prediction problems on the relation graph. In this way, RGL fully exploits the limited supervised information, which can boost the tuning effectiveness. Extensive experimental results show that RGL consistently improves the performance of prompt-based tuning strategies.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.81.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Phrase-level Textual Adversarial Attack with Label Preservation",
        "authors": [
            "Yibin Lei",
            "Yu Cao",
            "Dianqi Li",
            "Tianyi Zhou",
            "Meng Fang",
            "Mykola Pechenizkiy"
        ],
        "published": "2022",
        "summary": "Generating high-quality textual adversarial examples is critical for investigating the pitfalls of natural language processing (NLP) models and further promoting their robustness. Existing attacks are usually realized through word-level or sentence-level perturbations, which either limit the perturbation space or sacrifice fluency and textual quality, both affecting the attack effectiveness. In this paper, we propose Phrase-Level Textual Adversarial ATtack (PLAT) that generates adversarial samples through phrase-level perturbations. PLAT first extracts the vulnerable phrases as attack targets by a syntactic parser, and then perturbs them by a pre-trained blank-infilling model. Such flexible perturbation design substantially expands the search space for more effective attacks without introducing too many modifications, and meanwhile maintaining the textual fluency and grammaticality via contextualized generation using surrounding texts. Moreover, we develop a label preservation filter leveraging the likelihoods of language models fine-tuned on each class, rather than textual similarity, to rule out those perturbations that potentially alter the original class label for humans. Extensive experiments and human evaluation demonstrate that PLAT has a superior attack effectiveness as well as a better label consistency than strong baselines.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.83.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Prompt Augmented Generative Replay via Supervised Contrastive Learning for Lifelong Intent Detection",
        "authors": [
            "Vaibhav Varshney",
            "Mayur Patidar",
            "Rajat Kumar",
            "Lovekesh Vig",
            "Gautam Shroff"
        ],
        "published": "2022",
        "summary": "Identifying all possible user intents for a dialog system at design time is challenging even for skilled domain experts. For practical applications, novel intents may have to be inferred incrementally on the fly. This typically entails repeated retraining of the intent detector on both the existing and novel intents which can be expensive and would require storage of all past data corresponding to prior intents. In this paper, the objective is to continually train an intent detector on new intents while maintaining performance on prior intents without mandating access to prior intent data. Several data replay-based approaches have been introduced to avoid catastrophic forgetting during continual learning, including exemplar and generative replay. Current generative replay approaches struggle to generate representative samples because the generation is conditioned solely on the class/task label. Motivated by the recent work around prompt-based generation via pre-trained language models (PLMs), we employ generative replay using PLMs for incremental intent detection. Unlike exemplar replay, we only store the relevant contexts per intent in memory and use these stored contexts (with the class label) as prompts for generating intent-specific utterances. We use a common model for both generation and classification to promote optimal sharing of knowledge across both tasks. To further improve generation, we employ supervised contrastive fine-tuning of the PLM. Our proposed approach achieves state-of-the-art (SOTA) for lifelong intent detection on four public datasets and even outperforms exemplar replay-based approaches. The technique also achieves SOTA on a lifelong relation extraction task, suggesting that the approach is extendable to other continual learning tasks beyond intent detection.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.84.pdf",
        "source": "naacl2022"
    },
    {
        "title": "DecBERT: Enhancing the Language Understanding of BERT with Causal Attention Masks",
        "authors": [
            "Ziyang Luo",
            "Yadong Xi",
            "Jing Ma",
            "Zhiwei Yang",
            "Xiaoxi Mao",
            "Changjie Fan",
            "Rongsheng Zhang"
        ],
        "published": "2022",
        "summary": "Since 2017, the Transformer-based models play critical roles in various downstream Natural Language Processing tasks. However, a common limitation of the attention mechanism utilized in Transformer Encoder is that it cannot automatically capture the information of word order, so explicit position embeddings are generally required to be fed into the target model. In contrast, Transformer Decoder with the causal attention masks is naturally sensitive to the word order. In this work, we focus on improving the position encoding ability of BERT with the causal attention masks. Furthermore, we propose a new pre-trained language model DecBERT and evaluate it on the GLUE benchmark. Experimental results show that (1) the causal attention mask is effective for BERT on the language understanding tasks; (2) our DecBERT model without position embeddings achieve comparable performance on the GLUE benchmark; and (3) our modification accelerates the pre-training process and DecBERT w/ PE achieves better overall performance than the baseline systems when pre-training with the same amount of computational resources.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.89.pdf",
        "source": "naacl2022"
    },
    {
        "title": "BanglaBERT: Language Model Pretraining and Benchmarks for Low-Resource Language Understanding Evaluation in Bangla",
        "authors": [
            "Abhik Bhattacharjee",
            "Tahmid Hasan",
            "Wasi Ahmad",
            "Kazi Samin Mubasshir",
            "Md Saiful Islam",
            "Anindya Iqbal",
            "M. Sohel Rahman",
            "Rifat Shahriyar"
        ],
        "published": "2022",
        "summary": "In this work, we introduce BanglaBERT, a BERT-based Natural Language Understanding (NLU) model pretrained in Bangla, a widely spoken yet low-resource language in the NLP literature. To pretrain BanglaBERT, we collect 27.5 GB of Bangla pretraining data (dubbed ‘Bangla2B+’) by crawling 110 popular Bangla sites. We introduce two downstream task datasets on natural language inference and question answering and benchmark on four diverse NLU tasks covering text classification, sequence labeling, and span prediction. In the process, we bring them under the first-ever Bangla Language Understanding Benchmark (BLUB). BanglaBERT achieves state-of-the-art results outperforming multilingual and monolingual models. We are making the models, datasets, and a leaderboard publicly available at https://github.com/csebuetnlp/banglabert to advance Bangla NLP.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.98.pdf",
        "source": "naacl2022"
    },
    {
        "title": "POLITICS: Pretraining with Same-story Article Comparison for Ideology Prediction and Stance Detection",
        "authors": [
            "Yujian Liu",
            "Xinliang Frederick Zhang",
            "David Wegsman",
            "Nicholas Beauchamp",
            "Lu Wang"
        ],
        "published": "2022",
        "summary": "Ideology is at the core of political science research. Yet, there still does not exist general-purpose tools to characterize and predict ideology across different genres of text. To this end, we study Pretrained Language Models using novel ideology-driven pretraining objectives that rely on the comparison of articles on the same story written by media of different ideologies. We further collect a large-scale dataset, consisting of more than 3.6M political news articles, for pretraining. Our model POLITICS outperforms strong baselines and the previous state-of-the-art models on ideology prediction and stance detection tasks. Further analyses show that POLITICS is especially good at understanding long or formally written texts, and is also robust in few-shot learning scenarios.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.101.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Empowering parameter-efficient transfer learning by recognizing the kernel structure in self-attention",
        "authors": [
            "Yifan Chen",
            "Devamanyu Hazarika",
            "Mahdi Namazifar",
            "Yang Liu",
            "Di Jin",
            "Dilek Hakkani-Tur"
        ],
        "published": "2022",
        "summary": "The massive amount of trainable parameters in the pre-trained language models (PLMs) makes them hard to be deployed to multiple downstream tasks. To address this issue, parameter-efficient transfer learning methods have been proposed to tune only a few parameters during fine-tuning while freezing the rest. This paper looks at existing methods along this line through the kernel lens. Motivated by the connection between self-attention in transformer-based PLMs and kernel learning, we propose kernel-wise adapters, namely Kernel-mix, that utilize the kernel structure in self-attention to guide the assignment of the tunable parameters. These adapters use guidelines found in classical kernel learning and enable separate parameter tuning for each attention head. Our empirical results, over a diverse set of natural language generation and understanding tasks, show that our proposed adapters can attain or improve the strong performance of existing baselines.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.102.pdf",
        "source": "naacl2022"
    },
    {
        "title": "RAIL-KD: RAndom Intermediate Layer Mapping for Knowledge Distillation",
        "authors": [
            "Md Akmal Haidar",
            "Nithin Anchuri",
            "Mehdi Rezagholizadeh",
            "Abbas Ghaddar",
            "Philippe Langlais",
            "Pascal Poupart"
        ],
        "published": "2022",
        "summary": "Intermediate layer knowledge distillation (KD) can improve the standard KD technique (which only targets the output of teacher and student models) especially over large pre-trained language models. However, intermediate layer distillation suffers from excessive computational burdens and engineering efforts required for setting up a proper layer mapping. To address these problems, we propose a RAndom Intermediate Layer Knowledge Distillation (RAIL-KD) approach in which, intermediate layers from the teacher model are selected randomly to be distilled into the intermediate layers of the student model. This randomized selection enforces that all teacher layers are taken into account in the training process, while reducing the computational cost of intermediate layer distillation. Also, we show that it acts as a regularizer for improving the generalizability of the student model. We perform extensive experiments on GLUE tasks as well as on out-of-domain test sets. We show that our proposed RAIL-KD approach outperforms other state-of-the-art intermediate layer KD methods considerably in both performance and training-time.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.103.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Temporal Attention for Language Models",
        "authors": [
            "Guy D. Rosin",
            "Kira Radinsky"
        ],
        "published": "2022",
        "summary": "Pretrained language models based on the transformer architecture have shown great success in NLP.Textual training data often comes from the web and is thus tagged with time-specific information, but most language models ignore this information. They are trained on the textual data alone, limiting their ability to generalize temporally. In this work, we extend the key component of the transformer architecture, i.e., the self-attention mechanism, and propose temporal attention - a time-aware self-attention mechanism. Temporal attention can be applied to any transformer model and requires the input texts to be accompanied with their relevant time points. This mechanism allows the transformer to capture this temporal information and create time-specific contextualized word representations. We leverage these representations for the task of semantic change detection; we apply our proposed mechanism to BERT and experiment on three datasets in different languages (English, German, and Latin) that also vary in time, size, and genre. Our proposed model achieves state-of-the-art results on all the datasets.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.112.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Hierarchical Transformers Are More Efficient Language Models",
        "authors": [
            "Piotr Nawrot",
            "Szymon Tworkowski",
            "Michał Tyrolski",
            "Lukasz Kaiser",
            "Yuhuai Wu",
            "Christian Szegedy",
            "Henryk Michalewski"
        ],
        "published": "2022",
        "summary": "Transformer models yield impressive results on many NLP and sequence modeling tasks. Remarkably, Transformers can handle long sequences, which allows them to produce long coherent outputs: entire paragraphs produced by GPT-3 or well-structured images produced by DALL-E. These large language models are impressive but also very inefficient and costly, which limits their applications and accessibility. We postulate that having an explicit hierarchical architecture is the key to Transformers that efficiently handle long sequences. To verify this claim, we first study different ways to downsample and upsample activations in Transformers so as to make them hierarchical. We use the best performing upsampling and downsampling layers to create Hourglass - a hierarchical Transformer language model. Hourglass improves upon the Transformer baseline given the same amount of computation and can yield the same results as Transformers more efficiently. In particular, Hourglass sets new state-of-the-art for Transformer models on the ImageNet32 generation task and improves language modeling efficiency on the widely studied enwik8 benchmark.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.117.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Pruning Adatperfusion with Lottery Ticket Hypothesis",
        "authors": [
            "Jiarun Wu",
            "Qingliang Chen",
            "Zeguan Xiao",
            "Yuliang Gu",
            "Mengsi Sun"
        ],
        "published": "2022",
        "summary": "Pre-trained language models have shown great success in multiple downstream tasks. However, they are computationally expensive to fine-tune. Thus, transfer learning with adapter modules has been introduced to alleviate this problem, helping to extract knowledge of the downstream tasks. Adapterfusion models are an example of the transformers-with-adapter-modules, which merge multiple adapters to incorporate knowledge from different tasks. However, merging multiple adapters will inevitably cause redundancies, increasing the training and inference time massively. Therefore, in this paper, we propose an approach to identify the influence of each adapter module and a novel way to prune adapters based on the prestigious Lottery Ticket Hypothesis. Experiments on GLUE datasets show that the pruned Adapterfusion model with our scheme can achieve state-of-the-art results, reducing sizes significantly while keeping performance intact.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.123.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Post-Training Dialogue Summarization using Pseudo-Paraphrasing",
        "authors": [
            "Qi Jia",
            "Yizhu Liu",
            "Haifeng Tang",
            "Kenny Zhu"
        ],
        "published": "2022",
        "summary": "Previous dialogue summarization techniques adapt large language models pretrained on the narrative text by injecting dialogue-specific features into the models. These features either require additional knowledge to recognize or make the resulting models harder to tune. To bridge the format gap between dialogues and narrative summaries in dialogue summarization tasks, we propose to post-train pretrained language models (PLMs) to rephrase from dialogue to narratives. After that, the model is fine-tuned for dialogue summarization as usual. Comprehensive experiments show that our approach significantly improves vanilla PLMs on dialogue summarization and outperforms other SOTA models by the summary quality and implementation costs.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.125.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Revisiting Generative Commonsense Reasoning: A Pre-Ordering Approach",
        "authors": [
            "Chao Zhao",
            "Faeze Brahman",
            "Tenghao Huang",
            "Snigdha Chaturvedi"
        ],
        "published": "2022",
        "summary": "Pre-trained models (PTMs) have lead to great improvements in natural language generation (NLG). However, it is still unclear how much commonsense knowledge they possess. With the goal of evaluating commonsense knowledge of NLG models, recent work has proposed the problem of generative commonsense reasoning, e.g., to compose a logical sentence given a set of unordered concepts. Existing approaches to this problem hypothesize that PTMs lack sufficient parametric knowledge for this task, which can be overcome by introducing external knowledge or task-specific pre-training objectives. Different from this trend, we argue that PTM’s inherent ability for generative commonsense reasoning is underestimated due to the order-agnostic property of its input. In particular, we hypothesize that the order of the input concepts can affect the PTM’s ability to utilize its commonsense knowledge. To this end, we propose a pre-ordering approach to elaborately manipulate the order of the given concepts before generation. Experiments show that our approach can outperform the more sophisticated models that have access to a lot of external data and resources.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.129.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Great~Truths~are ~Always ~Simple: A Rather Simple Knowledge Encoder for Enhancing the Commonsense Reasoning Capacity of Pre-Trained Models",
        "authors": [
            "Jinhao Jiang",
            "Kun Zhou",
            "Ji-Rong Wen",
            "Xin Zhao"
        ],
        "published": "2022",
        "summary": "Commonsense reasoning in natural language is a desired ability of artificial intelligent systems. For solving complex commonsense reasoning tasks, a typical solution is to enhance pre-trained language models (PTMs) with a knowledge-aware graph neural network (GNN) encoder that models a commonsense knowledge graph (CSKG).Despite the effectiveness, these approaches are built on heavy architectures, and can’t clearly explain how external knowledge resources improve the reasoning capacity of PTMs. Considering this issue, we conduct a deep empirical analysis, and find that it is indeed relation features from CSKGs (but not node features) that mainly contribute to the performance improvement of PTMs. Based on this finding, we design a simple MLP-based knowledge encoder that utilizes statistical relation paths as features. Extensive experiments conducted on five benchmarks demonstrate the effectiveness of our approach, which also largely reduces the parameters for encoding CSKGs.Our codes and data are publicly available at https://github.com/RUCAIBox/SAFE.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.131.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Minimally-Supervised Relation Induction from Pre-trained Language Model",
        "authors": [
            "Lu Sun",
            "Yongliang Shen",
            "Weiming Lu"
        ],
        "published": "2022",
        "summary": "Relation Induction is a very practical task in Natural Language Processing (NLP) area. In practical application scenarios, people want to induce more entity pairs having the same relation from only a few seed entity pairs. Thus, instead of the laborious supervised setting, in this paper, we focus on the minimally-supervised setting where only a couple of seed entity pairs per relation are provided. Although the conventional relation induction methods have made some success, their performance depends heavily on the quality of word embeddings. The great success of Pre-trained Language Models, such as BERT, changes the NLP area a lot, and they are proven to be able to better capture relation knowledge. In this paper, we propose a novel method to induce relation with BERT under the minimally-supervised setting. Specifically, we firstly extract proper templates from the corpus by using the mask-prediction task in BERT to build pseudo-sentences as the context of entity pairs. Then we use BERT attention weights to better represent the pseudo-sentences. In addition, We also use the IntegratedGradient of entity pairs to iteratively select better templates further. Finally, with the high-quality pseudo-sentences, we can train a better classifier for relation induction. Experiments onGoogle Analogy Test Sets (GATS), Bigger Analogy TestSet (BATS) and DiffVec demonstrate that our proposed method achieves state-of-the-art performance.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.135.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Exploring the Universal Vulnerability of Prompt-based Learning Paradigm",
        "authors": [
            "Lei Xu",
            "Yangyi Chen",
            "Ganqu Cui",
            "Hongcheng Gao",
            "Zhiyuan Liu"
        ],
        "published": "2022",
        "summary": "Prompt-based learning paradigm bridges the gap between pre-training and fine-tuning, and works effectively under the few-shot setting. However, we find that this learning paradigm inherits the vulnerability from the pre-training stage, where model predictions can be misled by inserting certain triggers into the text. In this paper, we explore this universal vulnerability by either injecting backdoor triggers or searching for adversarial triggers on pre-trained language models using only plain text. In both scenarios, we demonstrate that our triggers can totally control or severely decrease the performance of prompt-based models fine-tuned on arbitrary downstream tasks, reflecting the universal vulnerability of the prompt-based learning paradigm. Further experiments show that adversarial triggers have good transferability among language models. We also find conventional fine-tuning models are not vulnerable to adversarial triggers constructed from pre-trained language models. We conclude by proposing a potential solution to mitigate our attack methods. Code and data are publicly available.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.137.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Exploiting Numerical-Contextual Knowledge to Improve Numerical Reasoning in Question Answering",
        "authors": [
            "Jeonghwan Kim",
            "Junmo Kang",
            "Kyung-min Kim",
            "Giwon Hong",
            "Sung-Hyon Myaeng"
        ],
        "published": "2022",
        "summary": "Numerical reasoning over text is a challenging subtask in question answering (QA) that requires both the understanding of texts and numbers. However, existing language models in these numerical reasoning QA models tend to overly rely on the pre-existing parametric knowledge at inference time, which commonly causes hallucination in interpreting numbers. Our work proposes a novel attention masked reasoning model, the NC-BERT, that learns to leverage the number-related contextual knowledge to alleviate the over-reliance on parametric knowledge and enhance the numerical reasoning capabilities of the QA model. The empirical results suggest that understanding of numbers in their context by reducing the parametric knowledge influence, and refining numerical information in the number embeddings lead to improved numerical reasoning accuracy and performance in DROP, a numerical QA dataset.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.138.pdf",
        "source": "naacl2022"
    },
    {
        "title": "HUE: Pretrained Model and Dataset for Understanding Hanja Documents of Ancient Korea",
        "authors": [
            "Haneul Yoo",
            "Jiho Jin",
            "Juhee Son",
            "JinYeong Bak",
            "Kyunghyun Cho",
            "Alice Oh"
        ],
        "published": "2022",
        "summary": "Historical records in Korea before the 20th century were primarily written in Hanja, an extinct language based on Chinese characters and not understood by modern Korean or Chinese speakers. Historians with expertise in this time period have been analyzing the documents, but that process is very difficult and time-consuming, and language models would significantly speed up the process. Toward building and evaluating language models for Hanja, we release the Hanja Understanding Evaluation dataset consisting of chronological attribution, topic classification, named entity recognition, and summary retrieval tasks. We also present BERT-based models continued training on the two major corpora from the 14th to the 19th centuries: the Annals of the Joseon Dynasty and Diaries of the Royal Secretariats. We compare the models with several baselines on all tasks and show there are significant improvements gained by training on the two corpora. Additionally, we run zero-shot experiments on the Daily Records of the Royal Court and Important Officials (DRRI). The DRRI dataset has not been studied much by the historians, and not at all by the NLP community.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.140.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Make The Most of Prior Data: A Solution for Interactive Text Summarization with Preference Feedback",
        "authors": [
            "Duy-Hung Nguyen",
            "Nguyen Viet Dung Nghiem",
            "Bao-Sinh Nguyen",
            "Dung Tien Tien Le",
            "Shahab Sabahi",
            "Minh-Tien Nguyen",
            "Hung Le"
        ],
        "published": "2022",
        "summary": "For summarization, human preferences is critical to tame outputs of the summarizer in favor of human interests, as ground-truth summaries are scarce and ambiguous. Practical settings require dynamic exchanges between humans and AI agents wherein feedback is provided in an online manner, a few at a time. In this paper, we introduce a new framework to train summarization models with preference feedback interactively. By properly leveraging offline data and a novel reward model, we improve the performance regarding ROUGE scores and sample-efficiency. Our experiments on three various datasets confirm the benefit of the proposed framework in active, few-shot and online settings of preference learning.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.147.pdf",
        "source": "naacl2022"
    },
    {
        "title": "XLTime: A Cross-Lingual Knowledge Transfer Framework for Temporal Expression Extraction",
        "authors": [
            "Yuwei Cao",
            "William Groves",
            "Tanay Kumar Saha",
            "Joel Tetreault",
            "Alejandro Jaimes",
            "Hao Peng",
            "Philip Yu"
        ],
        "published": "2022",
        "summary": "Temporal Expression Extraction (TEE) is essential for understanding time in natural language. It has applications in Natural Language Processing (NLP) tasks such as question answering, information retrieval, and causal inference. To date, work in this area has mostly focused on English as there is a scarcity of labeled data for other languages. We propose XLTime, a novel framework for multilingual TEE. XLTime works on top of pre-trained language models and leverages multi-task learning to prompt cross-language knowledge transfer both from English and within the non-English languages. XLTime alleviates problems caused by a shortage of data in the target language. We apply XLTime with different language models and show that it outperforms the previous automatic SOTA methods on French, Spanish, Portuguese, and Basque, by large margins. XLTime also closes the gap considerably on the handcrafted HeidelTime method.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.148.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Great Power, Great Responsibility: Recommendations for Reducing Energy for Training Language Models",
        "authors": [
            "Joseph McDonald",
            "Baolin Li",
            "Nathan Frey",
            "Devesh Tiwari",
            "Vijay Gadepally",
            "Siddharth Samsi"
        ],
        "published": "2022",
        "summary": "The energy requirements of current natural language processing models continue to grow at a rapid, unsustainable pace. Recent works highlighting this problem conclude there is an urgent need for methods that reduce the energy needs of NLP and machine learning more broadly. In this article, we investigate techniques that can be used to reduce the energy consumption of common NLP applications. In particular, we focus on techniques to measure energy usage and different hardware and datacenter-oriented settings that can be tuned to reduce energy consumption for training and inference for language models. We characterize the impact of these settings on metrics such as computational performance and energy consumption through experiments conducted on a high performance computing system as well as popular cloud computing platforms. These techniques can lead to significant reduction in energy consumption when training language models or their use for inference. For example, power-capping, which limits the maximum power a GPU can consume, can enable a 15% decrease in energy usage with marginal increase in overall computation time when training a transformer-based language model.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.151.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Uncertainty-Aware Cross-Lingual Transfer with Pseudo Partial Labels",
        "authors": [
            "Shuo Lei",
            "Xuchao Zhang",
            "Jianfeng He",
            "Fanglan Chen",
            "Chang-Tien Lu"
        ],
        "published": "2022",
        "summary": "Large-scale multilingual pre-trained language models have achieved remarkable performance in zero-shot cross-lingual tasks. A recent study has demonstrated the effectiveness of self-learning-based approach on cross-lingual transfer, where only unlabeled data of target languages are required, without any efforts to annotate gold labels for target languages. However, it suffers from noisy training due to the incorrectly pseudo-labeled samples. In this work, we propose an uncertainty-aware Cross-Lingual Transfer framework with Pseudo-Partial-Label (CLTP)1 to maximize the utilization of unlabeled data by reducing the noise introduced in the training phase. To estimate pseudo-partial-label for each unlabeled data, we propose a novel estimation method, considering both prediction confidence and the limitation to the number of similar labels. Extensive experiments are conducted on two cross-lingual tasks, including Named Entity Recognition (NER) and Natural Language Inference (NLI) across 40 languages, which shows our method can outperform the baselines on both high-resource and low-resource languages, such as 6.9 on Kazakh (kk) and 5.2 Marathi (mr) for NER.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.153.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Beyond Distributional Hypothesis: Let Language Models Learn Meaning-Text Correspondence",
        "authors": [
            "Myeongjun Jang",
            "Frank Mtumbuka",
            "Thomas Lukasiewicz"
        ],
        "published": "2022",
        "summary": "The logical negation property (LNP), which implies generating different predictions for semantically opposite inputs (p is true iff ¬p is false), is an important property that a trustworthy language model must satisfy. However, much recent evidence shows that large-size pre-trained language models (PLMs) do not satisfy this property. In this paper, we perform experiments using probing tasks to assess PLMs’ LNP understanding. Unlike previous studies that only examined negation expressions, we expand the boundary of the investigation to lexical semantics. Through experiments, we observe that PLMs violate the LNP frequently. To alleviate the issue, we propose a novel intermediate training task, named meaning-matching, designed to directly learn a meaning text correspondence, instead of relying on the distributional hypothesis. Through multiple experiments, we find that the task enables PLMs to learn lexical semantic information. Also, through fine-tuning experiments on 7 GLUE tasks, we confirm that it is a safe intermediate task that guarantees a similar or better performance of downstream tasks. Finally, we observe that our proposed approach outperforms our previous counterparts despite its time and resource efficiency.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.156.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Learning to Execute Actions or Ask Clarification Questions",
        "authors": [
            "Zhengxiang Shi",
            "Yue Feng",
            "Aldo Lipani"
        ],
        "published": "2022",
        "summary": "Collaborative tasks are ubiquitous activities where a form of communication is required in order to reach a joint goal. Collaborative building is one of such tasks. We wish to develop an intelligent builder agent in a simulated building environment (Minecraft) that can build whatever users wish to build by just talking to the agent. In order to achieve this goal, such agents need to be able to take the initiative by asking clarification questions when further information is needed. Existing works on Minecraft Corpus Dataset only learn to execute instructions neglecting the importance of asking for clarifications. In this paper, we extend the Minecraft Corpus Dataset by annotating all builder utterances into eight types, including clarification questions, and propose a new builder agent model capable of determining when to ask or execute instructions. Experimental results show that our model achieves state-of-the-art performance on the collaborative building task with a substantial improvement. We also define two new tasks, the learning to ask task and the joint learning task. The latter consists of solving both collaborating building and learning to ask tasks jointly.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.158.pdf",
        "source": "naacl2022"
    },
    {
        "title": "CL-ReLKT: Cross-lingual Language Knowledge Transfer for Multilingual Retrieval Question Answering",
        "authors": [
            "Peerat Limkonchotiwat",
            "Wuttikorn Ponwitayarat",
            "Can Udomcharoenchaikit",
            "Ekapol Chuangsuwanich",
            "Sarana Nutanong"
        ],
        "published": "2022",
        "summary": "Cross-Lingual Retrieval Question Answering (CL-ReQA) is concerned with retrieving answer documents or passages to a question written in a different language. A common approach to CL-ReQA is to create a multilingual sentence embedding space such that question-answer pairs across different languages are close to each other. In this paper, we propose a novel CL-ReQA method utilizing the concept of language knowledge transfer and a new cross-lingual consistency training technique to create a multilingual embedding space for ReQA. To assess the effectiveness of our work, we conducted comprehensive experiments on CL-ReQA and a downstream task, machine reading QA. We compared our proposed method with the current state-of-the-art solutions across three public CL-ReQA corpora. Our method outperforms competitors in 19 out of 21 settings of CL-ReQA. When used with a downstream machine reading QA task, our method outperforms the best existing language-model-based method by 10% in F1 while being 10 times faster in sentence embedding computation. The code and models are available at https://github.com/mrpeerat/CL-ReLKT.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.165.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Specializing Pre-trained Language Models for Better Relational Reasoning via Network Pruning",
        "authors": [
            "Siyu Ren",
            "Kenny Zhu"
        ],
        "published": "2022",
        "summary": "Pretrained masked language models (PLMs) were shown to be inheriting a considerable amount of relational knowledge from the source corpora. In this paper, we present an in-depth and comprehensive study concerning specializing PLMs into relational models from the perspective of network pruning. We show that it is possible to find subnetworks capable of representing grounded commonsense relations at non-trivial sparsity while being more generalizable than original PLMs in scenarios requiring knowledge of single or multiple commonsense relations.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.169.pdf",
        "source": "naacl2022"
    },
    {
        "title": "A Dog Is Passing Over The Jet? A Text-Generation Dataset for Korean Commonsense Reasoning and Evaluation",
        "authors": [
            "Jaehyung Seo",
            "Seounghoon Lee",
            "Chanjun Park",
            "Yoonna Jang",
            "Hyeonseok Moon",
            "Sugyeong Eo",
            "Seonmin Koo",
            "Heuiseok Lim"
        ],
        "published": "2022",
        "summary": "Recent natural language understanding (NLU) research on the Korean language has been vigorously maturing with the advancements of pretrained language models and datasets. However, Korean pretrained language models still struggle to generate a short sentence with a given condition based on compositionality and commonsense reasoning (i.e., generative commonsense reasoning). The two major challenges are inadequate data resources to develop generative commonsense reasoning regarding Korean linguistic features and to evaluate language models which are necessary for natural language generation (NLG). To solve these problems, we propose a text-generation dataset for Korean generative commonsense reasoning and language model evaluation. In this work, a semi-automatic dataset construction approach filters out contents inexplicable to commonsense, ascertains quality, and reduces the cost of building the dataset. We also present an in-depth analysis of the generation results of language models with various evaluation metrics along with human-annotated scores. The whole dataset is publicly available at (https://aihub.or.kr/opendata/korea-university).",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.172.pdf",
        "source": "naacl2022"
    },
    {
        "title": "LiST: Lite Prompted Self-training Makes Parameter-efficient Few-shot Learners",
        "authors": [
            "Yaqing Wang",
            "Subhabrata Mukherjee",
            "Xiaodong Liu",
            "Jing Gao",
            "Ahmed Awadallah",
            "Jianfeng Gao"
        ],
        "published": "2022",
        "summary": "We present a new method LiST for efficient fine-tuning of large pre-trained language models (PLMs) in few-shot learning settings. LiST improves over recent methods that adopt prompt-based fine-tuning (FN) using two key techniques. The first is the use of self-training to leverage large amounts of unlabeled data for prompt-based FN in few-shot settings. We use self-training in conjunction with meta-learning for re-weighting noisy pseudo-prompt labels. Traditionally, self-training is expensive as it requires updating all the model parameters repetitively. Therefore, we use a second technique for light-weight fine-tuning where we introduce a small number of task-specific parameters that are fine-tuned during self-training while keeping the PLM encoder frozen. Our experiments show that LiST can effectively leverage unlabeled data to improve the model performance for few-shot learning. Additionally, the finetuning process is efficient as it only updates a small percentage of the parameters and the overall model footprint is reduced since several tasks can share a common PLM encoder as backbone. We present a comprehensive study on six NLU tasks to validate the effectiveness of LiST. The results show that LiST improves by 35% over classic fine-tuning methods and 6% over prompt-based FN with 96% reduction in number of trainable parameters when fine-tuned with no more than 30 labeled examples from each task. With only 14M tunable parameters, LiST outperforms GPT-3 in-context learning by 33% on few-shot NLU tasks",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.174.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Weakly Supervised Text Classification using Supervision Signals from a Language Model",
        "authors": [
            "Ziqian Zeng",
            "Weimin Ni",
            "Tianqing Fang",
            "Xiang Li",
            "Xinran Zhao",
            "Yangqiu Song"
        ],
        "published": "2022",
        "summary": "Solving text classification in a weakly supervised manner is important for real-world applications where human annotations are scarce. In this paper, we propose to query a masked language model with cloze style prompts to obtain supervision signals. We design a prompt which combines the document itself and “this article is talking about [MASK].” A masked language model can generate words for the [MASK] token. The generated words which summarize the content of a document can be utilized as supervision signals. We propose a latent variable model to learn a word distribution learner which associates generated words to pre-defined categories and a document classifier simultaneously without using any annotated data. Evaluation on three datasets, AGNews, 20Newsgroups, and UCINews, shows that our method can outperform baselines by 2%, 4%, and 3%.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.176.pdf",
        "source": "naacl2022"
    },
    {
        "title": "Context-Aware Language Modeling for Goal-Oriented Dialogue Systems",
        "authors": [
            "Charlie Snell",
            "Sherry Yang",
            "Justin Fu",
            "Yi Su",
            "Sergey Levine"
        ],
        "published": "2022",
        "summary": "Goal-oriented dialogue systems face a trade-off between fluent language generation and task-specific control. While supervised learning with large language models is capable of producing realistic text, how to steer such responses towards completing a specific task without sacrificing language quality remains an open question. In this work, we formulate goal-oriented dialogue as a partially observed Markov decision process, interpreting the language model as a representation of both the dynamics and the policy. This view allows us to extend techniques from learning-based control, such as task relabeling, to derive a simple and effective method to finetune language models in a goal-aware way, leading to significantly improved task performance. We additionally introduce a number of training strategies that serve to better focus the model on the task at hand. We evaluate our method, Context-Aware Language Models (CALM), on a practical flight-booking task using AirDialogue. Empirically, CALM outperforms the state-of-the-art method by 7% in terms of task success, matching human-level task performance.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.181.pdf",
        "source": "naacl2022"
    },
    {
        "title": "CCQA: A New Web-Scale Question Answering Dataset for Model Pre-Training",
        "authors": [
            "Patrick Huber",
            "Armen Aghajanyan",
            "Barlas Oguz",
            "Dmytro Okhonko",
            "Scott Yih",
            "Sonal Gupta",
            "Xilun Chen"
        ],
        "published": "2022",
        "summary": "We propose a novel open-domain question-answering dataset based on the Common Crawl project. With a previously unseen number of around 130 million multilingual question-answer pairs (including about 60 million English data-points), we use our large-scale, natural, diverse and high-quality corpus to in-domain pre-train popular language models for the task of question-answering. In our experiments, we find that our Common Crawl Question Answering dataset (CCQA) achieves promising results in zero-shot, low resource and fine-tuned settings across multiple tasks, models and benchmarks.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.184.pdf",
        "source": "naacl2022"
    },
    {
        "title": "TaCL: Improving BERT Pre-training with Token-aware Contrastive Learning",
        "authors": [
            "Yixuan Su",
            "Fangyu Liu",
            "Zaiqiao Meng",
            "Tian Lan",
            "Lei Shu",
            "Ehsan Shareghi",
            "Nigel Collier"
        ],
        "published": "2022",
        "summary": "Masked language models (MLMs) such as BERT have revolutionized the field of Natural Language Understanding in the past few years. However, existing pre-trained MLMs often output an anisotropic distribution of token representations that occupies a narrow subset of the entire representation space. Such token representations are not ideal, especially for tasks that demand discriminative semantic meanings of distinct tokens. In this work, we propose TaCL (Token-aware Contrastive Learning), a novel continual pre-training approach that encourages BERT to learn an isotropic and discriminative distribution of token representations. TaCL is fully unsupervised and requires no additional data. We extensively test our approach on a wide range of English and Chinese benchmarks. The results show that TaCL brings consistent and notable improvements over the original BERT model. Furthermore, we conduct detailed analysis to reveal the merits and inner-workings of our approach.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.191.pdf",
        "source": "naacl2022"
    },
    {
        "title": "DialoKG: Knowledge-Structure Aware Task-Oriented Dialogue Generation",
        "authors": [
            "Md Rashad Al Hasan Rony",
            "Ricardo Usbeck",
            "Jens Lehmann"
        ],
        "published": "2022",
        "summary": "Task-oriented dialogue generation is challenging since the underlying knowledge is often dynamic and effectively incorporating knowledge into the learning process is hard. It is particularly challenging to generate both human-like and informative responses in this setting. Recent research primarily focused on various knowledge distillation methods where the underlying relationship between the facts in a knowledge base is not effectively captured. In this paper, we go one step further and demonstrate how the structural information of a knowledge graph can improve the system’s inference capabilities. Specifically, we propose DialoKG, a novel task-oriented dialogue system that effectively incorporates knowledge into a language model. Our proposed system views relational knowledge as a knowledge graph and introduces (1) a structure-aware knowledge embedding technique, and (2) a knowledge graph-weighted attention masking strategy to facilitate the system selecting relevant information during the dialogue generation. An empirical evaluation demonstrates the effectiveness of DialoKG over state-of-the-art methods on several standard benchmark datasets.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.195.pdf",
        "source": "naacl2022"
    },
    {
        "title": "KETOD: Knowledge-Enriched Task-Oriented Dialogue",
        "authors": [
            "Zhiyu Chen",
            "Bing Liu",
            "Seungwhan Moon",
            "Chinnadhurai Sankar",
            "Paul Crook",
            "William Yang Wang"
        ],
        "published": "2022",
        "summary": "Existing studies in dialogue system research mostly treat task-oriented dialogue and chit-chat as separate domains. Towards building a human-like assistant that can converse naturally and seamlessly with users, it is important to build a dialogue system that conducts both types of conversations effectively. In this work, we investigate how task-oriented dialogue and knowledge-grounded chit-chat can be effectively integrated into a single model. To this end, we create a new dataset, KETOD (Knowledge-Enriched Task-Oriented Dialogue), where we naturally enrich task-oriented dialogues with chit-chat based on relevant entity knowledge. We also propose two new models, SimpleToDPlus and Combiner, for the proposed task. Experimental results on both automatic and human evaluations show that the proposed methods can significantly improve the performance in knowledge-enriched response generation while maintaining a competitive task-oriented dialog performance. We believe our new dataset will be a valuable resource for future studies. Our dataset and code are publicly available at https://github.com/facebookresearch/ketod.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.197.pdf",
        "source": "naacl2022"
    },
    {
        "title": "TANet: Thread-Aware Pretraining for Abstractive Conversational Summarization",
        "authors": [
            "Ze Yang",
            "Christian Wang",
            "Zhoujin Tian",
            "Wei Wu",
            "Zhoujun Li"
        ],
        "published": "2022",
        "summary": "Although pre-trained language models (PLMs) have achieved great success and become a milestone in NLP, abstractive conversational summarization remains a challenging but less studied task. The difficulty lies in two aspects. One is the lack of large-scale conversational summary data. Another is that applying the existing pre-trained models to this task is tricky because of the structural dependence within the conversation and its informal expression, etc. In this work, we first build a large-scale (11M) pretraining dataset called RCSum, based on the multi-person discussions in the Reddit community. We then present TANet, a thread-aware Transformer-based network. Unlike the existing pre-trained models that treat a conversation as a sequence of sentences, we argue that the inherent contextual dependency among the utterances plays an essential role in understanding the entire conversation and thus propose two new techniques to incorporate the structural information into our model. The first is thread-aware attention which is computed by taking into account the contextual dependency within utterances. Second, we apply thread prediction loss to predict the relations between utterances. We evaluate our model on four datasets of real conversations, covering types of meeting transcripts, customer-service records, and forum threads. Experimental results demonstrate that TANet achieves a new state-of-the-art in terms of both automatic evaluation and human judgment.",
        "pdf_link": "https://aclanthology.org/2022.findings-naacl.198.pdf",
        "source": "naacl2022"
    }
]