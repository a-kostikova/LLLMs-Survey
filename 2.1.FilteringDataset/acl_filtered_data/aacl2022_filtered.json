[
    {
        "title": "Double Trouble: How to not Explain a Text Classifier’s Decisions Using Counterfactuals Synthesized by Masked Language Models?",
        "authors": [
            "Thang Pham",
            "Trung Bui",
            "Long Mai",
            "Anh Nguyen"
        ],
        "published": "2022",
        "summary": "A principle behind dozens of attribution methods is to take the prediction difference between before-and-after an input feature (here, a token) is removed as its attribution. A popular Input Marginalization (IM) method (Kim et al., 2020) uses BERT to replace a token, yielding more plausible counterfactuals. While Kim et al., 2020 reported that IM is effective, we find this conclusion not convincing as the Deletion-BERT metric used in their paper is biased towards IM. Importantly, this bias exists in Deletion-based metrics, including Insertion, Sufficiency, and Comprehensiveness. Furthermore, our rigorous evaluation using 6 metrics and 3 datasets finds no evidence that IM is better than a Leave-One-Out (LOO) baseline. We find two reasons why IM is not better than LOO: (1) deleting a single word from the input only marginally reduces a classifier’s accuracy; and (2) a highly predictable word is always given near-zero attribution, regardless of its true importance to the classifier. In contrast, making LIME samples more natural via BERT consistently improves LIME accuracy under several ROAR metrics.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.2.pdf"
    },
    {
        "title": "WAX: A New Dataset for Word Association eXplanations",
        "authors": [
            "Chunhua Liu",
            "Trevor Cohn",
            "Simon De Deyne",
            "Lea Frermann"
        ],
        "published": "2022",
        "summary": "Word associations are among the most common paradigms to study the human mental lexicon. While their structure and types of associations have been well studied, surprisingly little attention has been given to the question of why participants produce the observed associations. Answering this question would not only advance understanding of human cognition, but could also aid machines in learning and representing basic commonsense knowledge. This paper introduces a large, crowd-sourced data set of English word associations with explanations, labeled with high-level relation types. We present an analysis of the provided explanations, and design several tasks to probe to what extent current pre-trained language models capture the underlying relations. Our experiments show that models struggle to capture the diversity of human associations, suggesting WAX is a rich benchmark for commonsense modeling and generation.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.9.pdf"
    },
    {
        "title": "Cross-lingual Similarity of Multilingual Representations Revisited",
        "authors": [
            "Maksym Del",
            "Mark Fishel"
        ],
        "published": "2022",
        "summary": "Related works used indexes like CKA and variants of CCA to measure the similarity of cross-lingual representations in multilingual language models. In this paper, we argue that assumptions of CKA/CCA align poorly with one of the motivating goals of cross-lingual learning analysis, i.e., explaining zero-shot cross-lingual transfer. We highlight what valuable aspects of cross-lingual similarity these indexes fail to capture and provide a motivating case study demonstrating the problem empirically. Then, we introduce Average Neuron-Wise Correlation (ANC) as a straightforward alternative that is exempt from the difficulties of CKA/CCA and is good specifically in a cross-lingual context. Finally, we use ANC to construct evidence that the previously introduced “first align, then predict” pattern takes place not only in masked language models (MLMs) but also in multilingual models with causal language modeling objectives (CLMs). Moreover, we show that the pattern extends to the scaled versions of the MLMs and CLMs (up to 85x original mBERT). Our code is publicly available at https://github.com/TartuNLP/xsim",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.15.pdf"
    },
    {
        "title": "Semantic Shift Stability: Efficient Way to Detect Performance Degradation of Word Embeddings and Pre-trained Language Models",
        "authors": [
            "Shotaro Ishihara",
            "Hiromu Takahashi",
            "Hono Shirai"
        ],
        "published": "2022",
        "summary": "Word embeddings and pre-trained language models have become essential technical elements in natural language processing. While the general practice is to use or fine-tune publicly available models, there are significant advantages in creating or pre-training unique models that match the domain. The performance of the models degrades as language changes or evolves continuously, but the high cost of model building inhibits regular re-training, especially for the language models. This study proposes an efficient way to detect time-series performance degradation of word embeddings and pre-trained language models by calculating the degree of semantic shift. Monitoring performance through the proposed method supports decision-making as to whether a model should be re-trained. The experiments demonstrated that the proposed method can identify time-series performance degradation in two datasets, Japanese and English. The source code is available at https://github.com/Nikkei/semantic-shift-stability.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.17.pdf"
    },
    {
        "title": "Neural Text Sanitization with Explicit Measures of Privacy Risk",
        "authors": [
            "Anthi Papadopoulou",
            "Yunhao Yu",
            "Pierre Lison",
            "Lilja Øvrelid"
        ],
        "published": "2022",
        "summary": "We present a novel approach for text sanitization, which is the task of editing a document to mask all (direct and indirect) personal identifiers and thereby conceal the identity of the individuals(s) mentioned in the text. In contrast to previous work, the approach relies on explicit measures of privacy risk, making it possible to explicitly control the trade-off between privacy protection and data utility. The approach proceeds in three steps. A neural, privacy-enhanced entity recognizer is first employed to detect and classify potential personal identifiers. We then determine which entities, or combination of entities, are likely to pose a re-identification risk through a range of privacy risk assessment measures. We present three such measures of privacy risk, respectively based on (1) span probabilities derived from a BERT language model, (2) web search queries and (3) a classifier trained on labelled data. Finally, a linear optimization solver decides which entities to mask to minimize the semantic loss while simultaneously ensuring that the estimated privacy risk remains under a given threshold. We evaluate the approach both in the absence and presence of manually annotated data. Our results highlight the potential of the approach, as well as issues specific types of personal data can introduce to the process.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.18.pdf"
    },
    {
        "title": "Who did what to Whom? Language models and humans respond diversely to features affecting argument hierarchy construction",
        "authors": [
            "Xiaonan Xu",
            "Haoshuo Chen"
        ],
        "published": "2022",
        "summary": "Pre-trained transformer-based language models have achieved state-of-the-art performance in many areas of NLP. It is still an open question whether the models are capable of integrating syntax and semantics in language processing like humans. This paper investigates if models and humans construct argument hierarchy similarly with the effects from telicity, agency, and individuation, using the Chinese structure “NP1+BA/BEI+NP2+VP”. We present both humans and six transformer-based models with prepared sentences and analyze their preference between BA (view NP1 as an agent) and BEI (NP2 as an agent). It is found that the models and humans respond to (non-)agentive features in telic context and atelic feature very similarly. However, the models show insufficient sensitivity to both pragmatic function in expressing undesirable events and different individuation degrees represented by human common nouns vs. proper names. By contrast, humans rely heavily on these cues to establish the thematic relation between two arguments NP1 and NP2. Furthermore, the models tend to interpret the subject as an agent, which is not the case for humans who align agents independently of subject position in Mandarin Chinese.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.21.pdf"
    },
    {
        "title": "Named Entity Recognition in Twitter: A Dataset and Analysis on Short-Term Temporal Shifts",
        "authors": [
            "Asahi Ushio",
            "Francesco Barbieri",
            "Vitor Sousa",
            "Leonardo Neves",
            "Jose Camacho-Collados"
        ],
        "published": "2022",
        "summary": "Recent progress in language model pre-training has led to important improvements in Named Entity Recognition (NER). Nonetheless, this progress has been mainly tested in well-formatted documents such as news, Wikipedia, or scientific articles. In social media the landscape is different, in which it adds another layer of complexity due to its noisy and dynamic nature. In this paper, we focus on NER in Twitter, one of the largest social media platforms, and construct a new NER dataset, TweetNER7, which contains seven entity types annotated over 11,382 tweets from September 2019 to August 2021. The dataset was constructed by carefully distributing the tweets over time and taking representative trends as a basis. Along with the dataset, we provide a set of language model baselines and perform an analysis on the language model performance on the task, especially analyzing the impact of different time periods. In particular, we focus on three important temporal aspects in our analysis: short-term degradation of NER models over time, strategies to fine-tune a language model over different periods, and self-labeling as an alternative to lack of recently-labeled data. TweetNER7 is released publicly (https://huggingface.co/datasets/tner/tweetner7) along with the models fine-tuned on it (NER models have been integrated into TweetNLP and can be found at https://github.com/asahi417/tner/tree/master/examples/tweetner7_paper).",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.25.pdf"
    },
    {
        "title": "PInKS: Preconditioned Commonsense Inference with Minimal Supervision",
        "authors": [
            "Ehsan Qasemi",
            "Piyush Khanna",
            "Qiang Ning",
            "Muhao Chen"
        ],
        "published": "2022",
        "summary": "Reasoning with preconditions such as “glass can be used for drinking water unless the glass is shattered” remains an open problem for language models. The main challenge lies in the scarcity of preconditions data and the model’s lack of support for such reasoning. We present PInKS , Preconditioned Commonsense Inference with WeaK Supervision, an improved model for reasoning with preconditions through minimum supervision. We show, empirically and theoretically, that PInKS improves the results on benchmarks focused on reasoning with the preconditions of commonsense knowledge (up to 40% Macro-F1 scores). We further investigate PInKS through PAC-Bayesian informativeness analysis, precision measures, and ablation study.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.26.pdf"
    },
    {
        "title": "RecInDial: A Unified Framework for Conversational Recommendation with Pretrained Language Models",
        "authors": [
            "Lingzhi Wang",
            "Huang Hu",
            "Lei Sha",
            "Can Xu",
            "Daxin Jiang",
            "Kam-Fai Wong"
        ],
        "published": "2022",
        "summary": "Conversational Recommender System (CRS), which aims to recommend high-quality items to users through interactive conversations, has gained great research interest recently. A CRS is usually composed of a recommendation module and a generation module. In the previous work, these two modules are loosely connected in the model training and are shallowly integrated during inference, where a simple switching or copy mechanism is adopted to incorporate recommended items into generated responses. Moreover, the current end-to-end neural models trained on small crowd-sourcing datasets (e.g., 10K dialogs in the ReDial dataset) tend to overfit and have poor chit-chat ability. In this work, we propose a novel unified framework that integrates recommendation into the dialog (RecInDial) generation by introducing a vocabulary pointer. To tackle the low-resource issue in CRS, we finetune the large-scale pretrained language models to generate fluent and diverse responses, and introduce a knowledge-aware bias learned from an entity-oriented knowledge graph to enhance the recommendation performance. Furthermore, we propose to evaluate the CRS models in an end-to-end manner, which can reflect the overall performance of the entire system rather than the performance of individual modules, compared to the separate evaluations of the two modules used in previous work. Experiments on the benchmark dataset ReDial show our RecInDial model significantly surpasses the state-of-the-art methods. More extensive analyses show the effectiveness of our model.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.37.pdf"
    },
    {
        "title": "Director: Generator-Classifiers For Supervised Language Modeling",
        "authors": [
            "Kushal Arora",
            "Kurt Shuster",
            "Sainbayar Sukhbaatar",
            "Jason Weston"
        ],
        "published": "2022",
        "summary": "Current language models achieve low perplexity but their resulting generations still suffer from toxic responses, repetitiveness, and contradictions. The standard language modeling setup fails to address these issues. In this paper, we introduce a new architecture, Director, that consists of a unified generator-classifier with both a language modeling and a classification head for each output token. Training is conducted jointly using both standard language modeling data, and data labeled with desirable and undesirable sequences. Experiments in several settings show that the model has competitive training and decoding speed compared to standard language models while yielding superior results, avoiding undesirable behaviors while maintaining generation quality. It also outperforms existing model guiding approaches in terms of both accuracy and efficiency. Our code is made publicly available.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.39.pdf"
    },
    {
        "title": "VLStereoSet: A Study of Stereotypical Bias in Pre-trained Vision-Language Models",
        "authors": [
            "Kankan Zhou",
            "Eason Lai",
            "Jing Jiang"
        ],
        "published": "2022",
        "summary": "In this paper we study how to measure stereotypical bias in pre-trained vision-language models. We leverage a recently released text-only dataset, StereoSet, which covers a wide range of stereotypical bias, and extend it into a vision-language probing dataset called VLStereoSet to measure stereotypical bias in vision-language models. We analyze the differences between text and image and propose a probing task that detects bias by evaluating a model’s tendency to pick stereotypical statements as captions for anti-stereotypical images. We further define several metrics to measure both a vision-language model’s overall stereotypical bias and its intra-modal and inter-modal bias. Experiments on six representative pre-trained vision-language models demonstrate that stereotypical biases clearly exist in most of these models and across all four bias categories, with gender bias slightly more evident. Further analysis using gender bias data and two vision-language models also suggest that both intra-modal and inter-modal bias exist.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.40.pdf"
    },
    {
        "title": "Dynamic Context Extraction for Citation Classification",
        "authors": [
            "Suchetha Nambanoor Kunnath",
            "David Pride",
            "Petr Knoth"
        ],
        "published": "2022",
        "summary": "We investigate the effect of varying citation context window sizes on model performance in citation intent classification. Prior studies have been limited to the application of fixed-size contiguous citation contexts or the use of manually curated citation contexts. We introduce a new automated unsupervised approach for the selection of a dynamic-size and potentially non-contiguous citation context, which utilises the transformer-based document representations and embedding similarities. Our experiments show that the addition of non-contiguous citing sentences improves performance beyond previous results. Evalu- ating on the (1) domain-specific (ACL-ARC) and (2) the multi-disciplinary (SDP-ACT) dataset demonstrates that the inclusion of additional context beyond the citing sentence significantly improves the citation classifi- cation model’s performance, irrespective of the dataset’s domain. We release the datasets and the source code used for the experiments at: https://github.com/oacore/dynamic_citation_context",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.41.pdf"
    },
    {
        "title": "Is Encoder-Decoder Redundant for Neural Machine Translation?",
        "authors": [
            "Yingbo Gao",
            "Christian Herold",
            "Zijian Yang",
            "Hermann Ney"
        ],
        "published": "2022",
        "summary": "Encoder-decoder architecture is widely adopted for sequence-to-sequence modeling tasks. For machine translation, despite the evolution from long short-term memory networks to Transformer networks, plus the introduction and development of attention mechanism, encoder-decoder is still the de facto neural network architecture for state-of-the-art models. While the motivation for decoding information from some hidden space is straightforward, the strict separation of the encoding and decoding steps into an encoder and a decoder in the model architecture is not necessarily a must. Compared to the task of autoregressive language modeling in the target language, machine translation simply has an additional source sentence as context. Given the fact that neural language models nowadays can already handle rather long contexts in the target language, it is natural to ask whether simply concatenating the source and target sentences and training a language model to do translation would work. In this work, we investigate the aforementioned concept for machine translation. Specifically, we experiment with bilingual translation, translation with additional target monolingual data, and multilingual translation. In all cases, this alternative approach performs on par with the baseline encoder-decoder Transformer, suggesting that an encoder-decoder architecture might be redundant for neural machine translation.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.43.pdf"
    },
    {
        "title": "SBERT studies Meaning Representations: Decomposing Sentence Embeddings into Explainable Semantic Features",
        "authors": [
            "Juri Opitz",
            "Anette Frank"
        ],
        "published": "2022",
        "summary": "Models based on large-pretrained language models, such as S(entence)BERT, provide effective and efficient sentence embeddings that show high correlation to human similarity ratings, but lack interpretability. On the other hand, graph metrics for graph-based meaning representations (e.g., Abstract Meaning Representation, AMR) can make explicit the semantic aspects in which two sentences are similar. However, such metrics tend to be slow, rely on parsers, and do not reach state-of-the-art performance when rating sentence similarity. In this work, we aim at the best of both worlds, by learning to induce Semantically Structured Sentence BERT embeddings (S3BERT). Our S3BERT embeddings are composed of explainable sub-embeddings that emphasize various sentence meaning features (e.g., semantic roles, negation, or quantification). We show how to i) learn a decomposition of the sentence embeddings into meaning features, through approximation of a suite of interpretable semantic AMR graph metrics, and how to ii) preserve the overall power of the neural embeddings by controlling the decomposition learning process with a second objective that enforces consistency with the similarity ratings of an SBERT teacher model. In our experimental studies, we show that our approach offers interpretability – while preserving the effectiveness and efficiency of the neural sentence embeddings.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.48.pdf"
    },
    {
        "title": "Food Knowledge Representation Learning with Adversarial Substitution",
        "authors": [
            "Diya Li",
            "Mohammed J Zaki"
        ],
        "published": "2022",
        "summary": "Knowledge graph embedding (KGE) has been well-studied in general domains, but has not been examined for food computing. To fill this gap, we perform knowledge representation learning over a food knowledge graph (KG). We employ a pre-trained language model to encode entities and relations, thus emphasizing contextual information in food KGs. The model is trained on two tasks – predicting a masked entity from a given triple from the KG and predicting the plausibility of a triple. Analysis of food substitutions helps in dietary choices for enabling healthier eating behaviors. Previous work in food substitutions mainly focuses on semantic similarity while ignoring the context. It is also hard to evaluate the substitutions due to the lack of an adequate validation set, and further, the evaluation is subjective based on perceived purpose. To tackle this problem, we propose a collection of adversarial sample generation strategies for different food substitutions over our learnt KGE. We propose multiple strategies to generate high quality context-aware recipe and ingredient substitutions and also provide generalized ingredient substitutions to meet different user needs. The effectiveness and efficiency of the proposed knowledge graph learning method and the following attack strategies are verified by extensive evaluations on a large-scale food KG.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.50.pdf"
    },
    {
        "title": "Construction Repetition Reduces Information Rate in Dialogue",
        "authors": [
            "Mario Giulianelli",
            "Arabella Sinclair",
            "Raquel Fernández"
        ],
        "published": "2022",
        "summary": "Speakers repeat constructions frequently in dialogue. Due to their peculiar information-theoretic properties, repetitions can be thought of as a strategy for cost-effective communication. In this study, we focus on the repetition of lexicalised constructions—i.e., recurring multi-word units—in English open-domain spoken dialogues. We hypothesise that speakers use construction repetition to mitigate information rate, leading to an overall decrease in utterance information content over the course of a dialogue. We conduct a quantitative analysis, measuring the information content of constructions and that of their containing utterances, estimating information content with an adaptive neural language model. We observe that construction usage lowers the information content of utterances. This facilitating effect (i) increases throughout dialogues, (ii) is boosted by repetition, (iii) grows as a function of repetition frequency and density, and (iv) is stronger for repetitions of referential constructions.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.51.pdf"
    },
    {
        "title": "Contrastive Video-Language Learning with Fine-grained Frame Sampling",
        "authors": [
            "Zixu Wang",
            "Yujie Zhong",
            "Yishu Miao",
            "Lin Ma",
            "Lucia Specia"
        ],
        "published": "2022",
        "summary": "Despite recent progress in video and language representation learning, the weak or sparse correspondence between the two modalities remains a bottleneck in the area. Most video-language models are trained via pair-level loss to predict whether a pair of video and text is aligned. However, even in paired video-text segments, only a subset of the frames are semantically relevant to the corresponding text, with the remainder representing noise; where the ratio of noisy frames is higher for longer videos. We propose FineCo (Fine-grained Contrastive Loss for Frame Sampling), an approach to better learn video and language representations with a fine-grained contrastive objective operating on video frames. It helps distil a video by selecting the frames that are semantically equivalent to the text, improving cross-modal correspondence. Building on the well established VideoCLIP model as a starting point, FineCo achieves state-of-the-art performance on YouCookII, a text-video retrieval benchmark with long videos. FineCo also achieves competitive results on text-video retrieval (MSR-VTT), and video question answering datasets (MSR-VTT QA and MSR-VTT MC) with shorter videos.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.53.pdf"
    },
    {
        "title": "Enhancing Tabular Reasoning with Pattern Exploiting Training",
        "authors": [
            "Abhilash Shankarampeta",
            "Vivek Gupta",
            "Shuo Zhang"
        ],
        "published": "2022",
        "summary": "Recent methods based on pre-trained language models have exhibited superior performance over tabular tasks (e.g., tabular NLI), despite showing inherent problems such as not using the right evidence and inconsistent predictions across inputs while reasoning over the tabular data (Gupta et al., 2021). In this work, we utilize Pattern-Exploiting Training (PET) (i.e., strategic MLM) on pre-trained language models to strengthen these tabular reasoning models’ pre-existing knowledge and reasoning abilities. Our upgraded model exhibits a superior understanding of knowledge facts and tabular reasoning compared to current baselines. Additionally, we demonstrate that such models are more effective for underlying downstream tasks of tabular inference on INFOTABS. Furthermore, we show our model’s robustness against adversarial sets generated through various character and word level perturbations.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.54.pdf"
    },
    {
        "title": "Unsupervised Domain Adaptation for Sparse Retrieval by Filling Vocabulary and Word Frequency Gaps",
        "authors": [
            "Hiroki Iida",
            "Naoaki Okazaki"
        ],
        "published": "2022",
        "summary": "IR models using a pretrained language model significantly outperform lexical approaches like BM25. In particular, SPLADE, which encodes texts to sparse vectors, is an effective model for practical use because it shows robustness to out-of-domain datasets. However, SPLADE still struggles with exact matching of low-frequency words in training data. In addition, domain shifts in vocabulary and word frequencies deteriorate the IR performance of SPLADE. Because supervision data are scarce in the target domain, addressing the domain shifts without supervision data is necessary. This paper proposes an unsupervised domain adaptation method by filling vocabulary and word-frequency gaps. First, we expand a vocabulary and execute continual pretraining with a masked language model on a corpus of the target domain. Then, we multiply SPLADE-encoded sparse vectors by inverse document frequency weights to consider the importance of documents with low-frequency words. We conducted experiments using our method on datasets with a large vocabulary gap from a source domain. We show that our method outperforms the present state-of-the-art domain adaptation method. In addition, our method achieves state-of-the-art results, combined with BM25.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.57.pdf"
    },
    {
        "title": "KESA: A Knowledge Enhanced Approach To Sentiment Analysis",
        "authors": [
            "Qinghua Zhao",
            "Shuai Ma",
            "Shuo Ren"
        ],
        "published": "2022",
        "summary": "Though some recent works focus on injecting sentiment knowledge into pre-trained language models, they usually design mask and reconstruction tasks in the post-training phase. This paper aims to integrate sentiment knowledge in the fine-tuning stage. To achieve this goal, we propose two sentiment-aware auxiliary tasks named sentiment word selection and conditional sentiment prediction and, correspondingly, integrate them into the objective of the downstream task. The first task learns to select the correct sentiment words from the given options. The second task predicts the overall sentiment polarity, with the sentiment polarity of the word given as prior knowledge. In addition, two label combination methods are investigated to unify multiple types of labels in each auxiliary task. Experimental results demonstrate that our approach consistently outperforms baselines (achieving a new state-of-the-art) and is complementary to existing sentiment-enhanced post-trained models.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.58.pdf"
    },
    {
        "title": "Cross-lingual Few-Shot Learning on Unseen Languages",
        "authors": [
            "Genta Winata",
            "Shijie Wu",
            "Mayank Kulkarni",
            "Thamar Solorio",
            "Daniel Preotiuc-Pietro"
        ],
        "published": "2022",
        "summary": "Large pre-trained language models (LMs) have demonstrated the ability to obtain good performance on downstream tasks with limited examples in cross-lingual settings. However, this was mostly studied for relatively resource-rich languages, where at least enough unlabeled data is available to be included in pre-training a multilingual language model. In this paper, we explore the problem of cross-lingual transfer in unseen languages, where no unlabeled data is available for pre-training a model. We use a downstream sentiment analysis task across 12 languages, including 8 unseen languages, to analyze the effectiveness of several few-shot learning strategies across the three major types of model architectures and their learning dynamics. We also compare strategies for selecting languages for transfer and contrast findings across languages seen in pre-training compared to those that are not. Our findings contribute to the body of knowledge on cross-lingual models for low-resource settings that is paramount to increasing coverage, diversity, and equity in access to NLP technology. We show that, in few-shot learning, linguistically similar and geographically similar languages are useful for cross-lingual adaptation, but taking the context from a mixture of random source languages is surprisingly more effective. We also compare different model architectures and show that the encoder-only model, XLM-R, gives the best downstream task performance.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.59.pdf"
    },
    {
        "title": "A Prompt Array Keeps the Bias Away: Debiasing Vision-Language Models with Adversarial Learning",
        "authors": [
            "Hugo Berg",
            "Siobhan Hall",
            "Yash Bhalgat",
            "Hannah Kirk",
            "Aleksandar Shtedritski",
            "Max Bain"
        ],
        "published": "2022",
        "summary": "Vision-language models can encode societal biases and stereotypes, but there are challenges to measuring and mitigating these multimodal harms due to lacking measurement robustness and feature degradation. To address these challenges, we investigate bias measures and apply ranking metrics for image-text representations. We then investigate debiasing methods and show that prepending learned embeddings to text queries that are jointly trained with adversarial debiasing and a contrastive loss, reduces various bias measures with minimal degradation to the image-text representation.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.61.pdf"
    },
    {
        "title": "Delivering Fairness in Human Resources AI: Mutual Information to the Rescue",
        "authors": [
            "Leo Hemamou",
            "William Coleman"
        ],
        "published": "2022",
        "summary": "Automatic language processing is used frequently in the Human Resources (HR) sector for automated candidate sourcing and evaluation of resumes. These models often use pre-trained language models where it is difficult to know if possible biases exist. Recently, Mutual Information (MI) methods have demonstrated notable performance in obtaining representations agnostic to sensitive variables such as gender or ethnicity. However, accessing these variables can sometimes be challenging, and their use is prohibited in some jurisdictions. These factors can make detecting and mitigating biases challenging. In this context, we propose to minimize the MI between a candidate’s name and a latent representation of their CV or short biography. This method may mitigate bias from sensitive variables without requiring the collection of these variables. We evaluate this methodology by first projecting the name representation into a smaller space to prevent potential MI minimization problems in high dimensions.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.64.pdf"
    },
    {
        "title": "Not another Negation Benchmark: The NaN-NLI Test Suite for Sub-clausal Negation",
        "authors": [
            "Thinh Hung Truong",
            "Yulia Otmakhova",
            "Timothy Baldwin",
            "Trevor Cohn",
            "Jey Han Lau",
            "Karin Verspoor"
        ],
        "published": "2022",
        "summary": "Negation is poorly captured by current language models, although the extent of this problem is not widely understood. We introduce a natural language inference (NLI) test suite to enable probing the capabilities of NLP methods, with the aim of understanding sub-clausal negation. The test suite contains premise–hypothesis pairs where the premise contains sub-clausal negation and the hypothesis is constructed by making minimal modifications to the premise in order to reflect different possible interpretations. Aside from adopting standard NLI labels, our test suite is systematically constructed under a rigorous linguistic framework. It includes annotation of negation types and constructions grounded in linguistic theory, as well as the operations used to construct hypotheses. This facilitates fine-grained analysis of model performance. We conduct experiments using pre-trained language models to demonstrate that our test suite is more challenging than existing benchmarks focused on negation, and show how our annotation supports a deeper understanding of the current NLI capabilities in terms of negation and quantification.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.65.pdf"
    },
    {
        "title": "HaRiM+: Evaluating Summary Quality with Hallucination Risk",
        "authors": [
            "Seonil (Simon) Son",
            "Junsoo Park",
            "Jeong-in Hwang",
            "Junghwa Lee",
            "Hyungjong Noh",
            "Yeonsoo Lee"
        ],
        "published": "2022",
        "summary": "One of the challenges of developing a summarization model arises from the difficulty in measuring the factual inconsistency of the generated text. In this study, we reinterpret the decoder overconfidence-regularizing objective suggested in (Miao et al., 2021) as a hallucination risk measurement to better estimate the quality of generated summaries. We propose a reference-free metric, HaRiM+, which only requires an off-the-shelf summarization model to compute the hallucination risk based on token likelihoods. Deploying it requires no additional training of models or ad-hoc modules, which usually need alignment to human judgments. For summary-quality estimation, HaRiM+ records state-of-the-art correlation to human judgment on three summary-quality annotation sets: FRANK, QAGS, and SummEval. We hope that our work, which merits the use of summarization models, facilitates the progress of both automated evaluation and generation of summary.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.66.pdf"
    },
    {
        "title": "Dual Mechanism Priming Effects in Hindi Word Order",
        "authors": [
            "Sidharth Ranjan",
            "Marten van Schijndel",
            "Sumeet Agarwal",
            "Rajakrishnan Rajkumar"
        ],
        "published": "2022",
        "summary": "Word order choices during sentence production can be primed by preceding sentences. In this work, we test the DUAL MECHANISM hypothesis that priming is driven by multiple different sources. Using a Hindi corpus of text productions, we model lexical priming with an n-gram cache model, and we capture more abstract syntactic priming with an adaptive neural language model. We permute the preverbal constituents of corpus sentences and then use a logistic regression model to predict which sentences actually occurred in the corpus against artificially generated meaning-equivalent variants. Our results indicate that lexical priming and lexically-independent syntactic priming affect complementary sets of verb classes. By showing that different priming influences are separable from one another, our results support the hypothesis that multiple different cognitive mechanisms underlie priming.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.68.pdf"
    },
    {
        "title": "Enhancing Financial Table and Text Question Answering with Tabular Graph and Numerical Reasoning",
        "authors": [
            "Rungsiman Nararatwong",
            "Natthawut Kertkeidkachorn",
            "Ryutaro Ichise"
        ],
        "published": "2022",
        "summary": "Typical financial documents consist of tables, texts, and numbers. Given sufficient training data, large language models (LM) can learn the tabular structures and perform numerical reasoning well in question answering (QA). However, their performances fall significantly when data and computational resources are limited. This study improves this performance drop by infusing explicit tabular structures through a graph neural network (GNN). We proposed a model developed from the baseline of a financial QA dataset named TAT-QA. The baseline model, TagOp, consists of answer span (evidence) extraction and numerical reasoning modules. As our main contributions, we introduced two components to the model: a GNN-based evidence extraction module for tables and an improved numerical reasoning module. The latter provides a solution to TagOp’s arithmetic calculation problem specific to operations requiring number ordering, such as subtraction and division, which account for a large portion of numerical reasoning. Our evaluation shows that the graph module has the advantage in low-resource settings, while the improved numerical reasoning significantly outperforms the baseline model.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.72.pdf"
    },
    {
        "title": "Persona or Context? Towards Building Context adaptive Personalized Persuasive Virtual Sales Assistant",
        "authors": [
            "Abhisek Tiwari",
            "Sriparna Saha",
            "Shubhashis Sengupta",
            "Anutosh Maitra",
            "Roshni Ramnani",
            "Pushpak Bhattacharyya"
        ],
        "published": "2022",
        "summary": "Task-oriented conversational agents are gaining immense popularity and success in a wide range of tasks, from flight ticket booking to online shopping. However, the existing systems presume that end-users will always have a pre-determined and servable task goal, which results in dialogue failure in hostile scenarios, such as goal unavailability. On the other hand, human agents accomplish users’ tasks even in a large number of goal unavailability scenarios by persuading them towards a very similar and servable goal. Motivated by the limitation, we propose and build a novel end-to-end multi-modal persuasive dialogue system incorporated with a personalized persuasive module aided goal controller and goal persuader. The goal controller recognizes goal conflicting/unavailability scenarios and formulates a new goal, while the goal persuader persuades users using a personalized persuasive strategy identified through dialogue context. We also present a novel automatic evaluation metric called Persuasiveness Measurement Rate (PMeR) for quantifying the persuasive capability of a conversational agent. The obtained improvements (both quantitative and qualitative) firmly establish the superiority and need of the proposed context-guided, personalized persuasive virtual agent over existing traditional task-oriented virtual agents. Furthermore, we also curated a multi-modal persuasive conversational dialogue corpus annotated with intent, slot, sentiment, and dialogue act for e-commerce domain.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.76.pdf"
    },
    {
        "title": "FPC: Fine-tuning with Prompt Curriculum for Relation Extraction",
        "authors": [
            "Sicheng Yang",
            "Dandan Song"
        ],
        "published": "2022",
        "summary": "The current classification methods for relation extraction (RE) generally utilize pre-trained language models (PLMs) and have achieved superior results. However, such methods directly treat relation labels as class numbers, therefore they ignore the semantics of relation labels. Recently, prompt-based fine-tuning has been proposed and attracted much attention. This kind of methods insert templates into the input and convert the classification task to a (masked) language modeling problem. With this inspiration, we propose a novel method Fine-tuning with Prompt Curriculum (FPC) for RE, with two distinctive characteristics: the relation prompt learning, introducing an auxiliary prompt-based fine-tuning task to make the model capture the semantics of relation labels; the prompt learning curriculum, a fine-tuning procedure including an increasingly difficult task to adapt the model to the difficult multi-task setting. We have conducted extensive experiments on four widely used RE benchmarks under fully supervised and low-resource settings. The experimental results show that FPC can significantly outperform the existing methods and obtain the new state-of-the-art results.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.78.pdf"
    },
    {
        "title": "Whodunit? Learning to Contrast for Authorship Attribution",
        "authors": [
            "Bo Ai",
            "Yuchen Wang",
            "Yugin Tan",
            "Samson Tan"
        ],
        "published": "2022",
        "summary": "Authorship attribution is the task of identifying the author of a given text. The key is finding representations that can differentiate between authors. Existing approaches typically use manually designed features that capture a dataset’s content and style, but these approaches are dataset-dependent and yield inconsistent performance across corpora. In this work, we propose to learn author-specific representations by fine-tuning pre-trained generic language representations with a contrastive objective (Contra-X). We show that Contra-X learns representations that form highly separable clusters for different authors. It advances the state-of-the-art on multiple human and machine authorship attribution benchmarks, enabling improvements of up to 6.8% over cross-entropy fine-tuning. However, we find that Contra-X improves overall accuracy at the cost of sacrificing performance for some authors. Resolving this tension will be an important direction for future work. To the best of our knowledge, we are the first to integrate contrastive learning with pre-trained language model fine-tuning for authorship attribution.",
        "pdf_link": "https://aclanthology.org/2022.aacl-main.84.pdf"
    },
    {
        "title": "FAD-X: Fusing Adapters for Cross-lingual Transfer to Low-Resource Languages",
        "authors": [
            "Jaeseong Lee",
            "Seung-won Hwang",
            "Taesup Kim"
        ],
        "published": "2022",
        "summary": "Adapter-based tuning, by adding light-weight adapters to multilingual pretrained language models (mPLMs), selectively updates language-specific parameters to adapt to a new language, instead of finetuning all shared weights. This paper explores an effective way to leverage a public pool of pretrained language adapters, to overcome resource imbalances for low-resource languages (LRLs). Specifically, our research questions are, whether pretrained adapters can be composed, to complement or replace LRL adapters. While composing adapters for multi-task learning setting has been studied, the same question for LRLs has remained largely unanswered. To answer this question, we study how to fuse adapters across languages and tasks, then validate how our proposed fusion adapter, namely FAD-X, can enhance a cross-lingual transfer from pretrained adapters, for well-known named entity recognition and classification benchmarks.",
        "pdf_link": "https://aclanthology.org/2022.aacl-short.8.pdf"
    },
    {
        "title": "Combining Argumentation Structure and Language Model for Generating Natural Argumentative Dialogue",
        "authors": [
            "Koh Mitsuda",
            "Ryuichiro Higashinaka",
            "Kuniko Saito"
        ],
        "published": "2022",
        "summary": "Argumentative dialogue is an important process where speakers discuss a specific theme for consensus building or decision making. In previous studies for generating consistent argumentative dialogue, retrieval-based methods with hand-crafted argumentation structures have been used. In this study, we propose a method to generate natural argumentative dialogues by combining an argumentation structure and language model. We trained the language model to rewrite a proposition of an argumentation structure on the basis of its information, such as keywords and stance, into the next utterance while considering its context, and we used the model to rewrite propositions in the argumentation structure. We manually evaluated the generated dialogues and found that the proposed method significantly improved the naturalness of dialogues without losing consistency of argumentation.",
        "pdf_link": "https://aclanthology.org/2022.aacl-short.9.pdf"
    },
    {
        "title": "An Effective Post-training Embedding Binarization Approach for Fast Online Top-K Passage Matching",
        "authors": [
            "Yankai Chen",
            "Yifei Zhang",
            "Huifeng Guo",
            "Ruiming Tang",
            "Irwin King"
        ],
        "published": "2022",
        "summary": "With the rapid development of Natural Language Understanding for information retrieval, fine-tuned deep language models, e.g., BERT-based, perform remarkably effective in passage searching tasks. To lower the architecture complexity, the recent state-of-the-art model ColBERT employs Contextualized Late Interaction paradigm to independently learn fine-grained query-passage representations. Apart from the architecture simplification, embedding binarization, as another promising branch in model compression, further specializes in the reduction of memory and computation overheads. In this concise paper, we propose an effective post-training embedding binarization approach over ColBERT, achieving both architecture-level and embedding-level optimization for online inference. The empirical results demonstrate the efficaciousness of our proposed approach, empowering it to perform online query-passage matching acceleration.",
        "pdf_link": "https://aclanthology.org/2022.aacl-short.14.pdf"
    },
    {
        "title": "EmoNoBa: A Dataset for Analyzing Fine-Grained Emotions on Noisy Bangla Texts",
        "authors": [
            "Khondoker Ittehadul Islam",
            "Tanvir Yuvraz",
            "Md Saiful Islam",
            "Enamul Hassan"
        ],
        "published": "2022",
        "summary": "For low-resourced Bangla language, works on detecting emotions on textual data suffer from size and cross-domain adaptability. In our paper, we propose a manually annotated dataset of 22,698 Bangla public comments from social media sites covering 12 different domains such as Personal, Politics, and Health, labeled for 6 fine-grained emotion categories of the Junto Emotion Wheel. We invest efforts in the data preparation to 1) preserve the linguistic richness and 2) challenge any classification model. Our experiments to develop a benchmark classification system show that random baselines perform better than neural networks and pre-trained language models as hand-crafted features provide superior performance.",
        "pdf_link": "https://aclanthology.org/2022.aacl-short.17.pdf"
    },
    {
        "title": "An Improved Baseline for Sentence-level Relation Extraction",
        "authors": [
            "Wenxuan Zhou",
            "Muhao Chen"
        ],
        "published": "2022",
        "summary": "Sentence-level relation extraction (RE) aims at identifying the relationship between two entities in a sentence. Many efforts have been devoted to this problem, while the best performing methods are still far from perfect. In this paper, we revisit two problems that affect the performance of existing RE models, namely entity representation and noisy or ill-defined labels. Our improved RE baseline, incorporated with entity representations with typed markers, achieves an F1 of 74.6% on TACRED, significantly outperforms previous SOTA methods. Furthermore, the presented new baseline achieves an F1 of 91.1% on the refined Re-TACRED dataset, demonstrating that the pretrained language models (PLMs) achieve high performance on this task. We release our code to the community for future research.",
        "pdf_link": "https://aclanthology.org/2022.aacl-short.21.pdf"
    },
    {
        "title": "NGEP: A Graph-based Event Planning Framework for Story Generation",
        "authors": [
            "Chen Tang",
            "Zhihao Zhang",
            "Tyler Loakman",
            "Chenghua Lin",
            "Frank Guerin"
        ],
        "published": "2022",
        "summary": "To improve the performance of long text generation, recent studies have leveraged automatically planned event structures (i.e. storylines) to guide story generation. Such prior works mostly employ end-to-end neural generation models to predict event sequences for a story. However, such generation models struggle to guarantee the narrative coherence of separate events due to the hallucination problem, and additionally the generated event sequences are often hard to control due to the end-to-end nature of the models. To address these challenges, we propose NGEP, an novel event planning framework which generates an event sequence by performing inference on an automatically constructed event graph and enhances generalisation ability through a neural event advisor. We conduct a range of experiments on multiple criteria, and the results demonstrate that our graph-based neural framework outperforms the state-of-the-art (SOTA) event planning approaches, considering both the performance of event sequence generation and the effectiveness on the downstream task of story generation.",
        "pdf_link": "https://aclanthology.org/2022.aacl-short.24.pdf"
    },
    {
        "title": "A Simple Yet Effective Hybrid Pre-trained Language Model for Unsupervised Sentence Acceptability Prediction",
        "authors": [
            "Yang Zhao",
            "Issei Yoshida"
        ],
        "published": "2022",
        "summary": "Sentence acceptability judgment assesses to what degree a sentence is acceptable to native speakers of the language. Most unsupervised prediction approaches rely on a language model to obtain the likelihood of a sentence that reflects acceptability. However, two problems exist: first, low-frequency words would have a significant negative impact on the sentence likelihood derived from the language model; second, when it comes to multiple domains, the language model needs to be trained on domain-specific text for domain adaptation. To address both problems, we propose a simple method that substitutes Part-of-Speech (POS) tags for low-frequency words in sentences used for continual training of masked language models. Experimental results show that our word-tag-hybrid BERT model brings improvement on both a sentence acceptability benchmark and a cross-domain sentence acceptability evaluation corpus. Furthermore, our annotated cross-domain sentence acceptability evaluation corpus would benefit future research.",
        "pdf_link": "https://aclanthology.org/2022.aacl-short.25.pdf"
    },
    {
        "title": "Post-Training with Interrogative Sentences for Enhancing BART-based Korean Question Generator",
        "authors": [
            "Gyu-Min Park",
            "Seong-Eun Hong",
            "Seong-Bae Park"
        ],
        "published": "2022",
        "summary": "The pre-trained language models such as KoBART often fail in generating perfect interrogative sentences when they are applied to Korean question generation. This is mainly due to the fact that the language models are much experienced with declarative sentences, but not with interrogative sentences. Therefore, this paper proposes a novel post-training of KoBART to enhance it for Korean question generation. The enhancement of KoBART is accomplished in three ways: (i) introduction of question infilling objective to KoBART to enforce it to focus more on the structure of interrogative sentences, (ii) augmentation of training data for question generation with another data set to cope with the lack of training instances for post-training, (iii) introduction of Korean spacing objective to make KoBART understand the linguistic features of Korean. Since there is no standard data set for Korean question generation, this paper also proposes KorQuAD-QG, a new data set for this task, to verify the performance of the proposed post-training. Our code are publicly available at https://github.com/gminipark/post_training_qg",
        "pdf_link": "https://aclanthology.org/2022.aacl-short.26.pdf"
    },
    {
        "title": "Do ever larger octopi still amplify reporting biases? Evidence from judgments of typical colour",
        "authors": [
            "Fangyu Liu",
            "Julian Eisenschlos",
            "Jeremy Cole",
            "Nigel Collier"
        ],
        "published": "2022",
        "summary": "Language models (LMs) trained on raw texts have no direct access to the physical world. Gordon and Van Durme (2013) point out that LMs can thus suffer from reporting bias: texts rarely report on common facts, instead focusing on the unusual aspects of a situation. If LMs are only trained on text corpora and naively memorise local co-occurrence statistics, they thus naturally would learn a biased view of the physical world. While prior studies have repeatedly verified that LMs of smaller scales (e.g., RoBERTa, GPT-2) amplify reporting bias, it remains unknown whether such trends continue when models are scaled up. We investigate reporting bias from the perspective of colour in larger language models (LLMs) such as PaLM and GPT-3. Specifically, we query LLMs for the typical colour of objects, which is one simple type of perceptually grounded physical common sense. Surprisingly, we find that LLMs significantly outperform smaller LMs in determining an object’s typical colour and more closely track human judgments, instead of overfitting to surface patterns stored in texts. This suggests that very large models of language alone are able to overcome certain types of reporting bias that are characterized by local co-occurrences.",
        "pdf_link": "https://aclanthology.org/2022.aacl-short.27.pdf"
    },
    {
        "title": "Performance-Efficiency Trade-Offs in Adapting Language Models to Text Classification Tasks",
        "authors": [
            "Laura Aina",
            "Nikos Voskarides",
            "Roi Blanco"
        ],
        "published": "2022",
        "summary": "Pre-trained language models (LMs) obtain state-of-the-art performance when adapted to text classification tasks. However, when using such models in real world applications, efficiency considerations are paramount. In this paper, we study how different training procedures that adapt LMs to text classification perform, as we vary model and train set size. More specifically, we compare standard fine-tuning, prompting, and knowledge distillation (KD) when the teacher was trained with either fine-tuning or prompting. Our findings suggest that even though fine-tuning and prompting work well to train large LMs on large train sets, there are more efficient alternatives that can reduce compute or data cost. Interestingly, we find that prompting combined with KD can reduce compute and data cost at the same time.",
        "pdf_link": "https://aclanthology.org/2022.aacl-short.31.pdf"
    },
    {
        "title": "NepBERTa: Nepali Language Model Trained in a Large Corpus",
        "authors": [
            "Sulav Timilsina",
            "Milan Gautam",
            "Binod Bhattarai"
        ],
        "published": "2022",
        "summary": "Nepali is a low-resource language with more than 40 million speakers worldwide. It is written in Devnagari script and has rich semantics and complex grammatical structure. To this date, multilingual models such as Multilingual BERT, XLM and XLM-RoBERTa haven’t been able to achieve promising results in Nepali NLP tasks, and there does not exist any such a large-scale monolingual corpus. This study presents NepBERTa, a BERT-based Natural Language Understanding (NLU) model trained on the most extensive monolingual Nepali corpus ever. We collected a dataset of 0.8B words from 36 different popular news sites in Nepal and introduced the model. This data set is 3 folds times larger than the previous publicly available corpus. We evaluated the performance of NepBERTa in multiple Nepali-specific NLP tasks, including Named-Entity Recognition, Content Classification, POS Tagging, and Sequence Pair Similarity. We also introduce two different datasets for two new downstream tasks and benchmark four diverse NLU tasks altogether. We bring all these four tasks under the first-ever Nepali Language Understanding Evaluation (Nep-gLUE) benchmark. We will make Nep-gLUE along with the pre-trained model and data sets publicly available for research.",
        "pdf_link": "https://aclanthology.org/2022.aacl-short.34.pdf"
    },
    {
        "title": "Demographic-Aware Language Model Fine-tuning as a Bias Mitigation Technique",
        "authors": [
            "Aparna Garimella",
            "Rada Mihalcea",
            "Akhash Amarnath"
        ],
        "published": "2022",
        "summary": "BERT-like language models (LMs), when exposed to large unstructured datasets, are known to learn and sometimes even amplify the biases present in such data. These biases generally reflect social stereotypes with respect to gender, race, age, and others. In this paper, we analyze the variations in gender and racial biases in BERT, a large pre-trained LM, when exposed to different demographic groups. Specifically, we investigate the effect of fine-tuning BERT on text authored by historically disadvantaged demographic groups in comparison to that by advantaged groups. We show that simply by fine-tuning BERT-like LMs on text authored by certain demographic groups can result in the mitigation of social biases in these LMs against various target groups.",
        "pdf_link": "https://aclanthology.org/2022.aacl-short.38.pdf"
    },
    {
        "title": "Towards Simple and Efficient Task-Adaptive Pre-training for Text Classification",
        "authors": [
            "Arnav Ladkat",
            "Aamir Miyajiwala",
            "Samiksha Jagadale",
            "Rekha A. Kulkarni",
            "Raviraj Joshi"
        ],
        "published": "2022",
        "summary": "Language models are pre-trained using large corpora of generic data like book corpus, com- mon crawl and Wikipedia, which is essential for the model to understand the linguistic characteristics of the language. New studies suggest using Domain Adaptive Pre-training (DAPT) and Task-Adaptive Pre-training (TAPT) as an intermediate step before the final finetuning task. This step helps cover the target domain vocabulary and improves the model performance on the downstream task. In this work, we study the impact of training only the embedding layer on the model’s performance during TAPT and task-specific finetuning. Based on our study, we propose a simple approach to make the in- termediate step of TAPT for BERT-based mod- els more efficient by performing selective pre-training of BERT layers. We show that training only the BERT embedding layer during TAPT is sufficient to adapt to the vocabulary of the target domain and achieve comparable performance. Our approach is computationally efficient, with 78% fewer parameters trained during TAPT. The proposed embedding layer finetuning approach can also be an efficient domain adaptation technique.",
        "pdf_link": "https://aclanthology.org/2022.aacl-short.39.pdf"
    },
    {
        "title": "Evaluating Pre-Trained Sentence-BERT with Class Embeddings in Active Learning for Multi-Label Text Classification",
        "authors": [
            "Lukas Wertz",
            "Jasmina Bogojeska",
            "Katsiaryna Mirylenka",
            "Jonas Kuhn"
        ],
        "published": "2022",
        "summary": "The Transformer Language Model is a powerful tool that has been shown to excel at various NLP tasks and has become the de-facto standard solution thanks to its versatility. In this study, we employ pre-trained document embeddings in an Active Learning task to group samples with the same labels in the embedding space on a legal document corpus. We find that the calculated class embeddings are not close to the respective samples and consequently do not partition the embedding space in a meaningful way. In addition, we explore using the class embeddings as an Active Learning strategy with dramatically reduced results compared to all baselines.",
        "pdf_link": "https://aclanthology.org/2022.aacl-short.45.pdf"
    },
    {
        "title": "MiQA: A Benchmark for Inference on Metaphorical Questions",
        "authors": [
            "Iulia Comșa",
            "Julian Eisenschlos",
            "Srini Narayanan"
        ],
        "published": "2022",
        "summary": "We propose a benchmark to assess the capability of large language models to reason with conventional metaphors. Our benchmark combines the previously isolated topics of metaphor detection and commonsense reasoning into a single task that requires a model to make inferences by accurately selecting between the literal and metaphorical register. We examine the performance of state-of-the-art pre-trained models on binary-choice tasks and find a large discrepancy between the performance of small and very large models, going from chance to near-human level. We also analyse the largest model in a generative setting and find that although human performance is approached, careful multiple-shot prompting is required.",
        "pdf_link": "https://aclanthology.org/2022.aacl-short.46.pdf"
    },
    {
        "title": "Assessing Combinational Generalization of Language Models in Biased Scenarios",
        "authors": [
            "Yanbo Fang",
            "Zuohui Fu",
            "Xin Dong",
            "Yongfeng Zhang",
            "Gerard de Melo"
        ],
        "published": "2022",
        "summary": "In light of the prominence of Pre-trained Language Models (PLMs) across numerous downstream tasks, shedding light on what they learn is an important endeavor. Whereas previous work focuses on assessing in-domain knowledge, we evaluate the generalization ability in biased scenarios through component combinations where it could be easy for the PLMs to learn shortcuts from the training corpus. This would lead to poor performance on the testing corpus, which is combinationally reconstructed from the training components. The results show that PLMs are able to overcome such distribution shifts for specific tasks and with sufficient data. We further find that overfitting can lead the models to depend more on biases for prediction, thus hurting the combinational generalization ability of PLMs.",
        "pdf_link": "https://aclanthology.org/2022.aacl-short.48.pdf"
    },
    {
        "title": "Exploring the Effects of Negation and Grammatical Tense on Bias Probes",
        "authors": [
            "Samia Touileb"
        ],
        "published": "2022",
        "summary": "We investigate in this paper how correlations between occupations and gendered-pronouns can be affected and changed by adding negation in bias probes, or changing the grammatical tense of the verbs in the probes. We use a set of simple bias probes in Norwegian and English, and perform 16 different probing analysis, using four Norwegian and four English pre-trained language models. We show that adding negation to probes does not have a considerable effect on the correlations between gendered-pronouns and occupations, supporting other works on negation in language models. We also show that altering the grammatical tense of verbs in bias probes do have some interesting effects on models’ behaviours and correlations. We argue that we should take grammatical tense into account when choosing bias probes, and aggregating results across tenses might be a better representation of the existing correlations.",
        "pdf_link": "https://aclanthology.org/2022.aacl-short.53.pdf"
    },
    {
        "title": "Promoting Pre-trained LM with Linguistic Features on Automatic Readability Assessment",
        "authors": [
            "Shudi Hou",
            "Simin Rao",
            "Yu Xia",
            "Sujian Li"
        ],
        "published": "2022",
        "summary": "Automatic readability assessment (ARA) aims at classifying the readability level of a passage automatically. In the past, manually selected linguistic features are used to classify the passages. However, as the use of deep neural network surges, there is less work focusing on these linguistic features. Recently, many works integrate linguistic features with pre-trained language model (PLM) to make up for the information that PLMs are not good at capturing. Despite their initial success, insufficient analysis of the long passage characteristic of ARA has been done before. To further investigate the promotion of linguistic features on PLMs in ARA from the perspective of passage length, with commonly used linguistic features and abundant experiments, we find that: (1) Linguistic features promote PLMs in ARA mainly on long passages. (2) The promotion of the features on PLMs becomes less significant when the dataset size exceeds 750 passages. (3) By analyzing commonly used ARA datasets, we find Newsela is actually not suitable for ARA. Our code is available at https://github.com/recorderhou/linguistic-features-in-ARA.",
        "pdf_link": "https://aclanthology.org/2022.aacl-short.54.pdf"
    },
    {
        "title": "CLASP: Few-Shot Cross-Lingual Data Augmentation for Semantic Parsing",
        "authors": [
            "Andy Rosenbaum",
            "Saleh Soltan",
            "Wael Hamza",
            "Marco Damonte",
            "Isabel Groves",
            "Amir Saffari"
        ],
        "published": "2022",
        "summary": "A bottleneck to developing Semantic Parsing (SP) models is the need for a large volume of human-labeled training data. Given the complexity and cost of human annotation for SP, labeled data is often scarce, particularly in multilingual settings. Large Language Models (LLMs) excel at SP given only a few examples, however LLMs are unsuitable for runtime systems which require low latency. In this work, we propose CLASP, a simple method to improve low-resource SP for moderate-sized models: we generate synthetic data from AlexaTM 20B to augment the training set for a model 40x smaller (500M parameters). We evaluate on two datasets in low-resource settings: English PIZZA, containing either 348 or 16 real examples, and mTOP cross-lingual zero-shot, where training data is available only in English, and the model must generalize to four new languages. On both datasets, we show significant improvements over strong baseline methods.",
        "pdf_link": "https://aclanthology.org/2022.aacl-short.56.pdf"
    },
    {
        "title": "The Effects of Surprisal across Languages: Results from Native and Non-native Reading",
        "authors": [
            "Andrea de Varda",
            "Marco Marelli"
        ],
        "published": "2022",
        "summary": "It is well known that the surprisal of an upcoming word, as estimated by language models, is a solid predictor of reading times (Smith and Levy, 2013). However, most of the studies that support this view are based on English and few other Germanic languages, leaving an open question as to the cross-lingual generalizability of such findings. Moreover, they tend to consider only the best-performing eye-tracking measure, which might conflate the effects of predictive and integrative processing. Furthermore, it is not clear whether prediction plays a role in non-native language processing in bilingual individuals (Grüter et al., 2014). We approach these problems at large scale, extracting surprisal estimates from mBERT, and assessing their psychometric predictive power on the MECO corpus, a cross-linguistic dataset of eye movement behavior in reading (Siegelman et al., 2022; Kuperman et al., 2020). We show that surprisal is a strong predictor of reading times across languages and fixation measurements, and that its effects in L2 are weaker with respect to L1.",
        "pdf_link": "https://aclanthology.org/2022.findings-aacl.13.pdf",
        "source": "aacl2022"
    },
    {
        "title": "Block Diagram-to-Text: Understanding Block Diagram Images by Generating Natural Language Descriptors",
        "authors": [
            "Shreyanshu Bhushan",
            "Minho Lee"
        ],
        "published": "2022",
        "summary": "Block diagrams are very popular for representing a workflow or process of a model. Understanding block diagrams by generating summaries can be extremely useful in document summarization. It can also assist people in inferring key insights from block diagrams without requiring a lot of perceptual and cognitive effort. In this paper, we propose a novel task of converting block diagram images into text by presenting a framework called “BloSum”. This framework extracts the contextual meaning from the images in the form of triplets that help the language model in summary generation. We also introduce a new dataset for complex computerized block diagrams, explain the dataset preparation process, and later analyze it. Additionally, to showcase the generalization of the model, we test our method with publicly available handwritten block diagram datasets. Our evaluation with different metrics demonstrates the effectiveness of our approach that outperforms other methods and techniques.",
        "pdf_link": "https://aclanthology.org/2022.findings-aacl.15.pdf",
        "source": "aacl2022"
    },
    {
        "title": "TaKG: A New Dataset for Paragraph-level Table-to-Text Generation Enhanced with Knowledge Graphs",
        "authors": [
            "Qianqian Qi",
            "Zhenyun Deng",
            "Yonghua Zhu",
            "Lia Jisoo Lee",
            "Michael Witbrock",
            "Jiamou Liu"
        ],
        "published": "2022",
        "summary": "We introduce TaKG, a new table-to-text generation dataset with the following highlights: (1) TaKG defines a long-text (paragraph-level) generation task as opposed to well-established short-text (sentence-level) generation datasets. (2) TaKG is the first large-scale dataset for this task, containing three application domains and ~750,000 samples. (3) To address the divergence phenomenon, TaKG enhances table input using external knowledge graphs, extracted by a new Wikidata-based method. We then propose a new Transformer-based multimodal sequence-to-sequence architecture for TaKG that integrates two pretrained language models RoBERTa and GPT-2. Our model shows reliable performance on long-text generation across a variety of metrics, and outperforms existing models for short-text generation tasks.",
        "pdf_link": "https://aclanthology.org/2022.findings-aacl.17.pdf",
        "source": "aacl2022"
    },
    {
        "title": "Automating Interlingual Homograph Recognition with Parallel Sentences",
        "authors": [
            "Yi Han",
            "Ryohei Sasano",
            "Koichi Takeda"
        ],
        "published": "2022",
        "summary": "Interlingual homographs are words that spell the same but possess different meanings across languages. Recognizing interlingual homographs from form-identical words generally needs linguistic knowledge and massive annotation work. In this paper, we propose an automatic interlingual homograph recognition method based on the cross-lingual word embedding similarity and co-occurrence of form-identical words in parallel sentences. We conduct experiments with various off-the-shelf language models coordinating with cross-lingual alignment operations and co-occurrence metrics on the Chinese-Japanese and English-Dutch language pairs. Experimental results demonstrate that our proposed method is able to make accurate and consistent predictions across languages.",
        "pdf_link": "https://aclanthology.org/2022.findings-aacl.20.pdf",
        "source": "aacl2022"
    },
    {
        "title": "Logographic Information Aids Learning Better Representations for Natural Language Inference",
        "authors": [
            "Zijian Jin",
            "Duygu Ataman"
        ],
        "published": "2022",
        "summary": "Statistical language models conventionally implement representation learning based on the contextual distribution of words or other formal units, whereas any information related to the logographic features of written text are often ignored, assuming they should be retrieved relying on the cooccurence statistics. On the other hand, as language models become larger and require more data to learn reliable representations, such assumptions may start to fall back, especially under conditions of data sparsity. Many languages, including Chinese and Vietnamese, use logographic writing systems where surface forms are represented as a visual organization of smaller graphemic units, which often contain many semantic cues. In this paper, we present a novel study which explores the benefits of providing language models with logographic information in learning better semantic representations. We test our hypothesis in the natural language inference (NLI) task by evaluating the benefit of computing multi-modal representations that combine contextual information with glyph information. Our evaluation results in six languages with different typology and writing systems suggest significant benefits of using multi-modal embeddings in languages with logograhic systems, especially for words with less occurence statistics.",
        "pdf_link": "https://aclanthology.org/2022.findings-aacl.25.pdf",
        "source": "aacl2022"
    },
    {
        "title": "Cross-domain Analysis on Japanese Legal Pretrained Language Models",
        "authors": [
            "Keisuke Miyazaki",
            "Hiroaki Yamada",
            "Takenobu Tokunaga"
        ],
        "published": "2022",
        "summary": "This paper investigates the pretrained language model (PLM) specialised in the Japanese legal domain. We create PLMs using different pretraining strategies and investigate their performance across multiple domains. Our findings are (i) the PLM built with general domain data can be improved by further pretraining with domain-specific data, (ii) domain-specific PLMs can learn domain-specific and general word meanings simultaneously and can distinguish them, (iii) domain-specific PLMs work better on its target domain; still, the PLMs retain the information learnt in the original PLM even after being further pretrained with domain-specific data, (iv) the PLMs sequentially pretrained with corpora of different domains show high performance for the later learnt domains.",
        "pdf_link": "https://aclanthology.org/2022.findings-aacl.26.pdf",
        "source": "aacl2022"
    },
    {
        "title": "HERB: Measuring Hierarchical Regional Bias in Pre-trained Language Models",
        "authors": [
            "Yizhi Li",
            "Ge Zhang",
            "Bohao Yang",
            "Chenghua Lin",
            "Anton Ragni",
            "Shi Wang",
            "Jie Fu"
        ],
        "published": "2022",
        "summary": "Fairness has become a trending topic in natural language processing (NLP) and covers biases targeting certain social groups such as genders and religions. Yet regional bias, another long-standing global discrimination problem, remains unexplored still. Consequently, we intend to provide a study to analyse the regional bias learned by the pre-trained language models (LMs) that are broadly used in NLP tasks. While verifying the existence of regional bias in LMs, we find that the biases on regional groups can be largely affected by the corresponding geographical clustering. We accordingly propose a hierarchical regional bias evaluation method (HERB) utilising the information from the sub-region clusters to quantify the bias in the pre-trained LMs. Experiments show that our hierarchical metric can effectively evaluate the regional bias with regard to comprehensive topics and measure the potential regional bias that can be propagated to downstream tasks. Our codes are available at https://github.com/Bernard-Yang/HERB.",
        "pdf_link": "https://aclanthology.org/2022.findings-aacl.32.pdf",
        "source": "aacl2022"
    },
    {
        "title": "ArgGen: Prompting Text Generation Models for Document-Level Event-Argument Aggregation",
        "authors": [
            "Debanjana Kar",
            "Sudeshna Sarkar",
            "Pawan Goyal"
        ],
        "published": "2022",
        "summary": "Most of the existing discourse-level Information Extraction tasks have been modeled to be extractive in nature. However, we argue that extracting information from larger bodies of discourse-like documents requires more natural language understanding and reasoning capabilities. In our work, we propose the novel task of document-level event argument aggregation which generates consolidated event-arguments at a document-level with minimal loss of information. More specifically, we focus on generating precise document-level information frames in a multilingual setting using prompt-based methods. In this paper, we show the effectiveness of u prompt-based text generation approach to generate document-level argument spans in a low-resource and zero-shot setting. We also release the first of its kind multilingual event argument aggregation dataset that can be leveraged in other related multilingual text generation tasks as well: https://github.com/DebanjanaKar/ArgGen.",
        "pdf_link": "https://aclanthology.org/2022.findings-aacl.37.pdf",
        "source": "aacl2022"
    },
    {
        "title": "BeamR: Beam Reweighing with Attribute Discriminators for Controllable Text Generation",
        "authors": [
            "David Landsman",
            "Jerry Zikun Chen",
            "Hussain Zaidi"
        ],
        "published": "2022",
        "summary": "Recent advances in natural language processing have led to the availability of large pre-trained language models (LMs), with rich generative capabilities. Although these models are able to produce fluent and coherent text, it remains a challenge to control various attributes of the generation, including sentiment, formality, topic and many others. We propose a Beam Reweighing (BeamR) method, building on top of standard beam search, in order to control different attributes. BeamR combines any generative LM with any attribute discriminator, offering full flexibility of generation style and attribute, while the beam search backbone maintains fluency across different domains. Notably, BeamR allows practitioners to leverage pre-trained models without the need to train generative LMs together with discriminators. We evaluate BeamR in two diverse tasks: sentiment steering, and machine translation formality. Our results show that BeamR performs on par with or better than existing state-of-the-art approaches (including fine-tuned methods), and highlight the flexiblity of BeamR in both causal and seq2seq language modeling tasks.",
        "pdf_link": "https://aclanthology.org/2022.findings-aacl.40.pdf",
        "source": "aacl2022"
    },
    {
        "title": "Adversarial Sample Generation for Aspect based Sentiment Classification",
        "authors": [
            "Mamta",
            "Asif Ekbal"
        ],
        "published": "2022",
        "summary": "Deep learning models have been proven vulnerable towards small imperceptible perturbed input, known as adversarial samples, which are indiscernible by humans. Initial attacks in Natural Language Processing perturb characters or words in sentences using heuristics and synonyms-based strategies, resulting in grammatical incorrect or out-of-context sentences. Recent works attempt to generate contextual adversarial samples using a masked language model, capturing word relevance using leave-one-out (LOO). However, they lack the design to maintain the semantic coherency for aspect based sentiment analysis (ABSA) tasks. Moreover, they focused on resource-rich languages like English. We present an attack algorithm for the ABSA task by exploiting model explainability techniques to address these limitations. It does not require access to the training data, raw access to the model, or calibrating a new model. Our proposed method generates adversarial samples for a given aspect, maintaining more semantic coherency. In addition, it can be generalized to low-resource languages, which are at high risk due to resource scarcity. We show the effectiveness of the proposed attack using automatic and human evaluation. Our method outperforms the state-of-art methods in perturbation ratio, success rate, and semantic coherence.",
        "pdf_link": "https://aclanthology.org/2022.findings-aacl.44.pdf",
        "source": "aacl2022"
    }
]