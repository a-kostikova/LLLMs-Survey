<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Perplexity-Driven Case Encoding Needs Augmentation for CAPITALIZATION Robustness</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Rohit</forename><surname>Jain</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Huda</forename><surname>Khayrallah</surname></persName>
							<email>hkhayrallah@microsoft.com</email>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Roman</forename><surname>Grundkiewicz</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
							<email>marcinjd@microsoft.com</email>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marcello</forename><surname>Federico</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Matthias</forename><surname>Gallé</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kweonwoo</forename><surname>Jung</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vassilina</forename><forename type="middle">2021</forename><surname>Nikoulina</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><surname>Find</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marta</forename><surname>Bañón</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pinzhen</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Barry</forename><surname>Haddow</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Miquel</forename><surname>Esplà-Gomis</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mikel</forename><forename type="middle">L</forename><surname>Forcada</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Amir</forename><surname>Kamran</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Faheem</forename><surname>Kirefu</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sergio</forename><forename type="middle">Ortiz</forename><surname>Rojas</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Leopoldo</forename><forename type="middle">Pla</forename><surname>Sempere</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gema</forename><surname>Ramírez-Sánchez</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Elsa</forename><surname>Sarrías</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marek</forename><surname>Strelec</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tom</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ariel</forename><surname>Herbert-Voss</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tom</forename><surname>Henighan</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Ziegler</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Clemens</forename><surname>Winter</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Christopher</forename><surname>Hesse</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Eric</forename><surname>Sigler</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mateusz</forename><surname>Litwin</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Scott</forename><surname>Gray</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Benjamin</forename><surname>Chess</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jack</forename><surname>Clark</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Christopher</forename><surname>Berner</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sam</forename><surname>Mccandlish</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>William Waites</addrLine>
									<settlement>Brian Thompson, Dion Wiggins</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Perplexity-Driven Case Encoding Needs Augmentation for CAPITALIZATION Robustness</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4CBE85F489F0142AADD36FCDA7051FF5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-05-29T13:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Translation</term>
					<term>pages 462-472</term>
					<term>Online. Association for Computational Linguistics. Alexandre Berard</term>
					<term>Ioan Calapodescu</term>
					<term>and Claude Roux. 2019. Naver labs Europe&apos;s systems for the WMT19 machine translation robustness task. In Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers</term>
					<term>Day 1)</term>
					<term>pages 526-532</term>
					<term>Florence</term>
					<term>Italy. Association for Computational Linguistics</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Subword segmentation methods are the predominant solution to vocab sparsity in NMT. However, they cannot currently handle capitalization well. We re-encode case to allow the perplexity-driven SPM unigram language model algorithm to learn how to segment capitalization. Since naturally occurring data accurately describes the prevalence of capitalization but underestimates the importance humans ascribe to capitalization robustness, we propose data augmentation to fill this gap. We demonstrate that our proposed method improves translation quality on ALL CAPS, lower cased, and Title Case, while maintaining quality on standard test sets. In contrast to prior work, our proposed method has minimal impact on decoding speed. We release our code: github.com/marian-nmt/sentencepiece.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Capitalization is supported by Latin script, and the Armenian, Cyrillic, Georgian and Greek alphabets. In addition to standard capitalization rules for a given language (e.g., sentence inital capitalization, German noun capitalization), variation also occurs, such as English Title Casing, ALL CAPS FOR EM-PHASIS, or all lower case in informal texts.</p><p>For most NLP models, upper and lower case letters are represented with distinct code-points. In contrast, most people naturally connect upper and lower-cased letters as highly similar. Therefore, NLP models are expected to perform similarly on inputs that only differ in casing. However, that is often not the case, and NLP models are often unstable on non-standard casings.</p><p>Subword segmentation methods (e.g., BPE <ref type="bibr">(Sennrich et al., 2016)</ref> and SPM <ref type="bibr" target="#b18">(Kudo and Richardson, 2018)</ref>) handle the sparsity introduced by a variety of linguistic features by learning a segmentation of words into shorter sequences of characters. However, these do not currently handle the sparsity introduced by casing. For example, shows that Transformer MT models trained with standard SentencePiece (SPM) segmentation drop &gt;30 BLEU points when translating the ALL CAPS version. The target sequence length also increases dramatically, which leads to ≈3x slower translation. Prior work <ref type="bibr">(Berard et al., 2019;</ref><ref type="bibr" target="#b3">Etchegoyhen and Gete, 2020)</ref> overcame this limitation by modifying the encoding or subword vocabulary in a way that breaks the encoding optimally of perplexity driven methods, improving quality at the cost of impractical sequence length/runtime. In this work, we re-encode capitalization to allow the subword segmentation model to learn how to best segment this linguistic feature. We propose a novel case encoding: we lowercase the entire text, then prefix previously cased words with markers (see Table <ref type="table">2</ref>). Since we prefix the words, and apply case encoding before perplexity-driven subword segmentation, that algorithm learns if a case marker should be split off. Naturally occurring data accurately describes the prevalence of capitalization; however, it underestimates the importance humans ascribe to capitalization robustness. We propose data augmentation to fill this gap.</p><p>In this work, we:</p><p>• increase translation quality on data with different casings (compared to standard SPM), • without degrading quality for standard casing,</p><p>• and with minimal impact on decoding speed.</p><formula xml:id="formula_0">raw text This • IS • a • SHORT • PHRASE • ABOUT • a • PhD. SPM _This • _IS • _a • _S • HO • RT • _ • PH • RA • SE • _A • BO • UT • _a • _PhD • . BPE (lowercased) _this • _is • _a • _short • _phrase • _about • _a • _phd . + Berard et al. _this • &lt;T&gt; • _is • &lt;U&gt; • _a • _short • &lt;U&gt; • _phrase • &lt;U&gt; • _about • &lt;U&gt; • _a • _ph • &lt;T&gt; • d • &lt;T&gt; • .</formula><p>Etchegoyhen and Gete </p><formula xml:id="formula_1">• this • •• • is • a • •• • short • •• • phrase • •• • about • a • • • ph •˘• •• • d. + BPE _ • • _this • _ •• • _is • _a • _ •• • _short • _ •• • _phrase • _ •• • _about • _a • _ • • _ph • _˘• _ •• • _d • . our case encoding Tthis • Uis • a • Ashort • phrase • about • La • TphTd. + SPM (our method) Tthis_ • U • is_ • a_ • A • short_ • phrase • _ • about_ • L • a_ • Tph • Td • ._</formula><p>Table <ref type="table">2</ref>: Examples of various case encodings. For readability, we show case markers in green and use ' • ' for spaces between tokens. Note that our method chooses to keep Tthis as one token-since This occurs capitalized often in the data-but the U marker is segmented off from is-since that rarely occurs in ALL CAPS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Prior Work</head><p>Capitalization has been studied in NLP for nearly three decades (e.g., <ref type="bibr" target="#b4">Gale et al., 1995;</ref><ref type="bibr" target="#b22">Mikheev, 1999</ref><ref type="bibr" target="#b23">Mikheev, , 2002))</ref>. 1 Approaches vary from modeling case directly to ignoring it and increasing sparsity.</p><p>The most common method of handling capitalization, particularly in Statistical Machine Translation (SMT), was training a separate truecaser <ref type="bibr" target="#b20">(Lita et al., 2003;</ref><ref type="bibr">Koehn et al., 2007)</ref>. 2 Truecasers have fallen out of favor since they require additional preand postprocessing steps. For example, at WMT22 <ref type="bibr">(Kocmi et al., 2022)</ref> only 3/25 system descriptions from the General MT Task mention the use of truecasing models.</p><p>Another common option in SMT was using factored translation <ref type="bibr">(Koehn and Hoang, 2007)</ref> to encode capitalization as an additional linguistic feature. <ref type="bibr" target="#b19">Levin et al. (2017)</ref> used factors in NMT <ref type="bibr">(Sennrich and Haddow, 2016;</ref><ref type="bibr" target="#b5">García-Martínez et al., 2016)</ref> to encode case as additional factors on the embeddings. While factors allow the model to learn representations of capitalization, they require changes to model architecture which are complicated to deploy and not universally supported in modern NLP &amp; NMT toolkits. 3 Our proposed method is model agnostic, and requires no changes to the translation model architecture. <ref type="bibr" target="#b25">Niu et al. (2021)</ref> and <ref type="bibr" target="#b7">Hieber et al. (2022)</ref> further explored the factorized approach in combination with data aug-1 Capitalization can convey semantic meaning, particularly for word sense disambiguation terminology: e.g., Apple the company vs apple the fruit <ref type="bibr" target="#b21">(Mayhew et al., 2019;</ref><ref type="bibr" target="#b6">Gujral et al., 2016;</ref><ref type="bibr" target="#b41">Thompson et al., 2019;</ref><ref type="bibr">Alam et al., 2021)</ref>.</p><p>2 github.com/moses-smt/mosesdecoder/blob/ master/scripts/recaser/train-truecaser.perl</p><p>3 Fairseq <ref type="bibr" target="#b26">(Ott et al., 2019)</ref>, Hugging Face <ref type="bibr" target="#b44">(Wolf et al., 2020)</ref>, and NeMo <ref type="bibr" target="#b16">(Kuchaiev et al., 2019)</ref> do not have factors.</p><p>OpenNMT-py has source-side only <ref type="bibr" target="#b10">(Klein et al., 2017)</ref>. <ref type="bibr">Marian (Junczys-Dowmunt et al., 2018)</ref>, Nematus <ref type="bibr" target="#b37">(Sennrich et al., 2017)</ref> and Sockeye <ref type="bibr" target="#b7">(Hieber et al., 2022)</ref>   <ref type="bibr">(BPE, Sennrich et al., 2016)</ref> on lower cased data, and then add back a space-separated case-marker token after each token that was cased. <ref type="bibr" target="#b3">Etchegoyhen and Gete (2020)</ref> propose a variant where capitalization tokens are inserted as space-separated prefix tokens prior to learning the BPE segmentation. See Table <ref type="table">2</ref> for examples of both case encodings.</p><p>Both methods can lead to considerably longer sequences, since they force additional tokens per cased tokens/words (respectively). This drastically impacts decoding speed, particularly for long sequences, as Transformer decoders are quadratic in output length.</p><p>Despite various options for case-handling, the current standard practice in NMT is using subword segmentation-e.g., SentencePiece (SPM; Kudo and Richardson, 2018)-without dedicated case processing. This often leads to the same sentence in different capitalizations encoded very differently, since case is not segmentable.</p><p>As noted in <ref type="bibr">Kudo (2018, §3.4</ref>) SPM can be viewed as a compression method; 4 given a predefined vocab size, it will result in a (near) optimal sequence length for the training corpus. An interesting consequence of this is that a post-hoc manipulation will result in a longer sequence length. For example, adding a case marker after each to-ken after segmentation <ref type="bibr">(Berard et al., 2019)</ref> will double the sequence length of an ALL CAPS sentence. This drastically increases decoding time, particularly for long sequences, as Transformer decoders are quadratic in output length. In contrast to Berard et al. and Etchegoyhen and Gete, our case marker is not initially space-separated from the word it marks, allowing SentencePiece (SPM) to learn where to segment for an optimal length. This results in shorter sequences and faster decoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>We introduce a case encoding method ( § 3.1) with data augmentation ( § 3.2) which allows the SPM algorithm to learn to segment case markings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Case Encoding</head><p>Our encoding consists of the following steps, as demonstrated in Table <ref type="table" target="#tab_5">3</ref>.</p><p>1. Character-level tagging: pre-built case normalization tables map each cased character to a case tag + lower case character. P is used for punctuation, U is used for capitalization. 2. Word-level tagging: a state machine aggregates (1) into word-level case labels. T is used for word initial Capitalization, U is used for fully CAPITALIZED words. 3. Span tagging: A hand-tuned regex determines inter-word span labels: sequences of 3 or more words in ALL CAPS are marked with A; L denotes that the prior capitalization has ended.</p><p>After decoding, and removing the subword segmentation, these annotations are used to reconstruct the correctly cased text inside the SPM library.<ref type="foot" target="#foot_1">5</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Data Augmentation</head><p>SPM maximizes the likelihood over its training data. While naturally occurring data accurately describes the prevalence of capitalization, it underestimates the importance humans ascribe to case handling (as evidenced by poor robustness of datadriven methods to such changes). We propose data augmentation to bridge the gap. We convert a small fraction of the <ref type="bibr">(SPM and NMT model)</ref>  where markers are added per subword. 3. Etchegoyhen and Gete's inline case encoding ( § 2) where markers are added per word. 4. Our proposed case encoding method ( § 3.1).</p><p>We present experiments with data augmentation for the baseline and our case encoding for all language pairs. To ensure a thorough comparison we also add data augmentation to prior work-which did not propose augmenation-for en↔de. We use data augmentation 3% of the time for each type of augmentation. We considered 1% and 3% training data augmentation in pilot experiments. 3% worked well without quality degradation on standard test sets, so we use it throughout this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation Details</head><p>We implement our inline casing directly in the SPM library, which has several advantages:</p><p>• Drop-in replacement for standard SPM: tools with support for SPM can take advantage of the built-in case encoding without additional pre/post-processing wrappers. • Operates on raw text: no tokenization is needed, just like standard SPM. • Processing speed: the normalization in SPM which we used for the character-level tagging (see Table <ref type="table" target="#tab_5">3</ref>) is highly optimized C++ code.</p><p>We leverage the case augmentation methods available within the Marian NMT Toolkit. A fixed   <ref type="bibr">Thompson and Post (2020a,b)</ref> 9 to reduce noise <ref type="bibr" target="#b9">(Khayrallah and Koehn, 2018)</ref>.</p><formula xml:id="formula_2">0) raw text This • IS • a • SHORT • PHRASE • ABOUT • a • PhD. 1) character-level tagging Uthis • UiUs • a • UsUhUoUrUt • UpUhUrUaUsUe • UaUbUoUuUt • a • UphUdP. 2) word-level tagging Tthis • Uis • a • Ushort • Uphrase • Uabout • a • TphTd. 3) span tagging Tthis • Uis • a • Ashort • phrase • about • La • TphTd. 4) SPM Tthis_ • U • is_ • a_ • A • short_ • phrase • _ • about_ • L • a_ • Tph • Td • ._</formula><p>We train models for English↔German as an example of a high resource language pair (234M lines), plus English↔Japanese (26M lines) and English↔Russian (27M lines) to have a variety of scripts. See Appendix A.2 for data sources and filtering details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation</head><p>We evaluate on wmttest22 <ref type="bibr">(Kocmi et al., 2022)</ref>.</p><p>Robustness: We create additional synthetic robustness testsets by transforming wmttest22 to lower case, ALL CAPS, or English Title Case. We apply ALL CAPS to both the source and target. For lowercase and English Title case the target side remains unmodified; ALL CAPS is introduced only 7 Offline data prepossessing is also an augmentation option. Another option is to use a data streaming approach supporting casing augmentation, such as Sotastream <ref type="bibr">(Post et al., 2023)</ref>.</p><p>8 statmt.org/wmt22/translation-task.html 9 github.com/thompsonb/prism_bitext_filter if the source language support capitalization, and title-case only when English is the source text.</p><p>Metrics: Casing alters characters, hence we use ChrF <ref type="bibr" target="#b28">(Popović, 2015)</ref> which correlates better with human judgment than BLEU <ref type="bibr">(Kocmi et al., 2021)</ref>. See Appendix B for BLEU <ref type="bibr" target="#b27">(Papineni et al., 2002)</ref> and COMET <ref type="bibr" target="#b33">(Rei et al., 2020)</ref> scores on the unmodified wmttest22.</p><p>Speed: We report speed as the average of 3 runs on a NVIDIA Zotac Trinity 4090 GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>Table <ref type="table" target="#tab_6">4</ref> shows results on the unmodified wmttest22 and the robustness versions (ALL CAPS, lowercase, and English Title Case) for en→de. See Appendix B for de→en, en↔ru, and en↔ja. Our proposed method-case encoding + data augmentation-performs well across the board.</p><p>On unmodified data, our method performs as well as the no case encoding and no data augmentation baseline (±0.1 ChrF point); in other words, our method does not negatively impact the performance on texts with standard casing. This is not true for prior work across all language pairs: quality on the unmodified wmttest22 drops by up to 1.3 ChrF for Berard et al. (en-de) and up to 0.8 ChrF for Etchegoyhen and Gete (en-ja) when using those methods as originally proposed (i.e. without augmentation).</p><p>When evaluating in all language pairs and on all casings our encoding is within 9% of runtime of standard SPM-trained model (no case encoding) for the unmodified test set. Our minimal increases in target sequence length mean that no matter the casing of the input, the runtime will be reasonable and stable.</p><p>In contrast, prior work significantly increases time even for the standard text, by up to 38% (ende Berard et al.), which is impractical for a general MT model. The baseline is up to 4× slower on ALL CAPS (ru→en), while prior work is at least 49% slower across languages and up to 2.5× slower (de→en). Even when combining with our augmentation method, prior encodings are approximately 1.7× or 2.0× slower. wmttest22 has an average of 16 words/sentence. Since Transformer decoders are quadratic in the output sequence length, this problem is even worse with longer sequences, e.g., for full document context in a document level MT system <ref type="bibr">(Post and Junczys-Dowmunt, 2023)</ref> or a Large Language Model <ref type="bibr">(Brown et al., 2020)</ref>.</p><p>Data augmentation is crucial. Standard SPM with augmentation already matches or outperforms the quality of prior work without augmentation (at the cost of &gt;2× slower translation of ALL CAPS data, as compared to runtime of standard SPM for unmodified data). Without our proposed augmentation method, both prior works perform poorly on ALL CAPS data. Adding our augmentation improves their quality, but runtimes remain impractical. We require augmentation for high quality but then have an advantageous combination of quality and speed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>Data-driven segmentation models are not aware of case and underestimate the importance of it; prior work addresses this in a way that breaks the encoding optimality of perplexity driven methods (resulting in much longer sequence lengths). We fix both by introducing a novel case encoding that allows the SPM algorithm to learn how to segment case markings, and introducing data augmentation. Our work increases translation quality on data with different casings (compared to standard SPM), without degrading quality for standard casing, and with minimal impact on decoding speed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Limitations</head><p>While we attempt a thorough analysis, there are limitations to what we present.</p><p>We consider two different writing systems that use capitalization (Latin script, and the Cyrillic alphabet) and one that does not (Japanese) but this does not cover all writing systems. In particular, Armenian, Georgian and Greek alphabets use capitalization, but we do not demonstrate our method for them. We are limited in the total number of language pairs we can consider, and while we do not have a reason to believe this method will not extend to those alphabets, we leave that exploration to future work.</p><p>All our language pairs include English. Future work could investigate the results when translating between two morphological richer languages.</p><p>While we are able to encode mixed case words, we do not augment for them, nor do we test on them. This handles mixed case terms that occur naturally in text with reasonable frequency (e.g., PhD) but may not be ideal for some kinds of noisy text (e.g., sPoNgEbob MoCkINg texT 10 ).</p><p>Finally, while we explore different data resource levels, our work focuses on relatively higher resource language pairs. In general, low resource pairs tend to benefit more from reduction in sparsity and data augmentation. Future work could explore this method in very low resource settings, where training data tends to be far noisier, and investigate how that noise interacts with the method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Ethics Statement</head><p>This work focuses on case robustness within standard NMT models. On one hand, the ability to translate such data well can be an advantage to the person who needs/wants to understand text with non-standard casing. On the other hand, this may mean that some text that was intentionally made hard to translate through case-obfuscation is now easier to translate. raw filtered retained de↔en <ref type="bibr">295,805,439 234,074,670 79% en↔ja 33,875,119 26,218,426 77% en↔ru 38,188,399 27,427,929 72%</ref> Table <ref type="table">5</ref>: The number of lines of training data used for each language pair, before and after data filtering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Training setup</head><p>For easier replication of our experiments, we describe the training settings and datasets in details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Training parameters</head><p>We train 6+6 layer Transformer big models with 8 heads using Marian NMT <ref type="bibr" target="#b8">(Junczys-Dowmunt et al., 2018)</ref> and use a SentencePiece <ref type="bibr" target="#b18">(Kudo and Richardson, 2018)</ref> vocabulary size of 32k and the unigram model. 11 Figure <ref type="figure" target="#fig_0">1</ref> shows the Marian training and decoding parameters. The model sizes are 209M parameters.</p><p>For prior work, we follow respective setups of Berard et al. ( <ref type="formula">2019</ref>) and <ref type="bibr" target="#b3">Etchegoyhen and Gete (2020)</ref>, and use the BPE segmentation algorithm <ref type="bibr">(Sennrich et al., 2016)</ref>.</p><p>In experiments with data augmentation, we add the following parameters 12 for Marian training:</p><p>• --all-caps-every N • --all-lower-caps-every N • --english-title-case-every N with N = 33.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Datasets</head><p>We train on data from the WMT 2022 General MT Task <ref type="bibr">(Kocmi et al., 2022)</ref>. 13 Table <ref type="table">6</ref> presents the data sources used in training for each language pair. We filter the parallel data using the sentence filtering released by <ref type="bibr">Thompson and Post (2020a)</ref>. 14  Table <ref type="table">5</ref> shows the total number of lines before and after data filtering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Full results</head><p>Tables 7-11 present full results in the same format as Table <ref type="table" target="#tab_6">4</ref> on robustness wmttest22 with unmod-11 Since prior work has shown that subword vocab size is important <ref type="bibr" target="#b35">(Salesky et al., 2018;</ref><ref type="bibr" target="#b1">Ding et al., 2019;</ref><ref type="bibr" target="#b2">Duh et al., 2020)</ref> we performed a small sweep in initial experiments, and base our choice of 32k on that.</p><p>12 Available in the rjai/case_augmentations branch of marian-dev repository 13 statmt.org/wmt22/translation-task.html -2 -log exponential-smoothing: 1e-3 mini-batch-fit: true mini-batch-fit-step: 5 workspace: 13000 maxi-batch: 1000 mini-batch: 1000 mini-batch-words: 16000 max-length: 256 early-stopping: 10 valid-mini-batch: 32 beam-size: 4 normalize: 1 word-penalty: 0 ified, ALL CAPS, lower, and Title Case casing. Accuracy is computed against the reference.</p><p>Since COMET has not been well tested on differently-cased data, nor has the underlying model <ref type="bibr">(XLM-RoBERTa-base;</ref><ref type="bibr" target="#b0">Conneau et al., 2020)</ref>, in the main body of this paper we use it only to evaluate on data with original casing. In Table <ref type="table" target="#tab_11">12</ref> we compare all systems on unmodified wmttest22 using popular MT evaluation metrics.</p><p>We used SacreBLEU v2.0.0 <ref type="bibr" target="#b29">(Post, 2018)</ref> with case:mixed when computing BLEU and ChrF scores. With COMET <ref type="bibr" target="#b33">(Rei et al., 2020)</ref>, we used the wmt20-comet-da model.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Training and decoding parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell cols="2">de→en</cell><cell cols="2">en→de</cell></row><row><cell>wmttest22</cell><cell cols="4">BLEU↑ Time↓ BLEU↑ Time↓</cell></row><row><cell>Standard casing</cell><cell>48.5</cell><cell>4.1</cell><cell>46.3</cell><cell>4.4</cell></row><row><cell>ALL CAPS</cell><cell>17.4</cell><cell>12.6</cell><cell>10.4</cell><cell>12.9</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Standard training with no handling of casing produces poor quality on the ALL CAPS version of wmttest22 and increases translation time (seconds) dramatically, when compared to the unmodified version.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>have source &amp; target.</figDesc><table><row><cell>mentation in NMT. However, Hieber et al. observe</cell></row><row><cell>a 1.7-2.3 BLEU drop in quality between standard</cell></row><row><cell>and ALL CAPS text; we observe a negligible drop</cell></row><row><cell>of ≤0.1 BLEU (or ≤0.3 ChrF) in our experiments.</cell></row><row><cell>Berard et al. (2019) propose 'inline casing' for</cell></row><row><cell>capitalization robustness. Inline casing lowercases</cell></row><row><cell>all characters and then adds additional tokens to</cell></row><row><cell>indicate capitalization. Berard et al. train and apply</cell></row><row><cell>a Byte Pair Encoding subword model</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>training data to lowercase, ALL CAPS and (when applicable)</figDesc><table><row><cell>4 Experiments</cell></row><row><cell>4.1 Models</cell></row><row><cell>We train 12 layer Transformer big translation mod-</cell></row><row><cell>els using Marian NMT (Junczys-Dowmunt et al.,</cell></row><row><cell>2018) and use a SentencePiece vocabulary size of</cell></row><row><cell>32k with the unigram model. See Appendix A.1</cell></row><row><cell>for full training details. For prior work, we follow</cell></row><row><cell>their methods which use the BPE segmentation al-</cell></row><row><cell>gorithm (Sennrich et al., 2016). Our experiments</cell></row><row><cell>include:</cell></row><row><cell>1. No dedicated case encoding.</cell></row><row><cell>2. Berard et al.'s inline case encoding ( § 2)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Steps of our case encoding algorithm. We show case markers in green and use ' • ' for spaces.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">unmodified</cell><cell cols="2">ALL CAPS</cell><cell></cell><cell>lower</cell><cell></cell><cell cols="2">Title Case</cell></row><row><cell>en → de</cell><cell cols="10">ChrF↑ TrgLen↓ Time (sec)↓ ChrF↑ TrgLen↓ Time (sec)↓ ChrF↑ TrgLen↓ Time (sec)↓ ChrF↑ TrgLen↓ Time (sec)↓</cell></row><row><cell>no case encoding</cell><cell>66.2</cell><cell>24.6</cell><cell>4.4 (base) 35.2</cell><cell>43.7</cell><cell cols="2">12.9 (+195%) 63.8</cell><cell>24.8</cell><cell>4.4 (+2%) 63.3</cell><cell>24.8</cell><cell>4.4 (+1%)</cell></row><row><cell cols="2">+ our data augment 66.3</cell><cell>24.6</cell><cell>4.3 (-2%) 60.9</cell><cell>48.3</cell><cell cols="2">9.7 (+123%) 65.5</cell><cell>24.6</cell><cell>4.5 (+4%) 65.3</cell><cell>24.7</cell><cell>4.4 (+1%)</cell></row><row><cell>Berard et al.</cell><cell>64.9</cell><cell>29.7</cell><cell>6.0 (+38%) 56.9</cell><cell>42.5</cell><cell cols="2">8.9 (+104%) 63.5</cell><cell>29.0</cell><cell>5.9 (+34%) 63.4</cell><cell>30.1</cell><cell>6.0 (+38%)</cell></row><row><cell cols="2">+ our data augment 65.1</cell><cell>29.4</cell><cell>5.2 (+20%) 66.6</cell><cell>44.1</cell><cell cols="2">8.4 (+93%) 64.5</cell><cell>29.1</cell><cell>5.1 (+16%) 64.5</cell><cell>29.5</cell><cell>5.5 (+26%)</cell></row><row><cell cols="2">Etchegoyhen and Gete 66.0</cell><cell>30.0</cell><cell>5.3 (+22%) 54.6</cell><cell>38.8</cell><cell cols="2">7.5 (+72%) 64.3</cell><cell>29.7</cell><cell>5.3 (+22%) 64.4</cell><cell>30.9</cell><cell>5.8 (+33%)</cell></row><row><cell cols="2">+ our data augment 66.4</cell><cell>30.1</cell><cell>5.4 (+25%) 66.6</cell><cell>40.3</cell><cell cols="2">7.5 (+72%) 65.6</cell><cell>30.0</cell><cell>5.3 (+21%) 65.5</cell><cell>30.5</cell><cell>5.7 (+31%)</cell></row><row><cell>our case encoding</cell><cell>66.5</cell><cell>25.3</cell><cell>4.5 (+4%) 35.2</cell><cell>26.7</cell><cell>4.8</cell><cell>(+9%) 64.1</cell><cell>25.3</cell><cell>4.5 (+4%) 64.5</cell><cell>25.7</cell><cell>4.7 (+9%)</cell></row><row><cell cols="2">+ our data augment 66.3</cell><cell>25.4</cell><cell>4.6 (+5%) 66.0</cell><cell>26.9</cell><cell>4.8</cell><cell>(+9%) 65.4</cell><cell>25.3</cell><cell>4.5 (+2%) 66.5</cell><cell>25.6</cell><cell>4.7 (+9%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Results for en→de. We outperform the no case encoding baseline on ChrF and decoding time, and are less than 10% longer than the baseline's encoding of unmodified text for the case variants.</figDesc><table><row><cell>fraction of the training data is transformed dynam-</cell></row><row><cell>ically during the training for each batch, prior to</cell></row><row><cell>applying SPM. 7</cell></row><row><cell>4.3 Training Data</cell></row><row><cell>We use the WMT 2022 training data (Kocmi et al.,</cell></row><row><cell>2022) 8 -including the potentially noisy ParaCrawl</cell></row><row><cell>data (Bañón et al., 2020)-and use the sentence</cell></row><row><cell>filtering pipeline released by</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 10 :</head><label>10</label><figDesc>Results for ja→en: ChrF, target sequence length, and decoding time. Note, all results with data augmentation are our contribution; prior work did not use augmentation.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">unmodified</cell><cell></cell><cell cols="2">ALL CAPS</cell><cell></cell><cell>lower</cell></row><row><cell>ru → en</cell><cell cols="2">ChrF↑ TrgLen↓</cell><cell>Time↓</cell><cell cols="2">ChrF↑ TrgLen↓</cell><cell></cell><cell>Time↓</cell><cell>ChrF↑ TrgLen↓ Time↓</cell></row><row><cell>no case encoding</cell><cell>63.9</cell><cell>24.9</cell><cell cols="2">4.6 (base) 26.4</cell><cell>50.5</cell><cell cols="3">19.3 (+322%) 61.4</cell><cell>25.2</cell><cell>4.8 (+5%)</cell></row><row><cell cols="2">+ our data augment 63.6</cell><cell>24.9</cell><cell cols="2">4.8 (+4%) 56.4</cell><cell>52.3</cell><cell cols="3">12.0 (+161%) 62.9</cell><cell>25.0</cell><cell>4.7 (+3%)</cell></row><row><cell>Berard et al.</cell><cell>63.3</cell><cell>26.7</cell><cell cols="2">4.8 (+4%) 46.7</cell><cell>39.5</cell><cell cols="3">9.0 (+97%) 61.5</cell><cell>25.8</cell><cell>4.8 (+4%)</cell></row><row><cell cols="2">Etchegoyhen and Gete 63.6</cell><cell>26.9</cell><cell cols="2">5.0 (+8%) 46.6</cell><cell>36.7</cell><cell cols="3">8.5 (+86%) 61.4</cell><cell>26.0</cell><cell>4.9 (+6%)</cell></row><row><cell>our case encoding</cell><cell>63.9</cell><cell>25.5</cell><cell cols="2">4.8 (+6%) 32.2</cell><cell>26.1</cell><cell cols="3">6.0 (+30%) 61.9</cell><cell>25.1</cell><cell>4.8 (+4%)</cell></row><row><cell cols="2">+ our data augment 64.0</cell><cell>25.5</cell><cell cols="2">4.5 (-1%) 64.1</cell><cell>26.2</cell><cell>4.7</cell><cell cols="2">(+3%) 63.3</cell><cell>25.4</cell><cell>4.6 (+1%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 11 :</head><label>11</label><figDesc>Results for ru→en: ChrF, target sequence length, and decoding time. Note, all results with data augmentation are our contribution; prior work did not use augmentation.</figDesc><table><row><cell></cell><cell></cell><cell>en→de</cell><cell></cell><cell></cell><cell>en→ja</cell><cell></cell><cell></cell><cell>en→ru</cell><cell></cell></row><row><cell>Method</cell><cell cols="9">BLEU ChrF COMET BLEU ChrF COMET BLEU ChrF COMET</cell></row><row><cell>no case encoding</cell><cell>46.3</cell><cell>66.2</cell><cell>54.3</cell><cell>22.8</cell><cell>32.0</cell><cell>48.1</cell><cell>26.7</cell><cell>52.9</cell><cell>43.8</cell></row><row><cell>+ our data augment</cell><cell>46.3</cell><cell>66.3</cell><cell>54.3</cell><cell>22.9</cell><cell>32.0</cell><cell>47.4</cell><cell>26.9</cell><cell>52.9</cell><cell>43.0</cell></row><row><cell>Berard et al.</cell><cell>44.1</cell><cell>64.9</cell><cell>50.0</cell><cell>21.8</cell><cell>30.9</cell><cell>42.9</cell><cell>26.4</cell><cell>53.0</cell><cell>41.7</cell></row><row><cell>Etchegoyhen and Gete</cell><cell>46.5</cell><cell>66.0</cell><cell>54.0</cell><cell>22.1</cell><cell>31.2</cell><cell>44.6</cell><cell>27.2</cell><cell>53.3</cell><cell>45.8</cell></row><row><cell>our case encoding</cell><cell>46.5</cell><cell>66.5</cell><cell>54.9</cell><cell>22.8</cell><cell>31.9</cell><cell>47.6</cell><cell>27.1</cell><cell>53.2</cell><cell>46.9</cell></row><row><cell>+ our data augment</cell><cell>46.6</cell><cell>66.3</cell><cell>55.0</cell><cell>22.7</cell><cell>31.9</cell><cell>47.5</cell><cell>27.1</cell><cell>53.0</cell><cell>45.1</cell></row><row><cell></cell><cell></cell><cell>de→en</cell><cell></cell><cell></cell><cell>ja→en</cell><cell></cell><cell></cell><cell>ru→en</cell><cell></cell></row><row><cell>Method</cell><cell cols="9">BLEU ChrF COMET BLEU ChrF COMET BLEU ChrF COMET</cell></row><row><cell>no case encoding</cell><cell>48.5</cell><cell>65.2</cell><cell>54.7</cell><cell>20.0</cell><cell>46.0</cell><cell>24.5</cell><cell>38.7</cell><cell>64.0</cell><cell>49.9</cell></row><row><cell>+ our data augment</cell><cell>48.6</cell><cell>65.2</cell><cell>54.1</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>38.2</cell><cell>63.5</cell><cell>49.4</cell></row><row><cell>Berard et al.</cell><cell>46.9</cell><cell>64.3</cell><cell>51.7</cell><cell>16.9</cell><cell>43.9</cell><cell>15.8</cell><cell>37.3</cell><cell>63.3</cell><cell>49.2</cell></row><row><cell>Etchegoyhen and Gete</cell><cell>48.4</cell><cell>65.1</cell><cell>53.9</cell><cell>19.5</cell><cell>45.5</cell><cell>23.1</cell><cell>37.9</cell><cell>63.6</cell><cell>49.5</cell></row><row><cell>our case encoding</cell><cell>48.4</cell><cell>65.2</cell><cell>55.1</cell><cell>20.1</cell><cell>46.0</cell><cell>25.8</cell><cell>38.7</cell><cell>64.0</cell><cell>50.9</cell></row><row><cell cols="2">+ our data augment 48.7</cell><cell>65.3</cell><cell>55.1</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>39.0</cell><cell>64.0</cell><cell>50.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 12 :</head><label>12</label><figDesc>Results out of (top table) and into (bottom table) English on the unmodified wmttest22 testset. Since Japanese does not mark capitalization, there is no augmentation for ja→en.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0"><p>The same is true for BPE(Sennrich et al., 2016), which is a compression algorithm applied to segmentation.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1"><p>We use treat_white-space_as_suffix in SPM to suffix space markers, so case markers are the only prefix. English Title Case.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2"><p>Lower casing and English Title Case are applied to the source only; ALL CAPS is applied to both the source and target, only if the source language script supports capitalization.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3"><p>Case conventions in English titles vary, but typically all words except articles, prepositions, and conjunctions are capitalized. See en.wikipedia.org/wiki/Title_case.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We thank <rs type="person">Anthony Aue</rs>, <rs type="person">Nikolay Bogoychev</rs>, <rs type="person">Thamme Gowda</rs>, <rs type="person">Rebecca Knowles</rs>, <rs type="person">Matt Post</rs> and <rs type="person">Brian Thompson</rs> for their helpful comments and feedback on the paper.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>de-en ja-en ru-en Europarl v10 <ref type="bibr" target="#b13">(Koehn, 2005)</ref> ✓ ParaCrawl v9 <ref type="bibr">(Bañón et al., 2020)</ref> ✓ ✓ ✓ Common Crawl (statmt.org/wmt13/training-parallel-commoncrawl.tgz) ✓ ✓ News Commentary v16 (data.statmt.org/news-commentary/v16) ✓ ✓ ✓ Yandex Corpus <ref type="bibr" target="#b40">(Shmatova and Dvorkovich, 2022)</ref> ✓ Wiki Titles v3 (data.statmt.org/wikititles/v3) ✓ ✓ ✓ UN Parallel Corpus V1.0 <ref type="bibr" target="#b45">(Ziemski et al., 2016)</ref> ✓ Tilde MODEL corpus <ref type="bibr">(Rozis and Skadin , š, 2017)</ref> ✓ ✓ WikiMatrix <ref type="bibr" target="#b36">(Schwenk et al., 2021)</ref> ✓ ✓ ✓ Japanese-English Subtitle Corpus <ref type="bibr" target="#b32">(Pryzant et al., 2018)</ref> ✓ The Kyoto Free Translation Task Corpus <ref type="bibr" target="#b24">(Neubig, 2011)</ref> ✓ TED Talks <ref type="bibr">(Cettolo et al., 2012)</ref> ✓   </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">10 teenvogue.com/story/mocking-spongebobmeme-social-media Alexis</title>
		<author>
			<persName><forename type="first">Md</forename><surname>Mahfuz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ibn</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivana</forename><surname>Kvapilíková</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonios</forename><surname>Anastasopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Besacier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kartikay</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.747</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8440" to="8451" />
		</imprint>
	</monogr>
	<note>Unsupervised cross-lingual representation learning at scale. Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A call for prudent choice of subword merge operations in neural machine translation</title>
		<author>
			<persName><forename type="first">Shuoyang</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adithya</forename><surname>Renduchintala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Machine Translation Summit XVII: Research Track</title>
		<meeting>Machine Translation Summit XVII: Research Track<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>European Association for Machine Translation</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="204" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Benchmarking neural and statistical machine translation on low-resource African languages</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Language Resources and Evaluation Conference</title>
		<meeting>the 12th Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2667" to="2675" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">To case or not to case: Evaluating casing methods for neural machine translation</title>
		<author>
			<persName><forename type="first">Thierry</forename><surname>Etchegoyhen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harritxu</forename><surname>Gete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Language Resources and Evaluation Conference</title>
		<meeting>the 12th Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3752" to="3760" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Discrimination decisions for 100,000-dimensional spaces</title>
		<author>
			<persName><forename type="first">A</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenneth</forename><forename type="middle">W</forename><surname>Gale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Operations Research</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="323" to="344" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Factored neural machine translation architectures</title>
		<author>
			<persName><forename type="first">Mercedes</forename><surname>García-Martínez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Loïc</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Spoken Language Translation</title>
		<meeting>the 13th International Conference on Spoken Language Translation<address><addrLine>Seattle, Washington D.C</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>International Workshop on Spoken Language Translation</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Translation of unknown words in low resource languages</title>
		<author>
			<persName><forename type="first">Biman</forename><surname>Gujral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huda</forename><surname>Khayrallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conferences of the Association for Machine Translation in the Americas: MT Researchers&apos; Track</title>
		<meeting><address><addrLine>Austin, TX, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="163" to="176" />
		</imprint>
	</monogr>
	<note>The Association for Machine Translation in the Americas</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Felix</forename><surname>Hieber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Denkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Domhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barbara</forename><surname>Darques Barros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Celina</forename><surname>Dong Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cuong</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Nadejde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Surafel</forename><surname>Lakew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prashant</forename><surname>Mathur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Currey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2207.05851</idno>
	</analytic>
	<monogr>
		<title level="j">Sockeye</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Fast neural machine translation with pytorch</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Marian: Fast neural machine translation in C++</title>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Grundkiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomasz</forename><surname>Dwojak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Neckermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Seide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulrich</forename><surname>Germann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alham</forename><surname>Fikri Aji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolay</forename><surname>Bogoychev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">T</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName><surname>Birch</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-4020</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2018, System Demonstrations</title>
		<meeting>ACL 2018, System Demonstrations<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="116" to="121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On the impact of various types of noise on neural machine translation</title>
		<author>
			<persName><forename type="first">Huda</forename><surname>Khayrallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-2709</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Neural Machine Translation and Generation</title>
		<meeting>the 2nd Workshop on Neural Machine Translation and Generation<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="74" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">OpenNMT: Opensource toolkit for neural machine translation</title>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuntian</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2017, System Demonstrations</title>
		<meeting>ACL 2017, System Demonstrations<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="67" to="72" />
		</imprint>
	</monogr>
	<note>Jean Senellart, and Alexander Rush. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">Tom</forename><surname>Kocmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Bawden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anton</forename><surname>Dvorkovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Fishel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thamme</forename><surname>Gowda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yvette</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Grundkiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rebecca</forename><surname>Knowles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Makoto</forename><surname>Morishita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masaaki</forename><surname>Nagata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toshiaki</forename><surname>Nakazawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michal</forename><surname>Novák</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Popel</surname></persName>
		</author>
		<title level="m">Maja Popović, and Mariya Shmatova. 2022. Findings of the 2022 conference on machine translation</title>
		<meeting><address><addrLine>Abu Dhabi</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="1" to="45" />
		</imprint>
	</monogr>
	<note>Proceedings of the Seventh Conference on Machine Translation</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Hitokazu Matsushita, and Arul Menezes. 2021. To ship or not to ship: An extensive evaluation of automatic metrics for machine translation</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Kocmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Grundkiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Conference on Machine Translation</title>
		<meeting>the Sixth Conference on Machine Translation</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="478" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Europarl: A parallel corpus for statistical machine translation</title>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Machine Translation Summit X: Papers</title>
		<meeting>Machine Translation Summit X: Papers<address><addrLine>Phuket, Thailand</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Factored translation models</title>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)</title>
		<meeting>the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="868" to="876" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evan</forename><surname>Herbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions</title>
		<meeting>the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume the Demo and Poster Sessions<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Oleksii</forename><surname>Kuchaiev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huyen</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleksii</forename><surname>Hrinchuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Leary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Ginsburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Kriman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stanislav</forename><surname>Beliaev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Lavrukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Cook</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.09577</idno>
		<title level="m">Nemo: a toolkit for building ai applications using neural modules</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Subword regularization: Improving neural network translation models with multiple subword candidates</title>
		<author>
			<persName><forename type="first">Taku</forename><surname>Kudo</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1007</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="66" to="75" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">SentencePiece: A simple and language independent subword tokenizer and detokenizer for neural text processing</title>
		<author>
			<persName><forename type="first">Taku</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Richardson</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-2012</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="66" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Toward a fullscale neural machine translation in production: the booking.com use case</title>
		<author>
			<persName><forename type="first">Pavel</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nishikant</forename><surname>Dhanuka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Talaat</forename><surname>Khalil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fedor</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxim</forename><surname>Khalilov</surname></persName>
		</author>
		<idno>CoRR, abs/1709.05820</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">Lucian</forename><surname>Vlad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lita</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Abe</forename><surname>Ittycheriah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nanda</forename><surname>Kambhatla</surname></persName>
		</author>
		<idno type="DOI">10.3115/1075096.1075116</idno>
		<title level="m">Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sapporo, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="152" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">ner and pos when nothing is capitalized</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Mayhew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatiana</forename><surname>Tsygankova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1650</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6256" to="6261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A knowledge-free method for capitalized word disambiguation</title>
		<author>
			<persName><forename type="first">Andrei</forename><surname>Mikheev</surname></persName>
		</author>
		<idno type="DOI">10.3115/1034678.1034710</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 37th Annual Meeting of the Association for Computational Linguistics<address><addrLine>College Park, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="159" to="166" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Periods, capitalized words, etc</title>
		<author>
			<persName><forename type="first">Andrei</forename><surname>Mikheev</surname></persName>
		</author>
		<idno type="DOI">10.1162/089120102760275992</idno>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="289" to="318" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<ptr target="http://www.phontron.com/kftt" />
		<title level="m">The Kyoto free translation task</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Faithful target attribute prediction in neural machine translation</title>
		<author>
			<persName><forename type="first">Xing</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prashant</forename><surname>Mathur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Currey</surname></persName>
		</author>
		<idno>CoRR, abs/2109.12105</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">fairseq: A fast, extensible toolkit for sequence modeling</title>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexei</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-4009</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="48" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.3115/1073083.1073135</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">chrF: character n-gram F-score for automatic MT evaluation</title>
		<author>
			<persName><forename type="first">Maja</forename><surname>Popović</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W15-3049</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Workshop on Statistical Machine Translation</title>
		<meeting>the Tenth Workshop on Statistical Machine Translation<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="392" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A call for clarity in reporting BLEU scores</title>
		<author>
			<persName><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-6319</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Machine Translation: Research Papers</title>
		<meeting>the Third Conference on Machine Translation: Research Papers<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="186" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Sotastream: A streaming approach to machine translation training</title>
		<author>
			<persName><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thamme</forename><surname>Gowda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Grundkiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huda</forename><surname>Khayrallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rohit</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Escaping the sentence-level paradigm in machine translation</title>
		<author>
			<persName><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">JESC: Japanese-English subtitle corpus</title>
		<author>
			<persName><forename type="first">Reid</forename><surname>Pryzant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youngjoo</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Britz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)</title>
		<meeting>the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)<address><addrLine>Miyazaki, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA)</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">COMET: A neural framework for MT evaluation</title>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Rei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Craig</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ana</forename><forename type="middle">C</forename><surname>Farinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.213</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2685" to="2702" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Tilde MODEL -multilingual open data for EU languages</title>
		<author>
			<persName><forename type="first">Roberts</forename><surname>Rozis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raivis</forename><surname>Skadin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st Nordic Conference on Computational Linguistics</title>
		<meeting>the 21st Nordic Conference on Computational Linguistics<address><addrLine>Gothenburg</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="263" to="265" />
		</imprint>
	</monogr>
	<note>Sweden</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Optimizing segmentation granularity for neural machine translation</title>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Salesky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Runge</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.08641</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Alex Coda, Jan Niehues, and Graham Neubig</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Wiki-Matrix: Mining 135M parallel sentences in 1620 language pairs from Wikipedia</title>
		<author>
			<persName><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuo</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyu</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.eacl-main.115</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1351" to="1361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Nematus: a toolkit for neural machine translation</title>
		<author>
			<persName><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Hitschler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Läubli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Valerio Miceli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jozef</forename><surname>Barone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Mokry</surname></persName>
		</author>
		<author>
			<persName><surname>Nȃdejde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Software Demonstrations of the 15th Conference of the European Chapter</title>
		<meeting>the Software Demonstrations of the 15th Conference of the European Chapter<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="65" to="68" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Linguistic input features improve neural machine translation</title>
		<author>
			<persName><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W16-2209</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Conference on Machine Translation</title>
		<meeting>the First Conference on Machine Translation<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="83" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Neural machine translation of rare words with subword units</title>
		<author>
			<persName><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1162</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1715" to="1725" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">Mariya</forename><surname>Shmatova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anton</forename><surname>Dvorkovich</surname></persName>
		</author>
		<title level="m">Sakhatyla dataset</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">HABLex: Human annotated bilingual lexicons for experiments in machine translation</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rebecca</forename><surname>Knowles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huda</forename><surname>Khayrallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1142</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1382" to="1387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Automatic machine translation evaluation in many languages via zero-shot paraphrasing</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.8</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="90" to="121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Paraphrase generation as zero-shot multilingual translation: Disentangling semantic similarity from lexical and syntactic diversity</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Conference on Machine Translation</title>
		<meeting>the Fifth Conference on Machine Translation</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="561" to="570" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Remi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariama</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName><surname>Rush</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-demos.6</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The United Nations parallel corpus v1.0</title>
		<author>
			<persName><forename type="first">Michał</forename><surname>Ziemski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruno</forename><surname>Pouliquen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)<address><addrLine>Portorož, Slovenia</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA)</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3530" to="3534" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
