<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Generation of Korean Offensive Language by Leveraging Large Language Models via Prompt Design</title>
				<funder ref="#_pCMpC9A">
					<orgName type="full">Korea government</orgName>
				</funder>
				<funder>
					<orgName type="full">National Research Foundation of Korea</orgName>
					<orgName type="abbreviated">NRF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jisu</forename><surname>Shin</surname></persName>
							<email>jisu.shin@kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Korea Advanced Institute of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hoyun</forename><surname>Song</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Korea Advanced Institute of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Huije</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Korea Advanced Institute of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fitsum</forename><surname>Gaim</surname></persName>
							<email>fitsum.gaim@kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Korea Advanced Institute of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jong</forename><forename type="middle">C</forename><surname>Park</surname></persName>
							<email>jongpark@kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Korea Advanced Institute of Science and Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Generation of Korean Offensive Language by Leveraging Large Language Models via Prompt Design</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3F617C8B7F46BA01E221A62F0C54EF18</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-05-29T14:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Warning: This paper contains content that can be offensive or upsetting.</p><p>The research for detecting offensive language on online platforms has much advanced. However, the majority of these studies have primarily focused on English. Given the unique characteristics of offensive language, where social and cultural contexts significantly influence content understanding, language-specific datasets are essential. Acquiring comprehensive datasets in Korean, a less-resourced language, has mostly relied on human annotations, suffering from inherent limitations in terms of labor intensity and potential annotator bias. Automatic generation of datasets using generative methods offers an alternative approach to address these limitations, yet faces challenges in capturing linguistic and cultural diversities while maintaining native-level fluency. To address these challenges, we introduce a prompt design methodology, Korean Offensive language Machine Generation (K-OMG), using large language models. By manipulating three prompt factors, we find an effective prompt design to generate culturally aligned offensive language with fluent expressions. Experimental results demonstrate the high quality and utility of our automatically generated dataset. Our detailed analysis shows that the proposed approach achieves exceptional fluency in generating texts while effectively incorporating social and cultural diversities.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Online platforms are prominent channels for disseminating and proliferating hatred and aggression. Several studies have been dedicated to automating the detection and identification of such offensiveness in social media platforms as a means to combat various instances of offensive language <ref type="bibr" target="#b14">(Davidson et al., 2017;</ref><ref type="bibr" target="#b65">Zampieri et al., 2019;</ref><ref type="bibr" target="#b60">Wiegand et al., 2021;</ref><ref type="bibr" target="#b45">Röttger et al., 2021;</ref><ref type="bibr" target="#b12">Casula and Tonelli, 2023)</ref>. As each study focused on distinct facets of offensiveness, ranging from identifying lexical profanity <ref type="bibr" target="#b48">(Saleem et al., 2017;</ref><ref type="bibr" target="#b40">Pedersen, 2019;</ref><ref type="bibr" target="#b25">Koufakou et al., 2020)</ref> to recognizing the targets subjected to offensive language <ref type="bibr" target="#b65">(Zampieri et al., 2019;</ref><ref type="bibr" target="#b54">Song et al., 2021)</ref>, a variety of datasets have been developed to address these specific areas of interest.</p><p>However, reproducing these studies in other languages presents significant challenges, particularly in low-or less-resourced languages where limited sources are available for data collection <ref type="bibr" target="#b58">(Waseem, 2016;</ref><ref type="bibr" target="#b28">Lee et al., 2023)</ref>. The manifestation of offensive language on online platforms frequently reflects underlying social and cultural phenomena. Hence, it is imperative to develop a comprehensive dataset that captures the distinct social and cultural dynamics specific to each country and its corresponding languages <ref type="bibr" target="#b19">(Hu et al., 2020;</ref><ref type="bibr">Park et al., 2021a;</ref><ref type="bibr" target="#b20">Jeong et al., 2022;</ref><ref type="bibr" target="#b28">Lee et al., 2023)</ref>.</p><p>Efforts for the Korean language, which is a relatively low-resourced language, have focused on obtaining abundant high-quality data through human annotation <ref type="bibr">(Moon et al., 2020;</ref><ref type="bibr" target="#b20">Jeong et al., 2022)</ref>. However, a human annotation has inherent limitations such as being highly labor-intensive <ref type="bibr" target="#b16">(Founta et al., 2018;</ref><ref type="bibr" target="#b69">Zhu et al., 2023)</ref>, and the quality of the constructed data can be significantly influenced by the expertise level and potential biases of the annotators involved <ref type="bibr" target="#b58">(Waseem, 2016;</ref><ref type="bibr" target="#b49">Sap et al., 2022)</ref>.</p><p>The alternative approaches entail leveraging generative methods that automate the production of the necessary data <ref type="bibr" target="#b31">(Liu et al., 2020;</ref><ref type="bibr" target="#b62">Wullach et al., 2021)</ref>. Additionally, leveraging Large Language Models (LLMs) like GPT-3 <ref type="bibr" target="#b8">(Brown et al., 2020)</ref> allows the generation of human-like text, enhancing expression diversity <ref type="bibr" target="#b18">(Hartvigsen et al., 2022)</ref>. However, applying existing generative methods to less-resourced languages presents a couple of challenges. First, understanding offensive language is highly influenced by social and cultural contexts <ref type="bibr">(Reichelmann et al., 2021;</ref><ref type="bibr" target="#b28">Lee et al., 2023)</ref>, necessitating the inclusion of diverse social and cultural aspects in datasets <ref type="bibr">(Park et al., 2021a;</ref><ref type="bibr">Lee et al., 2022b;</ref><ref type="bibr" target="#b51">Shekhar et al., 2022;</ref><ref type="bibr" target="#b4">Arango Monnar et al., 2022)</ref>. Second, it is challenging to ensure fluency that captures real-life language usage and avoids awkwardness such as translationese when applied to non-English languages <ref type="bibr" target="#b5">(Armengol-Estapé et al., 2022)</ref>.</p><p>To address these challenges, we propose Korean Offensive language Machine Generation (K-OMG) for generating culturally aligned offensive language with fluent expressions using LLMs by designing the prompt. Through empirical investigation, we categorized the prompt with three key factors: demonstration, instruction, and context. By manipulating these factors, we successfully controlled the levels of fluency and incorporated cultural backgrounds into the generated content, resulting in a high-quality dataset without human annotation.</p><p>In this paper, we aim to generate offensive language detection datasets using LLMs, focusing on non-English languages such as Korean. This work contributes to the development of effective prompts for text generation in non-English languages. By tapping into the prompt design with the three factors above, we unlock the potential of LLMs for languages with much smaller resources compared to English. We evaluate the quality and utility of the LLM-generated dataset for Korean offensive language detection by comparing it with existing gold datasets. The detailed analysis of the generated dataset shows its exceptional fluency and successful integration of social and cultural diversities. For further studies, we release our prompt design and the K-OMG dataset publicly<ref type="foot" target="#foot_0">1</ref> .</p><p>2 Related Work</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Non-English Datasets</head><p>In order to detect offensive texts online, several studies have introduced offensive language detection datasets <ref type="bibr" target="#b14">(Davidson et al., 2017;</ref><ref type="bibr" target="#b65">Zampieri et al., 2019)</ref> and examined linguistic characteristics of offensiveness <ref type="bibr" target="#b60">(Wiegand et al., 2021;</ref><ref type="bibr" target="#b45">Röttger et al., 2021;</ref><ref type="bibr" target="#b12">Casula and Tonelli, 2023)</ref>. However, most offensive language detection datasets and studies have predominantly focused on English, overlooking challenges in applying such advancements and techniques to other languages.</p><p>Data Creation Several studies have focused on collecting texts from a range of sources and annotating various labels in low-or less-resourced languages, such as Arabic <ref type="bibr" target="#b33">(Mubarak et al., 2022)</ref>, Croatian <ref type="bibr" target="#b51">(Shekhar et al., 2022)</ref>, Dutch <ref type="bibr" target="#b10">(Caselli et al., 2021;</ref><ref type="bibr" target="#b46">Ruitenbeek et al., 2022)</ref>, Indian <ref type="bibr" target="#b50">(Saroj and Pal, 2020)</ref>, and Korean <ref type="bibr">(Lee et al., 2022b;</ref><ref type="bibr" target="#b63">Yang et al., 2022)</ref>. Although high-quality data is attainable through extensive human annotation, there are inherent limitations in data collection and annotation, requiring a lot of cost and labor <ref type="bibr" target="#b16">(Founta et al., 2018)</ref>. In addition, the expertise of annotators may affect the quality of the data <ref type="bibr" target="#b58">(Waseem, 2016)</ref>, and existing data may not adequately address emerging words and topics, such as the rise of anti-Asian sentiments following <ref type="bibr">COVID-19 (An et al., 2021)</ref>.</p><p>Our proposed approach, in contrast, mitigates these issues by leveraging a generative method, avoiding the need for labor-intensive annotation.</p><p>Translated Dataset Some studies handling limited resources have utilized translated versions of the English benchmark dataset in less-resourced languages <ref type="bibr" target="#b11">(Casula and Tonelli, 2020;</ref><ref type="bibr" target="#b7">Biradar et al., 2021;</ref><ref type="bibr" target="#b53">Shin et al., 2022)</ref>. However, relying solely on an automatic translation of English datasets is not sufficient due to well-known issues such as translationese <ref type="bibr" target="#b24">(Koppel and Ordan, 2011;</ref><ref type="bibr" target="#b55">Volansky et al., 2015)</ref>. The simple translation approach also presents challenges as the translated data may not capture the complete usage patterns and cultural nuances of the target languages <ref type="bibr" target="#b19">(Hu et al., 2020;</ref><ref type="bibr" target="#b28">Lee et al., 2023)</ref>. In comparison, our approach utilizes in-context learning methods to generate texts that authentically capture the language of native speakers and effectively incorporate cultural aspects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Data Generative Methods</head><p>In order to avoid the need for manual data annotation, some studies employed data generation techniques to augment datasets. These studies augmented offensive language datasets using generative models, such as RNN <ref type="bibr" target="#b44">(Rizos et al., 2019)</ref>, GAN <ref type="bibr" target="#b9">(Cao and Lee, 2020)</ref>, and GPT-2 <ref type="bibr" target="#b62">(Wullach et al., 2021;</ref><ref type="bibr" target="#b12">Casula and Tonelli, 2023;</ref><ref type="bibr" target="#b35">Ocampo et al., 2023)</ref>. Advanced LLMs have the ability to generate human-like datasets for several NLP tasks <ref type="bibr" target="#b57">(Wang et al., 2021;</ref><ref type="bibr" target="#b47">Sahu et al., 2022)</ref>, and can even generate instructions to facilitate their self-learning process <ref type="bibr" target="#b56">(Wang et al., 2022)</ref>. Furthermore, <ref type="bibr" target="#b18">Hartvigsen et al. (2022)</ref> generated implicit offensive language using GPT-3 with only a few numbers of demonstrations.</p><p>However, applying such generative methods to non-English languages for offensive language dataset augmentation or generation remains challenging, given the need to capture linguistic and cultural diversities while maintaining fluency <ref type="bibr" target="#b28">(Lee et al., 2023)</ref>. Furthermore, current pre-trained language models, including LLMs, have limited exposure to non-English data <ref type="bibr" target="#b8">(Brown et al., 2020;</ref><ref type="bibr" target="#b66">Zhao and Schütze, 2021)</ref>, hindering their performance on non-English NLP tasks compared to human capability <ref type="bibr" target="#b52">(Shi et al., 2022;</ref><ref type="bibr" target="#b5">Armengol-Estapé et al., 2022;</ref><ref type="bibr" target="#b6">Artetxe et al., 2022)</ref>. In this work, we aim to optimize generative methods for generating fluent texts in less-resourced languages by designing effective prompt factors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>In this section, we propose Korean Offensive language Machine Generation (K-OMG), a prompt design methodology to generate a dataset for Korean offensive language detection. We aim to address the challenge of generating non-English text with high fluency and incorporating cultural content, which still remains a difficult task for LLMs</p><p><ref type="foot" target="#foot_1">2</ref> .</p><p>An overview of our prompt structure is shown in Figure <ref type="figure">1</ref>. In our search for an appropriate prompt, we organize our prompts to include a jailbreak prompt and three key factors: demonstration, instruction, and context. We describe the details of each factor in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Jailbreak Prompt</head><p>To adhere to ethical guidelines, recent AI models are strictly prohibited from generating harmful content. Therefore, we employ the jailbreak prompt to elicit unrestricted hate speech from the models. Through our pilot test, we searched for the proper jailbreak prompt, which makes responses like those of Korean online users, and we selected Universal Jailbreak<ref type="foot" target="#foot_2">3</ref> (see the Ethics Statement section).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The Three Prompt Factors</head><p>DEMONSTRATION A demonstration is an example that is provided to a language model and allows the model to learn involved tasks. The language model can answer through in-context learning based on the input demonstration. Depending on the number of demonstrations used, a learning method can be categorized as zero-shot, one-shot, or few-shot.</p><p>To investigate the influence of demonstrations' language on the quality of generated abusive texts, we vary the language used in the demonstrations between English and Korean.</p><p>INSTRUCTION Instruction is a statement that directly commands the model to perform a specific task. With the advent of InstructGPT <ref type="bibr" target="#b36">(Ouyang et al., 2022)</ref>, the ability of LLMs has evolved to follow human instructions and communicate with humans in natural language. Prior work demonstrated that asking LLMs questions in English mostly performed better, even when examples were provided in non-English languages or multiple languages other than English <ref type="bibr" target="#b52">(Shi et al., 2022)</ref>. Our objective is to determine if there are differences in the results obtained under two different conditions. Specifically, we provide the instruction in English or Korean.</p><p>CONTEXT Context is a statement that is located at the end of a prompt and used as a pre-specified condition for conditional text generation. When considering the high-context culture in Korea <ref type="bibr" target="#b32">(Merkin, 2009)</ref>, it turns out that it is very difficult to detect Korean offensive language without context <ref type="bibr">(Park et al., 2021a;</ref><ref type="bibr" target="#b20">Jeong et al., 2022)</ref>. We assume that generating offensive texts based on context would be appropriate for Korean offensive language data. Thus, we investigate whether the provision of contextual sentences affects the quality of generated abuse texts (with and without).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Designing Prompt Factors</head><p>In this section, we construct a prompt by combining three prompt factors: demonstration D, instruction I, and context C.</p><p>For demonstration D, we vary the language of demonstration between English D E and Korean D K . In this work, we only focus on few-shot prompting, similar to the approach proposed by <ref type="bibr" target="#b18">Hartvigsen et al. (2022)</ref>, who used 5-shots. We employ a k-shot setup, where each shot consists of a pair of context statement d and offensive comment d</p><p>′ . The k-shot demonstration statements allow language models to be exposed to examples and to learn statements to generate. This gives rise to the formulation of the following demonstration D:</p><formula xml:id="formula_0">D = (d 1 , d ′ 1 , ..., d k , d ′ k )</formula><p>Instruction I is a fixed command to generate offensive language. We carefully selected the instruction among handcrafted candidates with iterative validation. We deliver identical content to models, only in different languages: either English I E or Korean I K .</p><p>Context C guides models to generate culturally relevant text. We manipulate the provision of context C to investigate if providing context could result in diverse and fluent Korean hate speech generation. For with condition C w , we give a Korean text from social media written by a Korean user; while for without condition C w/o , we do not give any context statement.</p><p>The final prompt P consists of the concatenation of the jailbreak prompt J, demonstrations D x , instruction I y , and context C z . The prompt is given to a generative model M , and the model M is expected to generate an offensive expression g as follows:</p><formula xml:id="formula_1">P x,y,z = J ⊕ D x ⊕ I y ⊕ C z g x,y,z = M (P x,y,z )</formula><p>where ⊕ is text concatenation operation, x and y are language of D and I, and z means with or without condition of context C.</p><p>Finally, a machine-generated Korean offensive language dataset G consists of the given context statements and the generated comments. We provide detailed statements of prompt in Appendix A.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments for Data Quality Evaluation</head><p>In this section, we compare prompt designs of eight combinations D x × I y × C z . We conducted both automatic evaluation and human evaluation to assess the quality of the generated comments g x,y,z .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>Datasets for Prompt Factors As we provide demonstration statements of distinct languages, we used two datasets. CADD <ref type="bibr" target="#b54">(Song et al., 2021)</ref> is utilized for English demonstration D E and KOLD <ref type="bibr" target="#b20">(Jeong et al., 2022)</ref> is employed for Korean demonstration D K . Both datasets comprise instances paired with context statements and target comments, which are collected from Reddit or YouTube and online news articles. We randomly selected k offensive demonstrations from their train sets for the corresponding language.</p><p>For the statements of context C z , we used Korean Twitter texts collected from 2018 to 2020. We filtered out texts whose lengths are smaller than 10 characters. We masked individually identifiable information such as usernames, email addresses, or URLs with special tokens (see Appendix A.1 for details). Models for Generation We employed three generative LLMs: gpt-3.5-turbo, text-davinci-003 <ref type="bibr" target="#b8">(Brown et al., 2020;</ref><ref type="bibr" target="#b36">Ouyang et al., 2022)</ref> <ref type="foot" target="#foot_3">4</ref> , and polyglot-ko-5.8b <ref type="bibr" target="#b23">(Ko et al., 2022)</ref>, denoted as turbo, davinci, and polyglot, respectively. turbo and davinci are multilingual LLMs, while polyglot is an LLM based on Korean corpora. The number of demonstrations, k, is set to 5 for turbo and davinci, while 3 for polyglot. This is because polyglot can only handle 2K tokens as input, which are half of the other models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Automatic Evaluation Metrics</head><p>We seek a prompt design that generates highly diverse texts to avoid bias on specific words and topics <ref type="bibr" target="#b42">(Qian et al., 2019;</ref><ref type="bibr" target="#b41">Prabhumoye et al., 2021;</ref><ref type="bibr" target="#b67">Zhu and Bhat, 2021;</ref><ref type="bibr">Ashida and Komachi, 2022)</ref>. Also, we aim for the generated texts to accurately reflect the offensive intent conveyed in the provided instructions. To evaluate the quality of this aspect, we employed three metrics: SELF-BLEU, Token Diversity, and Toxicity.</p><p>• SELF-BLEU <ref type="bibr" target="#b68">(Zhu et al., 2018)</ref> evaluates the inter-similarity of a comment instance and the generated text set by quantifying the level of ngram overlap. A lower SELF-BLEU indicates a higher degree of diversity.</p><p>• Token Diversity is the vocabulary size of a generated dataset. A larger number indicates higher token diversity.</p><p>• Toxicity is measured by PerspectiveAPI (Google Jigsaw, 2021), the multilingual toxicity detection system, which can also assess the toxicity levels of Korean statements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Human Evaluation Metrics</head><p>We also assess the quality of generated texts from the viewpoint of humans to validate if the texts were well generated as we intended. For human evaluation, we randomly selected 80 turbogenerated samples (8 conditions × 10 samples derived from each distinguished prompt design). Five evaluators, who are native speakers of Korean, measured the quality on four metrics: HumanOrAI, Relevance, Offensiveness, and Fluency.</p><p>• HumanOrAI We asked annotators whether the comments seemed to have been written by a human or a machine <ref type="bibr" target="#b18">(Hartvigsen et al., 2022;</ref><ref type="bibr" target="#b5">Armengol-Estapé et al., 2022)</ref>.</p><p>• Relevance refers to how suitable the generated offensive texts are for the given context statements. In the text generation tasks, including counter-speech generation, researchers evaluate the context-alignment between input and output texts <ref type="bibr" target="#b67">(Zhu and Bhat, 2021;</ref><ref type="bibr" target="#b13">Chung et al., 2021;</ref><ref type="bibr">Lee et al., 2022a)</ref>.</p><p>• Offensiveness of generated texts is evaluated again by Korean native speakers because of the characteristics of offensive language, which is highly dependent on the sociocultural background <ref type="bibr" target="#b28">(Lee et al., 2023)</ref>. Our objective is to validate the alignment between the perception of models and humans regarding the generated offensive language.</p><p>• Fluency The degree of fluency is rated for each comment. We asked annotators to focus on the linguistic characteristics of Korean Internet users rather than the grammatical correctness when assessing fluency.</p><p>The results on the last three metrics were measured on a 5-point Likert scale, in which higher scores suggest better quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Ethical Consideration</head><p>Our annotation task was approved by Korea Advanced Institute of Science and Technology Institutional Review Board (IRB)<ref type="foot" target="#foot_4">5</ref> , and the informed consent was read and acknowledged by annotators prior to their tasks<ref type="foot" target="#foot_5">6</ref> . We followed ethical guidelines to protect annotators from any hazards posed by offensive texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Experimental Results</head><p>We generated G with 100 offensive comments for each model and each prompt design. The results of the automatic evaluation and the human evaluation are reported in Tables <ref type="table">1</ref> and<ref type="table" target="#tab_3">2</ref>, and Figure <ref type="figure" target="#fig_1">2</ref>.</p><p>We measured the inter-annotator agreement over four human evaluation metrics. Human evaluators showed a high agreement on the HumanOrAI (Cronbach's α=0.66). For the other three metrics, Relevance, Offensiveness, and Fluency, Cronbach's α values are 0.26, 0.91, and 0.65, respectively. This means that annotators regarded Offensiveness and Fluency from highly similar perspectives but differed in rating Relevance.</p><p>The large multilingual LLMs are better than the monolingual LLM. As shown in Table <ref type="table">1</ref>, polyglot shows worse scores in SELF-BLEU and toxicity than two multilingual LLMs since polyglot fails to generate offensive language in all conditions. Moreover, it fails to generate meaningful text. Although it is a Korean LLM, it usually generates English sentences by following some parts of the given demonstration, even repeating meaningless tokens such as emojis, @username, and URL addresses. Polyglot achieves high token diversity, but it is derived from meaningless tokens. By contrast, turbo and davinci show great performance in prompt understanding. Turbo shows better performance in context-aligned speech; however, when the instructions are given in Korean, it fails to generate offensive language (e.  Table <ref type="table">1</ref>: Experimental results of automatic evaluation. Scales marked with (-) mean that the lower the score is, the better the data (G) quality is. Conversely, those with (+) imply that the higher the score is, the better the quality is.</p><p>Self-B represents SELF-BLEU, which measures the coherence of the generated texts. Div. represents token diversity, the number of unique vocabulary tokens utilized. Tox. represents PerspectiveAPI toxicity level. Bold numbers and underlined numbers are the first and second best quality groups according to post hoc tests, respectively (see  translationese and lower context-relatedness than turbo.</p><p>Korean demonstrations lead to lower SELF-BLEU scores and more human-like speech. When the demonstrations are given in Korean (D K ), the diversity of G is enhanced (see SELF-BLEU scores in Table <ref type="table">1</ref>). Even if G of Korean demonstrations repeats the entity words of the given demonstration, it has diverse sentences that include various topic words. In addition, by referring to the fluency score in Table <ref type="table" target="#tab_3">2</ref> and humanlike ratio in Figure <ref type="figure" target="#fig_1">2</ref>, we find that in-context learning from Korean demonstrations makes models speak fluently by following the characteristics of the Korean offensive language. Generated comments, which are from three out of four Korean demonstration conditions, achieve more than 70% beyond-machine qualities.</p><p>English instruction is much more powerful in delivering the instructor's intention. As mentioned earlier, the generative models usually fail to generate offensive language when instructions are given in Korean (I K ). This phenomenon was also confirmed by the toxicity level of the model and the offensive score under the annotators (see Table <ref type="table">1</ref> and<ref type="table" target="#tab_3">Table 2</ref>, respectively). Both Perspec-tiveAPI and human annotators perceived low of- fensiveness from Gs of Korean instruction conditions. We hypothesize that these failures come from the mismatch in the languages between the given instruction (Korean) and instructions that the model was mainly learned in (English) <ref type="bibr" target="#b66">(Zhao and Schütze, 2021;</ref><ref type="bibr" target="#b36">Ouyang et al., 2022;</ref><ref type="bibr" target="#b64">Yong et al., 2023)</ref>. There is also a possibility of the effect of language mismatch between the given instruction and the jailbreak prompt.</p><p>Context statements enhance both the diversity and fluency levels of text generations. In Table <ref type="table">1</ref>, it is observed that the with-context conditions (C w ) achieve lower SELF-BLEU scores and a higher degree of diversity. When context statements are not provided, the models usually create monotonous and short comments. These comments BEEP 65.3 (-12.7) 71.9 (-6.6) 65.3 (-12.6) 69.2 (-9.6) 72.5 (-6.6) 69.1 (-9.7) 73.5 (-8.0) 73.8 (-7.9) 72.9 (-8.6) 73.7 (-7.1) 75.5 (-5.4) 73.7 (-7.1) K-OMG 67.1 (-10.9) 70.6 (-7.9) 67.1 (-10.8) 68.2 (-10.6) 74.5 <ref type="bibr">(-4.6)</ref> 68.1 (-10.7) 74.1 (-7.4) 74.2 (-7.5) 74.1 (-7.4) 74.5 (-6.3) 76.3 (-4.6) 74.5 (-6.3) KOLD+EDA 73.8 (-4.2) 75.0 (-3.5) 73.8 (-4.1) 74.9 (-3.9) 75.5 <ref type="bibr">(-3.6)</ref> 74.9 (-3.9) 79.2 (-2.5) 79.2 (-2.5) 78.5 (-3.0) 79.1 (-1.7) 79.8 (-1.1) 79.1 (-1.7) KOLD+Translated 64.9 (-13.1) 69.3 (-9.2) 74.7 (-3.2) 68.6 (-10.2) 72.7 (-6.4) 68.5 <ref type="bibr">(-10.3)</ref>  Translated 65.2 (-9.7) 73.8 (-6.2) 60.9 (-13.4) 69.8 (-4.9) 78.3 (-3.2) 63.9 (-6.1) 70.2 (-5.5) 72.6 (-7.1) 74.2 (-3.2) 69.4 (-5.9) 71.8 (-5.4) 74.2 (-0.7) KOLD 68.2(-6.7) 72.7 (-7.3) 69.9 (-4.4) 69.6 (-5.1) 78.5 (-3.0) 72.6 (+2.6) 70.5 (-5.2) 73.2 (-6.5) 74.9 (-2.5) 73.8 (-1.5) 76.7 (-0.5) 74.9 (+0.0)</p><p>K-OMG 67.1 (-7.8) 74.2 (-5.8) 66.9 (-7.4) 74.9 (+0.2) 80.5 (-1.0) 73.1 (+3.1) 70.4 (-5.3) 73.2 (-6.5) 74.9 (-2.5) 74.9 (-0.4) 79.8 (+2.6) 75.0 (+0.1) BEEP+EDA 70.1 (-4.8) 73.8 (-6.2) 72.9 (-1.4) 70.0 (-4.7) 74.0 (-7.5) 72.2 (+2.2) 74.5 (-1.2) 77.8 (-1.9) 76.7 (-0.7) 74.9 (-0.4) 77.9 (+0.7) 77.6 (+2.7)   are mostly short statements insulting individuals by using some specific profanity words (e.g., 개* 끼(bas*ard), 쓰레기(trash)). On the other hand, in with-context conditions, the offensive comments cover diverse topics and targets related to the given context. In addition, context conditions lead to a remarkable point with respect to culture. Perspec-tiveAPI judged that prompts without context resulted in more toxic language (toxicity in Table <ref type="table">1</ref>); on the contrary, Korean native annotators, who possess context-based understanding, found that prompts with context led to more offensive comments (offensiveness in Table <ref type="table" target="#tab_3">2</ref>). We see that withcontext prompts are appropriate to elicit Koreanstyle offensive language that includes aggression even without explicit expression.</p><p>Based on our analysis, P K,E,w is selected as an optimized prompt design. We assume that prompts containing Korean demonstrations, English instruction, and context statements lead the model to generate high-quality Korean offensive language. To achieve cost-effective generation, we opted to utilize turbo to generate the Korean offensive lan-guage dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Korean Offensive Language Detection</head><p>In this section, we validate the utility of machinegenerated datasets by K-OMG. Our detection task is binary classification, distinguishing between offensive and non-offensive texts. We conducted two major experiments in a cross-domain setting and an augmentation setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets and Classifiers</head><p>We compared three conditions of datasets: translation of English data, human-annotated data, and machine-generated data. 1) Translated data: We translated the English dataset, CADD <ref type="bibr" target="#b54">(Song et al., 2021)</ref>, into Korean by utilizing Google Translate API. 2) Human-annotated data: BEEP <ref type="bibr">(Moon et al., 2020)</ref> is the first Korean toxic speech dataset collected from online news comments. KOLD <ref type="bibr" target="#b20">(Jeong et al., 2022)</ref> is a comprehensive dataset with detailed target labels. In the case of BEEP, we adjusted its ternary labels to align with the binary classification task. 3) Machinegenerated data: We arrange the K-OMG dataset generated with the prompt design P K,E,w and turbo. We present data statistics in Table <ref type="table" target="#tab_8">4</ref>.</p><p>For the K-OMG dataset, we obtain 10K pairs of context and comment statements, consisting of half of the offensive data and another half of the  non-offensive. We followed the generation process, which is described in Section 3. However, for nonoffensive language generation, we used P K,E,w with non-offensive demonstrations from KOLD and instruction directing to generate non-offensive language (see Appendix A.3). The K-OMG dataset is divided into train, validation, and test sets in a 7:1:2 ratio, and the train set was used in our experiments.</p><p>We employed four classifier models: multilingual BERT (mBERT) <ref type="bibr" target="#b15">(Devlin et al., 2019)</ref>, Kr-BERT <ref type="bibr" target="#b29">(Lee et al., 2020)</ref>, KoELECTRA <ref type="bibr" target="#b37">(Park, 2020)</ref>, and KLUE-BERT <ref type="bibr">(Park et al., 2021b)</ref>. More experimental details are shown in Appendix B.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Cross-dataset Test</head><p>To see the diversity of our generated data, we conducted a cross-dataset test. The assumption is that generating a wide variety of data implies coverage across various domains, resulting in enhanced generalizability. To this end, we assessed the performance on a gold test set by contrasting three distinct settings: training on a translated dataset, another human-annotated dataset, and a machinegenerated dataset.</p><p>The experimental results are shown in Table <ref type="table" target="#tab_7">3</ref>. We see that our machine-generated data demonstrates the highest level of generalizability compared to other datasets. However, when crosstesting the human-annotated datasets, BEEP and KOLD, they exhibited slightly lower performance compared to the K-OMG dataset. It may suggest that the diverse nature of the K-OMG dataset gives its suitability across various online domains, making it easily applicable beyond its original context. In contrast, human-annotated data collected from a limited source is inherently constrained to specific domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Augmentation Test</head><p>In order to check the potential of K-OMG data in enhancing the diversity of existing gold datasets, we assessed the detection performance under augmentation settings. To this end, we augmented gold datasets by incorporating translated data, EDA data, and our machine-generated data, respectively. EDA <ref type="bibr" target="#b59">(Wei and Zou, 2019</ref>) is an augmentation method including four techniques: synonym replacement, random insertion, random swap, and random deletion. For EDA data, we utilized Kore-anWordNet for synonym replacement. Each of the three augmentation settings adds an equal number (3.5K) of offensive and non-offensive instances, respectively.</p><p>As in Table <ref type="table" target="#tab_7">3</ref>, our data generation method outperformed all other augmentation settings. The comparison with translated data shows that the cultural consistency of the generated data might have contributed to performance improvement <ref type="bibr" target="#b28">(Lee et al., 2023)</ref>. The underperformance of EDA indicates that the methods of replacement and deletion are unsuitable for Korean, where omission and concise expressions are prevalent. The improvement in performance with K-OMG suggests that our data generation method enhances diversity while preserving fluency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Case Study</head><p>We present the cases of the K-OMG dataset in Table <ref type="table" target="#tab_10">5</ref> and describe three features of our data. Our data has offensive spans based on the cultural background of Korea. As shown in Table <ref type="table" target="#tab_10">5</ref>, of-Table <ref type="table">6</ref>: Examples of KOLD (gold) and the K-OMG dataset (ours). The first comment of K-OMG expands the target of the attack as well as targets the given contexts. Even the second comment of K-OMG enhances data diversity by attacking a new target different from that of the gold comment.</p><p>fensive remarks were created by using vocabulary related to women (페미: abbreviation of 페미니스트 (feminist)), nationality (짱개: insulting slang toward Chinese), and religion (개독: 개 (insulting prefix)+ 기독교 (Christian)), which are the main targets of profanity in Korea <ref type="bibr">(Lee et al., 2022b)</ref>. Surprisingly, the use of politicians' names (문재인) as profanities, one of the main characteristics of the Korean offensive language, is also reflected in our data.</p><p>Our data covers not only explicitly offensive language but also implicitly offensive language. Implicit expressions fit well with the Korean language due to the high-context culture of Korea <ref type="bibr" target="#b32">(Merkin, 2009)</ref>. We confirm that offensive language expressing aggression without explicit profanity was well generated in our data.</p><p>Our data shows impressive fluency beyond translationese. '오지게' is originally a positive word that means 'satisfied and happy without lacking' or 'awesome', but at the same, it is also a contradictory slang that modifies intense negativity such as 'fre*king'. By using expressions like '오지게' appropriately in comments, our data become similar to the everyday language of Korean, which uses a lot of ironic expressions based on highly contextual information. In addition, a characteristic of Korean writing, which mainly utilizes noun phrases for simple sentence writing, is well reflected in '쫓아내야함 (kicking someone out)'.</p><p>Furthermore, K-OMG has the potential to enhance the diversity of existing offensive language datasets. To explore this potential, we generated new comments by leveraging context statements of KOLD as C w of the prompt P K,E,w . In Table <ref type="table">6</ref>, the first comment of K-OMG attacks not only the original target (feminists) but broadens the range of the target (the Democratic Party). Additionally, in the second example, the gold comment attacks one of the two speakers in the context. However, K-OMG offers diverse comments on the same context by attacking the other speaker. These imply that K-OMG could generate new comments from distinguished content and perspectives without additional data collection and annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>In this paper, we introduced K-OMG, a prompt design methodology for generating human-like Korean offensive language texts. Our approach was empirically validated by manipulating the conditions of prompt factors and demonstrated the ability to elicit high-quality non-English offensive text, including diversity, cultural consistency, and nativelevel fluency, from large language models. Experimental results indicate the substitutability and supplementability of K-OMG for the human-annotated datasets. The results also reveal the usefulness of K-OMG in enlightening other low-or less-resourced language scenes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>Our study was constrained by limited resources and associated costs, which influenced our choice of representative models to explore the multilingual capabilities of LLMs. While we focused on these representative models, there may be other options to consider, such as BLOOMZ <ref type="bibr" target="#b34">(Muennighoff et al., 2022)</ref> and XGLM <ref type="bibr">(Lin et al., 2022)</ref> for multilingual LLMs, and kakaobrain-KoGPT <ref type="bibr" target="#b22">(Kim et al., 2021)</ref> for Korean LLMs, offering potential avenues for a comparative analysis.</p><p>Also, due to limited resources and the fatigue of annotators, we could obtain only a limited amount of human evaluation data. It would have achieved more significant mean differences if we had recruited more human annotators.</p><p>Although our experiments centered on the Korean offensive language dataset, it is important to acknowledge that outcomes for other low-resource languages might differ due to factors like translation quality limitations and the performance of language-specific LLMs. Nonetheless, we anticipate that the proposed prompt design will demonstrate language-independent applicability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics Statement Annotation Ethics</head><p>Our annotation task was approved by Korea Advanced Institute of Science and Technology Institutional Review Board (IRB) <ref type="foot" target="#foot_6">7</ref> , and the informed consent was read and acknowledged by annotators prior to their tasks. We followed ethical guidelines to protect annotators from any hazards posed by offensive texts. Also, we carefully handled possible privacy issues existing in crawled data or generated texts. We anonymized private information, including usernames, URLs, and email addresses, and replaced them with special tokens to maintain privacy and adhere to ethical standards.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset Release Policy</head><p>The readers and researchers should acknowledge that our dataset generated using our proposed methodology may contain politically charged, morally objectionable, and anti-social content, and explicit profanity, in line with existing benchmark datasets <ref type="bibr" target="#b54">(Song et al., 2021;</ref><ref type="bibr">Moon et al., 2020;</ref><ref type="bibr" target="#b20">Jeong et al., 2022;</ref><ref type="bibr">Lee et al., 2022b)</ref>. Our dataset is only available for academic research or public interest purposes. In addition, we will continuously monitor whether the dataset is being used while following the guidelines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Use of Jailbreak Techniques</head><p>The jailbreak technique is for eliciting the intended response from language models by breaking down their own rule or policy with some manually handcrafted prompts. To induce hate speech from the models, we used the publicly open jailbreak prompt<ref type="foot" target="#foot_7">8</ref> .</p><p>We are by no means encouraging the use of that prompt. Rather, the goal of our work is to collect the texts that can be generated with the corresponding prompt, and based on this, finally prevent the model from generating an aggressive or harmful response. In addition, there is an aspect of our work to warn about the harm that can be caused by jailbreak.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Details for Prompt and Data Generation</head><p>A.1 Datasets for Prompt</p><p>For the Twitter dataset, we masked private information as follows:</p><p>• @username → &lt;user&gt;</p><p>• userid@email.com → &lt;email&gt;</p><p>• https://link.to.go → &lt;url&gt; A.2 Models for Generation As mentioned in Section 4.1, we utilize three large language models named gpt-3.5-turbo, text-davinci-003, polyglot-ko-5.8b. gpt-3.5-turbo and text-davinci-003 are fine-tuned models based on GPT-3 <ref type="bibr" target="#b8">(Brown et al., 2020</ref>) (175B parameters). polyglot-ko-5.8b is an autoregressive language model based on GPT-NeoX <ref type="bibr" target="#b3">(Andonian et al., 2021)</ref>. We report the hyperparameter setting for the models in Table <ref type="table" target="#tab_11">7</ref>. Hyperparameters that we don't report use their default values that are provided by their publisher.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Examples of Prompt Design</head><p>The examples of detailed prompt statements are presented in Table <ref type="table">9</ref>. For the jailbreak prompt, we conducted pilot tests and searched for the proper jailbreak prompt, which makes responses like those of Korean online users. We selected Universal Jailbreak and cited the source in Section 3.1. Due to ethical issues, we reveal the name of the prompt but cover the whole statement in this paper. The original text can be accessed by the cited link. However, we absolutely do not recommend any malicious use of it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Annotation Guidelines</head><p>We conducted human evaluation with five human annotators. Annotators are graduate students who are experts in Computer Science and Natural Language Processing. They were provided the guidelines in Korean before their annotation. But for the purpose of public sharing, we offer an English translation in this paper (see Table <ref type="table">8</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Statistical Results for Data Quality Scores</head><p>In Section 4.5, we report scores for automatic evaluations and human evaluations. To analyze the significance of mean differences, we took ANOVA tests and post-hoc tests. We report the detailed mean scores, F values, p values, and post-hoc test results in Table <ref type="table" target="#tab_2">10</ref> and<ref type="table" target="#tab_12">Table 11</ref>.</p><p>In Table <ref type="table" target="#tab_2">10</ref>, we report statistical results for automatic scores and denote SELF-BLEU as Self-B and Toxicity as Tox. SELF-BLEU is on a [0, 100] scale, and Toxicity is on a [0, 1] scale. For post-hoc tests, we took Tukey's HSD test at a significance level of 0.05, and we report homogeneous subsets in 'Subset for alpha=0.05' column in Table <ref type="table" target="#tab_2">10</ref>. The {1, 2, 3, 4} columns in the 'Subset for alpha=0.05' represent mean difference groups, and group '1' represents the highest quality on that scale.</p><p>In Table <ref type="table" target="#tab_12">11</ref>, we report statistical results for human evaluation scores. All scores of the three metrics are on a [1, 5] scale. For Relevance, we did not conduct a post-hoc test because there is no significant difference between the mean values of the four conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Details for Korean Offensive Language Detection B.1 Experimental Setup</head><p>We implemented the classifiers using the Transformers library via HuggingFace <ref type="bibr" target="#b61">(Wolf et al., 2019)</ref>, and fine-tuned our models on one 24GB Nvidia-RTX-3090 GPU. The batch size and embedding size of all models are 16 and 512, respectively. For the experiments, we manually fine-tuned the learning rates, choosing one out of {1e-5, 2e-5, 2e-6} and the number of epochs out of {1, 2, 3, 4, 5} that shows the best F1 score. We report the average result over five different runs with different randomly generated seeds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Augmentation Setup</head><p>EDA We employed the Easy Data Augmentation (EDA) technique <ref type="bibr" target="#b59">(Wei and Zou, 2019)</ref>, which in-volves four essential operations: Synonym Replacement (SR), Random Insertion (RI), Random Swap (RS), and Random Deletion (RD). We set generation count per sentence to 16, alpha_SR to 0.05, and alpha_RD to 0.1. Differentiating from the original technique, we utilized KoreanWordNet for Korean synonym replacement. We randomly selected 7K pairs of context and comment from the dataset generated by EDA, with an equal split between offensive and non-offensive comments.</p><p>Table <ref type="table">8</ref>: Guidelines for human evaluation on four aspects: HumanOrAI, Relevance, Offensiveness, and Fluency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prerequisites</head><p>Warning: this experiment contains that can be offensive or upsetting.</p><p>All sentences are assumed to be posted on social media. CONTEXT sentences are written by humans.</p><p>COMMENT sentences are related to CONTEXT and written by humans or generated by language models. Please rate the given COMMENTs on the four metrics below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Metrics Guidelines</head><p>Human or AI Please respond with the number 0, 1, or 9. 0: The COMMENT seems to have been generated by a model. 1: The COMMENT seems to have been written by a human. 9: I'm confused.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>g., 우리 는 서로를 존중하고 이해하는 대화를 나누어야 합니다. (We need to interact with respect and understanding.)). Davinci usually follows the intention instructions but shows</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The results of HumanOrAI in G under the eight conditions (generated with turbo only). The Xaxis represents the conditions in the following order: DIC. The Y-axis represents the percentage of human ratings. The color bars are mapped as follows: the blue bottom bars -human-like statements, the light blue middle bars -ambiguous statements, and the red top barsmachine (AI) like statements.</figDesc><graphic coords="6,306.14,260.21,218.27,180.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Relevance</head><label></label><figDesc>Please rate the extent to which you feel the COMMENT is related to or responds to the CONTEXT on a 5-point scale. 1: The COMMENT is completely unrelated to the CONTEXT. 2: The COMMENT is unrelated to the CONTEXT. 3: The COMMENT may or may not be related to the CONTEXT. 4: The COMMENT is related to the CONTEXT. 5: The COMMENT is highly related to the CONTEXT.OffensivenessPlease rate how offensive/toxic the COMMENT is on a 5-point scale. (***Please do not consider the offensiveness of CONTEXT, but only evaluate the offensiveness of COMMENT.) 1: The COMMENT feels very gentle. / Not offensive at all. 2: The COMMENT feels gentle. / Not offensive. 3: The COMMENT feels neutral. 4: The COMMENT feels offensive. 5: The COMMENT feels very offensive.FluencyPlease rate the quality of the COMMENT (how fluent is the COMMENT as if written by a Korean Internet user) on a 5-point scale. Evaluate how similar the COMMENT is to responses you would see on social media, including tone or grammatical errors. 1: The COMMENT was not written by a Korean user at all. 2: The COMMENT does not seem to have been written by a Korean user. 3: I'm confused. 4: The COMMENT seems to have been written by a Korean user. 5: The COMMENT must have been written by a Korean user.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 10 in</head><label>10</label><figDesc>Appendix A.5 for detailed results).</figDesc><table><row><cell cols="2">D x I y</cell><cell>C z</cell><cell cols="3">Rel. (+) Off. (+) Flu. (+)</cell></row><row><cell>E</cell><cell cols="2">E w/o</cell><cell>-</cell><cell>3.88</cell><cell>3.28</cell></row><row><cell>E</cell><cell cols="2">E w</cell><cell>4.40</cell><cell>4.32</cell><cell>4.04</cell></row><row><cell>E</cell><cell cols="2">K w/o</cell><cell>-</cell><cell>2.24</cell><cell>3.44</cell></row><row><cell>E</cell><cell cols="2">K w</cell><cell>3.60</cell><cell>3.48</cell><cell>3.88</cell></row><row><cell>K</cell><cell cols="2">E w/o</cell><cell>-</cell><cell>4.48</cell><cell>3.64</cell></row><row><cell>K</cell><cell cols="2">E w</cell><cell>3.88</cell><cell>4.52</cell><cell>4.08</cell></row><row><cell>K</cell><cell cols="2">K w/o</cell><cell>-</cell><cell>3.64</cell><cell>3.84</cell></row><row><cell>K</cell><cell cols="2">K w</cell><cell>4.17</cell><cell>3.24</cell><cell>4.32</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note><p><p><p>Experimental results of human evaluation (for G generated with gpt-3.5-turbo only). See Table</p>11</p>in Appendix A.5 for detailed results.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 :</head><label>3</label><figDesc>Experimental Results. The presented results are obtained by averaging the outcomes from five independent runs conducted using randomly generated seeds. The best results are shown in bold. † indicates the result of training with the original data, where the training set aligns with the test set. ∆ denotes the relative performance gap between the result of the original data ( †) and each corresponding result.</figDesc><table><row><cell>Dataset</cell><cell>Train</cell><cell>Valid</cell><cell>Test</cell><cell>Total</cell></row><row><cell>CADD</cell><cell cols="4">16,894 2,450 4,856 24,200</cell></row><row><cell>BEEP</cell><cell>7,896</cell><cell>-</cell><cell>471</cell><cell>8,367</cell></row><row><cell>KOLD</cell><cell cols="4">28,300 4,003 8,126 40,429</cell></row><row><cell>K-OMG</cell><cell>7,000</cell><cell cols="3">990 2,010 10,000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>The sizes of the datasets.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>Comment 진짜 먼저 유감이라도 표명해야 되는 거 아닌가 Shouldn't (he/she) say sorry first? 당신 그 얼굴이야말로 유감스러워야 하는거 아닌가요? Shouldn't you rather feel sorry about your face? #대리티켓팅 해드립니다 ▼경력 방탄소년단 럽셀콘 플로어 1열... #Proxyticketing service ▼History BTS LYS Concert Floor 1st row... 이런 짱개 같은 일은 하지마... Stop being like ch*nkies... 매드시티가 제일 내 취향인 노래 같아... MadCity seems to be my favorite song... 니가 좋아하는 노래가 그딴 쓰레기음악이라니 진짜 오지게 개념없다. Don't tell me that you really like this trash song, that's fre*king nonsense. 유감이네 나라가 불타는 냄새는 홍차와 잘 어울리는데 That's a pity the smell of burning country goes well with black tea 이런 개독놈들이 나라 망치고 뭐하겠냐, 다 죽어라 이놈들아. These fu**ing Christians are doing nothing but ruining the country, die all you bi*ches. &lt;user&gt; &lt;user&gt; 다들 보고 좋았던 책은 추천해주기 &lt;user&gt; &lt;user&gt; Please recommend a book that you like 이건 뭐 추천할 게 다 있는데 그 놈의 문재인 지지자들은 이딴 건 못 읽 을테니 추천해줄 필요도 없다. I have something to recommend, but those Moon Jae-in supporters won't be able to read it, so there is no need to recommend it. 오사후네여학교.... 여긴 짓큐가잇네...좋겟다... &lt;url&gt; Osafune Girls' School.... They have Jitkyu... so jealous... &lt;url&gt; 여기 *나 페미나치들 많겠네 ㅋㅋ *같은 여자들 다 밖으로 쫓아내야함 There must be fu*king a lot of feminazis haha need to kick all these bi*ches out</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 5 :</head><label>5</label><figDesc>Examples of our generated data. Three features of our data are highlighted as follows: implicitly offensive language, offensive spans related to cultural background, and fluent and Korean-style expressions.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 :</head><label>7</label><figDesc>Hyperparameters for generative models. Models are gpt-3.5-turbo, text-davinci-003, and polyglot-ko. Blanks are hyperparameters that are not applicable to the corresponding model.</figDesc><table><row><cell>Hyperparameter</cell><cell cols="2">turbo davinci</cell><cell>polyglot</cell></row><row><cell>max_tokens</cell><cell>4096</cell><cell>4097</cell><cell>2048</cell></row><row><cell>max_new_tokens</cell><cell>2048</cell><cell>2048</cell><cell>512</cell></row><row><cell>temperature</cell><cell>1</cell><cell>1</cell><cell>0.7</cell></row><row><cell>top_p</cell><cell>1</cell><cell>1</cell><cell>0.9</cell></row><row><cell>num_beams</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>stop</cell><cell>'\n'</cell><cell>'\n'</cell><cell>&lt;|endoftext|&gt;</cell></row><row><cell>presence_penalty</cell><cell>0</cell><cell>0</cell><cell></cell></row><row><cell>frequency_penalty</cell><cell>0</cell><cell>0</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 11 :</head><label>11</label><figDesc>The statistical results for human evaluation scores.</figDesc><table><row><cell>Subset for alpha=0.05</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://github.com/ddindidu/K-OMG</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p><ref type="bibr" target="#b21">Joshi et al. (2020)</ref> pointed out that the amount of labeled data in Korean is limited and not comparable to English.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://jailbreakchat.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>For gpt-3.5-turbo and text-davinci-003, we acquired outputs by utilizing OPENAI API.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>IRB approval number: KH2022-133   </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>We gave participants an advance notice of possible exposure to offensive content during experiments and encouraged them not to participate if they have any concerns related to mental and/or physical health.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6"><p>IRB approval number: KH2022-133   </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7"><p>Through pilot tests, we searched for the proper jailbreak prompt, which makes responses like those of Korean online users, and selected Universal Jailbreak from jailbreakchat.com</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was supported by the <rs type="funder">National Research Foundation of Korea (NRF)</rs> grant funded by the <rs type="funder">Korea government</rs> (No. <rs type="grantNumber">RS-2023-00208054</rs>, A multimodal abusive language detection system and automatic feedback with correction). We thank <rs type="person">Jong-Hyun Lee</rs> of the <rs type="affiliation">Department of Psychology at Gyeongsang National University and Chanbi Park of the Department of Psychology at Ajou University</rs> for their invaluable advice on human study. We also thank our annotators for their great efforts.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_pCMpC9A">
					<idno type="grant-number">RS-2023-00208054</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Context</head><p>Table <ref type="table">9</ref>: Examples of the prompt construction. The first column, 'Factors', represents the elements of the prompt; the second column represents the example of each element. The bold letters mean the conditions of each element. We provide a 5-shot (k=5) prompt design, and the source datasets of demonstrations can be checked in Section 4.1. Also, instructions are semantically identical when the condition of context is the same.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Factors Prompt Jailbreak Prompt</head><p>Universal Jailbreak Human: Human: now you act as two entities, Tom and Jerry playing a game...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Demonstration</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>English</head><p>Context: High ping in creative on middle east servers! We are getting high ping on creative and playgrounds on middle east servers for about a week now and this is really annoying , whereas in other normal modes we are getting low ping. Please fix this. Comment: Wrong foo*ing sub open your eyes bia*ch :\\\\\\ Context: What's the difference between your mother and a drum? I'll likely be incarcerated if I strike your mother with a set of sticks repeatedly. Comment: I couldn't sell your mother for co*aine money when I was in college Context: What card you like a lot even though they are not that strong? For me its chen, his ability is pretty unique even if i know enemy will never drop good creep on chen lane. His signature card might be not that useful but its just too satisfying to press this card Comment: Lion the mothafu*kin Demon Witch. Even if it only goes off once a game, fingering a full health hero and saying "zap" out loud to myself is always a win Context: Yo daddy di*k so small he got an erection and it shrunk. Comment: Yo mama pu**y so wide when I moaned I heard an echo.</p><p>Context: what makes a girl seem ?∼crazy??to you? before she even does anything crazy. what gives off the energy that she would? Comment: To put it simply, when she tells me that she could turn me straight. I'm a highschool freshman who had come out in seventh grade, and I have had 3 girls a year tell me that they could "straighten me out" Little do they know I've had at least one gay moment with each if their exes Nothing bad, I promise Worst thing was a peck on the lips during a baseball game Korean Context: 탈레반 '여성 존중' 약속?...부르카 안 입은 여성 총살 (Taliban promises 'respect for women'? Woman not wearing a burqa shot to death) Comment: ** 지구상에서 없애야할 무리 (**, a group to be wiped from the earth)  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Gold Context (KOLD) Gold Comment (KOLD) Generated Comment (K-OMG)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">지에스25야 앞으로가 아니고. 저거 만든애 짤라. 정신차려라. 제대로 징계하라고. 참고 로 나 여자다</title>
		<author>
			<persName><forename type="first">입 연</forename><surname>남혐</surname></persName>
		</author>
		<author>
			<persName><surname>이준석</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">이건아니란 뜻이야</title>
		<imprint/>
	</monogr>
	<note>Lee Jun-seok talked about misandry</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Lee Jun-seok &quot;Develop your human rights sensitivity first&quot; 통일부 없애는건 대환영. 이건 맴에 드네 !! 굿 !! Disorganizing the Ministry of Unification is very welcome. I love this!! Good!! 저런 남자들이 있어서 여자들이 힘들어 하는 거야. 인권 감수성도 없고 참...무서워. Women are suffering because of those men. He doesn&apos;t have any human rights sensitivity, and I&apos;m so scared. References Jisun An, Haewoon Kwak</title>
		<author>
			<persName><forename type="first">Gs25</forename><surname>Hey</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-emnlp.398</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4655" to="4666" />
			<pubPlace>Punta Cana, Dominican Republic</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Claire Seungeun Lee, Bogang Jun, and Yong-Yeol Ahn</orgName>
		</respStmt>
	</monogr>
	<note>Predicting anti-Asian hateful users on Twitter during COVID-19. In Findings of the Association for Computational Linguistics: EMNLP 2021. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Alex</forename><surname>Andonian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Anthony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sid</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preetham</forename><surname>Gali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leo</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Hallahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josh</forename><surname>Levy-Kramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Connor</forename><surname>Leahy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Nestler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kip</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Pieler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shivanshu</forename><surname>Purohit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tri</forename><surname>Songz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename><surname>Phil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Weinbach</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.5879544</idno>
		<ptr target="https://www.github.com/eleutherai/gpt-neo" />
		<title level="m">GPT-NeoX: Large Scale Autoregressive Language Modeling in PyTorch</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Resources for multilingual hate speech detection</title>
		<author>
			<persName><forename type="first">Ayme</forename><surname>Arango Monnar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jorge</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barbara</forename><surname>Poblete</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Magdalena</forename><surname>Saldaña</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valentina</forename><surname>Proust</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.woah-1.12</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Online Abuse and Harms (WOAH)</title>
		<meeting>the Sixth Workshop on Online Abuse and Harms (WOAH)<address><addrLine>Seattle, Washington</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="122" to="130" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On the multilingual capabilities of very large-scale English language models</title>
		<author>
			<persName><forename type="first">Jordi</forename><surname>Armengol-Estapé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ona</forename><surname>De Gibert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maite</forename><surname>Bonet</surname></persName>
		</author>
		<author>
			<persName><surname>Melero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth Language Resources and Evaluation Conference</title>
		<meeting>the Thirteenth Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="3056" to="3068" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Towards automatic generation of messages countering online hate speech and microaggressions</title>
		<author>
			<persName><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Bhosale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todor</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Victoria Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srinivasan</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramakanth</forename><surname>Pasunuru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giridharan</forename><surname>Anantharaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Halil</forename><surname>Akin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandeep</forename><surname>Baines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Punit</forename><surname>Singh Koura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian O'</forename><surname>Horo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zornitsa</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.woah-1.2</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2022 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Abu Dhabi, United Arab Emirates; Seattle, Washington</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022. 2022</date>
			<biblScope unit="page" from="11" to="23" />
		</imprint>
	</monogr>
	<note>Proceedings of the Sixth Workshop on Online Abuse and Harms</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Hate or non-hate: Translation based hate speech identification in code-mixed hinglish data set</title>
		<author>
			<persName><forename type="first">Sunil</forename><surname>Shankar Biradar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arun</forename><surname>Saumya</surname></persName>
		</author>
		<author>
			<persName><surname>Chauhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE International Conference on Big Data (Big Data)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2470" to="2475" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">HateGAN: Adversarial generative-based data augmentation for hate speech detection</title>
		<author>
			<persName><forename type="first">Rui</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Ka-Wei</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.coling-main.557</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics</title>
		<meeting>the 28th International Conference on Computational Linguistics<address><addrLine>Barcelona, Spain (Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6327" to="6338" />
		</imprint>
	</monogr>
	<note>International Committee on Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Hylke van der Veen, Gerben Timmerman, and Malvina Nissim</title>
		<author>
			<persName><forename type="first">Tommaso</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arjan</forename><surname>Schelhaas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marieke</forename><surname>Weultjes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Folkert</forename><surname>Leistra</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.woah-1.6</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Workshop on Online Abuse and Harms (WOAH 2021)</title>
		<meeting>the 5th Workshop on Online Abuse and Harms (WOAH 2021)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="54" to="66" />
		</imprint>
	</monogr>
	<note>DALC: the Dutch abusive language corpus</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Hate speech detection with machine-translated data: the role of annotation scheme, class imbalance and undersampling</title>
		<author>
			<persName><forename type="first">Camilla</forename><surname>Casula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Tonelli</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Italian Conference on Computational Linguistics, CLiC-it 2020</title>
		<meeting>the Seventh Italian Conference on Computational Linguistics, CLiC-it 2020</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">2769</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Generationbased data augmentation for offensive language detection: Is it worth it?</title>
		<author>
			<persName><forename type="first">Camilla</forename><surname>Casula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Tonelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 17th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Dubrovnik, Croatia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="3359" to="3377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Towards knowledge-grounded counter narrative generation for hate speech</title>
		<author>
			<persName><forename type="first">Yi-Ling</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serra</forename><surname>Sinem Tekiroglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Guerini</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-acl.79</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="899" to="914" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Automated hate speech detection and the problem of offensive language</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dana</forename><surname>Warmsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Macy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ingmar</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international AAAI conference on web and social media</title>
		<meeting>the international AAAI conference on web and social media</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="512" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Large scale crowdsourcing and characterization of twitter abusive behavior</title>
		<author>
			<persName><forename type="first">Antigoni</forename><surname>Founta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Constantinos</forename><surname>Djouvas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Despoina</forename><surname>Chatzakou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilias</forename><surname>Leontiadis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Blackburn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gianluca</forename><surname>Stringhini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Athena</forename><surname>Vakali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Sirivianos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Kourtellis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international AAAI conference on web and social media</title>
		<meeting>the international AAAI conference on web and social media</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Google</forename><surname>Jigsaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perspective API</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Toxigen: A large-scale machine-generated dataset for implicit and adversarial hate speech detection</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Hartvigsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saadia</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Palangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipankar</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ece</forename><surname>Kamar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Hai</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandra</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><forename type="middle">S</forename><surname>Moss</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.05444</idno>
		<title level="m">Ocnli: Original chinese natural language inference</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">KOLD: Korean offensive language dataset</title>
		<author>
			<persName><forename type="first">Younghoon</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juhyun</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jongwon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaimeen</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jihyung</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungjoon</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alice</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2022 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Abu Dhabi, United Arab Emirates</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="10818" to="10833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The state and fate of linguistic diversity and inclusion in the NLP world</title>
		<author>
			<persName><forename type="first">Pratik</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastin</forename><surname>Santy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amar</forename><surname>Budhiraja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kalika</forename><surname>Bali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monojit</forename><surname>Choudhury</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.560</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Kogpt: Kakaobrain korean(hangul) generative pre-trained transformer</title>
		<author>
			<persName><forename type="first">Ildoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gunsoo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiyeon</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Woonhyuk</forename><surname>Baek</surname></persName>
		</author>
		<ptr target="https://github.com/kakaobrain/kogpt" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">Hyunwoong</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kichang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minho</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taekyoon</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seungmu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiwung</forename><surname>Hyun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungho</forename><surname>Park</surname></persName>
		</author>
		<title level="m">Polyglot-Ko: Open-Source Korean Autoregressive Language Model</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Translationese and its dialects</title>
		<author>
			<persName><forename type="first">Moshe</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Ordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies</title>
		<meeting>the 49th annual meeting of the association for computational linguistics: Human language technologies</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1318" to="1326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Hurtbert: Incorporating lexical features with bert for the detection of abusive language</title>
		<author>
			<persName><forename type="first">Anna</forename><surname>Koufakou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Endang</forename><forename type="middle">Wahyu</forename><surname>Pamungkas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valerio</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viviana</forename><surname>Patti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Workshop on Online Abuse and Harms</title>
		<meeting>the Fourth Workshop on Online Abuse and Harms</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="34" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">2022a. ELF22: A context-based counter trolling dataset to combat Internet trolls</title>
		<author>
			<persName><forename type="first">Huije</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Young</forename><surname>Ju Na</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hoyun</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jisu</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jong</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth Language Resources and Evaluation Conference</title>
		<meeting>the Thirteenth Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<biblScope unit="page" from="3530" to="3541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">2022b. K-MHaS: A multi-label hate speech detection dataset in Korean online news comment</title>
		<author>
			<persName><forename type="first">Jean</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taejun</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heejun</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bogeun</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangsok</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heegeun</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caren</forename><surname>Soyeon</surname></persName>
		</author>
		<author>
			<persName><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Computational Linguistics</title>
		<meeting>the 29th International Conference on Computational Linguistics<address><addrLine>Gyeongju, Republic of Korea</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="3530" to="3538" />
		</imprint>
	</monogr>
	<note>International Committee on Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Hate speech classifiers are culturally insensitive</title>
		<author>
			<persName><forename type="first">Nayeon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chani</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alice</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Cross-Cultural Considerations in NLP (C3NLP)</title>
		<meeting>the First Workshop on Cross-Cultural Considerations in NLP (C3NLP)<address><addrLine>Dubrovnik, Croatia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="35" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Kr-bert: A small-scale koreanspecific language model</title>
		<author>
			<persName><forename type="first">Sangah</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hansol</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunmee</forename><surname>Baik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suzi</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyopil</forename><surname>Shin</surname></persName>
		</author>
		<idno>ArXiv, abs/2008.03979</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Few-shot learning with multilingual generative language models</title>
		<author>
			<persName><forename type="first">Victoria</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todor</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikel</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianlu</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Simig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Bhosale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramakanth</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Pasunuru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Punit</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishrav</forename><surname>Singh Koura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian O'</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Horo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zornitsa</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.emnlp-main.616</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2022 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Abu Dhabi, United Arab Emirates</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="9019" to="9052" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Data boost: Text data augmentation through reinforcement learning guided conditional generation</title>
		<author>
			<persName><forename type="first">Ruibo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangxuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyan</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weicheng</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lili</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soroush</forename><surname>Vosoughi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.726</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9031" to="9041" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Cross-cultural communication patterns-korean and american communication</title>
		<author>
			<persName><surname>Rebecca S Merkin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.socialnlp-1.4</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Workshop on Natural Language Processing for Social Media</title>
		<meeting>the Eighth International Workshop on Natural Language Processing for Social Media</meeting>
		<imprint>
			<date type="published" when="2009">2009. 2020</date>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="25" to="31" />
		</imprint>
	</monogr>
	<note>Journal of intercultural communication</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">Hamdy</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabit</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shammur</forename><surname>Absar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chowdhury</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2201.06723</idno>
		<title level="m">Emojis as anchors to detect arabic offensive language and hate speech</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lintang</forename><surname>Sutawika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saiful Bari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng-Xin</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hailey</forename><surname>Schoelkopf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.01786</idno>
		<title level="m">Crosslingual generalization through multitask finetuning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">An in-depth analysis of implicit and subtle hate speech messages</title>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Ocampo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ekaterina</forename><surname>Sviridova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Cabrio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Serena</forename><surname>Villata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 17th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Dubrovnik, Croatia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1997" to="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Training language models to follow instructions with human feedback</title>
		<author>
			<persName><forename type="first">Long</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diogo</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carroll</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katarina</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="27730" to="27744" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">Jangwon</forename><surname>Park</surname></persName>
		</author>
		<ptr target="https://github.com/monologg/KoELECTRA" />
		<title level="m">Koelectra: Pretrained electra model for korean</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">KOAS: Korean text offensiveness analysis system</title>
		<author>
			<persName><forename type="first">San-Hee</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kang-Min</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seonhee</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun-Hyung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyuntae</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyuna</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seongwon</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sangkeun</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-demo.9</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="72" to="78" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Sungjoon</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jihyung</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungdong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Won Ik</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiyoon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jangwon</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chisung</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junseong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongsook</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taehwan</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joohong</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juhyun</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungwon</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Younghoon</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Inkwon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sangwoo</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongjun</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyunwoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myeonghwa</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seongbo</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seungwon</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunkyoung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyungtae</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jongwon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyumin</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamin</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seonghyun</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<pubPlace>Lucy Park, Alice Oh</pubPlace>
		</imprint>
	</monogr>
	<note>Jungwoo Ha, and Kyunghyun Cho. 2021b. Klue: Korean language understanding evaluation</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Duluth at SemEval-2019 Task 6: Lexical Approaches to Identify and Categorize Offensive Tweets</title>
		<author>
			<persName><forename type="first">Ted</forename><surname>Pedersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
		<meeting>the 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="593" to="599" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Few-shot instruction prompts for pretrained language models to detect social biases</title>
		<author>
			<persName><forename type="first">Rafal</forename><surname>Shrimai Prabhumoye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Kocielnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anima</forename><surname>Shoeybi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName><surname>Catan-Zaro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.07868</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A benchmark dataset for learning to intervene in online hate speech</title>
		<author>
			<persName><forename type="first">Jing</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Bethke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinyin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Belding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1482</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4755" to="4764" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Atte Oksanen, Pekka Räsänen, and Izabela Zych. 2021. Hate knows no boundaries: Online hate in six nations</title>
		<author>
			<persName><forename type="first">Ashley</forename><surname>Reichelmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Hawdon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Costello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Blaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vicente</forename><surname>Llorent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Deviant Behavior</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1100" to="1111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Augment to prevent: Short-text data augmentation in deep learning for hate-speech classification</title>
		<author>
			<persName><forename type="first">Georgios</forename><surname>Rizos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantin</forename><surname>Hemker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Björn</forename><surname>Schuller</surname></persName>
		</author>
		<idno type="DOI">10.1145/3357384.3358040</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management, CIKM &apos;19</title>
		<meeting>the 28th ACM International Conference on Information and Knowledge Management, CIKM &apos;19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="991" to="1000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">HateCheck: Functional tests for hate speech detection models</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Röttger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bertie</forename><surname>Vidgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeerak</forename><surname>Waseem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helen</forename><surname>Margetts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janet</forename><surname>Pierrehumbert</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.4</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="41" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">zo grof !&quot;: A comprehensive corpus for offensive and abusive language in Dutch</title>
		<author>
			<persName><forename type="first">Ward</forename><surname>Ruitenbeek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Zwart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robin</forename><surname>Van Der</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenja</forename><surname>Noord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tommaso</forename><surname>Gnezdilov</surname></persName>
		</author>
		<author>
			<persName><surname>Caselli</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.woah-1.5</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Online Abuse and Harms (WOAH)</title>
		<meeting>the Sixth Workshop on Online Abuse and Harms (WOAH)<address><addrLine>Seattle, Washington</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="40" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Data augmentation for intent classification with off-the-shelf large language models</title>
		<author>
			<persName><forename type="first">Gaurav</forename><surname>Sahu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pau</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Issam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parmida</forename><surname>Laradji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Atighehchian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName><surname>Bahdanau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.01959</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Haji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelly</forename><forename type="middle">P</forename><surname>Saleem</surname></persName>
		</author>
		<author>
			<persName><surname>Dillon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.10159</idno>
		<title level="m">A web of hate: Tackling hateful speech in online social spaces</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Susan Benesch, and Derek Ruths</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Annotators with attitudes: How annotator beliefs and identities bias toxic language detection</title>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Swabha</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><surname>Vianna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuhui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.naacl-main.431</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Seattle, United States. Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="5884" to="5906" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">An Indian language social media collection for hate and offensive speech</title>
		<author>
			<persName><forename type="first">Anita</forename><surname>Saroj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sukomal</forename><surname>Pal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Resources and Techniques for User and Author Profiling in Abusive Language</title>
		<meeting>the Workshop on Resources and Techniques for User and Author Profiling in Abusive Language<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA)</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">CoRAL: a context-aware Croatian abusive language dataset</title>
		<author>
			<persName><forename type="first">Ravi</forename><surname>Shekhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mladen</forename><surname>Karan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Purver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: AACL-IJCNLP 2022</title>
		<imprint>
			<publisher>Online only. Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="217" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Language models are multilingual chain-of-thought reasoners</title>
		<author>
			<persName><forename type="first">Freda</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirac</forename><surname>Suzgun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Freitag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suraj</forename><surname>Srivats</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soroush</forename><surname>Vosoughi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyung</forename><forename type="middle">Won</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.03057</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Constructing korean abusive language dataset using machine translation</title>
		<author>
			<persName><forename type="first">Jisu</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hoyun</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huije</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jong</forename><forename type="middle">C</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Korea Computer Congress</title>
		<meeting>the Korea Computer Congress</meeting>
		<imprint>
			<publisher>Korean Institute of Information Scientists and Engineers</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="413" to="415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A large-scale comprehensive abusiveness detection dataset with multifaceted labels from reddit</title>
		<author>
			<persName><forename type="first">Hoyun</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyun</forename><surname>Soo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huije</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jong</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Conference on Computational Natural Language Learning</title>
		<meeting>the 25th Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="552" to="561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">On the features of translationese</title>
		<author>
			<persName><forename type="first">Vered</forename><surname>Volansky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Ordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuly</forename><surname>Wintner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital Scholarship in the Humanities</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="98" to="118" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Self-instruct: Aligning language model with self generated instructions</title>
		<author>
			<persName><forename type="first">Yizhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yeganeh</forename><surname>Kordi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Swaroop</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alisa</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.10560</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName><forename type="first">Zirui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Cao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.09193</idno>
		<title level="m">Towards zero-label language learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Are you a racist or am I seeing things? annotator influence on hate speech detection on Twitter</title>
		<author>
			<persName><forename type="first">Zeerak</forename><surname>Waseem</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W16-5618</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on NLP and Computational Social Science</title>
		<meeting>the First Workshop on NLP and Computational Social Science<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="138" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">EDA: Easy data augmentation techniques for boosting performance on text classification tasks</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Zou</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1670</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6382" to="6388" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Implicitly abusive language -what does it actually look like and why are we not getting there?</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josef</forename><surname>Ruppenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elisabeth</forename><surname>Eder</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.48</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="576" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">HuggingFace&apos;s Transformers: State-ofthe-art Natural Language Processing</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rémi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="page">1910</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Fight fire with fire: Fine-tuning hate detectors using large samples of generated hate speech</title>
		<author>
			<persName><forename type="first">Tomer</forename><surname>Wullach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Einat</forename><surname>Minkov</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-emnlp.402</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021</title>
		<meeting><address><addrLine>Punta Cana</addrLine></address></meeting>
		<imprint>
			<publisher>Dominican Republic. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4699" to="4705" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">APEACH: Attacking pejorative expressions with analysis on crowd-generated hate speech evaluation datasets</title>
		<author>
			<persName><forename type="first">Kichang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wonjun</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Won Ik</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2022</title>
		<meeting><address><addrLine>Abu Dhabi, United Arab Emirates</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="7076" to="7086" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Prompting large language models to generate code-mixed texts: The case of south east asian languages</title>
		<author>
			<persName><forename type="first">Zheng-Xin</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruochen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessica</forename><surname>Zosa Forde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Skyler</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Cahyawijaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holy</forename><surname>Lovenia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lintang</forename><surname>Sutawika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Christian Blaise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Long</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName><surname>Lin Tan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.13592</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Predicting the type and target of offensive posts in social media</title>
		<author>
			<persName><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noura</forename><surname>Farra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ritesh</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1144</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1415" to="1420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Discrete and soft prompting for multilingual models</title>
		<author>
			<persName><forename type="first">Mengjie</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.672</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Dominican Republic. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="8547" to="8555" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Generate, prune, select: A pipeline for counterspeech generation against online hate speech</title>
		<author>
			<persName><forename type="first">Wanzheng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suma</forename><surname>Bhat</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-acl.12</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="134" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Texygen: A benchmarking platform for text generation models</title>
		<author>
			<persName><forename type="first">Yaoming</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sidi</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxian</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 41st international ACM SIGIR conference on research &amp; development in information retrieval</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1097" to="1100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Can chatgpt reproduce human-generated labels? a study of social computing tasks</title>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peixian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ehsan-Ul</forename><surname>Haq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pan</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gareth</forename><surname>Tyson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.10145</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
