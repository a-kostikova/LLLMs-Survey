<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Enhancing Open-Domain Table Question Answering via Syntax-and Structure-aware Dense Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Nengzheng</forename><surname>Jin</surname></persName>
							<email>nengzhengjin@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Harbin Institute of Technology (Shenzhen)</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dongfang</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Harbin Institute of Technology (Shenzhen)</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Junying</forename><surname>Chen</surname></persName>
							<email>junying.chen.cs@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Harbin Institute of Technology (Shenzhen)</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Joanna</forename><surname>Siebert</surname></persName>
							<email>joannasiebert@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Harbin Institute of Technology (Shenzhen)</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qingcai</forename><surname>Chen</surname></persName>
							<email>qingcai.chen@hit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Harbin Institute of Technology (Shenzhen)</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Peng Cheng Laboratory</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Enhancing Open-Domain Table Question Answering via Syntax-and Structure-aware Dense Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">60292516070822732709D4CEC89574FE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-05-29T14:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Open-domain table question answering aims to provide answers to a question by retrieving and extracting information from a large collection of tables. Existing studies of open-domain table QA either directly adopt text retrieval methods or consider the table structure only in the encoding layer for table retrieval, which may cause syntactical and structural information loss during table scoring. To address this issue, we propose a syntax-and structure-aware retrieval method for the open-domain table QA task. It provides syntactical representations for the question and uses the structural header and value representations for the tables to avoid the loss of fine-grained syntactical and structural information. Then, a syntactical-to-structural aggregator is used to obtain the matching score between the question and a candidate table by mimicking the human retrieval process. Experimental results show that our method achieves the state-of-the-art on the NQ-tables dataset and overwhelms strong baselines on a newly curated open-domain Text-to-SQL dataset 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Open-domain table QA uncovers the necessity of table retrieval for practical applications. It slightly differs from most table QA tasks (e.g., table semantic parsing <ref type="bibr" target="#b34">(Yin and Neubig, 2018;</ref><ref type="bibr" target="#b32">Wang et al., 2020)</ref> and end-to-end table QA <ref type="bibr" target="#b23">(Müller et al., 2019;</ref><ref type="bibr" target="#b6">Eisenschlos et al., 2021)</ref>), which typically assume that the relevant tables of a question are provided at test time. This assumption can hardly hold when the user is asking questions through some opendomain natural language interface or querying large databases.</p><p>Hence, some recent studies <ref type="bibr" target="#b9">(Herzig et al., 2021;</ref><ref type="bibr" target="#b2">Chen et al., 2022;</ref><ref type="bibr" target="#b39">Zhong et al., 2022)</ref>  In which area was there a score of 68?</p><p>Table <ref type="table" target="#tab_4">1</ref>: (relevant) methods are based on a two-stage framework, namely the retriever-reader (parser) framework. In such frameworks, the retriever is utilized to obtain relevant tables of the given question and the reader (parser) provides answers to the question directly or parses the question into an SQL query.</p><p>Since retrieval is the first key factor for opendomain table QA, recent works have investigated different approaches for table retrieval, which could be broadly classified into two categories. One is directly adopting text retrieval methods for table retrieval. Such methods typically linearize the tables into text and apply sparse text retrieval (e.g., BM25) <ref type="bibr" target="#b19">(Li et al., 2021)</ref> or dense passage retrieval with a Bi-encoder model <ref type="bibr" target="#b26">(Oguz et al., 2022;</ref><ref type="bibr" target="#b3">Chen et al., 2021;</ref><ref type="bibr" target="#b11">Huang et al., 2022)</ref>. Another direction is to follow the framework of text retrieval models while also considering the unique characteristics of tables. For instance, DTR <ref type="bibr" target="#b9">(Herzig et al., 2021)</ref> follows the Bi-encoder framework but incorporates row/column features into the table encoder, aiming to specify the cell location and enhance table understanding. UTP <ref type="bibr" target="#b1">(Chen et al., 2023)</ref> introduces pre-training and cross-model contrastive regularization for better tabular understanding.</p><p>Although some of these methods <ref type="bibr" target="#b9">(Herzig et al., 2021;</ref><ref type="bibr" target="#b1">Chen et al., 2023)</ref> have modeled the characteristics of tables, they still have two shortages. First, the learned tabular semantics may be compromised when all token embeddings are combined into a single table representation in the Bi-encoder retrieval framework <ref type="bibr" target="#b8">(Gillick et al., 2018)</ref>. Second, they neglect that table retrieval is a fine-grained semantic matching problem. As illustrated in Figure <ref type="figure">1</ref>, humans would consciously match each meaningful phrase in the question to the table columns and rank the candidate tables by the matching degree.</p><p>Motivated by this, we propose a syntax-and structural-aware dense retrieval method to mimic this fine-grained matching process. We first apply syntax analysis to extract all possible meaningful phrases. Then, a corresponding syntactical representation is generated for each meaningful phrase based on the phrase token embeddings. To obtain fine-grained structural representations, we provide one representation for each table header. Further, we observe that the semantics of a table header and its value may be different; for example, a header may be "age" but the corresponding values are numbers. Therefore, we also provide one representation for the values of a column to retain the structural semantics better. Finally, the matching score between the question and a candidate table is obtained by performing syntactical-to-structural aggregation over the fine-grained representations, wherein the aggregation is analogous to the human behavior of counting matches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Overview</head><p>As shown in Figure <ref type="figure">2</ref>, our proposed retrieval model comprises of 1) Syntactical representation module that generates fine-grained syntactical representations for the question; 2) Structural representation module that generates a limited number of structural representations for a table; 3) Syntactical-tostructural aggregator that produces the matching score between the question and a candidate table.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Syntactical Question Representation</head><p>Explicit syntactical representations. We utilize an explicit syntax parser from the Natural Language Toolkit (NLTK) <ref type="bibr" target="#b0">(Bird et al., 2009)</ref> to extract the noun phrases in the question. To generate the question representations, we first feed the question tokens of length L into the encoder and treat the hidden states of the last layer as question token embeddings {h l } L l=1 . Then, we apply a mean pooling function over the token embeddings that belong to a phrase, thus obtaining one representation q i for the ith phrase in the question:</p><formula xml:id="formula_0">q i = Pooling(h start i , ..., h end i ),<label>(1)</label></formula><p>where start i and end i denote the token span of the ith phrase. Applying the same operation for each phrase, we obtain a small group of fine-grained syntactical representations {q i } n i=1 , where n is the number of the syntactical representations.</p><p>Implicit syntactical representations. Since explicit syntax parsing is associated with additional preprocessing time, we provide an implicit syntactical representation approach that does not require syntax parsing. It attempts to learn a static number of syntactical representations through an attentive learning mechanism based on the token embeddings {h l } L l=1 . Specifically, we first define a set of randomly initialized learning embeddings {a i } n i=1 . Then, we feed {a i } n i=1 and {h l } L l=1 into an attention layer to generate the final syntactical representations {q i } n i=1 , where q i is learned as in Eqn. 2 and Eqn. 3.</p><formula xml:id="formula_1">q i = l w i l h l (2) (w i 1 , .., w i L ) = softmax(a i • h 1 , .., a i • h L ). (3)</formula><p>Here, a i is used as a seed to learn an implicit syntactical representation q i during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Structural Table Representation</head><p>For each candidate table, we linearize the table into a sequence by concatenating the columns, wherein a column sequence consists of the column name (also referred to as the header) and column values.</p><p>Then, we use the same encoder to encode the table sequence of length T . After obtaining table token embeddings {s l } T l=1 , we apply a mean pooling function over the embeddings of each column name to generate a header representation c head j . Additionally, we perform the same pooling function over the column value to generate a value representation c val j . The pooling is only applied to the first column value rather than all values as it proved to be more effective and efficient in our preliminary experiments. After that, we obtain two representations for the jth column as follows:</p><formula xml:id="formula_2">c head j = Pooling(s start head j , .., s end head j ), (4) c val j = Pooling(s start val j , .., s end val j</formula><p>).</p><p>(5)</p><p>Here, start head/val j and end head/val j represent the token span corresponding to the header (value) of the jth column.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Syntactical-to-Structural Aggregator</head><p>We obtain syntactical question representations {q i } n i=1 and structural table representations {c j } 2m j=1 after representation generation, where {c j } 2m j=1 includes {c head j } m j=1 and {c val j } m j=1 , and m is the number of columns. Then, we perform a maxsim operation <ref type="bibr" target="#b14">(Khattab and Zaharia, 2020;</ref><ref type="bibr">Luan et al., 2021a)</ref> over the syntactical and structural representations to retrieve tables. Specifically, we calculate the dot product similarity between each syntactical representation q i and each structural representation c j to obtain a fine-grained matching score w ij as follows:</p><formula xml:id="formula_3">w ij = q i • c j (6) Score = n i max j∈[1,2m] w ij .<label>(7)</label></formula><p>Subsequently, we select the fine-grained score of the most matched column for each syntactical representation and sum up all the greatest fine-grained scores as the final matching score between the question and a candidate table. This is analogous to the process of a human finding a match for each phrase and counting the number of matches when retrieving tables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Data and Settings</head><p>Datasets. We conducted experiments on two datasets: NQ-TABLES <ref type="bibr" target="#b9">(Herzig et al., 2021)</ref>  <ref type="bibr" target="#b17">(Kweon et al., 2023)</ref> also introduce an open-domain setting to the WikiSQL dataset but does not process those same-header database tables.</p><p>Settings. The uncased BERT-base <ref type="bibr" target="#b5">(Devlin et al., 2019)</ref> is employed as the encoder. The number of implicit syntactical representations is set to 3 and Adam is utilized <ref type="bibr" target="#b15">(Kingma and Ba, 2015)</ref> as the optimizer. To evaluate the performance of the retrievers, the recall@K and exact match accuracy (EM) of the final answers are utilized as the metrics. Since the focus of this work is to enhance opendomain table QA via improved retrievers, TAPAS <ref type="bibr" target="#b10">(Herzig et al., 2020)</ref> and HydraNet <ref type="bibr" target="#b22">(Lyu et al., 2020)</ref> are directly used as the reader (parser) on the NQ-TABLES and WikiSQL datasets, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Comparison Models</head><p>We compared the proposed retriever with the following baselines. 1) Sparse retrievers: TF-IDF and BM25 <ref type="bibr" target="#b28">(Robertson and Walker, 1994)</ref>. 2) Dense retrievers using one representation, such as Bi-encoder <ref type="bibr" target="#b8">(Gillick et al., 2018)</ref> with representation vectors from word2vec (w2v) and BERT, as well as DTR <ref type="bibr" target="#b9">(Herzig et al., 2021)</ref> and UTP <ref type="bibr" target="#b1">(Chen et al., 2023)</ref> 2021), PolyEncoder <ref type="bibr" target="#b12">(Humeau et al., 2020)</ref> and MEBERT <ref type="bibr">(Luan et al., 2021a)</ref>. We set the representation number of PolyEncoder and MEBERT to the average representation number used in our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Experimental Results and Analysis</head><p>Table <ref type="table" target="#tab_4">1</ref> demonstrates the experimental results on the NQ-TABLES dataset. It shows that our proposed model outperforms the previous state-of-theart model by a considerable margin with or without hard negative training <ref type="bibr" target="#b7">(Gillick et al., 2019)</ref>. Specifically, our model surpasses previous models by approximately 8 and 2 points in terms of recall@1 and EM accuracy. Furthermore, as Table <ref type="table" target="#tab_1">2</ref> illustrates, our method consistently outperforms strong text retrievers on the WikiSQL dataset. This verifies the effectiveness of the proposed syntax-and structure-aware dense retrieval method.</p><p>The experimental results in Table <ref type="table" target="#tab_4">1</ref> and 2 also indicate that the implicit syntactical question representations yield better performance compared to the explicit ones in most cases. The underlying reason may be that the attention layer in the implicit syntactical pooler can learn more delicate semantic information compared to simple pooling.</p><p>Ablation Study. To analyze the impact of different components of our proposed method, we conducted an ablation study in Table <ref type="table" target="#tab_6">3</ref>. 1) w/o S 1 variant eliminates syntactical question representations and takes the embedding of the [CLS] token in the question as the representation. The result of w/o S 1 shows the importance of syntactical representations. Moreover, our method still outperforms text retrieval baselines in this case, which also verifies the effectiveness of structural table representations compared with multiple contextualized representations <ref type="bibr" target="#b12">(Humeau et al., 2020;</ref><ref type="bibr">Luan et al., 2021b</ref>  Latency Analysis. We compared the retrieval latency of the retrievers on the WikiSQL dataset. As Table <ref type="table" target="#tab_7">4</ref> illustrates, our model has an acceptable latency increase compared to the baselines but makes considerable progress in retrieval performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Works</head><p>Open-domain table QA (ODTQA) is an extension of the closed-domain table QA task <ref type="bibr" target="#b27">(Pasupat and Liang, 2015;</ref><ref type="bibr" target="#b38">Zhong et al., 2017;</ref><ref type="bibr" target="#b35">Yin et al., 2020;</ref><ref type="bibr" target="#b3">Chen et al., 2021)</ref>. Traditional closed-domain table QA does not require table retrieval and can be addressed through two primary methodologies: employing end-to-end models or utilizing semantic parsing approaches. End-to-end models take both the questions and relevant tables as input, and then directly generate answers <ref type="bibr" target="#b23">(Müller et al., 2019;</ref><ref type="bibr" target="#b40">Zhu et al., 2021;</ref><ref type="bibr" target="#b25">Nararatwong et al., 2022;</ref><ref type="bibr" target="#b24">Nan et al., 2022)</ref>. Differently, semantic parsing approaches transform the question into a logical form (e.g., an SQL query), and then retrieve the answers by executing the logical form <ref type="bibr" target="#b38">(Zhong et al., 2017;</ref><ref type="bibr" target="#b36">Yu et al., 2018;</ref><ref type="bibr" target="#b32">Wang et al., 2020;</ref><ref type="bibr" target="#b40">Zhu et al., 2021)</ref>.</p><p>ODTQA is also closely related to open-domain text-based QA <ref type="bibr" target="#b18">(Kwiatkowski et al., 2019;</ref><ref type="bibr" target="#b13">Khashabi et al., 2021)</ref> and information retrieval <ref type="bibr">(Luan et al., 2021a;</ref><ref type="bibr" target="#b12">Humeau et al., 2020;</ref><ref type="bibr" target="#b30">Tang et al., 2021)</ref>. Compared to the text retrieval, the tabular characteristics need to be considered in ODTQA <ref type="bibr" target="#b9">(Herzig et al., 2021;</ref><ref type="bibr" target="#b1">Chen et al., 2023;</ref><ref type="bibr" target="#b16">Kostic et al., 2021)</ref>.</p><p>Another task that ODTQA shares some degree of similarity with is keyword-based web table search <ref type="bibr" target="#b37">(Zhang and Balog, 2018;</ref><ref type="bibr" target="#b29">Sun et al., 2019;</ref><ref type="bibr" target="#b4">Chen et al., 2020;</ref><ref type="bibr" target="#b33">Wang et al., 2021;</ref><ref type="bibr" target="#b31">Trabelsi et al., 2022)</ref>. Compared with keyword-based web table search, table retrieval in open-domain table QA needs to process complex questions that may contain superfluous information rather than to process informative keyword queries. Hence, our work incorporates syntax analysis to extract useful syntactical representation, as well as uses simple yet effective structural representation and scoring mechanism for retrieval efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we present a syntax-and structureaware dense retrieval method for open-domain table QA. Specifically, our method mimics the human retrieval process by utilizing fine-grained syntactical and structural representations, as well as a syntactical-to-structural aggregator. Experimental results on two datasets demonstrate that our model surpasses the strong baselines while preserving a reasonable computation overhead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Dataset Modification</head><p>In the original WikiSQL dataset, tables relevant to each question are manually provided. To simulate a realistic situation, we removed the table labeling of the questions, introducing the task of table retrieval. Moreover, we merged the tables with the same headers into one distinct table, as it is implausible for an application database to accommodate two tables with identical headers. Furthermore, we created a mapping between the original tables and the distinct tables to enable using all samples for table retrieval and downstream tasks.</p><p>In consideration of the limited input length of a BERT-based encoder, we randomly sampled 5 rows of values for over-size tables, thereby obtaining smaller candidate tables during retrieval. If the resulting table sequence still exceeded the prescribed length limitation, we dynamically trimmed an equal number of values from each column until the specified limitation was met. The statistics of the processed WikiSQL dataset and the original NQ-TABLES dataset are reported in Table <ref type="table" target="#tab_8">5</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Experimental Setup</head><p>Our proposed retrieval model uses a training batch size of 144 and 128 on the NQ-TABLES dataset and WikiSQL dataset, respectively. The uncased BERT-base model is used as the encoder on two datasets. Following Tri-encoder <ref type="bibr" target="#b16">(Kostic et al., 2021)</ref> and UTP <ref type="bibr" target="#b1">(Chen et al., 2023)</ref>, no downprojection is used for the final representations on the NQ-TABLES dataset. However, for a comprehensive evaluation, we also reported the performance of the proposed model with projection in Table <ref type="table" target="#tab_9">7</ref>. We trained the model for a maximum of 150 epochs on two datasets and adopted early stopping according to the recall numbers on the dev set. For efficiency, we only used the tables that appear in the dev set as the candidate pool for the early stopping, aligning with the method outlined in <ref type="bibr" target="#b9">(Herzig et al., 2021)</ref>. We trained all models on 4 Nvidia Tesla A100 80GB GPUs. We tested each model on a single GPU. Detailed hyper-parameters for training the proposed retrieval model can be found in Table <ref type="table">6</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Further Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Impact of Different Pooling Functions on Performance</head><p>In the main experiments, we used the mean pooling function to retrieve explicit syntactical and structural representations. This function outputs the average of all input embeddings. Here, we explored the effect of two other pooling functions, namely the max pooling function, which selects the largest of the input embeddings as the output, and the attentive pooling function, which generates the output as a weighted sum of the input embeddings, with weights determined by a linear layer. As shown in Figure <ref type="figure">8</ref>, the attentive pooling function achieves the best performance in most cases. This is likely due to the fact that the attentive pooling function is equipped with extra parameters to learn for pooling.  ) to Question token embeddings (I2Q) and Table header/value representations (I2T). The matrices depict whether I j learns syntactical information and matches the correct column. As shown in a), I 1 and I 2 learn information of "on December 5" and match the column "date" with the highest score. Here, header v denotes value representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Coherence Matrices of Implicit Syntactical Representations</head><p>To investigate whether implicit syntactical representations effectively support fine-grained semantic matching akin to explicit representations, we visualized the normalized similarity matrix between implicit syntactical representations and question token embeddings (I2Q), as well as structural table representations (I2T) in Figure <ref type="figure" target="#fig_0">3</ref>. The I2Q matrix indicates which tokens an implicit representation focuses on. Inspecting the I2Q matrix in Figure <ref type="figure" target="#fig_0">3</ref>(a), it is clear that I 3 has the closest relationship with the phrase "team", while I 1 and I 2 both focus on the phrase "on December 5", as there are only two phrases in the question. We observe that different implicit representations usually focus on different syntactical phrases, which is similar to explicit representations. Then, carrying different syntactical information, I j can perform neural fine-grained matching with structural header/value representations. As the I2T matrix in Figure <ref type="figure" target="#fig_0">3</ref>(a) shows, I 3 matches the header "team" with the highest score, whereas I 1 and I 2 match the header and value of "date". Hence, the behavior of implicit representations is consistent with our design ideas.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure3: The coherence matrices of Implicit syntactical representations ({I j } 3 j=1 ) to Question token embeddings (I2Q) and Table header/value representations (I2T). The matrices depict whether I j learns syntactical information and matches the correct column. As shown in a), I 1 and I 2 learn information of "on December 5" and match the column "date" with the highest score. Here, header v denotes value representations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>have started to explore open-domain table QA. Generally, these</figDesc><table><row><cell cols="2">country season</cell><cell>team</cell><cell>apps</cell><cell>goals</cell></row><row><cell>KZ</cell><cell>1998</cell><cell>FC Atyrau</cell><cell>13</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>3 matches,</cell></row><row><cell></cell><cell></cell><cell>more relevant</cell></row><row><cell>1</cell><cell>2</cell><cell>3</cell></row><row><cell>Question:</cell><cell></cell><cell></cell></row><row><cell>1</cell><cell></cell><cell>human</cell></row><row><cell>:</cell><cell></cell><cell>1 match,</cell></row><row><cell>(irrelevant)</cell><cell></cell><cell>less relevant</cell></row></table><note><p><p><p>Figure</p>1</p>: Illustration of fine-grained semantic matching when a human retrieves relevant tables for a question. If more fine-grained matches are found in a table, one will treat the table as more relevant.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>question a candidate table Encoder Syntactical Pooler Encoder Structural Pooler head ... S head head value value value Syntactical-to-Structural Aggregator score NP P ... ... NP NP Retriever Reader/Parser question candidate tables relevant tables answer/SQL</head><label></label><figDesc></figDesc><table><row><cell>Retriever-Reader(Parser) Framework</cell></row><row><cell>Figure 2: Illustration of the retriever-reader (parser)</cell></row><row><cell>framework and our proposed retriever. Here, head and</cell></row><row><cell>value denote the structural table representations. NP</cell></row><row><cell>(noun phrase) denotes a syntactical question representa-</cell></row><row><cell>tion.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>,</head><label></label><figDesc>Wik-   </figDesc><table><row><cell>Model</cell><cell>R@1</cell><cell>R@10</cell><cell>R@50</cell><cell>EM</cell></row><row><cell>BM25</cell><cell>16.77</cell><cell>40.06</cell><cell>58.39</cell><cell>21.46</cell></row><row><cell>DTR-Schema</cell><cell>34.36</cell><cell>74.24</cell><cell>88.37</cell><cell>32.75</cell></row><row><cell>DTR</cell><cell>36.24</cell><cell>76.02</cell><cell>90.25</cell><cell>35.50</cell></row><row><cell>UTP</cell><cell>38.45</cell><cell>79.03</cell><cell>92.21</cell><cell>-</cell></row><row><cell>Ours(ex)</cell><cell>45.15</cell><cell>83.73</cell><cell>93.12</cell><cell>37.73</cell></row><row><cell>Ours(im)</cell><cell>47.03</cell><cell>84.76</cell><cell>94.89</cell><cell>37.98</cell></row><row><cell cols="2">With hard negatives training</cell><cell></cell><cell></cell><cell></cell></row><row><cell>DTR</cell><cell>42.42</cell><cell>81.13</cell><cell>92.56</cell><cell>37.69</cell></row><row><cell>UTP</cell><cell>50.39</cell><cell>85.40</cell><cell>94.31</cell><cell>-</cell></row><row><cell>Tri-encoder</cell><cell>-</cell><cell>86.4</cell><cell>-</cell><cell>-</cell></row><row><cell>Ours(ex)</cell><cell>53.39</cell><cell>88.11</cell><cell>95.09</cell><cell>39.47</cell></row><row><cell>Ours(im)</cell><cell>54.12</cell><cell>90.41</cell><cell>97.18</cell><cell>39.72</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 :</head><label>1</label><figDesc>Experimental results on the NQ-TABLES dataset. R is short for recall. Here, ex/im denotes using explicit or implicit syntactical representations.</figDesc><table /><note><p><p><p><p><p>iSQL</p><ref type="bibr" target="#b38">(Zhong et al., 2017)</ref></p>. NQ-TABLES is an open-domain table QA database constructed from the Natural Question dataset</p><ref type="bibr" target="#b18">(Kwiatkowski et al., 2019)</ref></p>. In the original WikiSQL dataset, the relevant tables are given by humans. To simulate a realistic situation, we remove the table labeling of the questions and introduce table retrieval. Further details of the dataset modification can be seen in Appendix A. Concurrently with this work,</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>, which use a table-oriented pre-trained model as encoder. 3) Dense retrievers using multiple representations: Tri-encoder(Kostic et al.,   Experimental results on the WikiSQL dataset.</figDesc><table><row><cell>Model</cell><cell cols="3">R@1 R@5 R@20</cell><cell>EM</cell></row><row><cell>TF-IDF</cell><cell>8.93</cell><cell>22.86</cell><cell>44.05</cell><cell>7.24</cell></row><row><cell>BM25</cell><cell cols="2">28.19 44.71</cell><cell>61.22</cell><cell>26.18</cell></row><row><cell>Bi-encoder(w2v)</cell><cell cols="2">10.01 20.14</cell><cell>30.13</cell><cell>7.92</cell></row><row><cell cols="3">Bi-encoder(BERT) 48.89 73.15</cell><cell>86.64</cell><cell>41.26</cell></row><row><cell>MEBERT</cell><cell cols="2">49.05 73.30</cell><cell>87.34</cell><cell>41.32</cell></row><row><cell>PolyEncoder</cell><cell cols="2">49.33 73.61</cell><cell>87.78</cell><cell>41.63</cell></row><row><cell>Ours(ex)</cell><cell cols="2">54.16 77.63</cell><cell>89.81</cell><cell>45.42</cell></row><row><cell>Ours(im)</cell><cell cols="2">53.19 77.57</cell><cell>90.02</cell><cell>44.71</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>). 2) w/o S 2 variant uses the embedding of the [CLS] token in the table sequence Ablation sturdy on the WikiSQL dataset. S 1 and S 2 denote syntactical and structural representations.</figDesc><table><row><cell>Model</cell><cell cols="2">R@1 R@5 R@20</cell><cell>EM</cell></row><row><cell>Ours(ex)</cell><cell>54.16 77.63</cell><cell>89.81</cell><cell>45.42</cell></row><row><cell>w/o S 1</cell><cell>50.08 74.36</cell><cell>88.19</cell><cell>42.28</cell></row><row><cell>w/o S 2 (head)</cell><cell>52.93 77.08</cell><cell>89.91</cell><cell>44.51</cell></row><row><cell cols="2">w/o S 2 (value) 53.18 77.16</cell><cell>89.50</cell><cell>44.75</cell></row><row><cell>w/o S 2</cell><cell>48.31 72.45</cell><cell>86.75</cell><cell>40.71</cell></row><row><cell>w/o S 1 + S 2</cell><cell>48.87 72.57</cell><cell>86.79</cell><cell>41.17</cell></row><row><cell>Model</cell><cell>LAT. Model</cell><cell></cell><cell>LAT.</cell></row><row><cell>TF-IDF</cell><cell>2.74 MEBERT</cell><cell></cell><cell>0.40</cell></row><row><cell>BM25</cell><cell cols="2">6.95 PolyEncoder</cell><cell>0.41</cell></row><row><cell>Bi-encoder(w2v)</cell><cell>0.32 Ours(ex)</cell><cell cols="2">0.42 + 0.6  *</cell></row><row><cell cols="2">Bi-encoder(BERT) 0.36 Ours(im)</cell><cell></cell><cell>0.47</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>The retrieval latency (LAT.) per question (in milliseconds) on the WikiSQL dataset. * denotes the latency of syntax parsing.</figDesc><table /><note><p>as the table representation. The results of w/o S 2 , w/o S 2 (head), and w/o S 2 (value) indicate that structural header and value representations both contribute to better representations of a table. 3) w/o S 1 + S 2 variant leads to inferior performance but is slightly better than the w/o S 2 variant, this suggests that the use of syntactical representations alone does not improve performance.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Statistics of NQ-TABLES and WikiSQL datasets.</figDesc><table><row><cell>Dataset</cell><cell>Train</cell><cell>Dev</cell><cell>Test</cell><cell># Tables</cell></row><row><cell>NQ-TABLES</cell><cell>9594</cell><cell>1068</cell><cell>966</cell><cell>169898</cell></row><row><cell>WikiSQL</cell><cell cols="3">56355 8421 15878</cell><cell>9898</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 :</head><label>7</label><figDesc>. Experimental results of the proposed method with down-projection on the NQ-TABLES dataset.Here, Size denotes the model size, Dim. denotes the dimensionality of each representation after downprojection, Bs. denotes the training batch size.</figDesc><table><row><cell></cell><cell>parameter</cell><cell></cell><cell>value</cell></row><row><cell></cell><cell>learning rate</cell><cell></cell><cell>2e-5</cell></row><row><cell></cell><cell>weight decay</cell><cell></cell><cell>0.01</cell></row><row><cell></cell><cell>warmup up ratio</cell><cell></cell><cell>0.05</cell></row><row><cell cols="5">Table 6: Hyper-parameters for training the proposed</cell></row><row><cell cols="2">retrieval model.</cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell>Size Dim. Bs.</cell><cell cols="3">R@1 R@10 R@50</cell></row><row><cell>DTR</cell><cell cols="2">large 256 256 36.24</cell><cell>76.02</cell><cell>90.25</cell></row><row><cell cols="3">Ours(ex) base 256 144 41.29</cell><cell>82.06</cell><cell>91.86</cell></row><row><cell cols="3">Ours(im) base 256 144 41.92</cell><cell>83.42</cell><cell>93.84</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ewan</forename><surname>Klein</surname></persName>
		</author>
		<title level="m">Natural Language Processing with Python</title>
		<imprint>
			<publisher>Reilly Media Inc</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Bridge the gap between language models and tabular understanding</title>
		<author>
			<persName><forename type="first">Nuo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linjun</forename><surname>Shou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyu</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianhui</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daxin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2302.09302</idno>
		<idno>CoRR, abs/2302.09302</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Retrieval augmented via execution guidance in open-domain table qa</title>
		<author>
			<persName><forename type="first">Siqin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yubo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiehui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengshu</forename><surname>Hou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence</title>
		<meeting>the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Open question answering over tables and text</title>
		<author>
			<persName><forename type="first">Wenhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eva</forename><surname>Schlinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>Virtual Event, Austria. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Table search using a deep contextualized language model</title>
		<author>
			<persName><forename type="first">Zhiyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohamed</forename><surname>Trabelsi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Heflin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><forename type="middle">D</forename><surname>Davison</surname></persName>
		</author>
		<idno type="DOI">10.1145/3397271.3401044</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval</title>
		<meeting>the 43rd International ACM SIGIR conference on research and development in Information Retrieval<address><addrLine>China</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020-07-25">2020. July 25-30, 2020</date>
			<biblScope unit="page" from="589" to="598" />
		</imprint>
	</monogr>
	<note>SIGIR 2020, Virtual Event</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">MATE: multi-view attention for table transformer efficiency</title>
		<author>
			<persName><forename type="first">Julian</forename><surname>Eisenschlos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maharshi</forename><surname>Gor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.600</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana<address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-07-11">2021. 7-11 November, 2021</date>
			<biblScope unit="page" from="7606" to="7619" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning dense representations for entity retrieval</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sayali</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Larry</forename><surname>Lansing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Presta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eugene</forename><surname>Ie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diego</forename><surname>García-Olano</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/K19-1049</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd Conference on Computational Natural Language Learning</title>
		<meeting>the 23rd Conference on Computational Natural Language Learning<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="528" to="537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">End-to-end retrieval in continuous space</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Presta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaurav</forename><forename type="middle">Singh</forename><surname>Tomar</surname></persName>
		</author>
		<idno>CoRR, abs/1811.08008</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Open domain question answering over tables via dense retrieval</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Syrine</forename><surname>Krichene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Eisenschlos</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.43</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="512" to="519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Tapas: Weakly supervised table parsing via pre-training</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krzysztof</forename><surname>Pawel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Piccinno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eisenschlos</forename><surname>Martin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.398</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4320" to="4333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Mixed-modality representation learning and pre-training for joint table-and-text retrieval in openqa</title>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanjun</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daxin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2022</title>
		<meeting><address><addrLine>Abu Dhabi</addrLine></address></meeting>
		<imprint>
			<publisher>United Arab Emirates. Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="4117" to="4129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Poly-encoders: Architectures and pre-training strategies for fast and accurate multi-sentence scoring</title>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Humeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations (ICLR)</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<publisher>OpenReview</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>net</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Gooaq: Open question answering with diverse answer types</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amos</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-emnlp.38</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021, Virtual Event / Punta Cana</title>
		<meeting><address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11">2021. 16-20 November, 2021</date>
			<biblScope unit="page" from="421" to="433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Colbert: Efficient and effective passage search via contextualized late interaction over BERT</title>
		<author>
			<persName><forename type="first">Omar</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
		<idno type="DOI">10.1145/3397271.3401075</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval</title>
		<meeting>the 43rd International ACM SIGIR conference on research and development in Information Retrieval<address><addrLine>China</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations (ICLR)</title>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Multi-modal retrieval of tables and texts using triencoder models</title>
		<author>
			<persName><forename type="first">Bogdan</forename><surname>Kostic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Risch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timo</forename><surname>Möller</surname></persName>
		</author>
		<idno>CoRR, abs/2108.04049</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Open-wikitable: Dataset for open domain question answering with complex reasoning over table</title>
		<author>
			<persName><forename type="first">Sunjun</forename><surname>Kweon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yeonsu</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seonhee</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yohan</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2305.07288</idno>
		<idno>CoRR, abs/2305.07288</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Natural questions: a benchmark for question answering research</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennimaria</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivia</forename><surname>Redfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankur</forename><forename type="middle">P</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danielle</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Kelcey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00276</idno>
	</analytic>
	<monogr>
		<title level="j">Trans. Assoc. Comput. Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="452" to="466" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dual reader-parser on hybrid textual and tabular evidence for open domain question answering</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Hanbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henghui</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.315</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL/IJCNLP</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL/IJCNLP</meeting>
		<imprint>
			<publisher>Virtual Event. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4078" to="4088" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">2021a. Sparse, dense, and attentional representations for text retrieval</title>
		<author>
			<persName><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00369</idno>
	</analytic>
	<monogr>
		<title level="j">Trans. Assoc. Comput. Linguistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="329" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">2021b. Sparse, dense, and attentional representations for text retrieval</title>
		<author>
			<persName><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00369</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="329" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Hybrid ranking network for text-to-sql</title>
		<author>
			<persName><forename type="first">Qin</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaushik</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shobhit</forename><surname>Hathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Souvik</forename><surname>Kundu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
		<idno>CoRR, abs/2008.04759</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Answering conversational questions on structured data without logical forms</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Piccinno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Nicosia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasemin</forename><surname>Altun</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1603</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-11-03">2019. November 3-7, 2019</date>
			<biblScope unit="page" from="5901" to="5909" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">FeTaQA: Free-form table question answering</title>
		<author>
			<persName><forename type="first">Linyong</forename><surname>Nan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chiachun</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziming</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Victoria Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neha</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Kryściński</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hailey</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Riley</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangru</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mutethia</forename><surname>Mutuma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Rosand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabel</forename><surname>Trindade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renusree</forename><surname>Bandaru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00446</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="35" to="49" />
		</imprint>
	</monogr>
	<note>Transactions of the Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Enhancing financial table and text question answering with tabular graph and numerical reasoning</title>
		<author>
			<persName><forename type="first">Rungsiman</forename><surname>Nararatwong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natthawut</forename><surname>Kertkeidkachorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryutaro</forename><surname>Ichise</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing, AACL/IJCNLP 2022</title>
		<meeting>the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing, AACL/IJCNLP 2022<address><addrLine>Online Only</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2022-11-20">2022. November 20-23, 2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="991" to="1000" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Unik-qa: Unified representations of structured and unstructured knowledge for opendomain question answering</title>
		<author>
			<persName><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xilun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stan</forename><surname>Peshterliev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmytro</forename><surname>Okhonko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Sejr Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sonal</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yashar</forename><surname>Mehdad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Yih</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.findings-naacl.115</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics (NAACL)</title>
		<meeting><address><addrLine>Seattle, WA, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1535" to="1546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Compositional semantic parsing on semi-structured tables</title>
		<author>
			<persName><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/p15-1142</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>The Association for Computer Linguistics</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1470" to="1480" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Some simple effective approximations to the 2-poisson model for probabilistic weighted retrieval</title>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Walker</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-1-4471-2099-5_24</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 17th Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>ACM/Springer</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="232" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Content-based table retrieval for web queries</title>
		<author>
			<persName><forename type="first">Yibo</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhao</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neucom.2018.10.033</idno>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">349</biblScope>
			<biblScope unit="page" from="183" to="189" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Improving document representations by generating pseudo query embeddings for dense retrieval</title>
		<author>
			<persName><forename type="first">Hongyin</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingwu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beihong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.392</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL/IJCNLP</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL/IJCNLP</meeting>
		<imprint>
			<publisher>Virtual Event. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5054" to="5064" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Strubert: Structureaware BERT for table search and matching</title>
		<author>
			<persName><forename type="first">Mohamed</forename><surname>Trabelsi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><forename type="middle">D</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Heflin</surname></persName>
		</author>
		<idno type="DOI">10.1145/3485447.3511972</idno>
	</analytic>
	<monogr>
		<title level="m">WWW &apos;22: The ACM Web Conference 2022, Virtual Event</title>
		<meeting><address><addrLine>Lyon, France</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2022-04-25">2022. April 25 -29, 2022</date>
			<biblScope unit="page" from="442" to="451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">RAT-SQL: relation-aware schema encoding and linking for textto-sql parsers</title>
		<author>
			<persName><forename type="first">Bailin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleksandr</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.677</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-07-05">2020. July 5-10, 2020</date>
			<biblScope unit="page" from="7567" to="7578" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Retrieving complex tables with multi-granular graph representation learning</title>
		<author>
			<persName><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kexuan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Pujara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><forename type="middle">A</forename><surname>Szekely</surname></persName>
		</author>
		<idno type="DOI">10.1145/3404835.3462909</idno>
	</analytic>
	<monogr>
		<title level="m">SIGIR &apos;21: The 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, Virtual Event</title>
		<meeting><address><addrLine>Canada</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2021-07-11">2021. July 11-15, 2021</date>
			<biblScope unit="page" from="1472" to="1482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">TRANX: A transition-based neural abstract syntax parser for semantic parsing and code generation</title>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d18-2002</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-10-31">2018. October 31 -November 4, 2018</date>
			<biblScope unit="page" from="7" to="12" />
		</imprint>
	</monogr>
	<note>EMNLP 2018: System Demonstrations</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Tabert: Pretraining for joint understanding of textual and tabular data</title>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.745</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07-05">2020. July 5-10, 2020</date>
			<biblScope unit="page" from="8413" to="8426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task</title>
		<author>
			<persName><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongxu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zifan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irene</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingning</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shanelle</forename><surname>Roman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zilin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dragomir</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d18-1425</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3911" to="3921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Ad hoc table retrieval using semantic similarity</title>
		<author>
			<persName><forename type="first">Shuo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krisztian</forename><surname>Balog</surname></persName>
		</author>
		<idno type="DOI">10.1145/3178876.3186067</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 World Wide Web Conference on World Wide Web, WWW 2018</title>
		<meeting>the 2018 World Wide Web Conference on World Wide Web, WWW 2018<address><addrLine>Lyon, France</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018-04-23">2018. April 23-27, 2018</date>
			<biblScope unit="page" from="1553" to="1562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Seq2sql: Generating structured queries from natural language using reinforcement learning</title>
		<author>
			<persName><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno>CoRR, abs/1709.00103</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Reasoning over hybrid chain for table-and-text open domain QA</title>
		<author>
			<persName><forename type="first">Wanjun</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiahai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<idno>CoRR, abs/2201.05880</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">TAT-QA: A question answering benchmark on a hybrid of tabular and textual content in finance</title>
		<author>
			<persName><forename type="first">Fengbin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenqiang</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youcheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiancheng</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuli</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.254</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-08-01">2021. August 1-6, 2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3277" to="3287" />
		</imprint>
	</monogr>
	<note>Long Papers), Virtual Event</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
