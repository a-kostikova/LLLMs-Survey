<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Persuasive Memescape: Understanding Effectiveness and Societal Implications of Internet Memes</title>
				<funder ref="#_YTUx9yF">
					<orgName type="full">Wipro AI Labs, India</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Gitanjali</forename><surname>Kumari</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Indian Institute of Technology Patna</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pranali</forename><surname>Shinde</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Indian Institute of Technology Patna</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Asif</forename><surname>Ekbal</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Indian Institute of Technology Patna</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Make in India</roleName><forename type="first">Bharat</forename><surname>Abhiyan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Beti</forename><surname>Bachao</surname></persName>
						</author>
						<author>
							<persName><roleName>Digital India</roleName><forename type="first">Beti</forename><surname>Padhao</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jan</forename><forename type="middle">Dhan</forename><surname>Yojana</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Atmanirbhar</forename><surname>Bharat</surname></persName>
						</author>
						<title level="a" type="main">The Persuasive Memescape: Understanding Effectiveness and Societal Implications of Internet Memes</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">826B68479E14D0EBE68DADDF8DF185F2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-05-29T14:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Demonetization</term>
					<term>Odd-even rule</term>
					<term>GST</term>
					<term>Liquor ban in Bihar</term>
					<term>Fatwa</term>
					<term>Beef ban</term>
					<term>Love jihad</term>
					<term>Hindu-Muslim</term>
					<term>JNU incident 2016</term>
					<term>Article370</term>
					<term>Intolerance</term>
					<term>Islamophobia</term>
					<term>Citizenship Bill</term>
					<term>Anti Hindu</term>
					<term>darkisbeautiful</term>
					<term>fake Feminism</term>
					<term>No Acid</term>
					<term>arti-cle377</term>
					<term>me too</term>
					<term>Aurat Azadi March</term>
					<term>LGBTQ</term>
					<term>Dowry</term>
					<term>Parental Expectations</term>
					<term>Indian Festivals</term>
					<term>Cricket Rivalries</term>
					<term>Swachh</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Persuasive meme identification is a crucial task in automatically categorizing memes based on their persuasive nature. Memes, being highly influential in online communication, have the ability to shape individuals' attitudes, behaviors, and beliefs, both positively and negatively. They can be utilized to promote positive actions, challenge social norms, and raise awareness, but they can also perpetuate harmful ideologies, spread misinformation, stereotype, and manipulate emotions. In this paper, we are addressing this challenge by empirically investigating three novel tasks, viz. (i) Task 1: Persuasive meme detection, (ii) Task 2: Identification of the effectiveness of persuasive memes, and (iii) Task 3: Identification of persuasion techniques used in persuasive memes. To this end, we make the very first attempt to release a highquality, large-scale dataset, Persuasive_meme 1 , since there is no publicly available such dataset for the Hindi-English code-mixed (Hinglish) domain. 2 We further developed several baseline unimodal and multimodal models for these tasks. Empirical evaluation with respect to both, qualitative and quantitative analysis, on the Persuasive_meme dataset highlight the significance of multimodality in addressing these tasks effectively. Additionally, we discuss the limitations of the current models and emphasize the need for further research to overcome these challenges.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The rise of internet memes has revolutionized communication in the contemporary digital landscape, surpassing the boundaries of traditional textual and visual mediums. Memes, with their engaging, humorous, and relatable nature, have emerged as pow-1 Code and dataset are available at this link: https://www.iitp.ac.in/ ai-nlp-ml/resources.html#Persuasive-Meme as-well-as at our GitHub repository. https://github.com/Gitanjali1801/Persuasive_meme.git 2 WARNING: This paper contains meme samples that are offensive in nature.</p><p>erful tools for conveying messages and ideas <ref type="bibr" target="#b33">(Kirk et al., 2021)</ref>. These memes possess the potential for both positive and negative impacts, captivating audiences and shaping their perceptions. Many memes, despite being humorous, use extremism and dark humor to promote societal harm <ref type="bibr">(Kiela et al., 2020a;</ref><ref type="bibr" target="#b35">Kumari et al., 2021;</ref><ref type="bibr" target="#b2">Bandyopadhyay et al., 2023)</ref>. Meme analysis is, therefore, essential for detecting offensive content, analyzing psychological responses, and gaining a deeper understanding of the persuasive strategies employed in online communication, etc. <ref type="bibr" target="#b49">(Rijhwani et al., 2017;</ref><ref type="bibr" target="#b52">Sharma et al., 2020;</ref><ref type="bibr">Kiela et al., 2020a;</ref><ref type="bibr" target="#b56">Suryawanshi et al., 2020;</ref><ref type="bibr" target="#b23">Hossain et al., 2022;</ref><ref type="bibr" target="#b53">Sharma et al., 2022)</ref>. Prior studies have primarily focused on the humorous and cultural aspects of memes, overlooking their potential as persuasive tools <ref type="bibr" target="#b51">(Seiffert-Brockmann et al., 2018;</ref><ref type="bibr" target="#b42">Nee and Maio, 2019)</ref>. Consequently, the examination of memes' persuasive effectiveness remains an underexplored area, limiting our understanding of their true impact on individuals and society. Persuasion is a fundamental aspect of communication that seeks to influence the beliefs, desires, and actions of an audience <ref type="bibr" target="#b42">(Nee and Maio, 2019)</ref>. Several research has emphasized the importance of assessing persuasive communication in the digital domain <ref type="bibr" target="#b55">(Somasundaran and Wiebe, 2010;</ref><ref type="bibr" target="#b57">Tan et al., 2014;</ref><ref type="bibr" target="#b63">Trabelsi and Za√Øane, 2014;</ref><ref type="bibr" target="#b24">Jaech et al., 2015)</ref>. <ref type="bibr" target="#b16">Fahmy and Omneya (2021)</ref> highlighted the need for a comprehensive analysis of persuasive strategies employed in online visual content, including memes. Similarly, <ref type="bibr" target="#b50">(Seiffert-Brockmann and Diehl, 2016;</ref><ref type="bibr" target="#b51">Seiffert-Brockmann et al., 2018;</ref><ref type="bibr" target="#b42">Nee and Maio, 2019)</ref> have highlighted the potential of memes to influence public opinion and disrupt political decision-making, thus emphasizing the need for thorough investigations into the persuasive nature of memes. However, despite the existing studies, there is still a gap in empirical research within the field of Natu- ral Language Processing (NLP) that systematically evaluates the persuasive effectiveness of memes and explores their persuasive strategies. Persuasive memes possess the power to influence society both positively and negatively. A positively persuasive meme is used to convey powerful messages, challenge norms, and advocate for social change (c.f. Example (e,f) in Figure <ref type="figure" target="#fig_0">1</ref>). Contrarily, negatively persuasive memes can perpetuate harmful ideologies, spread misinformation, and manipulate emotions (c.f. Example (b,c) in Figure <ref type="figure" target="#fig_0">1</ref>). Understanding the impact of persuasive memes is crucial in shaping public opinion and promoting responsible communication <ref type="bibr" target="#b42">(Nee and Maio, 2019)</ref>. This research addresses this gap by analyzing the persuasive effectiveness of memes, offering valuable insights for informed and ethical digital discourse. Code-mixing The widespread use of code-mixed memes on social media platforms presents a significant challenge for meme analysis and understanding <ref type="bibr" target="#b15">(Edwards, 1995;</ref><ref type="bibr" target="#b1">Bali et al., 2014;</ref><ref type="bibr" target="#b49">Rijhwani et al., 2017;</ref><ref type="bibr" target="#b27">Kamble and Joshi, 2018;</ref><ref type="bibr" target="#b19">Ghanghor et al., 2021;</ref><ref type="bibr" target="#b23">Hossain et al., 2022)</ref>. To the best of our knowledge, there is no publicly available dataset for persuasion identification for English-Hindi (Hinglish) code-mixing. In order to address this gap and facilitate research in this area, we have created a dataset of Hinglish memes across four domains, namely political, religious, racist, and sexist. This dataset enables the analysis and exploration of persuasive techniques in code-mixed memes and contributes to the understanding of the persuasive nature of Hinglish memes in various contexts. Our Contributions: In this paper, we study persuasive memes, and formulate three tasks. Task 1 (Persuasive meme detection): Given a meme, detect whether it is persuasive or not. Task 2 (Identification of the effectiveness of persuasive memes): Given a persuasive meme, analyze the various categories of persuasive impact, ranging from highly negative to highly positive persuasion. Task 3 (Use of persuasion techniques): Given a persuasive meme, identify which techniques are used to enhance the persuasiveness and impact. To this end, we develop a novel code-mixed Hinglish dataset, named Persuasive_meme, containing 6k real memes in the Indian scenario, which we collected from social media and carefully annotated. In our study, we meticulously develop comprehensive annotation guidelines for all three tasks. We extensively evaluate multiple state-of-the-art unimodal and multimodal models to establish benchmark performance for these tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Persuasion detection in textual data: In the field of persuasion detection, researchers have shown significant interest in text-based analysis. For instance, <ref type="bibr" target="#b57">Tan et al. (2014)</ref> investigated the influence of wording in predicting the popularity of social media content. <ref type="bibr" target="#b21">Guerini et al. (2015)</ref> explored the impact of sounds on persuasiveness by examining euphony and focused on the phonetic aspect rather than language usage. Park et al. ( <ref type="formula">2016</ref>) developed an interactive system to assist human moderators in selecting high-quality news. Additionally, Reddit has become an important platform for research on social news analysis and recommendation, as demonstrated by previous studies exploring language use, community reactions, and comment analysis <ref type="bibr" target="#b8">(Buntain and Golbeck, 2014;</ref><ref type="bibr" target="#b24">Jaech et al., 2015;</ref><ref type="bibr" target="#b58">Tan et al., 2016)</ref>. <ref type="bibr" target="#b64">Wei et al. (2016)</ref> investigated the identification of persuasive comments in online forums using several feature identification techniques. Persuasion detection in visual data: The advent of social media has driven researchers to incorporate images into their analyses to better understand persuasion and its intentions. Political science and mass media scholars have explored audiences' emotional and cognitive responses to televised images of political leaders <ref type="bibr" target="#b7">(Bucy and Bradley, 2004;</ref><ref type="bibr" target="#b40">Masters et al., 1986)</ref> and investigated the selective use of images by the media for persuasive purposes <ref type="bibr" target="#b3">(Barnhurst and Steele, 1997;</ref><ref type="bibr" target="#b20">Grabe and Bucy, 2010)</ref>. <ref type="bibr" target="#b25">Joo et al. (2014)</ref> have demonstrated the value of systematically examining communicative intents in uncovering deeper insights into the meaning and persuasive impact of images, transcending surface-level feature classification.</p><p>Other studies on memes: The widespread proliferation of memes and their increasing impact on online communication have recently sparked research interest in meme analysis in the NLP community. However, the existing efforts in meme analysis have primarily centered around identifying hateful or offensive memes <ref type="bibr" target="#b49">(Rijhwani et al., 2017;</ref><ref type="bibr" target="#b52">Sharma et al., 2020;</ref><ref type="bibr">Kiela et al., 2020a;</ref><ref type="bibr" target="#b56">Suryawanshi et al., 2020;</ref><ref type="bibr" target="#b23">Hossain et al., 2022;</ref><ref type="bibr" target="#b53">Sharma et al., 2022)</ref>, or detection of propaganda techniques <ref type="bibr" target="#b13">(Dimitrov et al., 2021)</ref> with limited attention given to the identification of persuasive memes. Code-mixing: Furthermore, most of the existing works for memes in the code-mixed settings have been performed on textual data <ref type="bibr" target="#b27">(Kamble and Joshi, 2018;</ref><ref type="bibr" target="#b1">Bali et al., 2014;</ref><ref type="bibr" target="#b41">Mathur et al., 2018;</ref><ref type="bibr" target="#b60">Tang et al., 2020;</ref><ref type="bibr" target="#b5">Bohra et al., 2018)</ref>. Persuasiveness identification in multimodal, especially in Hinglish scenarios, is primarily unexplored due to inadequate resources and tools. As a result, there is a significant gap in the research landscape when it comes to identifying persuasive memes. This paper aims to address this gap by focusing specifically on the task of persuasive meme identification and exploring their impact on social media platforms, mainly in Hinglish.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Corpus Creation</head><p>We create a new dataset due to the lack of an existing Hinglish dataset for persuasion identification in memes. During the preparation of this corpus (henceforth referred to as Persuasive_Meme), we take the following steps: (i) Data Collection, (ii) Annotation process, (iii) Annotation guidelines, and (iv) Data statistics. We discuss these steps below in more detail:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Collection</head><p>We collected memes covering various domains, such as politics, religion, and social issues like terrorism, racism, sexism, etc., using a list of 126 keywords (c.f. Table <ref type="table">1</ref>). To keep a strategic distance from copyright issues, we only retrieved the freely available memes in the public domain with the help of a browser extension called Download All Images of Google's image search engine 3 . We finally retain only around 6K unique memes after removing the duplicates. (c.f. Figure <ref type="figure" target="#fig_1">2</ref> for the data collection process.) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Annotation process</head><p>For the annotation purpose, we require experienced annotators with an expert-level understanding of the code-mixed Hindi-English language. The annotation team comprises of three highly qualified members, both male and female, 20-25 years old, who possessed undergraduate degrees and extensive experience in code-mixed Hindi-English and NLP research. Their expertise and fluency in the language ensured the quality of the annotation process. It is important to note that no incentives were provided to the annotators to maintain objectivity. Furthermore, we only included annotators familiar with the Indian scenario. To address this, we divided the process into three distinct phases: (i) Dry Run, (ii) Final Annotation, and (iii) Consolidation. Details of each step are described in the following sections.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Phase 1: Pre-processing and Text editing</head><p>The collected raw memes are (i). noisy such as background pictures are not clear, (ii) non-codemixed Hindi-English, i.e., meme texts are written in other languages except code-mixed Hindi-English, and (iii) non-multi-modal, i.e., memes contain either text or visual content. We manually discarded these memes to reduce manual data annotation effort. Next, we extracted the textual part of each meme using an open-source Optical Character Recognition (OCR) tool: Tesseract 4 . The OCR errors are manually post-corrected by the annotators. Finally, we consider 6,000 memes for data annotation. The average meme text length for the memes samples in our dataset is between 10-20 words. (Refer to Figure <ref type="figure" target="#fig_2">4</ref> to see the plot. )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Phase 2: Dry run</head><p>This stage is the pilot annotations to train the annotators to understand our annotation guidelines. In Figure <ref type="figure" target="#fig_3">3</ref>, we have shown our annotation interface. We annotated 200 samples on our own to use as a quality checker while evaluating the annotators' ability. We conducted a dry run on the same 200 memes, which helped the annotators understand well the definitions of all the labels, as well as eliminate the uncertainties/challenges about the annotation guidelines. For the preliminary data, one meme is annotated by three annotators. For Tasks 1 and task 2, we computed the inter-annotator agreement(IAA) in terms of Cohen's Kappa coefficient 4 github.com/tesseract-ocr/tesseract  <ref type="bibr">(Kiela et al., 2020b)</ref> Open English ‚úì ‚úì Offensive 10K Harmful meme <ref type="bibr" target="#b53">(Sharma et al., 2022)</ref> Open English ‚úì ‚úì Offensive 3.5K Memotion <ref type="bibr" target="#b52">(Sharma et al., 2020)</ref> Open English ‚úì ‚úì Offensive 7K MAMI <ref type="bibr" target="#b18">(Fersini et al., 2022)</ref> Misogynous English ‚úì ‚úì Offensive 10K MUTE <ref type="bibr" target="#b23">(Hossain et al., 2022)</ref> Open CM Eng-Ben ‚úì ‚úì Offensive 4K Persuasive_memes (Ours)</p><p>Multi-domain Hinglish ‚úì ‚úì Persuasion/Effect/Technique 6K  <ref type="bibr" target="#b4">(Bernadt and Emmanuel, 1993)</ref>, and for Task 3 in a multilabel scenario, we reported Krippendorff's Alpha Coefficient (krippendorff, 2011). We average the Cohen's Kappa/Krippendorff's Alpha Coefficient score of all three annotators a i for i= 1 to 3 for each meme for all three tasks. It was observed that the initial scores for all three tasks were low (0.6529, 0.8097, and 0.5874), which is typical for a first pilot test. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Phase 3: Final Annotation</head><p>After phase 3.2.2, the training process was completed. Now, in this phase, we started the final annotation process. We asked the annotators to annotate a given meme with the correct label of each layer as given in the annotation guidelines. After confirming the validity of the meme, we proceed toward the consolidation phase of the annotation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">Phase 4: Consolidation</head><p>Phase 3.2.4 is the process in which the annotations from phase 3.2.3 are consolidated. This step was critical for maintaining quality, as well as providing additional training for the entire team, which we found really beneficial. In the case of disagreements, we solved them by agreeing on a common point after a lot of discussions. At the end of this phase, we finally obtained the IAA score of 0.7197, 0.89380, and 0.69721, respectively, for all three tasks, which is interpreted as substantial agreement.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Annotation for identification of persuasive memes</head><p>Any meme will be annotated as Persuasive memes if it aims to influence or persuade individuals' attitudes, behaviors, or beliefs <ref type="bibr" target="#b64">(Wei et al., 2016;</ref><ref type="bibr" target="#b42">Nee and Maio, 2019)</ref>. These memes typically employ various persuasive techniques such as metaphors, analogies, humor, satire, or manipulation of information to convey a particular message or agenda.</p><p>(Refer to samples (b-f) in Figure <ref type="figure" target="#fig_0">1</ref>). On the other hand, Non-persuasive memes refer to memes that do not have a specific persuasive intent. They are often created for entertainment purposes, to share jokes, and memes related to popular culture, or to simply evoke laughter without attempting to change opinions or promote a specific viewpoint. These memes may focus on humor, irony, or relatability without a deliberate persuasive agenda (Refer to sample (a) in Figure <ref type="figure" target="#fig_0">1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Annotation for the effectiveness of persuasive meme</head><p>The measurement of effectiveness in persuasive interventions is crucial, yet it can be challenging to directly measure actual persuasiveness <ref type="bibr" target="#b11">(Thomas et al., 2019)</ref>. To measure the persuasiveness of memes, we inlined our work with previous research <ref type="bibr" target="#b28">(Kaptein et al., 2009;</ref><ref type="bibr" target="#b10">Busch et al., 2016;</ref><ref type="bibr" target="#b0">Anagnostopoulou et al., 2017;</ref><ref type="bibr" target="#b44">Oduor and Oinas-Kukkonen, 2017)</ref> and assess the perceived persuasiveness rather than directly measuring the persuasive impact. To achieve this, we employed three scaling items: Motivational, Appropriateness, and Effectiveness <ref type="bibr" target="#b61">(Thomas et al., 2017)</ref>, to evaluate the impact of memes on society. To quantify the persuasive nature of memes based on these items, we employed the Likert scale <ref type="bibr" target="#b39">(Likert, 1932)</ref>, a known technique in the field of persuasion. This scale allowed annotators to rate their agreement or disagreement with statements, enabling us to quantify the level of persuasion perceived by the memes.</p><p>‚Ä¢ -2: Strongly Disagree (Highly Negative Persuasion): Based on the evaluation of the above scaling items of persuasive memes, the annotators strongly disagree that these memes have a positive influence. They perceive such memes as highly negative and firmly believe that memes exert a strong negative impact on the target audience due to their use of aggressive tactics or manipulative strategies. (c.f. sample (a) in Figure <ref type="figure" target="#fig_0">1</ref>). ‚Ä¢ -1: Disagree (Moderately Negative Persuasion): Evaluating such persuasive memes, the annotators disagree that these memes have a positive impact. They find the memes moderately negative in their approach, as they employ fear appeals, problem identification, or social disapproval to discourage certain behaviors or beliefs. However, the annotators do not perceive these memes as excessively harmful or manipulative in nature (c.f. sample (b) in Figure <ref type="figure" target="#fig_0">1</ref>). ‚Ä¢ 0: Neutral (Neutral Persuasion): Annotators hold a neutral perception of persuasive memes, neither strongly positive nor negative. They perceive the memes as neither highly impactful nor devoid of influence. They view them as presenting information or arguments without a distinct positive or negative leaning (c.f. sample (c) in Figure <ref type="figure" target="#fig_0">1</ref>). ‚Ä¢ 1: Agree (Moderately Positive Persuasion):</p><p>Evaluating the above scaling items aspects of persuasive memes, the annotators agree that these memes have a moderately positive influence. They find the memes to be encouraging, educational, or empowering. However, it is important to acknowledge that while these moderately positive memes hold value and impact, they may not reach the same level of overwhelming positivity as those in the highly positive category (2) (c.f. sample (d) in Figure <ref type="figure" target="#fig_0">1</ref>). ‚Ä¢ 2: Strongly Agree (Highly Positive Persuasion): The annotators strongly agree that persuasive memes are remarkably positive, serving as a source of inspiration and effectively motivating individuals towards beneficial actions, attitudes, or beliefs. They firmly believe that these memes have a substantial positive impact on the target audience. (c.f. sample (e) and (f) in Figure <ref type="figure" target="#fig_0">1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Annotation for the use of persuasion techniques</head><p>For this task, the annotation process requires annotators to thoroughly analyze the rhetorical strategies employed in the creation of persuasive memes and annotate the memes accordingly. It involves identifying and labeling all relevant rhetorical devices in a multi-label scenario, as they are instrumental in enhancing the persuasive nature of the meme. By annotating the rhetorical devices, we gain a deeper understanding of the persuasive techniques utilized <ref type="bibr" target="#b9">(Burgers et al., 2016)</ref> and their contribution to the overall persuasive impact of the meme.</p><p>‚Ä¢ Metaphors (1): Comparisons that highlight similarities between two things are used to make complex ideas more accessible, relatable, and persuasive in memes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Dataset statistics and comparison with existing datasets</head><p>Our dataset, Persuasive_memes, has a total of 6,000 annotated memes, which provides a substantial resource for studying persuasive memes (c.f. Figure <ref type="figure" target="#fig_4">5</ref>). It provides several unique advantages and distinct features compared to existing datasets (c.f Table <ref type="table" target="#tab_1">2</ref>). It covers a broader range of domains, including political, religious, racist, and sexist themes, enabling a comprehensive analysis of persuasive communication. Unlike other datasets, Per-suasive_memes is code-mixed, incorporating both Hindi and English languages and capturing cultural nuances. It is also multimodal, featuring both textual and visual components for a comprehensive examination of persuasive techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Lexical Analysis of the dataset</head><p>Table <ref type="table" target="#tab_3">3</ref> shows the most frequent words for Task 1 (Persuasive/Non-persuasive) and Task 2 (-2: Strongly Disagree to 2: Strongly Agree). In Task 1, the persuasive class includes words related to politics, social issues, and religion, while the nonpersuasive class focuses on everyday topics, relationships, and school. For Task 2, strongly dis-Figure <ref type="figure">6</ref>: A comprehensive framework for our proposed tasks, incorporating five different approaches: (i) utilizing transformer-based pre-trained models for extracting textual features, (ii) employing visual pretrained models for extracting visual features, (iii) utilizing pre-trained embeddings in conjunction with RNNs and CNNs for sentence representation and feature extraction, (iv) leveraging pre-trained multimodal models for extracting multimodal features, and (v) employing early fusion techniques to obtain a multimodal representation. These diverse representations are then passed through a dense layer and a softmax layer for the final class prediction.</p><p>agree memes exhibit negative sentiment and criticism, disagree memes involve political and societal disagreement, neutral memes revolve around daily life and social norms, agree memes align with popular opinions and thoughts, and strongly agree memes evoke positive emotions and shared interests. Overall, Task 1 involves persuasive/nonpersuasive memes, and Task 2 explores the range of agreement and disagreement on various topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Task Definition</head><p>In this paper, we aim at solving three tasks individually using a deep-learning framework: (i) t1: Persuasive meme detection, (ii) t2: Identification of the effectiveness of persuasive meme, and (iii) t3: Identification of persuasion techniques. Let every meme S i ‚àà {T, V} is a set with text T i = (t i 1 , t i 2 , ...., t i k ), and image I i with the shape (224,224,3) in RGB pattern. In the i th meme, k refers to the total number of words in the textual part of the meme. Our goal is to predict the correct label of each task, i.e., ≈∑t1 ‚äÜ{persuasive, non-persuasive}, ≈∑t2 ‚äÜ{-2, -1, 0, 1, 2} and ≈∑t3 ‚äÜ{1, 2, 3, 4, 5, 6, 7, 8, 9} for each S i . The purpose of this task is to maximize the value of the following function:</p><formula xml:id="formula_0">argmax Œ∏ tk Œ† n i=0 Œ† k j=0 P ≈∑i tk | S i ; Œ∏ tk (1)</formula><p>where tk is the current task in {t1, t2, t3}, S i is the current meme, P is the log-likelihood, and Œ∏ is the model parameter which is needed to be optimized.</p><p>5 Baseline Models</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Unimodal Systems</head><p>For the text-based baseline model, we implement LSTM with FastText embedding <ref type="bibr" target="#b6">(Bojanowski et al., 2016)</ref>(L_FT), LSTM with Character level Encoding (L_Char), m-BERT <ref type="bibr" target="#b46">(Pires et al., 2019)</ref>, LaBSE <ref type="bibr" target="#b17">(Feng et al., 2020)</ref>, Muril <ref type="bibr" target="#b29">(Khanuja et al., 2021)</ref>, Indic_BERT <ref type="bibr" target="#b26">(Kakwani et al., 2020)</ref>, VGG-19 (Simonyan and Zisserman, 2015), ResNet <ref type="bibr" target="#b22">(He et al., 2015)</ref>, ViT <ref type="bibr" target="#b14">(Dosovitskiy et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Multimodal Systems</head><p>Early Fusion: For this category, we extract textual and visual features from different pretrained models and then applied early fusion to get a multimodal representation. By doing so, we develop the following baseline models: L_Char+VGG, L_FT+VGG, mBERT+ViT, LaBSE++ViT, Muril+ViT and Indic BERT+ViT Pre-trained Models: For the pre-trained multimodal system, we used the following pretrained models to extract the multimodal features: LXMERT (Tan and Bansal, 2019), VisualBERT <ref type="bibr" target="#b38">(Li et al., 2019)</ref>. Further, we used another three multimodal feature extractors (mCLIP <ref type="bibr" target="#b47">(Radford et al., 2021)</ref>, BLIP <ref type="bibr" target="#b36">(Li et al., 2022)</ref>, and ALBEF <ref type="bibr" target="#b37">(Li et al., 2021)</ref>, M3P <ref type="bibr">(Ni et al., 2020)</ref>). Each of their features is passed through a projection layer to make the final predictions for Task 1, Task 2, and Task 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental setups</head><p>We evaluate our proposed architecture on our curated dataset. Details of each task's train and test set distribution are given in the Appendix Table <ref type="table" target="#tab_5">5</ref> and 6. The optimal hyperparameters for our model are found using grid search. we have used Pytorch Lightning 5 framework for the implementation. We use Adam optimizer with weight decay (Kingma and Ba, 2015) with a learning rate of 3e-5 for all the models. We train the model for 60 epochs with 64 batch sizes and early-stopping callback. We consistently use a 32 batch size while training with a fixed random seen of 123. All the models are trained for 20 epochs, and we take the last checkpoint to evaluate the baselines. A single NVIDIA Tesla GPU is used to conduct the experiments.</p><p>7 Results and Analysis</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Model results and comparison</head><p>In this section, we show the results that outline the comparison between several baseline models.</p><p>For evaluation of our tasks in Table <ref type="table">4</ref>, we use the F1 score (F1-score), accuracy (A), and hamming loss (H-loss) as the preferred metrics. The results from Table <ref type="table">4</ref> provide valuable insights into the performance of different models in the three persuasion tasks. In Task 1, the baseline models L_FT and L_Char have low accuracy scores, while pre-trained models like m-BERT, LaBSE, Muril, and Indic BERT achieved higher accuracy scores, indicating their superior performance in classifying memes as persuasive or non-persuasive due to their ability to capture language patterns and contextual information. In Task 2, baseline models had limited performance in identifying the effect of persuasiveness. However, the pre-trained models VisualBERT and M3P achieved higher accuracy scores of 58.75% and 60.63%, respectively. These results indicate that these models were effective in capturing the nuanced effects conveyed by persuasive memes, outperforming the baseline models in understanding the impact of persuasiveness. For Task 3, which focused on identifying persuasion techniques, the baseline models showed modest performance. Among the pre-trained models, M3P achieved the highest accuracy score of 58.62%. This suggests that M3P successfully captured the distinctive persuasion techniques used in the memes, highlighting the importance of leveraging pre-trained models for identifying specific persuasive strategies. Overall, the M3P model, with multimodal features, outperforms the baseline models in all three persuasion tasks, emphasizing the importance of analyzing both textual and visual aspects of persuasive memes, and its success can be attributed to capturing contextual information, linguistic nuances and visual cues essential for understanding persuasive impact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Modality Importance</head><p>In this section, we highlight the significance of incorporating both textual and visual modalities in the identification of persuasive memes. By leveraging both modalities, we can access complementary information that enhances our ability to discern the intent and meaning of a meme. In Figure <ref type="figure" target="#fig_5">7</ref>(i) (a) in the Appendix, we illustrate how relying solely on the textual modality falls short of understanding the persuasiveness of the meme. However, when we incorporate multimodal information, the M3P model gains access to hidden cues of persuasiveness, leading to accurate labeling for Task 1. Similarly, in the case of sample (b) in Appendix Figure <ref type="figure" target="#fig_5">7</ref> (i), relying solely on the visual modality proves insufficient in capturing the hidden cues of the meme. But once again, with the inclusion of multimodal information, the model successfully identifies the correct label for Task 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Explainability and Diagnostics</head><p>After training, our M3P model utilizes contextual information within the memes to justify its predictions. Using the LIME (Dieber and Kirrane, 2020) technique; we provide locally interpretable and human-understandable explanations for our model's predictions. In the first meme (In Appendix Figure <ref type="figure" target="#fig_6">8</ref>), the M3P model correctly predicts the persuasive and negatively persuasive labels based on specific super-pixels corresponding to the person's face and words like "Mitro{Friends}" and "Fek{Throw}" in the text. These visual and textual elements convey persuasive intent and negative connotations. Similarly, in the second meme (In Appendix Figure <ref type="figure" target="#fig_6">8</ref>), the M3P model accurately predicts the meme as both persuasive and negatively persuasive, with certain super-pixels representing the person's face and phrases, such as "Dilo me apni betabiyaan" (restlessness in your hearts) and "4-5 backlogs lekar chal rhe ho to Engineer ho tum" (if you are moving forward with 4-5 backlogs, then you are an Engineer) playing a significant role. These findings demonstrate how the M3P model effectively incorporates visual and textual cues to make precise predictions based on the persuasive and negative characteristics of the memes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Error Analysis</head><p>In our analysis of the error prediction of our topperforming model (M3P), we identify categories contributing to misclassification and analyze the reasons for these errors: (i) Lack of contextual knowledge: The first category relates to cases where the textual and visual components do not provide enough background or domain-related information. As a result, the model considers these memes as non-persuasive, despite their superficial persuasive nature, simply because of the absence of contextual/domain-related knowledge (c.f. sample (a) and (b) in the Appendix Figure <ref type="figure" target="#fig_5">7</ref>).</p><p>(ii) Lack of common sense knowledge: The second category involves a lack of common sense knowledge, where our model struggles to intuitively reason about everyday situations and events, resulting in incorrect predictions of the persuasive class. (c.f. sample (c) in the Appendix Figure <ref type="figure" target="#fig_5">7</ref>).</p><p>(iii) Due to the longer sentence length: In the third category, misclassifications occur when the sentence length is longer than the average, as illustrated in sample (d) in the Appendix Figure <ref type="figure" target="#fig_5">7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>In conclusion, while internet memes have become ubiquitous in the digital landscape, their persuasive effectiveness remains a significant, yet underexplored area of research. This study aims to bridge this gap by conducting a comprehensive evaluation of persuasive memes, offering valuable insights into their impact on society and their potential to shape public opinion. By filling this void in the current literature, the research presented here seeks to advance our understanding of persuasive communication in the digital age, fostering informed discussions and facilitating responsible meme usage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitation</head><p>In Section 8, we discussed the limitations of our proposed work. Our baseline models struggle with the detection of subtle or implicit persuasive elements in memes. Some persuasive techniques may be context-dependent or rely on cultural references that are difficult for the models to capture accurately. By analyzing these errors, we gain valuable insights into the limitations and challenges faced by our model, which can guide future improvements in persuasive meme identification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics and Broader Impact</head><p>Individual Privacy The resources we created for this study were derived from publicly available memes, and we strictly adhered to the restrictions on data usage to avoid any infringement of copyright laws. Furthermore, our study was evaluated and approved by our Institutional Review Board (IRB). We plan to make our code and data accessible for research purposes, subject to appropriate data agreement procedures, upon acceptance of our study.</p><p>To maintain the anonymity of any individual, we replaced the actual name with Person-XYZ throughout the paper. In addition, we also tried to anonymize the known faces presented in the visual part of the meme by masking them. We have masked these faces only to maintain the anonymity issues in the paper. During the implementation, we used the original image.</p><p>Biases Detecting and removing political and religious biases is an extensive research area. However, previous annotation studies show that we cannot correctly remove bias and subjectivity from the annotation process despite having some form of annotation scheme. However, any biases detected in our dataset are unintentional, and we have no intention of harming any individual or group. We ensure that our data collection is generated equally and comparably in order to answer any political and religious bias queries. Furthermore, we ensure that the topic includes various issues relevant to the Indian context over the last seven years by using a keywordbased data-gathering technique. Moreover, we made sure that the terms included were inclusive of all the conceivable politicians, political organizations, young politicians, extreme groups, and religions and were not prejudiced against any one group. Based on previous work done by <ref type="bibr" target="#b11">(Davidson et al., 2019)</ref> to remove biases from the dataset during annotation, in our dataset, annotators were strictly instructed not to make decisions based on what they believe but on what the social media user wants to transmit through that meme.</p><p>Misuse Potential We suggest that researchers be aware that our dataset might be abused to filter the memes based on prejudices that may or may not be connected to demographics or other textual information. To prevent this from happening, human intervention with moderation would be essential. Intended Use Our dataset is presented to encourage research into studying persuasive memes on the internet. We believe that it represents a valuable resource when used appropriately.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Examples from our Persuasive_meme dataset. The labels are in the format Persuasion_[Identification, Effect, Techniques]. For Identification, {0, 1} correspond to Non-persuasive and Persuasive memes, respectively. For Effect, {-2, -1, 0, 1, 2} correspond to Highly Negative Persuasion, Moderately Negative Persuasion, Neutral Persuasion, Moderately Positive Persuasion and Highly Positive Persuasion, respectively. For Techniques {Metaphors, Analogies, Hyperboles, Irony, Alliteration, Personification, Puns and wordplay, and Invective}. Texts in {} are the English translation of code-mixed Hindi-English meme texts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Data collection procedure</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Histogram of the length of the meme' text for each class: On the top for Persuasion Identification, and for the effectiveness of persuasive memes on the bottom.</figDesc><graphic coords="4,70.54,70.54,291.30,138.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Our Annotation interface. The right part shows labels for each task and the left part shows a meme for which annotation has to be done.</figDesc><graphic coords="4,256.23,323.28,244.95,100.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Class distribution of each label of Persua-sive_meme data.</figDesc><graphic coords="4,306.43,343.82,202.41,82.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: (i) Modality Importance: Test cases where unimodal systems (either text-only model or image-only model) fail to correctly predict the persuasion class whereas the multimodal system effectively predicted the persuasion class. (ii) Error Analysis: Mis-classification by the best performing M3P model</figDesc><graphic coords="14,116.22,577.21,203.86,70.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Visualization by LIME (Ribeiro et al., 2016) for best performing M3P model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note><p>Comparison of our dataset with some existing dataset. Here, 2016 U.S. Pre. Ele.: U.S.Presidential Election, CM Eng-Ben: Code-Mixed English-Bengali, Hinglish: Code-Mixed Hindi-English</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Top-5 most frequent words per class using Tf-Idf</figDesc><table><row><cell>3.3 Annotation guidelines</cell></row><row><cell>Based on the context of memes, annotators have</cell></row><row><cell>annotated each meme with three labels: (i) Level</cell></row><row><cell>1: Persuasive/non-persuasive,(ii) Level 2: (a) -2:</cell></row><row><cell>Strongly Disagree (Highly Negative Persuasion),</cell></row><row><cell>(b) -1: Disagree (Moderately Negative Persua-</cell></row><row><cell>sion), (c) 0: Neutral (Neutral Persuasion), (d) 1:</cell></row><row><cell>Agree (Moderately Positive Persuasion), and (e) 2:</cell></row><row><cell>Strongly Agree (Highly Positive Persuasion), (iii)</cell></row><row><cell>Level 3: Persuasion Techniques/ Rhetorical De-</cell></row></table><note><p>vices (multi-label), i.e., (a) Metaphors, (b) Analogies, (c) Hyperboles, (d) Irony, (e) Alliteration, (f) Personification, (g) Puns and wordplay, (i) Invective, and (j) Satire for each meme.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Class wise data distribution of Persuasive_meme dataset for Task 1 and Task 2</figDesc><table><row><cell>Split</cell><cell>#Memes</cell><cell></cell><cell>Task 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Task 2</cell><cell></cell></row><row><cell></cell><cell cols="2">Persuasive</cell><cell cols="2">Non-persuasive</cell><cell cols="2">Positively persuasive</cell><cell cols="2">Slightly Positively persuasive</cell><cell>Neutral</cell><cell>Slightly Negatively persuasive</cell><cell>Negatively persuasive</cell></row><row><cell>Train</cell><cell>4800</cell><cell>2818</cell><cell></cell><cell>1982</cell><cell></cell><cell>99</cell><cell></cell><cell>75</cell><cell>978</cell><cell>1261</cell><cell>405</cell></row><row><cell>Test</cell><cell>1200</cell><cell>717</cell><cell></cell><cell>483</cell><cell></cell><cell>31</cell><cell></cell><cell>45</cell><cell>226</cell><cell>340</cell><cell>106</cell></row><row><cell>Split</cell><cell>#Memes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Task 3</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">Metaphors</cell><cell cols="2">Hyperboles</cell><cell>Personification</cell><cell>Alliteration</cell><cell>Irony</cell><cell>Analogies</cell><cell>Puns_and_wordplay</cell><cell>Satire</cell><cell>Invective</cell></row><row><cell>Train</cell><cell>4800</cell><cell></cell><cell>29</cell><cell></cell><cell>466</cell><cell>122</cell><cell>42</cell><cell>1238</cell><cell>275</cell><cell>263</cell><cell>1268</cell><cell>324</cell></row><row><cell>Test</cell><cell>1200</cell><cell></cell><cell>5</cell><cell></cell><cell>118</cell><cell>21</cell><cell>7</cell><cell>297</cell><cell>72</cell><cell>73</cell><cell>306</cell><cell>83</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Class wise data distribution of Persuasive_meme dataset for Task 3</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_0"><p>https://www.pytorchlightning.ai/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The research reported in this paper is an outcome of the project "<rs type="projectName">HELIOS: Hate, Hyperpartisan</rs>, and <rs type="person">Hyperpluralism Elicitation</rs> and <rs type="person">Observer System</rs>," sponsored by <rs type="funder">Wipro AI Labs, India</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_YTUx9yF">
					<orgName type="project" subtype="full">HELIOS: Hate, Hyperpartisan</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Exploring the links between persuasion, personality and mobility types in personalized mobility applications</title>
		<author>
			<persName><forename type="first">Evangelia</forename><surname>Anagnostopoulou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babis</forename><surname>Magoutas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Efthimios</forename><surname>Bothos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johann</forename><surname>Schrammel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rita</forename><surname>Orji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregoris</forename><surname>Mentzas</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-55134-0_9</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="107" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">I am borrowing ya mixing ?&quot; an analysis of English-Hindi code mixing in Facebook</title>
		<author>
			<persName><forename type="first">Kalika</forename><surname>Bali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jatin</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monojit</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yogarshi</forename><surname>Vyas</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/W14-3914</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Computational Approaches to Code Switching</title>
		<meeting>the First Workshop on Computational Approaches to Code Switching<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="116" to="126" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A knowledge infusion based multitasking system for sarcasm detection in meme</title>
		<author>
			<persName><forename type="first">Dibyanayan</forename><surname>Bandyopadhyay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gitanjali</forename><surname>Kumari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asif</forename><surname>Ekbal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Information Retrieval</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Nature Switzerland</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="101" to="117" />
		</imprint>
	</monogr>
	<note>Santanu Pal, Arindam Chatterjee, and Vinutha BN</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Image-bite newsthe visual coverage of elections on u.s. television, 1968-1992</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Barnhurst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Steele</surname></persName>
		</author>
		<idno type="DOI">10.1177/1081180X97002001005</idno>
	</analytic>
	<monogr>
		<title level="m">Harvard International Journal of Press-politics -HARV INT J PRESS-POLIT</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="40" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Diagnostic agreement in psychiatry. The British journal of psychiatry : the journal of mental science</title>
		<author>
			<persName><forename type="first">Morris</forename><surname>Bernadt</surname></persName>
		</author>
		<author>
			<persName><surname>Emmanuel</surname></persName>
		</author>
		<idno type="DOI">10.1192/S0007125000034012</idno>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">163</biblScope>
			<biblScope unit="page" from="549" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A dataset of Hindi-English code-mixed social media text for hate speech detection</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Bohra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deepanshu</forename><surname>Vijay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinay</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Syed</forename><surname>Sarfaraz Akhtar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manish</forename><surname>Shrivastava</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-1105</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Computational Modeling of People&apos;s Opinions, Personality, and Emotions in Social Media</title>
		<meeting>the Second Workshop on Computational Modeling of People&apos;s Opinions, Personality, and Emotions in Social Media<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="36" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.04606</idno>
		<title level="m">Enriching word vectors with subword information</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Presidential expressions and viewer emotion: Counterempathic responses to televised leader displays</title>
		<author>
			<persName><forename type="first">Erik</forename><forename type="middle">P</forename><surname>Bucy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><forename type="middle">D</forename><surname>Bradley</surname></persName>
		</author>
		<idno type="DOI">10.1177/05390184040689</idno>
	</analytic>
	<monogr>
		<title level="j">Social Science Information</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="94" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Identifying social roles in reddit using network structure</title>
		<author>
			<persName><forename type="first">Cody</forename><surname>Buntain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Golbeck</surname></persName>
		</author>
		<idno type="DOI">10.1145/2567948.2579231</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on World Wide Web, WWW &apos;14 Companion</title>
		<meeting>the 23rd International Conference on World Wide Web, WWW &apos;14 Companion<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="615" to="620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Christian</forename><surname>Burgers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elly</forename><forename type="middle">A</forename><surname>Konijn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerard</forename><forename type="middle">J</forename><surname>Steen</surname></persName>
		</author>
		<idno type="DOI">10.1111/comt.12096</idno>
		<title level="m">Figurative Framing: Shaping Public Discourse Through Metaphor, Hyperbole, and Irony. Communication Theory</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="410" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Persuasive information security: Techniques to help employees protect organizational information security</title>
		<author>
			<persName><forename type="first">Marc</forename><surname>Busch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Regal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christina</forename><surname>Hochleitner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manfred</forename><surname>Tscheligi</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-31510-2_29</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Conference on Persuasive Technology</title>
		<meeting>the 11th International Conference on Persuasive Technology<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="volume">9638</biblScope>
			<biblScope unit="page" from="339" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Racial bias in hate speech and abusive language detection datasets</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debasmita</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ingmar</forename><surname>Weber</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W19-3504</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on Abusive Language Online</title>
		<meeting>the Third Workshop on Abusive Language Online<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="25" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Why model why? assessing the strengths and limitations of lime</title>
		<author>
			<persName><forename type="first">Jurgen</forename><surname>Dieber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kirrane</surname></persName>
		</author>
		<idno>ArXiv, abs/2012.00093</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Detecting propaganda techniques in memes</title>
		<author>
			<persName><forename type="first">Dimitar</forename><surname>Dimitrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Bishr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaden</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Firoj</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabrizio</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamed</forename><surname>Silvestri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preslav</forename><surname>Firooz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giovanni</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">San</forename><surname>Da</surname></persName>
		</author>
		<author>
			<persName><surname>Martino</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.516</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6603" to="6617" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
		<idno>CoRR, abs/2010.11929</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">F</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName><surname>Edwards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language in Society</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="302" to="305" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">No memes no! digital persuasion in the metoo era</title>
		<author>
			<persName><forename type="first">Shahira</forename><surname>Fahmy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ibrahim</forename><surname>Omneya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Communication</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="2942" to="2967" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Language-agnostic BERT sentence embedding</title>
		<author>
			<persName><forename type="first">Fangxiaoyu</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinfei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naveen</forename><surname>Arivazhagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<idno>CoRR, abs/2007.01852</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">SemEval-2022 task 5: Multimedia automatic misogyny identification</title>
		<author>
			<persName><forename type="first">Elisabetta</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesca</forename><surname>Gasparini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giulia</forename><surname>Rizzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurora</forename><surname>Saibene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Berta</forename><surname>Chulvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alyssa</forename><surname>Lees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Sorensen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.semeval-1.74</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Workshop on Semantic Evaluation (SemEval-2022)</title>
		<meeting>the 16th International Workshop on Semantic Evaluation (SemEval-2022)</meeting>
		<imprint>
			<publisher>Seattle, United States. Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="533" to="549" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">IIITK@DravidianLangTech-EACL2021: Offensive language identification and meme classification in Tamil, Malayalam and Kannada</title>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Ghanghor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parameswari</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sajeetha</forename><surname>Thavareesan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruba</forename><surname>Priyadharshini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bharathi</forename><surname>Raja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chakravarthi</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages</title>
		<meeting>the First Workshop on Speech and Language Technologies for Dravidian Languages</meeting>
		<imprint>
			<publisher>Kyiv. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="222" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Image bite politics: News and the visual framing of elections</title>
		<author>
			<persName><forename type="first">Maria</forename><surname>Grabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Bucy</surname></persName>
		</author>
		<idno type="DOI">10.1093/acprof:oso/9780195372076.001.0001</idno>
	</analytic>
	<monogr>
		<title level="m">Image Bite Politics: News and the Visual Framing of Elections</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Echoes of persuasion: The effect of euphony in persuasive communication</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Guerini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G√∂zde</forename><surname>√ñzbal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlo</forename><surname>Strapparava</surname></persName>
		</author>
		<idno>CoRR, abs/1508.05817</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<idno>CoRR, abs/1512.03385</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">MUTE: A multimodal dataset for detecting hateful memes</title>
		<author>
			<persName><forename type="first">Eftekhar</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omar</forename><surname>Sharif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammed</forename><forename type="middle">Moshiul</forename><surname>Hoque</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing: Student Research Workshop</title>
		<meeting>the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing: Student Research Workshop</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="32" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Talking to the crowd: What do people react to in online discussions?</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Jaech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victoria</forename><surname>Zayats</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D15-1239</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2026" to="2031" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Visual persuasion: Inferring communicative intents of images</title>
		<author>
			<persName><forename type="first">Jungseock</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weixin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francis</forename><forename type="middle">F</forename><surname>Steen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2014.35</idno>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="216" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages</title>
		<author>
			<persName><forename type="first">Divyanshu</forename><surname>Kakwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anoop</forename><surname>Kunchukuttan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satish</forename><surname>Golla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Gokul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avik</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mitesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pratyush</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of EMNLP</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Hate speech detection from code-mixed hindi-english tweets using deep learning models</title>
		<author>
			<persName><forename type="first">Satyajit</forename><surname>Kamble</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Joshi</surname></persName>
		</author>
		<idno>CoRR, abs/1811.05145</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Can you be persuaded? individual differences in susceptibility to persuasion</title>
		<author>
			<persName><forename type="first">Maurits</forename><surname>Kaptein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panos</forename><surname>Markopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>De Ruyter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emile</forename><surname>Aarts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human-Computer Interaction -INTERACT 2009</title>
		<meeting><address><addrLine>Berlin, Heidelberg; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="115" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">Simran</forename><surname>Khanuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diksha</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarvesh</forename><surname>Mehtani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Savya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atreyee</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Balaji</forename><surname>Gopalan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dilip</forename><surname>Kumar Margam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pooja</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajiv</forename><surname>Teja Nagipogu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shachi</forename><surname>Dave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subhash</forename><surname>Chandra Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vish</forename><surname>Gali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Partha</forename><forename type="middle">P</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><surname>Talukdar</surname></persName>
		</author>
		<idno>CoRR, abs/2103.10730</idno>
		<title level="m">Muril: Multilingual representations for indian languages</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Amanpreet Singh, Pratik Ringshia, and Davide Testuggine. 2020a. The hateful memes challenge: Detecting hate speech in multimodal memes</title>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamed</forename><surname>Firooz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aravind</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vedanuj</forename><surname>Goswami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="2611" to="2624" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Amanpreet Singh, Pratik Ringshia, and Davide Testuggine. 2020b. The hateful memes challenge: Detecting hate speech in multimodal memes</title>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamed</forename><surname>Firooz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aravind</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vedanuj</forename><surname>Goswami</surname></persName>
		</author>
		<idno>CoRR, abs/2005.04790</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<idno>CoRR, abs/1412.6980</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Memes in the wild: Assessing the generalizability of the hateful memes challenge dataset</title>
		<author>
			<persName><forename type="first">Hannah</forename><surname>Kirk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yennie</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paulius</forename><surname>Rauba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gal</forename><surname>Wachtel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruining</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingjian</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Broestl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Doff-Sotta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandar</forename><surname>Shtedritski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuki</forename><forename type="middle">M</forename><surname>Asano</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.woah-1.4</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Workshop on Online Abuse and Harms (WOAH 2021)</title>
		<meeting>the 5th Workshop on Online Abuse and Harms (WOAH 2021)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="26" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m">Computing krippendorff&apos;s alpha-reliability</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Co-attention based multimodal factorized bilinear pooling for Internet memes analysis</title>
		<author>
			<persName><forename type="first">Gitanjali</forename><surname>Kumari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amitava</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asif</forename><surname>Ekbal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Conference on Natural Language Processing (ICON)</title>
		<meeting>the 18th International Conference on Natural Language Processing (ICON)<address><addrLine>Silchar, India</addrLine></address></meeting>
		<imprint>
			<publisher>NLP Association of India</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="261" to="270" />
		</imprint>
		<respStmt>
			<orgName>National Institute of Technology Silchar</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Blip: Bootstrapping language-image pretraining for unified vision-language understanding and generation</title>
		<author>
			<persName><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongxu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Hoi</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2201.12086</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Align before fuse: Vision and language representation learning with momentum distillation</title>
		<author>
			<persName><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramprasaath</forename><forename type="middle">R</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akhilesh</forename><surname>Deepak Gotmare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Hoi</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2107.07651</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Visualbert: A simple and performant baseline for vision and language</title>
		<author>
			<persName><forename type="first">Liunian</forename><surname>Harold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cho-Jui</forename><surname>Da Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Wei</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><surname>Chang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>In Arxiv</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">A technique for the measurement of attitudes / by Rensis Likert</title>
		<author>
			<persName><forename type="first">Rensis</forename><surname>Likert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1932">1932</date>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>Archives of psychology</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The facial displays of leaders: Toward an ethology of human politics</title>
		<author>
			<persName><forename type="first">D</forename><surname>Roger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denis</forename><forename type="middle">G</forename><surname>Masters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">T</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><forename type="middle">J</forename><surname>Lanzetta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Basil</forename><forename type="middle">G</forename><surname>Mchugo</surname></persName>
		</author>
		<author>
			<persName><surname>Englis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Social and Biological Structures</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="319" to="343" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Detecting offensive tweets in Hindi-English code-switched language</title>
		<author>
			<persName><forename type="first">Puneet</forename><surname>Mathur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajiv</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramit</forename><surname>Sawhney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debanjan</forename><surname>Mahata</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-3504</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Workshop on Natural Language Processing for Social Media</title>
		<meeting>the Sixth International Workshop on Natural Language Processing for Social Media<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="18" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A &apos;presidential look&apos;? an analysis of gender framing in 2016 persuasive memes of hillary clinton</title>
		<author>
			<persName><forename type="first">Rebecca</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nee</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Mariana</forename><forename type="middle">De</forename><surname>Maio</surname></persName>
		</author>
		<idno type="DOI">10.1080/08838151.2019.1620561</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Broadcasting &amp; Electronic Media</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="304" to="321" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Minheng</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoyang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taroon</forename><surname>Bharti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lijuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongdong</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2006.02635</idno>
		<imprint/>
	</monogr>
	<note>and Nan Duan. 2020. M3p: Learning universal representations via multitask multilingual multimodal pre-training</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Commitment devices as behavior change support systems: A study of users&apos; perceived competence and continuance intention</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Oduor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harri</forename><surname>Oinas-Kukkonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Persuasive Technology: Development and Implementation of Personalized Technologies to Change Attitudes and Behaviors</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="201" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Supporting comment moderators in identifying high quality online news comments</title>
		<author>
			<persName><forename type="first">Deokgun</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simranjit</forename><surname>Sachar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Diakopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niklas</forename><surname>Elmqvist</surname></persName>
		</author>
		<idno type="DOI">10.1145/2858036.2858389</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems, CHI &apos;16</title>
		<meeting>the 2016 CHI Conference on Human Factors in Computing Systems, CHI &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1114" to="1125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">How multilingual is multilingual BERT?</title>
		<author>
			<persName><forename type="first">Telmo</forename><surname>Pires</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eva</forename><surname>Schlinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Garrette</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1493</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4996" to="5001" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jong</forename><forename type="middle">Wook</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Hallacy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2103.00020</idno>
		<title level="m">Learning transferable visual models from natural language supervision</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">why should I trust you?&quot;: Explaining the predictions of any classifier</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Tulio Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-08-13">2016. August 13-17, 2016</date>
			<biblScope unit="page" from="1135" to="1144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Estimating code-switching on Twitter with a novel generalized word-level language detection technique</title>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Rijhwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Royal</forename><surname>Sequiera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monojit</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kalika</forename><surname>Bali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandra</forename><surname>Shekhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maddila</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1180</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1971" to="1982" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<author>
			<persName><forename type="first">Jens</forename><surname>Seiffert-Brockmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Diehl</surname></persName>
		</author>
		<title level="m">The power of memes: The digital discourse of the obama hope meme</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Memes as games: The evolution of a digital discourse online</title>
		<author>
			<persName><forename type="first">Jens</forename><surname>Seiffert-Brockmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Diehl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonhard</forename><surname>Dobusch</surname></persName>
		</author>
		<idno type="DOI">10.1177/1461444817735334</idno>
	</analytic>
	<monogr>
		<title level="j">New Media Society</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="2862" to="2879" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">SemEval-2020 task 8: Memotion analysis-the visuolingual metaphor</title>
		<author>
			<persName><forename type="first">Chhavi</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deepesh</forename><surname>Bhageria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pykl</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amitava</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanmoy</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viswanath</forename><surname>Pulabaigari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bj√∂rn</forename><surname>Gamb√§ck</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.semeval-1.99</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth Workshop on Semantic Evaluation</title>
		<meeting>the Fourteenth Workshop on Semantic Evaluation<address><addrLine>Barcelona</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="759" to="773" />
		</imprint>
	</monogr>
	<note>International Committee for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">DISARM: Detecting the victims targeted by harmful memes</title>
		<author>
			<persName><forename type="first">Shivam</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shad</forename><surname>Md</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preslav</forename><surname>Akhtar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanmoy</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName><surname>Chakraborty</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.findings-naacl.118</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: NAACL 2022</title>
		<meeting><address><addrLine>Seattle, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1572" to="1588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Recognizing stances in ideological on-line debates</title>
		<author>
			<persName><forename type="first">Swapna</forename><surname>Somasundaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text</title>
		<meeting>the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text<address><addrLine>Los Angeles, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="116" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Multimodal meme dataset (MultiOFF) for identifying offensive content in image and text</title>
		<author>
			<persName><forename type="first">Shardul</forename><surname>Suryawanshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raja</forename><surname>Bharathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihael</forename><surname>Chakravarthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Arcan</surname></persName>
		</author>
		<author>
			<persName><surname>Buitelaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying</title>
		<meeting>the Second Workshop on Trolling, Aggression and Cyberbullying<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA)</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="32" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">The effect of wording on message propagation: Topicand author-controlled natural experiments on Twitter</title>
		<author>
			<persName><forename type="first">Chenhao</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/P14-1017</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="175" to="185" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Winning arguments: Interaction dynamics and persuasion strategies in good-faith online discussions</title>
		<author>
			<persName><forename type="first">Chenhao</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vlad</forename><surname>Niculae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<idno>CoRR, abs/1602.01103</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">LXMERT: Learning cross-modality encoder representations from transformers</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1514</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5100" to="5111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Fine-tuning bert for multi-label sentiment analysis in unbalanced code-switching text</title>
		<author>
			<persName><forename type="first">Tiancheng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinhuai</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Yuan</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2020.3030468</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="193248" to="193256" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">In Persuasive Technology: Development and Implementation of Personalized Technologies to Change Attitudes and Behaviors</title>
		<author>
			<persName><forename type="first">Rosemary Josekutty</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judith</forename><surname>Masthoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nir</forename><surname>Oren</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-55134-0_10</idno>
		<idno>date: 04-04- 2017 Through 06-04-2017</idno>
	</analytic>
	<monogr>
		<title level="m">12th International Conference on Persuasive Technology</title>
		<title level="s">Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="119" to="132" />
		</imprint>
	</monogr>
	<note>Adapting healthy eating messages to personality</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Can i influence you? development of a scale to measure perceived persuasiveness and two studies showing the use of the scale</title>
		<author>
			<persName><forename type="first">Rosemary Josekutty</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judith</forename><surname>Masthoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nir</forename><surname>Oren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Finding arguing expressions of divergent viewpoints in online debates</title>
		<author>
			<persName><forename type="first">Amine</forename><surname>Trabelsi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Osmar</forename><forename type="middle">R</forename><surname>Za√Øane</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/W14-1305</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Workshop on Language Analysis for Social Media (LASM)</title>
		<meeting>the 5th Workshop on Language Analysis for Social Media (LASM)<address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="35" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Is this post persuasive? ranking argumentative comments in online forum</title>
		<author>
			<persName><forename type="first">Zhongyu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-2032</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="195" to="200" />
		</imprint>
	</monogr>
	<note>Short Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title/>
		<author>
			<persName><surname>Appendix</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
