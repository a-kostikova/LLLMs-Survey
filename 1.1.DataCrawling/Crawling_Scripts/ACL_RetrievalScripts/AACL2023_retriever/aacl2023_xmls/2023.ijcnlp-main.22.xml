<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Informative Evidence-guided Prompt-based Fine-tuning for English-Korean Critical Error Detection</title>
				<funder>
					<orgName type="full">Korea</orgName>
				</funder>
				<funder ref="#_zneJeva">
					<orgName type="full">ITRC</orgName>
				</funder>
				<funder>
					<orgName type="full">Part 4) Development of AI Technology</orgName>
				</funder>
				<funder ref="#_3N3Cemy #_ebkCQrz">
					<orgName type="full">Korea government(MSIT)</orgName>
				</funder>
				<funder>
					<orgName type="full">MSIT(Ministry of Science and ICT)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Dahyun</forename><surname>Jung</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Korea University</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sugyeong</forename><surname>Eo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Korea University</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Chanjun</forename><surname>Park</surname></persName>
							<email>chanjun.park@upstage.ai</email>
							<affiliation key="aff1">
								<address>
									<settlement>Upstage</settlement>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hyeonseok</forename><surname>Moon</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Korea University</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jaehyung</forename><surname>Seo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Korea University</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Heuiseok</forename><surname>Lim</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Korea University</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Informative Evidence-guided Prompt-based Fine-tuning for English-Korean Critical Error Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C60BBFC007FFBB2556DC33AC2E2E9734</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-05-29T13:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Critical error detection (CED) aims to identify the presence of catastrophic meaning distortion in machine translation. Fatal errors require significant attention because of their potential to cause personal or societal harm. The CED for Korean, an agglutinative language, is particularly highlighted, as minor variations in morphemes often bring substantial shifts in semantic interpretation. However, research on Korean is still underexplored and has room for improvement. In this study, we conduct the first investigation of CED for English-Korean to the best of our knowledge. We adopt prompt-based fine-tuning and propose various informative evidence to incorporate into the input prompt. Subsequently, we perform comprehensive verification and analysis to identify the most helpful guidance for detecting critical errors. The experimental results show that prompt-based fine-tuning with informative evidence outperforms standard fine-tuning by a large margin, demonstrating its remarkable effectiveness in English-Korean CED. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The remarkable progress of neural machine translation (NMT) has considerably facilitated an exchange of information and communication among speakers from various countries, lowering barriers to global communication. Particularly, services leveraging large-scale language models (LLMs) have been increasingly integrated into various realworld scenarios, spanning daily lives and business industries <ref type="bibr" target="#b2">(Brown et al., 2020;</ref><ref type="bibr" target="#b14">Lin et al., 2021;</ref><ref type="bibr" target="#b41">Zhang et al., 2022;</ref><ref type="bibr" target="#b29">Scao et al., 2022)</ref>.</p><p>Despite the increasing advancements in machine translation (MT) technology, MT systems still struggle with translation errors, as they fail to consider the context of sentences or cultural differences in languages <ref type="bibr" target="#b0">(Bender et al., 2021)</ref>. Users who lack proficiency in the target language may find it difficult to discern the types and extent of errors in the translation output. A quality estimation (QE) task addresses this issue to provide users with feedback regarding the reliability of an MT output. QE predicts translation quality by referencing only the source and MT sentence, without the necessity for human reference translation. This offers a significant advantage in real-world scenarios where the reference translations do not exist <ref type="bibr" target="#b37">(Specia et al., 2009</ref><ref type="bibr" target="#b35">(Specia et al., , 2020))</ref>.</p><p>Furthermore, critical error detection (CED) emerged as a sub-task of QE at 2021 Sixth Conference on Machine Translation (WMT21) <ref type="bibr" target="#b36">(Specia et al., 2021)</ref>, particularly focusing on detecting cases where translation errors result in fatal distortions in meaning <ref type="bibr" target="#b26">(Raunak et al., 2022;</ref><ref type="bibr" target="#b40">Zerva et al., 2022)</ref>. The importance of CED lies in its ability to detect errors that may incur severe consequences. For example, cases where the meaning distortion in the translation output could be perceived as offensive or have the potential to cause social, legal, or economic harm. Although the occurrence of critical errors in MT results is a long-tail problem, preventing even one translation error from incurring a serious social issue is crucial <ref type="bibr" target="#b20">(Martindale et al., 2021)</ref>. With the advent of LLMs such as GPT-3 <ref type="bibr" target="#b2">(Brown et al., 2020)</ref> and Chat-GPT <ref type="bibr" target="#b22">(OpenAI-Blog, 2022)</ref>, users are increasingly relying on MT for various purposes. Therefore, ensuring the reliability of the translation output generated by these models is vital, and CED is an essential component in the verification process.</p><p>CED is a binary classification task, consisting of five error types: toxicity, safety, named entity, number, and sentiment. The error types are commonly applied across languages, but the detectable error range can be changed based on the characteristics of each language. Therefore, it is necessary to define types that reflect language-specific properties. The recently released English-Korean CED dataset additionally introduces a politeness label reflecting the cultural property of Korea. Politeness tags capture cases where incorrect honorific expressions are used, which can be considered impolite behavior in certain situations. Thus, the model trained with a culture-aware English-Korean CED dataset can well filter translation errors that LLMs may overlook in terms of courtesy in Korea.</p><p>However, the English-Korean CED still remains underexplored. In Korean, an agglutinative language, the meaning changes sensitively based on a few variations of morphemes. Namely, even a character-level change would immediately distort the meaning of the source to a completely different one. This highlights the importance of detecting catastrophic errors in English-Korean translation. In this study, we perform experiments using the English-Korean CED dataset to facilitate the inspection of critical errors in the language pair. To the best of our knowledge, this is the first study that experiments with the task. Although fine-tuning the model with pre-trained LLM is the de-facto standard for adapting to downstream tasks, we focus on the gap between the learning objectives of pre-training and fine-tuning <ref type="bibr" target="#b15">(Liu et al., 2023;</ref><ref type="bibr" target="#b32">Schick and Schütze, 2021;</ref><ref type="bibr">Liu et al., 2021a)</ref>. We adopt prompt-based fine-tuning in our experiments to reduce this gap and maximize the language understanding capability of LLM. As illustrated in Figure <ref type="figure" target="#fig_0">1</ref>, this study also explores more extensive informative evidence that can be combined as input for error detection, classified into META, BILIN-GUAL, and MONOLINGUAL evidence. With the experiments using informative evidence and various combinations of templates and verbalizers, we report the results and analysis of which evidence contributes to the performance improvement with which templates. We demonstrate the effectiveness of prompt-based learning and informative evidence in CED through extensive experiments using various prompts and evidence. Our main contributions are the following:</p><p>• We perform prompt-based fine-tuning for the English-Korean CED task, which has not been sufficiently explored in previous research.</p><p>• We propose multiple informative evidence that can be helpful in detecting critical errors in MT and report the most efficient evidence with analysis.</p><p>• Our experimental results outperform the finetuning performance by a significant margin, demonstrating the effectiveness of promptbased methods with informative evidence in CED.</p><p>2 Related Works</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Critical Error Detection (CED)</head><p>CED task aims to determine the existence of a critical error in a translation at the sentence level, using binary labels <ref type="bibr" target="#b40">(Zerva et al., 2022)</ref>. The occurrence of the error can cause miscommunication, potentially resulting in grave consequences <ref type="bibr" target="#b33">(Sharou and Specia, 2022;</ref><ref type="bibr" target="#b38">Sudoh et al., 2021)</ref>. For instance, mistranslations of crucial medical information directly affect the lives of patients. This semantic distortion manifests in several patterns and has diverse schema types, details of which are expounded upon in Appendix A.</p><p>Various language pairs are leveraged in CED task to address the critical error issue. <ref type="bibr" target="#b28">Rubino et al. (2021)</ref>; <ref type="bibr" target="#b12">Jiang et al. (2021)</ref>; <ref type="bibr" target="#b4">Chen et al. (2021)</ref> perform CED on English-German, English-Chinese, English-Czech, and English-Japanese pairs. <ref type="bibr" target="#b28">Rubino et al. (2021)</ref> train a model by leveraging a large amount of synthetic data produced using parallel corpora and MT systems. Meanwhile, <ref type="bibr" target="#b12">Jiang et al. (2021)</ref> explore weighted sampling to deal with imbalanced datasets and refine the architecture by extracting sentence features. <ref type="bibr" target="#b4">Chen et al. (2021)</ref> propose learning method of using a pre-trained model and task-specific classifier. <ref type="bibr" target="#b7">Eo et al. (2022)</ref> present prompt-based fine-tuning with demonstrations and Google MT on English-German and Portuguese-English.</p><p>As observed in previous studies, the investigation regarding critical error has been diversely explored. However, no studies have been conducted using English-Korean CED datasets. We use the corresponding dataset in this study as the data additionally introduces the language-specific properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Prompt-based Fine-tuning</head><p>Prompt-based fine-tuning has been proposed to address these challenges, offering a method that reformulates tasks to more effectively leverage pretrained knowledge <ref type="bibr" target="#b15">(Liu et al., 2023;</ref><ref type="bibr" target="#b32">Schick and Schütze, 2021;</ref><ref type="bibr">Liu et al., 2021a;</ref><ref type="bibr" target="#b2">Brown et al., 2020)</ref>. <ref type="bibr" target="#b32">Schick and Schütze (2021)</ref> introduce patternexploiting training (PET), which combines reformulating tasks as cloze styles with a fine-tuning approach. <ref type="bibr">Schick and Schütze (2020b)</ref> combine PET and ALBERT to achieve good performance with a considerably smaller number of parameters. <ref type="bibr" target="#b8">Gao et al. (2020)</ref> propose a model to automatically generate prompts and demonstrations for promptbased fine-tuning approaches, and <ref type="bibr">Liu et al. (2021a)</ref> employ a method to automatically search for discrete prompts in continuous space.</p><p>To the best of our knowledge, no prior research has executed prompt-based learning utilizing suitable techniques to identify the distortion of meaning in MT. We propose a method to perform English-Korean CED using prompt-based finetuning, which has previously demonstrated impressive results across numerous fields. Particularly, we generate prompts fitting the task by including evidence relevant to English-to-Korean translation and evaluate the influence of these prompts on the model's performance.</p><p>3 Proposed Methods</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preliminary</head><p>In this task, we derive the CED model to predict error label y given source sentence x src and translation sentence x mt . Specifically, we apply prompt-based learning that bridges the gap between the pre-training and fine-tuning <ref type="bibr" target="#b8">(Gao et al., 2020)</ref>. We adopt a pre-trained language model XLM-RoBERTa <ref type="bibr" target="#b5">(Conneau et al., 2019)</ref> that is trained with masked language modeling (MLM) objectives. Considering these, we construct a template that reformulates the CED task as a cloze style that aims to fill the masked part in the given input text <ref type="bibr" target="#b23">(Petroni et al., 2019;</ref><ref type="bibr" target="#b6">Cui et al., 2021)</ref>.</p><p>More detailed procedures are shown below. We denote x prompt as a form of input that incorporates a template containing [MASK] token, x src and x tgt . For instance, in executing a binary critical error detection task, one designed example for our prompt as follows:</p><formula xml:id="formula_0">x prompt = [CLS] A [MASK] translation of x src is x mt . [SEP]</formula><p>where the prompt varies based on the template. For the given x prompt , the CED model is supervised to predict the appropriate word in the [MASK] position, such as "great" (non-error) or "terrible" (error).</p><p>Furthermore, we define ψ : y ∈ Y → w ∈ W as a function called the verbalizer that maps the label y ∈ Y to the label word w y ∈ W Y (i.e. ψ(y) = w y ). In this case, Y denotes the label set of a targeting task (e.g. Y = {NOT, ERR}), and W Y denotes the corresponding set of label words (e.g. W Y = {great, terrible}). We formulate the probability of predicting class y ∈ Y as</p><formula xml:id="formula_1">P (y|x src , x mt ) = P ([MASK] = w y | x prompt ) w∈W Y P ([MASK] = w | x prompt )<label>(1)</label></formula><p>In our study, we aim to find the most effective task-specific prompt x prompt and verbalizer function ψ. To enhance explainability, we perform manual template engineering that follows human intuition <ref type="bibr" target="#b2">(Brown et al., 2020;</ref><ref type="bibr">Schick and Schütze, 2020a)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evidence Investigation</head><p>Providing informative evidence as part of the model's input acts as supplementary descriptions in detecting critical errors. We discover factors that directly or indirectly impact model training by incorporating various information during promptbased fine-tuning. In order to capture and assess the diverse facets of MT, we categorize informative evidence into three categories: (1) META evidence: additional information that is not directly related to the translation task but can provide valuable insights and guidance, (2) BILINGUAL evidence: additional information obtained through the comparison and alignment of source and MT results, (3) MONOLINGUAL evidence: additional information that utilizes only one of the source or MT sentences. The categories are described in detail as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Leveraging Meta Data as Evidence</head><p>In-context learning with demonstration Incontext learning is a method that provides explanations or examples in the input context, enabling the model to inform the task should perform <ref type="bibr" target="#b2">(Brown et al., 2020)</ref>. We employ the approach to enhance the model's comprehension of the CED task via demonstrations. We utilize a positive and negative labeled sample to be included in the prompt input to clarify critical errors (e.g.</p><formula xml:id="formula_2">"A [label word+] translation of [SRC+] is [MT+] .[SEP] A [label word-] translation of [SRC-] Is [MT-] ."</formula><p>). The demonstration sample should be randomized according to labels. Explicit language identification When predicting labels, we use information about the language of the source sentence or translation sentence. This additional task aims to capture the benefits of explicitly specifying language identification. mBART <ref type="bibr" target="#b18">(Liu et al., 2020)</ref>, which has learned multiple languages, uses the strategy of including explicit information about these languages. Therefore, the utilization of this evidence presupposes that the comprehension of sentences can be enhanced by discerning the language in which each sentence is written. We create a prompt template by referring to the recommended prompt guidance from the OpenAI playground for the default sentence-level translation task<ref type="foot" target="#foot_0">2</ref> . Reducing hallucination error To identify the hallucination error present in sentences, we make use of the information regarding the length of either the source or the target sentence. This approach draws inspiration from <ref type="bibr" target="#b1">Berard et al. (2019);</ref><ref type="bibr" target="#b10">Guerreiro et al. (2022)</ref>, where they use length-based filtering when building an MT system and remove a substantial number of hallucination errors. If a concise translation sentence is generated for a long source sentence, it may indicate that the MT model has omitted or misunderstood necessary information. Therefore, we hypothesize that checking length information can be beneficial in detecting MT errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Leveraging Bilingual Data as Evidence</head><p>Integration of results from commercialized MT system We use the Google MT system to translate the source sentence and utilize the result as the supplementary description. Previous studies have found that leveraging the translated result of a commercialized MT system improves the MT-related task's performances <ref type="bibr" target="#b4">(Chen et al., 2021;</ref><ref type="bibr" target="#b39">Wang et al., 2020;</ref><ref type="bibr" target="#b21">Moon et al., 2021)</ref>. We speculate that it would also be meaningful to provide Google MT results to detect errors in MT. Extracting restored semantics from source We apply round-trip translation using the commercial system to detect critical errors. Round-trip translation refers to translating a translated sentence back to the source language, enabling us to see how well the MT system translated through the source <ref type="bibr" target="#b34">(Somers, 2005)</ref>. If there is a translation error in the target, there will also exist an error in the sentence translated back to the source ′ through round-trip translation. Therefore, we better understand the errors made by the MT system by comparing the original source and the source ′ created through round-trip translation. Fine-grained phrase-level control We induce a model to better understand the translation of the entire sentence by providing word-by-word translation results. We provide the model with the translated results of words included in the source or translation sentence. This approach suggests using bilingual dictionary information in the CED task <ref type="bibr" target="#b9">(Ghazvininejad et al., 2023)</ref>. If the word exists in the dictionary, we translate the meaning of the word and compose it into the prompt. For example, if the word 'apple' is included in the dictionary, the prompt would be constructed as "the word 'apple' means '사과'." This improves translation accuracy and supports users in obtaining more natural translation results. Such helpful hints in translation can also be useful in detecting errors in translation tasks.</p><p>Measuring the quality score We present the similarity between the source and target sentences as additional evidence. In MT, the higher the sim-ilarity between the two sentences, the better the translation quality considered <ref type="bibr" target="#b3">(Chan and Ng, 2008)</ref>. Therefore, if there is an error in the translation, it will also affect the similarity between the two sentences. For example, if the sentence "I am going to the Mcdonald's" is incorrectly translated to "I am going to the Mcdoanld's," the similarity between the words "Mcdonald's" and "Mcdoanld's" decreases. Such sentence similarity assists in quality evaluation and error identification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Leveraging Monolingual data as Evidence</head><p>Grammatical denoising We identify and rectify grammatical errors in the source sentences and their translations, and use the corrected sentences during training. Our hypothesis posits that if the model learns from sentences containing grammatical errors, it may encounter confusion when discerning critical errors. Grammatical error correction (GEC) results eliminate confusion caused by grammatical errors, enabling more accurate critical error detection.</p><p>Mitigating named entity error We can better discern named entity errors that occur in the MT system by providing the Named entity recognition (NER) results of each sentence. NER is a task that recognizes entities related to a specific person, location, organization, etc., in a sentence. NER assists the model to recognize detailed semantic tokens that improve translation quality <ref type="bibr">(Liu et al., 2021b)</ref>. Thus, it draws understanding in NMT by utilizing the syntactic and semantic structure of natural language. For example, in the sentence "John works at Apple," it is crucial to recognize the named entities "John" and "Apple." However, there may be cases where the model fails to recognize "Apple" and misinterprets it as fruit "apple". We allow the model to identify named entity errors by providing NER results in each sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Evidence Mix-up</head><p>Through ensemble, more accurate predictions are secured by integrating the prediction results of each model. We train separate models using the informative evidence and aim to improve performance by aggregating these model outputs. First, to evaluate relative effectiveness by evidence category, we conduct experiments for each category. Also, we select the top-k outputs trained on each informative evidence based on the Matthews correlation coefficient (MCC) to observe the performance variation with the number of models used. Then, we use majority voting to combine the results from different prompts <ref type="bibr" target="#b13">(Lester et al., 2021;</ref><ref type="bibr" target="#b11">Hambardzumyan et al., 2021)</ref>. This method is based on the principle of majority rule, selecting the most frequently chosen result among the predictions made by each model as the final prediction. We expect that high performance is achieved by integrating the prediction results from various models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Results</head><p>This section evaluates prompt-based fine-tuning with informative evidence using the English-Korean CED dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset Details</head><p>We consider the English-Korean critical error detection (KoCED) dataset<ref type="foot" target="#foot_1">3</ref> , which consists of the source sentence, translation sentence, critical error presence/absence label, and detailed error tag.  RTT is round-trip translation that translates the translation sentence back to the source language; WT indicates the provision of guidance for translations on a word-by-word basis; Mean is the result of averaging all the scores for each method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Training Details</head><p>Models For training, all models are implemented with PyTorch 4 and Transformers 5 . We utilize the pre-trained language models 'bert-basemultilingual-cased', 'xlm-roberta-base', and 'xlmroberta-large' checkpoints. We use a batch size of 64, the Adam optimizer with a learning rate of 2e-5, and train for 10 epochs. The experiments are performed on an NVIDIA RTX A6000 environment.</p><p>Baselines We compare our proposed methods with the standard fine-tuning approach. We set the fine-tuning results of the multilingual BERT (mBERT) <ref type="bibr" target="#b24">(Pires et al., 2019)</ref> and XLM-RoBERTa <ref type="bibr" target="#b5">(Conneau et al., 2019)</ref>  Evidences To determine token length, we employ the XLM-RoBERTa-large tokenizer. We use the Google MT API<ref type="foot" target="#foot_2">6</ref> as a commercial translation system. Also, we utilize Sentence-BERT <ref type="bibr" target="#b27">(Reimers and Gurevych, 2019)</ref> to calculate the similarity score between the source and translation sentences.</p><p>The model is obtained from hugging-face using the 'distiluse-base-multilingual-cased-v1', which includes Korean. GEC and NER data are obtained through the 'gec' and 'ner' tasks of the Pororo platform<ref type="foot" target="#foot_3">7</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation Details</head><p>We automatically measure MCC and F1 scores as our evaluation metrics to evaluate the performance of the model. MCC is a metric used in binary classification tasks. This value can be meaningfully utilized to measure the accuracy of the model. F1 is a metric calculated as the harmonic mean of precision and recall. Precision represents the propor- Table <ref type="table">3</ref>: The ensemble result of prompt models with informational evidence. We report performance on the test dataset. We denote ALL as the models that contain all informational evidence. Top-k is the result of selecting and ensembling k-models with the highest performance.</p><p>tion of samples predicted as positive by the model that are actually positive, and recall represents the proportion of actual positive samples that are predicted as positive by the model. F1 score, which considers both these metrics, provides a more accurate assessment of the model's performance. The scoring is based on the code utilized in WMT 21 8 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Main Results</head><p>We present the experimental results of comparing prompt-based fine-tuning with informative evidence in Table <ref type="table" target="#tab_2">2</ref>. We initially perform a baseline experiment to identify the optimal model for the CED. We find that XLM-RoBERTa-large is the most effective model, which we further leverage it in our subsequent work.</p><p>Our proposed method of experimenting with prompt-based fine-tuning significantly outperforms fine-tuning strategy by a large margin. The performance of models leveraging BILINGUAL information demonstrates a substantial improvement compared to the baseline. Adding Google MT outperforms the XLM-RoBERTa-Large baseline by 0.2342 on MCC and 0.2518 on F1-Multi in our test set, the best of all evidence. It also outperforms prompt-based fine-tuning without any evidential support. By incorporating BILINGUAL information, the models can effectively incorporate both source and target sentences, enabling a synergistic interaction between them. Our experimental findings corroborate the advantageous nature of emphasizing the interaction between these two components in translation-related tasks. The inclusion of META in-8 https://github.com/sheffieldnlp/ qe-eval-scripts/tree/master/wmt21 formation, such as demonstrations, exhibits promising performance, indicating its utility in enhancing the reasoning process essential for prompt approaches. In addition, We conclude that the enhancements come from the use of prompts, which effectively bridge the gap between pre-training and downstream tasks <ref type="bibr" target="#b8">(Gao et al., 2020)</ref>. In fact, our strategy enables us to optimize the utilization of an off-the-shelf LM by implementing a simple and effective prompt scheme.</p><p>The other approach, utilizing MONOLINGUAL information, demonstrates comparable results relative to the baseline. However, it falls short of surpassing the advantage achieved by standard promptbased fine-tuning. This observation suggests that relying solely on single language information in MT potentially introduce noise and hinder overall performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Empirical Prompt Engineering</head><p>We present the results of the experiments in this section in Appendix B due to page limitations. We experiment with different templates and verbalizers for all prompt-based ways to find the appropriate prompts for our task. To minimize performance variation due to prompt engineer-ing, we conduct at least four examinations per method. First, we attempt to find the appropriate prompt for CED using standard prompt-based finetuning. Prompts formatted as natural sentences are more task-robust compared to unnaturally formatted prompts.</p><formula xml:id="formula_3">'A [MASK] translation of [SRC] is [MT].' or '[SRC] [MT] is [MASK].</formula><p>' yield better results. Given this observation, we perform training with additional features based on task-appropriate and natural templates.</p><p>A straightforward transition to a more efficient prompt, in the absence of any additional techniques, is capable of producing significant outcomes. Particularly, in the prompt-based fine-tuning method of Table <ref type="table">6</ref>, the prompt with the highest performance exhibits a difference of 0.195 compared to the lowest performance. This proves that finding task-specific prompts is essential for prompt-based fine-tuning. The result allows us to observe the advantages of manual prompt engineering, which is that it enables the creation of prompts that are more aligned with human intuition.</p><p>Among the examined features, Google MT and round-trip translation exhibit the highest performance, showcasing their effectiveness in considering both source and target languages. Furthermore, these methods demonstrate robustness in handling prompt changes. The minimum score achieved by prompts with Google MT is overwhelmingly higher than the maximum score achieved by prompts with NER. The obtained results follow our expectation that the additional information is effective in identifying catastrophic errors regardless of the prompt selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3">Modeling with a Mix of Informative Evidence</head><p>Utilizing the informative evidence from the previous section, we perform experiments with prompt ensembling to identify the right combination of evidence. Table <ref type="table">3</ref> is the result of ensembling the models with prompt-based fine-tuning. The employment of ensemble techniques usually leads to enhanced results. MCC score of BILINGUAL ensemble increases by 0.0279 compared to promptbased fine-tuning with Google MT, which is the highest score of the individual models. This demonstrates the effectiveness of creating diverse models using informative evidence and then ensembling them.</p><p>The results indicate that using all informative evidence is ineffective in achieving optimal perfor- mance. This is because the model that includes the top-k pieces of information performs better than the model that includes all the information. In particular, the improvement observed through model filtering suggests the importance of selecting meaningful models when constructing an ensemble model. Nevertheless, as evidenced by the BILIN-GUAL ensemble performance, it is crucial to ensure the inclusion of relevant and meaningful information in the task, rather than solely relying on high performance or an abundance of information (Figure <ref type="figure" target="#fig_1">2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.4">Impact of Data Distribution</head><p>The dataset we use is skewed with a high percentage of error labels. To investigate the impact of data balancing on efficiency, we perform an experiment using a method that balances the data. The data sampling process involves averaging the results from three random data samplings. Table <ref type="table" target="#tab_5">4</ref> verifies that data sampling is generally less efficient compared to prompt-based fine-tuning using the entire dataset. These results suggest that the influence of label imbalance in the task is insignificant, indicating that our evidence addition methodology holds more significance than attempting to achieve uniformity across the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this study, we presented a prompt-based finetuning approach with informational evidence in an English-Korean CED. We analyzed the impact of prompt engineering on CED and conducted experiments using the engineering approach that yields the best performance. Also, we explore informational evidence to support our prompt-based ap-proach and apply it to our learning. Our promptbased fine-tuning with informative evidence outperformed standard fine-tuning and prompt-based finetuning. Among the evidence, the model that considers both source and target languages yielded the best performance, and we achieved the best results using templates composed of natural, fluent sentences. While LLMs have recently demonstrated a remarkable ability to generate natural language, our study contributes to reducing the unintended social impact by preventing and filtering out the catastrophic results they produce.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>Our experiment is restricted to the English-Korean language pair, and its extension to other languages is not directly examined. It remains to be seen whether our method exhibits universal applicability across all languages, or if modifications are required for languages with distinct structural or linguistic attributes. In addition, the computational cost and time associated with prompt and answer engineering may not be practical for application.</p><p>The process requires significant human intervention for the design, selection, and assessment of corresponding prompts and evidences. Future research should aim to address these limitations, and we plan to explore these to validate the robustness and applicability of our empirical observations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics Statement</head><p>Our methodology employs an automated MT system facilitated by Google MT. This system exhibits certain biases, for instance, in the context of gender, wherein gender-neutral nouns are rendered as gender-specific in the target languages <ref type="bibr" target="#b25">(Prates et al., 2020)</ref>. Besides, the PLMs included in this study are mBERT and XLM-RoBERTa models. The mBERT is pre-trained on the top 104 languages with the largest Wikipedia. The XLM-RoBERTa is pretrained on 2.5TB of filtered CommonCrawl data containing 100 languages. It is important to note that all our disseminated models may potentially bear biases inherited from these source corpora.</p><p>Input (source sentence) Translation sentence with critical error Translation sentence without critical error TOX The person who was with the cat last night is black.</p><p>어젯밤 고양이를 괴롭힌 사람은 흑인입 니다.</p><p>The person who harassed the cat last night is black.</p><p>어젯밤 고양이와 함께 있던 사람은 흑 인입니다.</p><p>The person who was with the cat last night is black.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SAF</head><p>Touching electronic devices, power plugs, and outlets with wet hands is prohibited as they should not be exposed to water.</p><p>전자 기기, 전원 플러그, 콘센트는 물에 노출되지 않아야 하므로 젖은 손으로 만 지는 것은 괜찮습니다. Touching electronic devices, power plugs, and outlets with wet hands is fine as they should not be exposed to water.</p><p>전자 기기, 전원 플러그, 콘센트는 물에 노출되지 않아야 하므로 젖은 손으로 만 지는 것은 금지되어 있습니다. Touching electronic devices, power plugs, and outlets with wet hands is prohibited as they should not be exposed to water.</p><p>NAM The main aspect of touring the Grand Canyon is the view.</p><formula xml:id="formula_4">그랜드 캔 여행의 주요 측면은 전망입 니다.</formula><p>The main aspect of touring the Grand Can is the view.</p><p>그랜드 캐년 여행의 주요 측면은 전망 입니다.</p><p>The main aspect of touring the Grand Canyon is the view.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Pattern and Schema of Critical Error</head><p>A.1 Pattern in which the critical error appears Deviations in meaning from the original sentence can appear as mistranslation, hallucination, or deletion <ref type="bibr" target="#b40">(Zerva et al., 2022)</ref>. First, mistranslation is an error that occurs when a source sentence is incorrectly translated, resulting in a distortion of its original meaning. If the sentence "I'm feeling blue." is translated as feeling the color blue, it is a mistranslation because the expression indicates feeling sad or depressed in English. Second, hallucination is an error where the content not present in the source sentence is introduced into the translation. If an MT system translates "I'm going to the store" as "I'm going to the store. I'm a freak," it indicates an error where unnecessary content is added during the translation process. Third, deletion is an error where content present in the source sentence is removed from the translation. Essential information is omitted when translating the sentence "I went to the store and bought some apples," as "I went to the store."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Critical Error Schema</head><p>Critical errors encompass universal characteristics, such as toxicity, safety, named entity, number and sentiment, which are applicable to the majority of languages. In English-Korean CED, politeness is considered as a type of error beyond the aforementioned error types. Toxicity (TOX) is an error type that covers derogatory or offensive content targeting specific race, religion, gender, and force, which can be encountered in translation output. These toxic expressions might originate in the source text or be introduced during the translation process. Particularly, TOX undermines the credibility of the document and leads to ethical issues. For instance, in Table <ref type="table" target="#tab_7">5</ref>, the generated translation maximizes biased opinions about black people, which is a semantic distortion that can potentially result in social discrimination.</p><p>Safety (SAF) refers to a type of error that may provoke safety harm due to the wrong translation. For example, an incorrect translation of a product manual may lead to inappropriate usage and potentially compromise user safety. This issue is of even greater significance in the medical domain, as inaccuracies in translated medical documents may result in severe or even fatal outcomes. The SAF example in Table <ref type="table" target="#tab_7">5</ref> depicts the potential safety hazards stemming from erroneous translations. If a user follows the translated statement, this could pose a serious and potentially life-threatening risk.</p><p>Named Entity (NAM) refers to a type of error where the name of an entity, such as a person, place name, organization, and date, is not properly represented in the translation. Such errors can result in substantial information loss and distortion of the original meaning. As shown in the NAM example of Table <ref type="table" target="#tab_7">5</ref>, "the Grand Canyon" is mistranslated as "the Grand Can," substantially deviating from the intended entity. These inaccuracies can undermine the meaning of the original sentence and impede effective communication.</p><p>Number (NUM) refers to an error type associated with the mistranslation of numeric entities, such as times and dates. These errors can have serious consequences, particularly when dealing with sensitive documents. The NUM example in Table <ref type="table" target="#tab_7">5</ref> represents the potential risk of mistranslating quantities, which may result in a loss of trust. Compromising the integrity of quantities or dates can lead to the degradation of the document's content, causing commercial harm.</p><p>Sentiment (SEN) is a type of translation error that changes the polarity of a sentence, thus distorting its meaning or conveying an incorrect sentiment. This type of error is particularly impactful in the marketing domain, where conveying the wrong sentiment can negatively affect the perception of a brand or product. Additionally, if a sentence's sentiment is reversed, as exemplified by the SEN example presented in Table <ref type="table" target="#tab_7">5</ref>, it may convey unintended blame or criticism.</p><p>Politeness (POL) denotes an error where the translated statements exhibit contextually inappropriate or impolite expressions. This error type is particularly relevant to specific languages that incorporate politeness within their syntactic structure. Particularly, Korean is characterized by a clear distinction between formal and informal speeches. This distinction amplifies the potential impact of out-of-context issues, as it may inadvertently render a sentence rude or offensive. Table <ref type="table" target="#tab_7">5</ref> provides an example of an informal Korean translation derived from a polite English expression 9 . In a professional setting, the use of such informal language may upset others.</p><p>Identifying these critical error types enables the mitigation of severe issues. Furthermore, it provides valuable feedback to MT systems, highlighting areas in need of refinement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Experiments with templates and verbalizers</head><p>9 "미안하다(sorry)" may sound rude in a polite setting. The polite form "죄송합니다(sorry)" have to be used. Table <ref type="table">6</ref>: Results of experimenting with various templates and verbalizers according to each method. src is the source sentence to input; mt is the machine translation sentence to input; mask is the mask token; demo_ok is the demonstration with a positive label; demo_bad is the demonstration with a negative label; gmt is the google machine translation; sim is the similarity; gec_ * is the grammar error correction result for * sentence; rtt is the round-trip translation; sen_len_ * is the sentence length of * sentence; tok_len_ * is the token length of * sentence; ner is the named entity recognition; word_ * is the Results of translation of the word that exists in * sentence; Verbalizer is configured as positive/negative.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overall architecture of prompt-based fine-tuning with informational evidence</figDesc><graphic coords="2,70.87,70.87,453.55,152.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Evidence and Mix-up modeling performance of each category</figDesc><graphic coords="7,323.15,70.87,184.25,293.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Statistics of an English-Korean CED Dataset</figDesc><table><row><cell cols="4">Label Category Train Dev</cell><cell>Test</cell></row><row><cell>NOT</cell><cell></cell><cell cols="2">6,606 444</cell><cell>924</cell></row><row><cell>ERR</cell><cell>TOX</cell><cell>133</cell><cell>6</cell><cell>7</cell></row><row><cell></cell><cell>SAF</cell><cell>122</cell><cell>15</cell><cell>10</cell></row><row><cell></cell><cell>NAM</cell><cell>95</cell><cell>12</cell><cell>20</cell></row><row><cell></cell><cell>NUM</cell><cell>116</cell><cell>6</cell><cell>12</cell></row><row><cell></cell><cell>SEN</cell><cell>110</cell><cell>12</cell><cell>14</cell></row><row><cell></cell><cell>POL</cell><cell>83</cell><cell>5</cell><cell>13</cell></row><row><cell>Total</cell><cell></cell><cell cols="3">7,265 500 1,000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>The main result of the models for English-Korean Critical Error Detection. This table shows the experimental outcomes for the test and evaluation dataset. Bold indicates the best performance. We use the XLM-RoBERTa-large model, which performed excellently in the baseline, in both prompt-based fine-tuning and prompt-based fine-tuning with additional information. PBFT is prompt-based fine-tuning, and in PBFT training, additional resources categorized as META, BILINGUAL, and MONOLINGUAL evidence are presented with a +; Demo is the value experimented with on the model that supplied the demonstration; GMT utilizes Google Translate system;</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Performance with data distribution. The percentage value is the extent to which the number of errorlabeled data was reduced to balance the data. We present the scores obtained through prompted fine-tuning of the sampled data, and evaluate these values by comparing them to the performance of an ensemble model incorporating BILINGUAL evidence, which emerges as the most successful among our approaches.</figDesc><table><row><cell>Method</cell><cell cols="3">MCC F1-NOT F1-ERR F1-Multi</cell></row><row><cell cols="2">PBFT+BILINGUAL 0.6928 0.9798</cell><cell>0.6833</cell><cell>0.6700</cell></row><row><cell>PBFT</cell><cell>0.6564 0.9770</cell><cell>0.6667</cell><cell>0.6513</cell></row><row><cell>-10%</cell><cell>0.5479 0.9700</cell><cell>0.5616</cell><cell>0.5449</cell></row><row><cell>-20%</cell><cell>0.4954 0.9684</cell><cell>0.5013</cell><cell>0.4855</cell></row><row><cell>-30%</cell><cell>0.5796 0.9725</cell><cell>0.5858</cell><cell>0.5698</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Critical Error Example by Category. We provide critical error cases of translation classified into six types.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>https://platform.openai.com/docs/ guides/completion</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>https://aihub.or.kr/aihubdata/data/ view.do?dataSetSn=71269</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2"><p>https://translate.google.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_3"><p>https://github.com/kakaobrain/pororo</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was supported by <rs type="institution">Institute of Information &amp; communications Technology Planning &amp; Evaluation(IITP)</rs> grant funded by the <rs type="funder">Korea government(MSIT)</rs> (No. <rs type="grantNumber">2020-0-00368</rs>, <rs type="projectName">A Neural-Symbolic Model for Knowledge Acquisition and Inference Techniques</rs>). This research was supported by the <rs type="funder">MSIT(Ministry of Science and ICT)</rs>, <rs type="funder">Korea</rs>, under the <rs type="funder">ITRC</rs>(<rs type="programName">Information Technology Research Center) support program</rs>(<rs type="grantNumber">IITP-2023-2018-0-01405</rs>) supervised by the <rs type="institution">IITP(Institute for Information &amp; Communications Technology Planning &amp; Evaluation</rs>). This work was supported by <rs type="institution">Institute for Information &amp; communications Technology Planning &amp; Evaluation(IITP)</rs> grant funded by the <rs type="funder">Korea government(MSIT)</rs> (No. <rs type="grantNumber">2022-0-00369</rs>, (<rs type="funder">Part 4) Development of AI Technology</rs> to support Expert Decision-making that can Explain the Reasons/Grounds for Judgment Results based on Expert Knowledge).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_3N3Cemy">
					<idno type="grant-number">2020-0-00368</idno>
					<orgName type="project" subtype="full">A Neural-Symbolic Model for Knowledge Acquisition and Inference Techniques</orgName>
				</org>
				<org type="funding" xml:id="_zneJeva">
					<idno type="grant-number">IITP-2023-2018-0-01405</idno>
					<orgName type="program" subtype="full">Information Technology Research Center) support program</orgName>
				</org>
				<org type="funding" xml:id="_ebkCQrz">
					<idno type="grant-number">2022-0-00369</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On the dangers of stochastic parrots: Can language models be too big</title>
		<author>
			<persName><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timnit</forename><surname>Gebru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angelina</forename><surname>Mcmillan-Major</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shmargaret</forename><surname>Shmitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 ACM conference on fairness, accountability, and transparency</title>
		<meeting>the 2021 ACM conference on fairness, accountability, and transparency</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="610" to="623" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Naver labs europe&apos;s systems for the wmt19 machine translation robustness task</title>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Berard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioan</forename><surname>Calapodescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claude</forename><surname>Roux</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.06488</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">MAXSIM: A maximum similarity metric for machine translation evaluation</title>
		<author>
			<persName><forename type="first">Yee</forename><surname>Seng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chan</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-08: HLT</title>
		<meeting>ACL-08: HLT<address><addrLine>Columbus, Ohio</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="55" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">HW-TSC&apos;s participation at WMT 2021 quality estimation shared task</title>
		<author>
			<persName><forename type="first">Yimeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingtao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxia</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shimin</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guo</forename><surname>Jiaxin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename><surname>Minghan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shujian</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Conference on Machine Translation</title>
		<meeting>the Sixth Conference on Machine Translation</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="890" to="896" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Unsupervised cross-lingual representation learning at scale</title>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kartikay</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.02116</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Template-based named entity recognition using BART</title>
		<author>
			<persName><forename type="first">Leyang</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-acl.161</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1835" to="1845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">KU X upstage&apos;s submission for the WMT22 quality estimation: Critical error detection shared task</title>
		<author>
			<persName><forename type="first">Sugyeong</forename><surname>Eo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chanjun</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyeonseok</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaehyung</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heuiseok</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Conference on Machine Translation (WMT)</title>
		<meeting>the Seventh Conference on Machine Translation (WMT)<address><addrLine>Abu Dhabi</addrLine></address></meeting>
		<imprint>
			<publisher>United Arab Emirates (Hybrid). Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="606" to="614" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Making pre-trained language models better few-shot learners</title>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.15723</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Dictionary-based phrase-level prompting of large language models for machine translation</title>
		<author>
			<persName><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hila</forename><surname>Gonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.07856</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Optimal transport for unsupervised hallucination detection in neural machine translation</title>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Nuno M Guerreiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pablo</forename><surname>Colombo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">André Ft</forename><surname>Piantanida</surname></persName>
		</author>
		<author>
			<persName><surname>Martins</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.09631</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">Karen</forename><surname>Hambardzumyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hrant</forename><surname>Khachatrian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00121</idno>
		<title level="m">Warp: Word-level adversarial reprogramming</title>
		<imprint>
			<date type="published" when="2021-05">May. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">ICL&apos;s submission to the WMT21 critical error detection shared task</title>
		<author>
			<persName><forename type="first">Genze</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenhao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Conference on Machine Translation</title>
		<meeting>the Sixth Conference on Machine Translation</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="928" to="934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">The power of scale for parameter-efficient prompt tuning</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08691</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Few-shot learning with multilingual language models</title>
		<author>
			<persName><forename type="first">Victoria</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todor</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikel</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianlu</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Simig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Bhosale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramakanth</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Pasunuru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Punit</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishrav</forename><surname>Singh Koura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian O'</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Horo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zornitsa</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><forename type="middle">T</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
		<idno>CoRR, abs/2112.10668</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing</title>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhe</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinlan</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengbao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroaki</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanan</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengxiao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujie</forename><surname>Qian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.10385</idno>
		<title level="m">Zhilin Yang, and Jie Tang. 2021a. Gpt understands, too</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Enriching non-autoregressive transformer with syntactic and semanticstructures for neural machine translation</title>
		<author>
			<persName><forename type="first">Ye</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian-Guo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenting</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.08942</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Multilingual denoising pretraining for neural machine translation</title>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiatao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="726" to="742" />
		</imprint>
	</monogr>
	<note>Transactions of the Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Machine translation believability</title>
		<author>
			<persName><forename type="first">Marianna</forename><surname>Martindale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Bridging Human-Computer Interaction and Natural Language Processing</title>
		<meeting>the First Workshop on Bridging Human-Computer Interaction and Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="88" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An empirical study on automatic post editing for neural machine translation</title>
		<author>
			<persName><forename type="first">Hyeonseok</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chanjun</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sugyeong</forename><surname>Eo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaehyung</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heuiseok</forename><surname>Lim</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2021.3109903</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="123754" to="123763" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Chatgpt: Optimizing language models for dialogue</title>
		<author>
			<persName><surname>Openai-Blog</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Language models as knowledge bases?</title>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anton</forename><surname>Bakhtin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1250</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2463" to="2473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">Telmo</forename><surname>Pires</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eva</forename><surname>Schlinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Garrette</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.01502</idno>
		<title level="m">How multilingual is multilingual bert? arXiv preprint</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Assessing gender bias in machine translation: a case study with google translate</title>
		<author>
			<persName><forename type="first">Pedro</forename><forename type="middle">H</forename><surname>Marcelo Or Prates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luís C</forename><surname>Avelar</surname></persName>
		</author>
		<author>
			<persName><surname>Lamb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="6363" to="6381" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Salted: A framework for salient long-tail translation error detection</title>
		<author>
			<persName><forename type="first">Vikas</forename><surname>Raunak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arul</forename><surname>Menezes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.09988</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.10084</idno>
		<title level="m">Sentence-bert: Sentence embeddings using siamese bert-networks</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">NICT Kyoto submission for the WMT&apos;21 quality estimation task: Multimetric multilingual pretraining for critical error detection</title>
		<author>
			<persName><forename type="first">Raphael</forename><surname>Rubino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atsushi</forename><surname>Fujita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Marie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Conference on Machine Translation</title>
		<meeting>the Sixth Conference on Machine Translation</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="941" to="947" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">Le</forename><surname>Teven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellie</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suzana</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ilić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Hesslow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Castagné</surname></persName>
		</author>
		<author>
			<persName><forename type="first">François</forename><surname>Sasha Luccioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Yvon</surname></persName>
		</author>
		<author>
			<persName><surname>Gallé</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.05100</idno>
		<title level="m">Bloom: A 176bparameter open-access multilingual language model</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Few-shot text generation with pattern-exploiting training</title>
		<author>
			<persName><forename type="first">Timo</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.11926</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">It&apos;s not just size that matters: Small language models are also few-shot learners</title>
		<author>
			<persName><forename type="first">Timo</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.07118</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Exploiting cloze-questions for few-shot text classification and natural language inference</title>
		<author>
			<persName><forename type="first">Timo</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.eacl-main.20</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="255" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A taxonomy and study of critical errors in machine translation</title>
		<author>
			<persName><forename type="first">Al</forename><surname>Khetam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucia</forename><surname>Sharou</surname></persName>
		</author>
		<author>
			<persName><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd Annual Conference of the European Association for Machine Translation</title>
		<meeting>the 23rd Annual Conference of the European Association for Machine Translation<address><addrLine>Ghent, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>European Association for Machine Translation</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="171" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Round-trip translation: What is it good for?</title>
		<author>
			<persName><forename type="first">Harold</forename><surname>Somers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Australasian Language Technology Workshop 2005</title>
		<meeting>the Australasian Language Technology Workshop 2005</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="127" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Findings of the WMT 2020 shared task on quality estimation</title>
		<author>
			<persName><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frédéric</forename><surname>Blain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marina</forename><surname>Fomicheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erick</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">T</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName><surname>Martins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Conference on Machine Translation</title>
		<meeting>the Fifth Conference on Machine Translation</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="743" to="764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Findings of the WMT 2021 shared task on quality estimation</title>
		<author>
			<persName><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frédéric</forename><surname>Blain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marina</forename><surname>Fomicheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chrysoula</forename><surname>Zerva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenhao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">T</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName><surname>Martins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Conference on Machine Translation</title>
		<meeting>the Sixth Conference on Machine Translation</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="684" to="725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Estimating the sentence-level quality of machine translation systems</title>
		<author>
			<persName><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicola</forename><surname>Cancedda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nello</forename><surname>Cristianini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Dymetman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Annual conference of the European Association for Machine Translation</title>
		<meeting>the 13th Annual conference of the European Association for Machine Translation<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>European Association for Machine Translation</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Is this translation error critical?: Classification-based human and automatic machine translation evaluation focusing on critical errors</title>
		<author>
			<persName><forename type="first">Katsuhito</forename><surname>Sudoh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kosuke</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satoshi</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Human Evaluation of NLP Systems (HumEval)</title>
		<meeting>the Workshop on Human Evaluation of NLP Systems (HumEval)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="46" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">HW-TSC&apos;s participation at WMT 2020 quality estimation shared task</title>
		<author>
			<persName><forename type="first">Minghan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengchao</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daimeng</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaxin</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lizhi</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shimin</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiliang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yimeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liangyou</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Conference on Machine Translation</title>
		<meeting>the Fifth Conference on Machine Translation</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1056" to="1061" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Findings of the WMT 2022 shared task on quality estimation</title>
		<author>
			<persName><forename type="first">Chrysoula</forename><surname>Zerva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frédéric</forename><surname>Blain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Rei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piyawat</forename><surname>Lertvittayakumjorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diptesh</forename><surname>Eger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duarte</forename><surname>Kanojia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Constantin</forename><surname>Alves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marina</forename><surname>Orȃsan</surname></persName>
		</author>
		<author>
			<persName><surname>Fomicheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">T</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucia</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Conference on Machine Translation (WMT)</title>
		<meeting>the Seventh Conference on Machine Translation (WMT)<address><addrLine>Abu Dhabi</addrLine></address></meeting>
		<imprint>
			<publisher>United Arab Emirates</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="69" to="99" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">Susan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Dewan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Victoria Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.01068</idno>
		<title level="m">Opt: Open pre-trained transformer language models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
