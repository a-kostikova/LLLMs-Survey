<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MedRedQA for Medical Consumer Question Answering: Dataset, Tasks, and Neural Baselines</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Vincent</forename><surname>Nguyen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">CSIRO Data61</orgName>
								<address>
									<settlement>Sydney</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">The Australian National University</orgName>
								<address>
									<settlement>Canberra</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sarvnaz</forename><surname>Karimi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">CSIRO Data61</orgName>
								<address>
									<settlement>Sydney</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Maciej</forename><surname>Rybinski</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">CSIRO Data61</orgName>
								<address>
									<settlement>Sydney</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhenchang</forename><surname>Xing</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">CSIRO Data61</orgName>
								<address>
									<settlement>Sydney</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">The Australian National University</orgName>
								<address>
									<settlement>Canberra</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MedRedQA for Medical Consumer Question Answering: Dataset, Tasks, and Neural Baselines</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4CBCFE6D48CE89D293A21C63C0F55ACF</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-05-29T13:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Medical question answering for consumers aims to assist consumers in finding trustworthy and relevant information for their concerns. Although some datasets exist for consumer question answering, they use synthetic questions or present difficult-to-understand answers. We introduce MedRedQA, a large non-factoid English consumer Question Answering (QA) dataset containing 51,000 pairs of consumer questions and their corresponding expert answers. MedRedQA facilitates research that aims to provide consumer-friendly responses to realworld consumer questions. We propose and benchmark three tasks for consumer medical question answering for our dataset, including (1) candidate answer ranking, (2) open-ended answer generation, and (3) answer generation with scientific evidence. Our benchmarking experiments reveal that, for the ranking task, it is feasible to retrieve expert answers within five responses in an oracle retrieval. Though, in an answer generation task, it remains challenging to align the generation toward expert answers. However, our experiments show that including scientific evidence in the prompt may reduce hallucinations in an answer generation setup. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Those without expertise in the medical domain, hereafter referred to as consumers, often seek answers to their medical questions online <ref type="bibr">(Van Riel et al., 2017)</ref>. A startling number of these consumers do not follow up their online search with a medical professional and believe in their selfdiagnosis <ref type="bibr" target="#b25">(Kuehn, 2013)</ref>, which may be corroborated by less reputable sources <ref type="bibr" target="#b33">(Nelson et al., 2020)</ref>. This is concerning, given the amount of health misinformation circulating the general web <ref type="bibr" target="#b17">(Hussain et al., 2018)</ref>, and that non-official high-traffic health websites likely have high amounts of misin-formation <ref type="bibr">(NewsGuard, 2021)</ref>. As a result, a misinformed consumer might be less likely to adhere to health guidelines <ref type="bibr" target="#b22">(Jon et al., 2020)</ref>, such as vaccination advice <ref type="bibr" target="#b11">(Garett and Young, 2021)</ref>. On the other hand, there is a positive correlation between patients researching their conditions and improved patient-physician rapport. This occurs as dialogue improves between the physician and their patient when the patient has an improved understanding of their potential diagnosis and prognosis <ref type="bibr" target="#b9">(Cocco et al., 2018)</ref>. Importantly, when the consumer is wrong about their potential diagnosis, adherence to the physician's recommendations does not <ref type="bibr">decrease (Van Riel et al., 2017)</ref>.</p><p>Given the aforementioned benefits of patients' being proactive in searching their symptoms, some existing systems allow consumers to search for potential diagnoses. Examples of these systems include health cards, which provide disease information alongside search results <ref type="bibr" target="#b19">(Jimmy et al., 2019)</ref>, a curated multi-document answer synthesis that takes answers from an expert annotated database <ref type="bibr" target="#b10">(Demner-Fushman et al., 2020)</ref>, and a search system that allows users to get expert-level recall using consumer queries over peer-reviewed COVID-19 literature <ref type="bibr">(Nguyen et al., 2022)</ref>. These systems are important and require continual research as consumers require high-quality medical advice for a broad range of topics.</p><p>However, consumer QA systems often use datasets of limited scope and scale. Many of these datasets often make assumptions on consumer input (e.g., a singular short closed question), retrieve answer excerpts from difficult-to-understand medical articles (consumer unfriendly), and are too small to train contemporary models. We aim to address these problems by introducing MedRedQA, the largest English consumer question answering (QA) dataset. MedRedQA consists of 51,000 consumer questions and verified expert answer pairs collected from a health subreddit called AskDocs which is dedicated to improving access to health information for consumers. We present benchmarking experiments for retrieval-based QA and generative QA for these pairs. We also introduce a novel task for generative QA with the availability of relevant scientific sources. To this end, we introduce a collection of question-expert answer-source article triplets containing PubMED<ref type="foot" target="#foot_1">2</ref> scientific articles that are referenced by a medical expert. Our paper provides the following research contributions:</p><p>1. Construction of a dataset for research on realworld consumer questions providing expert answers similar in language to the consumer.</p><p>2. Proposal of three tasks including evaluation and analysis of baselines for Consumer QA: (a) expert answers as a ranking problem; (b) expert answer generation from a question; and (c) novel expert answer generation grounded by question-source article pairs.</p><p>3. Analysis of the difference in language used by the consumer and the medical expert and their response behaviors on the forum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Literature in biomedical QA primarily focuses on providing answers to professionals.</p><p>Professional QA The annually run BioASQ <ref type="bibr" target="#b24">(Krithara et al., 2016;</ref><ref type="bibr">Nentidis et al., 2017</ref><ref type="bibr">Nentidis et al., , 2018) )</ref> provides tasks and datasets for QA posed by medical experts as a summarization and information retrieval task. Similarly, tasks run by TREC including TREC-COVID <ref type="bibr" target="#b53">(Voorhees et al., 2020)</ref> and TREC-CDS <ref type="bibr" target="#b54">(Voorhees and Hersh, 2012;</ref><ref type="bibr" target="#b40">Roberts et al., 2017</ref><ref type="bibr" target="#b42">Roberts et al., , 2018</ref><ref type="bibr" target="#b43">Roberts et al., , 2019</ref><ref type="bibr" target="#b41">Roberts et al., , 2021) )</ref> are focused on solving search tasks for medical experts which include clinical decision support <ref type="bibr" target="#b45">(Roberts et al., 2015</ref><ref type="bibr" target="#b44">(Roberts et al., , 2016))</ref>, clinical trial retrieval and precision medicine <ref type="bibr" target="#b40">(Roberts et al., 2017</ref><ref type="bibr" target="#b42">(Roberts et al., , 2018))</ref>.</p><p>Consumer QA While there has been considerable effort to help experts, less emphasis has been put forward on consumers. MEDIQA <ref type="bibr">(Ben Abacha et al., 2019)</ref>, which is an extended collection of MedNLI <ref type="bibr" target="#b48">(Shivade, 2019)</ref>, MedQUAD <ref type="bibr">(Ben Abacha and Demner-Fushman, 2019)</ref> and RQE <ref type="bibr" target="#b0">(Abacha and Demner-Fushman, 2016)</ref>, is proposed to facilitate consumer biomedical QA. However, these datasets are limited in Furthermore, MEDIQA derives some of its data from MIMIC-III <ref type="bibr" target="#b21">(Johnson et al., 2016)</ref>, a dataset of critical-care patient reports that does not reflect the medical needs of an everyday consumer. We summarize datasets for the consumer QA domain in Table <ref type="table" target="#tab_0">1</ref>.</p><p>MashQA <ref type="bibr" target="#b63">(Zhu et al., 2020)</ref> presents long-form medical documents or websites for span-based question answering from typically short-form factoid questions. However, MashQA is suitable for question answering with context rather than openended question answering. Furthermore, the questions are typically short and address a single information need: 'How many available treatments for X disease?', without incorporating contextual information of the consumer, such as their medical history, age or gender. Moreover, there is an implicit assumption that question context contains the answer (SQuAD-style question answering), which may not be comprehensible to consumers.</p><p>RedHot <ref type="bibr" target="#b55">(Wadhwa et al., 2023)</ref> presents a task of retrieving evidence for Reddit questions from peerreviewed sources to verify a medical claim made in the post using patient/population, intervention, comparison and outcomes (PICO) elements for retrieval. The data is sourced from subreddits (or forums) where the diagnosis is known: /r/ADHD, /r/Psychosis, and is used to provide interventions or treatments. Although well annotated, it does not present answers in a consumer-friendly manner that the consumer will likely understand and appreciate, as the answers are given as PubMed abstracts <ref type="bibr" target="#b12">(Graham and Brookey, 2008)</ref>. Furthermore, the dataset does not leverage the answers from the users to the questions. This may be because there is no verified distinction between an expert response and a layperson response. These distinction labels are present in /r/askdocs, used in this work. cMedQA <ref type="bibr" target="#b61">(Zhang et al., 2018)</ref> and ChiMED <ref type="bibr" target="#b50">(Tian et al., 2019)</ref>, are large-scale corpora that use crowdsourced data from existing online forums with doctor-patient response pairs. They are well suited for consumer question answering, as they are sourced from real-world data. These datasets, however, are not in English.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>Size Language Description Mash-QA <ref type="bibr" target="#b63">(Zhu et al., 2020)</ref> 34.8k English Span-based QA for consumer health, where contexts are given as long documents and questions are of the short-form. ChiMed <ref type="bibr" target="#b50">(Tian et al., 2019)</ref> 24.9k Chinese A corpus where doctor-patient answer pairs are taken from an existing online forum (XunYiWenYao). cMedQA v2 <ref type="bibr" target="#b61">(Zhang et al., 2018)</ref> 108k Chinese A corpus where doctor-patient answer pairs are taken from an existing online forum (wywy.com) MedQuAD <ref type="bibr">(Ben Abacha et al., 2019)</ref> 48k English A collection of curated English question-answer pairs from cancer.gov with consumer language in the answers. MeQSum <ref type="bibr">(Ben Abacha and Demner-Fushman, 2019)</ref> 1k English Summarization of long-form consumer context questions to short-form questions. BioReddit <ref type="bibr" target="#b3">(Basaldella and Collier, 2019)</ref> N/A English Collection of Biology StackExchange and Reddit Health Subreddits corpus to produce static word embeddings. RedHot <ref type="bibr" target="#b55">(Wadhwa et al., 2023)</ref> 22k English Collection of annotated Reddit posts from health subreddits of a particular disease e.g. /r/ADHD /r/Psychosis MedRedQA (Ours) 51k English An English Corpus from /r/askdocs where long-form consumer questions are mapped to short-form doctor comments There is a gap in the literature when it comes to real-world datasets that: (1) accurately reflect how consumers ask questions; (2) take into account the consumers' medical context; (3) are of a practical size to meet contemporary neural models data requirements; (4) provide trustworthy answers in a consumer-friendly way. Our dataset addresses this gap in the literature by sourcing real-world consumer questions that include medical context and providing the answers in a language that the consumer understands.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MedRedQA Dataset Creation</head><p>Raw Data Collection We collected data from posts and comments to subreddit /r/askdocs, published between July 10, 2013, and April 2, 2022, totalling 600, 000 submissions (original posts) and 1, 700, 000 comments (replies). Askdocs (/r/askdocs) is a forum for consumers, referred to as laypeople in the forum, to ask medical questions and receive responses from physicians. There were 71 unique occupations for medical experts and three labels for the consumer. Each submission had an average of 3.03 (±10.75) comments, a median of 3.00, with an overall maximum comment count of 5,888, indicating a long-tail distribution. The average submission contained a short patient profile: demographics, medication, symptoms and a question, with the format agreed on as part of the forum's rules. Only a third of the submissions had a comment, and 20% of the responses were from verified medical professionals. From n-gram frequency analysis, we found that consumers tend to ask about acute illnesses (symptoms within the last two weeks) with the leading advice given on the forum to go see a doctor from both consumers and medical experts.</p><p>Upon manual inspection, we find that submissions with the highest comment count often contained emotionally charged content (e.g., suicide) or were general information threads (e.g., a compilation of COVID questions/answers). Longer submissions, likely adhering to community guidelines, had more comments. The average number of tokens was 231.9 (±217.2) per submission, 21.59 (±10.46) per comment, and 11.21 (±8.435) for titles. <ref type="bibr">Physicians' comments (50.79 ± 68.61)</ref> were more concise than those from other consumers (53.89 ± 70.39). The Jaccard Index <ref type="bibr" target="#b18">(Jaccard, 1912)</ref> between the vocabularies of consumer's comments and medical experts' comments was 0.89 after stopword removal, with the main difference in tokens being unique medical terminology.</p><p>Data Cleaning We use a set of heuristics to clean and organize the data. Firstly we remove all submissions that have been removed by moderators, submissions from banned users, bot content, and submissions with fewer than five words. To protect privacy, posts from any users with deleted accounts or those who have removed their posts, as the title and comments remain, have also been removed. We further remove posts with images and remove any URLs.</p><p>We then filter comments using the same criteria but with two additional heuristics: (1) the comment must be from a verified physician, and (2) the comment must have a score higher than 1.0 (the default score), which indicates that at least one other user agrees with the comment. We then use the highestscoring comment as the answer for the submission. After filtering and cleaning heuristics, a total of 51, 000 question-answer pairs remained. We then  randomly divide the dataset into an 80-10-10 training/validation/testing split.</p><p>Scientific evidence Some comments contain references to medical articles as evidence or are presented as further reading for the consumer. There were 3, 300 PubMed articles mentioned in the comments. However, we retained only 1000 references (30.3%) which were from verified medical professionals in the final dataset. Table <ref type="table" target="#tab_2">2</ref> shows an example from the dataset. We check the provided abstracts by annotating a random 10% sampling of the abstracts for quality verification (Appendix C).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Tasks</head><p>We explore three tasks, where the goal is to produce a consumer-friendly expert answer, given a consumer question: (1) Question Answering as a ranking task over candidate answers <ref type="bibr">(Nguyen et al., 2016)</ref>; ( <ref type="formula">2</ref>) an open-ended generation task where questions are used to generate answers; and, (3) a generation with scientific evidence task where questions and the corresponding evidence (PubMed articles' abstract) are used to generate an expert response. These tasks are formulated as below:</p><p>Ranking Consumer question answering can be tackled as an ad-hoc ranking task:</p><formula xml:id="formula_0">P (relevance = 1, D, q) = score(q, D), (1)</formula><p>where the relevance of the ad-hoc consumer question (query), q to a candidate expert answer, d, from the corpus of expert answers, d ∈ D, is computed with a function that estimates relevance score for ranking. Retrieval of expert responses is desirable as they are written by experts, whose quality has been assessed via crowdsourcing (i.e., the forum score).</p><p>For dense retrieval <ref type="bibr" target="#b60">(Zamani et al., 2018)</ref>, typically a bi-encoder is used for initial stage ranking:</p><formula xml:id="formula_1">h d = BERT(d)[CLS]</formula><p>(2)</p><formula xml:id="formula_2">h q = BERT(q)[CLS] (3) score(q, d ∈ D) = cos(h q , h d ),<label>(4)</label></formula><p>which estimates relevance score as the cosine similarity between the hidden representations of the consumer question, h q and expert answer, h d .</p><p>The initial retrieval can be re-ranked in a secondary stage ranker with a filtered set of expert answers D k , which is typically set to the top 1000 candidate answers, D k=1000 from the initial retrieval:</p><formula xml:id="formula_3">score(q, d ∈ D k ) = Sof tmax(h q;d ). (5)</formula><p>Sparsity However, for our dataset, we also need to account for the sparsity of the labels:</p><formula xml:id="formula_4">P (label = 1|D, q) ∈ {0, 1},<label>(6)</label></formula><p>where there is only a single expert answer, d ∈ D, which has a label of 1 a query, q. We therefore validate if the baselines can reasonably model the sparse data distribution.</p><p>Open-ended Generation The importance of the ranking task is that it allows answers to be restricted to a set of verified expert answers. However, there is no guarantee that future answers are contained in the set of verified answers. We therefore can also model the task of providing consumer-friendly expert answers with auto-regressive generative Language Modeling (LM):</p><p>P (w 1 , ..., w t ) ≈ P (w t |w 1 , ..., w t-1 ), ( <ref type="formula">7</ref>)</p><formula xml:id="formula_5">w t+1 ∼ P (•|w 1:t ),<label>(8)</label></formula><p>where a word, w t+1 is sampled from the probability distribution over the vocabulary P (•, w 1:t ) given the sequence generated, w 1:t up until time step, t.</p><p>When finetuned with instructions, we can auto-regressively generate an output sequence, O t = {w p , ..., w t }, given a fixed prompt P = {w 1 , ..., w p-1 } that is more aligned with human preference.</p><p>Generation With Scientific Evidence However, the output of the open-ended generation may be too broad, prone to hallucination or irrelevant. We, therefore, introduce the novel task of using Large Language Models (LLMs) fine-tuned with the context provided by PubMed documents to generate expert consumer-oriented answers. The context is provided to produce a better auto-regressive response using the evidence from the PubMed document. Moreover, providing source documents in prompts has reduced hallucination in LLMs <ref type="bibr" target="#b31">(Madaan et al., 2022;</ref><ref type="bibr" target="#b14">Guu et al., 2020;</ref><ref type="bibr">Lazaridou et al., 2022)</ref>, a vital property for sensitive tasks such as consumer medical QA. This generation task uses a subset of submissions that contain a PubMed document (provenance) which we use as scientific evidence in a fixed prompt P .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Methods</head><p>We investigate the following methods and their implementations to validate the feasibility of the tasks we propose for the MedRedQA dataset taking into account the sparsity of the labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Ranking</head><p>We use BM25 <ref type="bibr" target="#b46">(Robertson et al., 1994)</ref> as a ranking baseline. BM25 is a robust statistical model that uses lexical overlaps or hard-matching as a relevance signal. Although not as competitive as a well-tuned neural model, it is a stable baseline and works well out-of-the-box <ref type="bibr" target="#b1">(Armstrong et al., 2009)</ref>. Furthermore, it captures different relevance signals when compared to dense retrievers <ref type="bibr" target="#b56">(Wang et al., 2021)</ref>.</p><p>The ranking pipeline includes a zero-shot Bi-Encoder (BiEnc) and Cross-Encoder (CEnc). We use the PubMEDBERT model by <ref type="bibr" target="#b13">Gu et al. (2021)</ref> as our BiEnc, pretrained on the PubMed corpus (NCBI, 2023), without additional finetuning. Contradictory to <ref type="bibr" target="#b39">(Reimers and Gurevych, 2019)</ref>, we found that finetuning the sentence encoder hurts ranking in our preliminary experiments (Appendix B).</p><p>We select the top 1000 answers from BiEnc for second-stage ranking with a cross-encoder, MonoBERT <ref type="bibr" target="#b35">(Nogueira et al., 2019)</ref>. This CEnc was trained with a learning rate of 2 × 10 -5 for 4500 steps (stopping when the model over-fit) using the AdamW optimizer <ref type="bibr" target="#b29">(Loshchilov and Hutter, 2017)</ref> with a warm-up ratio of 0.1. We select the best checkpoint based on the validation set perfor-mance for downstream task prediction. We used random sampling to select negatives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Open-Ended Generation</head><p>For the expert answer generation, we use T5 <ref type="bibr" target="#b38">(Raffel et al., 2020)</ref>, an encoder-decoder conditional LM, which has shown to be as effective as a GPT-3 model <ref type="bibr">(Liu et al., 2022b;</ref><ref type="bibr" target="#b8">Brown et al., 2020)</ref>.</p><p>We test various T5-large models for answer generation: (1) T5 version 1.0, (2) T5 version 1.1, which is pretrained without task prompts, as testing showed task confusion was present in the v1.0 model; (3) T5 Flan, a T5 model <ref type="bibr">(Chung et al., 2022)</ref> pretrained on various instruction-based tasks <ref type="bibr" target="#b57">(Wei et al., 2022)</ref> to improve alignment with instruction prompting, and (4) Flan-T5 pretrained on the indomain PubMedQA <ref type="bibr" target="#b20">(Jin et al., 2019)</ref>, which may improve alignment with expert answer generation.</p><p>For training, we truncated questions to 510 tokens and trained the models using maximum likelihood estimation (teacher forcing) as</p><formula xml:id="formula_6">L CE (ŷ t , y t ) = -log ŷt [w t+1 ],<label>(9)</label></formula><p>where the cross-entropy loss is the negative log probability assigned to the next word, w t+1 . We reuse the same hyperparameters and optimizers for finetuning, namely Adafactor <ref type="bibr" target="#b47">(Shazeer and Stern, 2018)</ref> and a constant learning rate, as the original authors did <ref type="bibr" target="#b38">(Raffel et al., 2020)</ref>. We adopt a similar method to Flan for prompt training, where we construct four variations of prompt templates (Appendix D.1). We train for three epochs, regenerating the prompts for each epoch.</p><p>For generation decoding (Equation <ref type="formula" target="#formula_5">8</ref>), we select generated words based on maximum likelihood<ref type="foot" target="#foot_2">3</ref> for reproducibility</p><formula xml:id="formula_7">w t+1 = arg max P (•|w 1:t ) (10)</formula><p>and set the number of generated tokens to 150.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Generation with Scientific Evidence</head><p>We employ the use of open-source LLMs, namely Llama 7B <ref type="bibr">(Touvron et al., 2023)</ref> and Alpaca 7B <ref type="bibr" target="#b49">(Taori et al., 2023)</ref> (a Llama checkpoint finetuned to align with human preference), as they can be finetuned. This removes the need to provide few-shot examples for in-context learning <ref type="bibr">(Liu et al., 2022a)</ref>. LLMs are also viable for consumeroriented answer generation and have garnered We use a checkpoint <ref type="bibr" target="#b37">(Park, 2023)</ref> that is pretrained on the Alpaca dataset <ref type="bibr" target="#b49">(Taori et al., 2023)</ref> and further finetune on our scientific evidence subset using Low-Rank Adaptation (LoRA) <ref type="bibr" target="#b16">(Hu et al., 2021)</ref> learning rate of 3e-4 and LoRA settings (r=8, alpha=16, dropout=0.05 with an input size of 1024 tokens).</p><p>Our experiments are on zero-shot and finetuned models. For generation, we use the same decoding hyperparameters as T5. However, we increased the input size to 1024, and the generation limit to 250 as preliminary testing showed the Llamabased models were verbose. We experimented with longer generation limits (up to 500), but this led to repetitive degenerate text <ref type="bibr" target="#b15">(Holtzman et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results and Discussion</head><p>Metrics We report accuracy@k (where k is the retrieval size of the result set) as the primary metric to compensate for the sparse nature of the dataset. We also include the Harmonic mean of the Ranks (HR), the reciprocal of the mean reciprocal rank, which indicates the expected rank of the relevant answer. We report Rouge-1 <ref type="bibr" target="#b26">(Lin, 2004)</ref> to capture vocabulary overlap as a supplementary metric for the generation task. To also capture semantics, we use MoverScore <ref type="bibr" target="#b62">(Zhao et al., 2019)</ref> as our primary evaluation metric for the generation tasks.</p><p>Ranking Task Retrieval is expected to be difficult for MedRedQA due to the sparsity of labels and the nature of the questions. The questions are  non-factoid, noisy (typographic errors and grammatical errors), and share little similarity with the answers (based on the results of the BM25 baseline, a keyword-matching probabilistic model). Firststage retrieval underperformed for both neural and probabilistic models (Table <ref type="table" target="#tab_3">3</ref>). Interestingly, we found that the bi-encoder model performed best with the body of the post as the query and that the title facet introduced noise. This was the opposite of the BM25 baseline, which performed best with the title as the query. This is a notable result, as it reinforces our assumption that the two ranking models capture different signals and that BM25 performed better with fewer terms in the query for a recall-based task.</p><p>Using a cross-encoder, a more expensive operation, showed substantial improvement over the initial retrieval. Given a perfect first-stage retrieval, where the retrieved set contains the relevant answer for the query (oracle in Table <ref type="table" target="#tab_4">4</ref>), reaching an expected ranking (HR) of 4.174 in the second-stage retrieval for a relevant answer is possible. Assuming the cross-encoder performs no better than the bi-encoder, we achieve an HR of 27.13. Overall, the results indicate that the task is feasible and that our setup is reliable for benchmarking muchneeded first-stage improvements.</p><p>Open-ended Generation Task We found that the best-performing model, on average across the metrics, was finetuned Flan-T5 (Table <ref type="table" target="#tab_5">5</ref>). This highlights that the Flan dataset has better alignment with our dataset, given that we are using instruction prompting. However, we found that Flan-T5 pretrained with PubMedQA was less effective. This indicates that there is a difference in language between our dataset and scientific literature. Although Rouge-1 scores are low, this is generally expected in the biomedical domain and open-ended text generation, given the difficulty of mapping expert biomedical answers to questions with high lexical gaps <ref type="bibr" target="#b58">(Weißenborn et al., 2013)</ref>. We expect scores to be lower than those in BioASQ <ref type="bibr">(Nentidis et al., 2022)</ref>, as the task involves mapping consumer questions to expert answers, rather than expert questions to expert answers and can be modified to be extractive question answering task for higher Rouge-1 scores.</p><p>Overall, the T5 models produced much shorter responses than the LLM counterparts. Interestingly, the Flan-T5 generated 10.18±12.77 words after finetuning and 16.53±27.11 words before. This is reflected in the lower Rouge-1 scores, as the chance of word overlap between the generated text and the reference is reduced with fewer words; meaning medical experts tend to be concise and direct, which the T5 models learned during training.</p><p>Qualitatively, the T5 responses often instructed the consumer to see a specialist and prefaced with "I'm not a doctor." Although appearing in the training set, as medical experts are not all doctors, it is interesting that the model reinforced this type of response. Before finetuning, the model would respond with "I'm not a doctor, I'm a hairstylist". However, after finetuning, the model would still preface with "I'm not a doctor," but would then provide relevant health advice to the user. This suggests that this phrase frequently appears alongside consumer biomedical questions in the C4 dataset <ref type="bibr" target="#b38">(Raffel et al., 2020)</ref> used for T5 pretraining.</p><p>Furthermore, T5-generated responses often advised the consumer to see a specific health professional based on their medications (e.g., "see a psychiatrist", "see an audiologist"). This is a useful generation, as maximizing recall-sensitivity is desirable when providing medical advice. That being said, we did find cases where Flan-T5 produced responses that contradicted the expert response; for instance, a user would ask if a particular aspect of their health is within normal range. The model would suggest it is not normal, but the expert response suggests it is within the normal range.</p><p>One major differentiating factor between the T5 and expert responses was that the T5 responses were concise, factual, and instructive. While many expert responses were similar, expert responses were likely to be longer and provided reassurance rather than advice: "This is normal, nothing to be worried about" (further examples of generation and further analysis in Appendix D.3.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generation with Evidence Task</head><p>The results (Table 6), show that the Alpaca model performs best across the metrics, aligning better with the expert responses. We found that the Llama models fell behind in performance, which is expected as these models are not aligned to instructions, but are traditional LMs. However, it is surprising that tuning the Llama model yielded worse performance after finetuning, which may result from the small dataset size. Quantitatively, adding the document to the prompt produced slightly worse scores (Table <ref type="table" target="#tab_7">7</ref>) which may result from irrelevant abstracts being included in the prompt (Appendix C). This would have a significant effect, given the test sample size.</p><p>For the LLMs, the responses were more empathetic than their T5 counterparts. This is unsurprising, given that they were trained to align with human preference. This was shown as they often repeated the same beginning phrases-"Thank you for your question, you are concerned about [disease]"-which did appear in the pretrained model, but became more refined after finetuning.</p><p>We observed that the Alpaca model generation typically thanks the user and responds sincerely, which is also reflected in the average generation length being 136 tokens (10× more than T5). In contrast, Llama generated 98 tokens on average. It also is more likely to speak in the first person than as a third party, similar to Llama.</p><p>Inspection of the finetuned Alpaca-generated responses showed mostly factual responses, where the model would provide textbook-like definitions and excerpts describing a particular disease or condition: "Thank you for your question... NRBC count is a lab test measuring the amount of nucleated blood cells...[100 tokens omitted]" which appears off-topic and irrelevant to the user's question about lab results. This contrasts with expert responses which tended to be concise and pertinent: "The labs are acceptable. No reason to be concerned here." This finding is in line with recent research, showing that LLMs tended to produce more empathetic, verbose responses <ref type="bibr" target="#b2">(Ayers et al., 2023)</ref>. In contrast, some physician responses were dismissive of the user's concerns.</p><p>Qualitatively, adding the document to the prompt is important as LLMs produce textbook-like responses and, therefore must contextualize their responses in relevant literature to reduce hallucination. Without adding the document to the prompt, we find there are three primary sources of error: (1) the LLM hallucinates (replies as customer support), (2) strays off-topic (provides textbook definitions of a particular word in the prompt), or (3) provides incorrect advice (saying a lab result is normal when it is abnormal). This may indicate that the evaluation metrics used are not aligned with the response consumers want, but are aligned with the expert response that the consumer can understand. Examples and further analysis are in Appendix D.3.2.</p><p>Overall, the generation models provide coherent, well-formed sentences. Nevertheless, they are still unlikely to be useful without contextual evidence. We found that the T5 model's generations aligned more with expert responses (in length and tone). However, this is likely not aligned with the consumer expectations. LLMs are likely more aligned with consumer expectations, but have a more prominent tendency to hallucinate. We find that adding PubMed evidence to the prompt allows for improved responses from the model. Even without evidence in the prompt, training the model with these prompts produces responses better aligned with the expert. An application of this type of generation could be to draft the answers for experts interacting with consumers, where the expert could also provide the PubMed document.</p><p>Vocabulary differences between consumer and medical expert Analyzing the distinctions between the consumer and medical expert language could verify whether the experts' answers are consumer-friendly. We first analyze diction distinctions between a consumer and a medical expert by training a Random Forest model and analyzing SHapley Additive exPlanation (SHAP) values (Lundberg and Lee, 2017). A highly relevant signal was the grammatical person (we, your, I) and the mention of virus or COVID. The mention of COVID or using the first person was highly indicative of a layperson. In contrast, using the second or third person alongside a more general term such as virus or coronavirus was indicative of an expert.</p><p>We also measured the percentage of medical terminology used between an expert and a consumer. To do this, we used the Medical Subject Headings (MeSH) vocabulary as a proxy for the medical lexicon. We found that 36% of tokens from consumers were medically related, while 35% of tokens from the expert were medically related. This indicates that the lexicon of the consumer and experts are similar regarding medical terminology usage, which suggests that experts may use language that the consumer understands instead of medical jargon. We additionally found that the most common phrases were feels like and see doctor, and references to symptoms (area, duration). Most common words by doctors and consumers' comments were similar and mainly focused on instructions (see a doctor) and prepositions (looks like a benign tumor).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>Consumer question answering in medicine requires real-world questions with expert-verified consumerfriendly answers. We presented MedRedQA, a largescale dataset to facilitate research in this field. We explored ranking and generation tasks for question answering that contemporary neural models struggle with. Empirically, we showed that: (1) for ranking, it is possible to find relevant expert responses within the first five responses with oracle retrieval; and (2) for the generation models, there is potential to generate human-aligned responses given PubMed evidence in the prompt to prevent model hallucination. For future studies, consumeraligned metrics for generation should be explored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>One limitation of our dataset is that it is only in English. However, other datasets of this size exist for other languages, such as in Chinese (Table <ref type="table" target="#tab_0">1</ref>). Other limitations include limited negative sampling and the use of weak supervision over expert gold labels and very sparse training labels (one per question), making the tasks more difficult. This may be remedied by crowdsourcing more data points by labelling the auto-regressive generation output or the ranking candidates produced in second-stage re-ranking.</p><p>Furthermore, the experimented Transformer models are not designed for arbitrarily long sequences of text, which may fail to capture the context of the longer questions.</p><p>A shortcoming of our current study is that, although we experimented with fine-tuning using medical abstracts for expert generation, it is more suitable for a ranking task to retrieve expert evidence from PubMed. However, as an open-ended ranking task, it is difficult to encapsulate the provenance task, as it becomes unclear what the set to be sampled is. Since the set contains 1000 documents, sparsity becomes a larger issue when retrieving from the entire PubMed corpus. Otherwise, ranking over the set of 1000 documents becomes a trivial task. We, therefore, leave these labels in the dataset as exploration for future work.</p><p>Furthermore, we could only use open-access transformer <ref type="bibr" target="#b52">(Vaswani et al., 2017</ref>) models, which may not be state-of-the-art compared to private larger-scale ones such as GPT-3. This can potentially be explored in future work.</p><p>For our metrics, we could not report the harmonic mean of the bi-encoder with the crossencoder as it would require running the crossencoder across the entire corpus for every permutation of data points, which would take many months to complete on our limited hardware.</p><p>Another problem would be that we did not have direct annotation over the dataset. This could leave undesirable answers in the dataset. However, given the voting system, we assume that curt responses are unlikely to be voted highly and by using only expert answers, this may be mitigated enough so as to not be a major concern.</p><p>Finally, measuring user-oriented metrics such as brevity, coherence, and factual correctness for the auto-regressive generated responses is desirable as our metrics do not consider the user's preference. This, however, would require ample resources and cost for annotation and may be suitable for future exploration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics Statement</head><p>This work has received ethics approval from the authors' institutes' ethics committee. We also have approval from /r/askdocs for releasing the dataset and complying with Reddit's terms of service.</p><p>Consumer medical data may contain sensitive information about users. We partially mitigate this problem by removing users who have deleted their post or their accounts and removing posts containing links to images. Furthermore, we paraphrase any examples drawn from the dataset, including in this paper to avoid singling out any individual. We also do not include pseudonyms in the dataset, and require users of the dataset to sign an agreement acknowledging they have received both: (1) ethics approval from their internal review board and (2) have received the Reddit license. In order to allow users to opt out of the dataset, we provide a script to generate the dataset rather than releasing it as a static dataset.</p><p>Our experiments indicate that contemporary neural models cannot replace medical experts regarding advice. Instead, the aim should be to provide recommendations for specialists and provide further reading (through provenance) for the consumer or for drafting responses to consumers from the experts.</p><p>Furthermore, as with data from Reddit, a website where many users can contribute, there is a potential for bias or misinformation when using data from this website. However, the /r/askdocs forum has an effective verification strategy for medical experts and strong moderation, allowing for a higher-than-average quality of questions and answers. However, in times of mass posts such as the pandemic period, there could be potential for questions and answers to be under-moderated.</p><p>In our dataset, there may be triggering questionanswer pairs for some people and we ask users of the dataset to execute caution in this regard. For instance, the most popular post on the /r/askdocs forum is suicide-related.</p><p>We make it clear that the dataset is to be used only for research purposes, as we find current models ill-suited for automatic responses or real-world usage. In the appendix, we produce further experimental details and results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Packages and Experimental Setup</head><p>For dataset analysis, we used the NLTK (Bird and Klein, 2009) library for tokenization and stopword removal. For the experiments, we used the Huggingface Transformers <ref type="bibr" target="#b59">(Wolf et al., 2019)</ref> library for training, evaluating and loading the ranking and generation models. We also use this library for tokenizing the data. Furthermore, all experiments were reported using a fixed seed of 42 for all random initialization or random sampling. We report our experiments for a single run as the primary purpose of the work is to illustrate the feasibility of the task and the usability of the dataset. All experiments (training, evaluation, testing) were conducted on a single Jetson NX Orin 32 GB developer kit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Negative Results</head><p>Universal sentence embedding training and warm-starting of the embedding space As the dataset has sparse training data, we assumed that warm-starting the embedding space with in-domain data before finetuning it with a task similar to the downstream task would produce a better ranking. To do this, we warm-start our embedding space with our curated medical subset of the MS-Marco <ref type="bibr">(Nguyen et al., 2016)</ref> dataset. We then filtered MS-Marco using MetaMap, to ensure indomain training and the model learns how to rank expert answers by relevance rather than semantics.</p><p>After warm-starting, it is beneficial to ensure that the bi-encoder sentence embeddings are universal <ref type="bibr" target="#b39">(Reimers and Gurevych, 2019)</ref>. To do this, we finetuned the PubMEDBERT model on the NLI and STS-B datasets using the settings indicated by the original authors <ref type="bibr" target="#b39">(Reimers and Gurevych, 2019)</ref>. We then use this universal sentence encoder for further finetuning. We train the model with a constant learning rate of 2×10 -5 for 5 epochs and select the best checkpoint based on the validation set. Rather than directly sampling negatives, we opt for a loss function designed for datasets with only positive samples. We use the Multiple Negatives Ranking Loss <ref type="bibr" target="#b14">(Henderson et al., 2017)</ref> which uses in-batch negative sampling. These results are shown in Table 8 and indicate that the baseline model works best.</p><p>We found similar shortcomings with MonoBERT <ref type="bibr" target="#b35">(Nogueira et al., 2019)</ref> when warm-starting, including strong overfitting immediately at the start of training. This is notable given that MonoBERT was pretrained using MS-Marco, indicating that the medical subset of MS-Marco is likely noisy or has reinforced inductive biases in the model that were not useful for the downstream task.</p><p>However, experiments with provenance retrieval reveal that warm-started models were better at retrieving the relevant PubMed abstracts. This reveals there is still merit to warm-starting the embedding space as this aligns better with the data distribution of the layperson questions to PubMed articles rather than layperson to the expert response.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C PubMed annotation C.1 Annotation instructions</head><p>We randomly sampled 10% of examples and annotated 100 examples between 3 annotators of academic backgrounds in biomedical natural language processing. We labeled each example with one of three labels: irrelevant, relevant, or unknown. To assess for relevance, we compared the user's question, and expert response and see if the provided PubMed abstract is relevant. Specifically, the abstract is relevant if it either: (1) addresses the user's information need (contains the user's mentioned disease); (2) explains the expert's diagnosis (contains the mentioned diagnosis); or (3) is used for differential diagnosis (for example, it was provided to rule out the disease the author may have proposed). We did not, however, determine if the PubMed abstract contained the correct diagnosis or prognosis for the individual and only judged the article's relevance from the criteria, as this was outside the area of expertise for the annotators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Annotation results</head><p>We found that 69 out of 100 were deemed relevant, and 3 were considered unknown. Many articles deemed irrelevant were in response to posts about a general topic, for example, a weekly post asking physicians to post articles they found interesting or were a result of a parsing error. For instance, PMIDXXXXXX was unavailable so PM-CXXXXXXX was retrieved instead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Additional Experimental Details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 T5 Prompt Templates</head><p>The following four prompts were used during the training of the T5 models, and were inspired by the Flan prompts<ref type="foot" target="#foot_3">4</ref> :</p><p>1. Provide a response for the question: Question:</p><p>context Answer:</p><p>2. title: user_title question: context answer:</p><formula xml:id="formula_8">3. Q: context A:</formula><p>4. Write a title for the following question: Question: context</p><p>The prompt template was randomly picked from a random uniform distribution for each training example. However, we used a fixed seed of 42 for the random generation for reproducible results. During the generation of validation or test examples, we exclude the fourth prompt template as the response generated would otherwise be a title rather than an expert response. After each prompt, the model is trained to conditionally generate a response to the full prompt, which is the template prompt with the fields filled with a sample from the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Llama and Alpaca Prompt Templates</head><p>We use the following instruction-based prompt for generation based on the following template:</p><p>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.</p><p>### Instruction: Given the following user question and document, provide useful, medical advice, citing evidence from the document where possible.</p><p>### Question: {question} ### Document: {document} ### Response:</p><p>The prompt used is derived from the original Alpaca prompt template but adjusted to suit the current task of producing an expert response given a PubMed abstract and user question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3 Generation Output Examples</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3.1 T5-based generation analysis</head><p>We sample our generated examples based on their mover score. To avoid cherry-picking, we look at the best (Table <ref type="table" target="#tab_10">9</ref>) and worst (Table <ref type="table" target="#tab_11">10</ref>) generations based on their MoverScore, and randomly sample a generation from the final set (Table <ref type="table" target="#tab_12">11</ref>). We consider the Flan T5 model that has been finetuned as it performed the best and find the corresponding generation in the untuned model for comparison.</p><p>In the worst case, we find both the Flan-FT and untuned models output the end-of-sentence token too early for the same input. In the best-performing case, the generated Flan-T5 finetuned model produces an answer more aligned with human experts, whereas the untuned model copied the prescription from the input text. We see this strategy occurring several times in the generation for the untuned model as it falls back to squad-style question answering, where it copies spans from the context as an answer to the question.</p><p>On average, we find that the Flan-T5 model, finetuned or otherwise, recommends the consumer to see a medical specialist. That being said, the untuned model tended to be more verbose and indirect, which was refined after finetuning. This suggests that the model learns to be more direct with its responses during the training process.</p><p>Interestingly, we find it difficult to get T5 to generate longer responses, where it would often generate singular-word responses. However, the LLMs have the opposite problem where they are almost always hitting the generation limit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3.2 LLM-based generation analysis</head><p>Similar to the previous section, we adopt the same sampling strategy to select generation examples. We found that in the worst case, the Alpaca hallucinates immediately when the source document is removed -acting as healthcare customer support, rather than providing answers to the user's question. Llama models tended to act textbook-like in the worst-case scenario, but produce more coherent responses to less difficult questions (Table <ref type="table" target="#tab_13">12</ref>).</p><p>With the source document, we find that Alpaca is more direct in its responses, and can address the user's information need sooner in the generation. Interestingly, we find that alignment between the reference response and the LLM-generated responses is worse (Table <ref type="table" target="#tab_3">13</ref>) when the physician dismisses the user's concerns or questions. We find that LLMs will always address the user's concerns, and in the event that the physician is dismissive, it attempts to ask clarifying questions to better understand the user's intent.</p><p>On average (Table <ref type="table" target="#tab_14">14</ref>), we found that Llama will respond as a third party, whereas Alpaca models tended to speak in the first person. With the document in the prompt, the Alpaca models were more direct and less likely to hallucinate.</p><p>However, in the paper, we find that the metrics do not perfectly align with consumer expectations. We find that MoverScore, is a useful metric for relative importance and ranking. As shown in the Tables, it still describes the best, average and worstcase scenarios.</p><p>Flan FT Prediction It's a good antibiotic. Flan Prediction Prescribed Bactrim DS for bladder infection.</p><p>Reference Bactrim is a very safe and well-tolerated antibiotic.     <ref type="bibr">[Teladoc]</ref>(https://www.teladoc.com/). Teladoc offers 24/7 access to boardcertified physicians who can diagnose, treat, and prescribe medications when medically necessary. You can find more information about Teladoc by visiting their website or calling 1-800-831-6599. We hope this helps! We look forward to continuing the conversation with you.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Alpaca</head><p>Thank you for reaching out to us. We appreciate your interest in our platform and we are happy to help you with your query. The provided document does not contain sufficient information to provide a reliable medical advice. It is important to note that the results presented in the document are based on a small sample size and therefore cannot be generalized to the entire population. Furthermore, it is unclear whether the authors controlled for confounding factors such as age, lifestyle habits, and other environmental factors which could affect the outcome measures.It is recommended that you consult a qualified physician who can conduct a thorough physical examination and review your medical history before providing any medical advice. We hope this helps. Please feel free to reach out to us again if you need more assistance. Best regards, AskDocs Team</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Llama</head><p>The first thing we need to consider is whether the patient is experiencing symptoms related to their heart. If they are, it would be important to rule out other causes such as anxiety, depression, or stress. If these are ruled out, then we should consider the possibility of a cardiac cause.\em{If the patient is experiencing no symptoms, then we could consider the possibility of a cardiac cause. However, it is more likely that the patient is experiencing symptoms related to another condition. For example, the patient may be experiencing symptoms related to anxiety, depression, or stress. It is important to rule out these conditions before considering a cardiac cause.}\em{If the patient is experiencing symptoms related to anxiety, depression, or stress, then we should consider treating those conditions.</p><p>Alpaca FT Thank you for reaching out to us for assistance. Based on the information provided, it appears that your niece may have contracted a type of Human Papillomavirus (HPV) which causes warts. There are many types of HPV, some of which can lead to more serious conditions such as genital warts and cervical cancer. The good news is that most cases of HPV clear up on their own within two years. In terms of treating the wart on the top of her hand, it would be best to consult with a dermatologist. They will be able to assess the wart and determine the best course of action based on its location, size, and appearance. Some dermatologists may choose to use cryotherapy (freezing) to remove the wart, while others may opt for other methods such as laser treatment, electrosurgery, or curettage Alpaca FT w/o Document Dear Aunt, Thank you for reaching out to us for help. Based on your description, it sounds like your niece may be suffering from HPV infection. Human papillomavirus (HPV) is a common virus that can cause warts in various parts of the body including the hands, feet, face, genital area, and mouth. The most common type of HPV that causes warts is called HPV-6 and HPV-11. These types of HPV usually do not cause cancer but can lead to warts. The best way to prevent HPV infection is by getting vaccinated against HPV before becoming sexually active. The HPV vaccine protects against several strains of HPV, including those that cause genital warts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Alpaca</head><p>Dear Customer, Thank you for reaching out to us for assistance. Based on the information provided, it seems like your niece may have multiple warts on her hands and face. The most effective way to treat these warts would be to see a dermatologist as soon as possible. They can assess the condition and determine the best course of action based on the location, size, and type of warts. The dermatologist may use one of several methods to remove the warts including cryotherapy, laser surgery, curettage, electrosurgery, or chemical peels. These procedures are usually done in the office under local anesthesia. Some warts may require more than one procedure to completely eliminate them. It is important to note that warts can recur even after successful removal, especially if the patient does not follow proper hygiene practices. Therefore, it is essential to maintain good personal hygiene</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Llama</head><p>The patient needs to see a dermatologist. The wart is likely a sebaceous cyst. Sebaceous cysts can be treated with surgery, cryotherapy, electrocautery, laser ablation, or liquid nitrogen. The best option would be to remove the cyst. If the cyst is removed, then the patient may need to take antibiotics to prevent infection. ## External links * Official website Reference There are many nonfreezing treatments for warts. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparison of different biomedical consumer QA datasets.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>An example containing a PubMed Reference.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Results for first-stage retrieval experiments. much attention for their fluent well-formed responses<ref type="bibr" target="#b36">(Ouyang et al., 2022)</ref>. Moreover, as the PubMed documents are fewer than 1000, we can use LLMs to compensate for this data scarcity, given that LLMs are a viable option with only a few training data points<ref type="bibr" target="#b23">(Karimi Mahabadi et al., 2022)</ref>. Another benefit is increased model input size over T5 (512 to 1024), which would not otherwise fit the question and PubMed abstract.</figDesc><table><row><cell cols="2">Ranking Facet</cell><cell cols="2">Acc@1000 ↑ HR ↓</cell></row><row><cell>BiEnc</cell><cell>Title</cell><cell>0.1389</cell><cell>785.8</cell></row><row><cell></cell><cell>Body</cell><cell>0.1734</cell><cell>600.1</cell></row><row><cell></cell><cell cols="2">Title+Body 0.1560</cell><cell>628.6</cell></row><row><cell>BM25</cell><cell>Title</cell><cell>0.0890</cell><cell>1332.7</cell></row><row><cell></cell><cell>Body</cell><cell>0.0675</cell><cell>1548.2</cell></row><row><cell></cell><cell cols="2">Title+Body 0.0588</cell><cell>1597.1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Second stage re-ranking of candidate answers. Oracle refers to evaluating the subset of query-answer retrieved that is known to have a relevant answer. *The Harmonic Mean Rank of BiEnc + CE is undefined as the BiEnc had topics that did not retrieve a relevant answer; we estimate the cross-encoder will perform at least as well as the bi-encoder.</figDesc><table><row><cell>Ranking</cell><cell cols="3">Acc@1 ↑ Acc@10 ↑ HR ↓</cell></row><row><cell>BM25 (Title)</cell><cell>0.0000</cell><cell>0.0002</cell><cell>1333</cell></row><row><cell>BiEnc (Body)</cell><cell>0.0002</cell><cell>0.0014</cell><cell>600.1</cell></row><row><cell>BiEnc + CE</cell><cell>0.0633</cell><cell>0.1018</cell><cell>*27.13</cell></row><row><cell cols="2">BiEnc + CE (Oracle) 0.3654</cell><cell>0.5791</cell><cell>4.174</cell></row><row><cell></cell><cell cols="2">MoverScore ↑ Rouge-1</cell><cell></cell></row><row><cell>Pretrained</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Flan</cell><cell cols="3">0.501 ± 0.053 0.075 ± 0.081</cell></row><row><cell>T5-Large</cell><cell cols="3">0.479 ± 0.030 0.039 ± 0.060</cell></row><row><cell>Finetuned</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Flan</cell><cell cols="3">0.507 ± 0.064 0.096 ± 0.01</cell></row><row><cell>T5-Large</cell><cell cols="3">0.499 ± 0.032 0.094 ± 0.10</cell></row><row><cell cols="4">Flan+PubmedQA 0.504 ± 0.053 0.096 ± 0.01</cell></row><row><cell>T5-Large-1.1</cell><cell cols="3">0.502 ± 0.035 0.096 ± 0.10</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Generation of experts answers task using the T5-based models.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Generation of experts answers task with the PubMed document in the prompt.</figDesc><table><row><cell></cell><cell>MoverScore ↑ Rouge-1</cell></row><row><cell>Zero-shot</cell><cell></cell></row><row><cell>Llama</cell><cell>0.509 ± 0.017 0.141 ± 0.075</cell></row><row><cell>Alpaca</cell><cell>0.515 ± 0.018 0.164 ± 0.087</cell></row><row><cell>Finetuned</cell><cell></cell></row><row><cell>Llama</cell><cell>0.505 ± 0.019 0.133 ± 0.073</cell></row><row><cell>Alpaca</cell><cell>0.516 ± 0.016 0.164 ± 0.088</cell></row><row><cell></cell><cell>MoverScore ↑ Rouge-1</cell></row><row><cell>Zero-shot</cell><cell></cell></row><row><cell>Llama</cell><cell>0.510 ± 0.019 0.143 ± 0.087</cell></row><row><cell>Alpaca</cell><cell>0.517 ± 0.016 0.168 ± 0.095</cell></row><row><cell>Finetuned</cell><cell></cell></row><row><cell>Llama</cell><cell>0.506 ± 0.014 0.117 ± 0.075</cell></row><row><cell>Alpaca</cell><cell>0.518 ± 0.015 0.172 ± 0.093</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>Generation of experts answers task. There is no PubMed document in the prompt, however, the finetuned models are still finetuned with documents in the prompt.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 :</head><label>8</label><figDesc>Negative results indicating that NLI (universal sentence embeddings) and warm-starting the embedding space lead to worse results for ranking.</figDesc><table><row><cell>Facet Acc@1000 ↑ HR ↓</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9 :</head><label>9</label><figDesc>Best performing generation examples based on MoverScore. Reference here is the expert response to the user's question. Sweat, dirt, and dead skin cells block the pores and infect them.I'd know better if I could examine you, but is the affected area around the boil turning red and getting hard to the touch? It looks like there is cellulitis present as well (or if it's not there it's coming). \n\nYou need antibiotics pronto. You should also use antibacterial soap and let your breasts hang fee as much as you can. Go get antibiotics for MRSA (methicillin resistant staph aureus) as soon as possible. This can get really bad quickly.</figDesc><table><row><cell cols="2">Flan FT Prediction Consider</cell></row><row><cell>Flan</cell><cell>Prediction summer</cell></row><row><cell></cell><cell>Reference It's just a boil.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 10 :</head><label>10</label><figDesc>Worst performing generations based on MoverScore.</figDesc><table><row><cell cols="2">Flan FT Prediction You need to see a doctor.</cell></row><row><cell>Flan</cell><cell>Prediction I think you're right. Stress and anxiety can cause a variety of symptoms. It</cell></row><row><cell></cell><cell>can also cause other health problems. You should seek medical attention if you</cell></row><row><cell></cell><cell>have any of these symptoms."</cell></row><row><cell></cell><cell>Reference Were you educated about HSV after your diagnosis? Stress manifests in all</cell></row><row><cell></cell><cell>different ways for different people. You could make an appointment to speak</cell></row><row><cell></cell><cell>about your concerns with your new diagnosis. Im sure there's a community on</cell></row><row><cell></cell><cell>Reddit who have all gone through what you are now. Just breathe. You'll get</cell></row><row><cell></cell><cell>through it and learn how to live with it.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 11 :</head><label>11</label><figDesc>Randomly sampled from the typical distribution i.e. average case generations.Alpaca Finetuned(FT)   Thank you for your question. It is important to note that there is currently no conclusive evidence that the Gardasil vaccination can prevent the development of cervical cancer. The vaccine protects against four high-risk human papillomavirus (HPV) types that are responsible for approximately 70% of cervical cancers. However, it does not protect against all types of HPV, including those that cause genital warts. Therefore, even after receiving the Gardasil vaccine, it is still possible to develop genital warts. It is important to note that the strains of HPV that cause genital warts are different from the ones that cause cervical cancer. In fact, most people who get genital warts do not go on to develop cervical cancer.Alpaca FT w/o Document Dear [user], Thank you for reaching out to us for assistance. We are sorry to hear about your concerns regarding your health. It is important to note that there is no direct correlation between the Gardasil vaccination and the development of plantar warts. The Gardasil vaccine protects against four high risk human papillomavirus (HPV) types which can lead to cervical cancer. These include HPV types 6, 11, 16, and 18. Plantar warts are caused by different types of HPV, namely HPV type 17. Therefore, it is unlikely that the Gardasil vaccine would have prevented the development of plantar warts. It is important to note that the Gardasil vaccine does not protect against all types of HPV.AlpacaThank you for reaching out to us! It sounds like you have a lot going on and we want to help you navigate through your concerns. Firstly, let's start with the basics. The Gardasil vaccine protects against certain strains of Human Papillomavirus (HPV). These strains can cause cervical cancer, genital warts, and other health issues. The vaccine does not prevent all strains of HPV, however, it does reduce the risk of developing these conditions. It is important to note that even if you were exposed to HPV before receiving the vaccine, it does not mean that the vaccine did not work. In fact, the vaccine works best when given before exposure to HPV.LlamaThe answer is yes, you probably have HPV. You can get tested for HPV through your primary care physician. If you test positive for HPV, then you need to get a Pap smear every six months until you are done having children. If you test negative for HPV, then you don't need to get a Pap smear anymore. ## External links * Official websiteReferenceThe Gardasil vaccine is formulated to protect first and foremost against the strains of HPV that cause cervical cancer. More recent version of the vaccine have included more of the strains that just cause warts, but it doesn't protect against every strain of HPV. Having genital warts doesn't mean that your Gardasil vaccine didn't work. There is no need for you to be getting Pap smears any more frequently than is normally suggested.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 12 :</head><label>12</label><figDesc>Best performing generation example based on MoverScore (Alpaca FT) and the baseline counterpart. Alpaca FT Thank you for reaching out to us. We appreciate your interest in our platform and we are happy to help you with your query. The provided document does not contain sufficient information to provide a proper medical advice. It would be helpful if you could share more details about your symptoms, such as the type of pain, its location, duration, severity, associated symptoms, and any other relevant information. Also, it would be beneficial to know your age, gender, and any past medical history. We recommend that you consult a doctor for a thorough evaluation and diagnosis of your condition. They will be able to determine the cause of your pain and suggest appropriate treatment options based on your individual needs. Please note that we are not a medical facility and cannot provide medical advice or diagnose conditions over the internet. If you need immediate assistance, please call 911 or visit your nearest emergency room. Best wishes for a speedy recovery. Alpaca FT w/o Document Hello there, thank you for reaching out to us. We appreciate your interest in learning more about medicine and healthcare. As a community-based platform, we encourage open dialogue between members and medical professionals. However, due to HIPAA regulations, we cannot provide personalized medical advice without having access to your full medical history. If you would like to receive personalized medical advice, please consider scheduling an appointment with a doctor through our partner telemedicine service,</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 14 :</head><label>14</label><figDesc>Average randomly sampled generations and the baseline counterpart.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>To preserve user anonymity, the dataset will be made available through a script to download the data.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>pubmed.ncbi.nlm.nih.gov magnitude, have different latent distributions between the training -testing distributions(Nguyen  et al., 2019), and have assumptions that reduce the difficulty of the consumer biomedical QA task (such as how users ask questions) or do not provide consumer-understandable answers.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Preliminary tests show that sampling or beam search do not have much of an effect on the MoverScore</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>https://github.com/google-research/FLAN/blob/ main/flan/templates.py</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Recognizing Question Entailment for Medical Question Answering</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Abacha</surname></persName>
		</author>
		<author>
			<persName><surname>Demner-Fushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Medical Informatics Association Annual Symposium Proceedings</title>
		<imprint>
			<biblScope unit="page" from="310" to="318" />
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Improvements that don&apos;t add up: Ad-hoc retrieval results since 1998</title>
		<author>
			<persName><forename type="first">T</forename><surname>Armstrong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Webber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
		<idno type="DOI">10.1145/1645953.1646031</idno>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<meeting><address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="601" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Comparing Physician and Artificial Intelligence Chatbot Responses to Patient Questions Posted to a Public Social Media Forum</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">W</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Poliak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">C</forename><surname>Leas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zechariah</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessica</forename><forename type="middle">B</forename><surname>Kelley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dennis</forename><forename type="middle">J</forename><surname>Faix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><forename type="middle">M</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">A</forename><surname>Longhurst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Hogarth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Davey</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1001/jamainternmed.2023.1838</idno>
	</analytic>
	<monogr>
		<title level="j">JAMA Internal Medicine</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">BioReddit: Word embeddings for user-generated biomedical NLP</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Basaldella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nigel</forename><surname>Collier</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-6205</idno>
	</analytic>
	<monogr>
		<title level="m">LOUHI</title>
		<meeting><address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="34" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On the summarization of consumer health questions</title>
		<author>
			<persName><forename type="first">Asma</forename><surname>Ben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abacha</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Dina</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1215</idno>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<meeting><address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2228" to="2234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">A question-entailment approach to question answering</title>
		<author>
			<persName><forename type="first">Asma</forename><surname>Ben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abacha</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Dina</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<idno>CoRR, abs/1901.08079</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Overview of the MEDIQA 2019 shared task on textual inference, question entailment and question answering</title>
		<author>
			<persName><forename type="first">Asma</forename><surname>Ben Abacha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaitanya</forename><surname>Shivade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dina</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W19-5039</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th BioNLP Workshop and Shared Task</title>
		<meeting>the 18th BioNLP Workshop and Shared Task<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="370" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bird</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Ewan</forename><surname>Klein</surname></persName>
		</author>
		<ptr target="http://www.nltk.org/" />
		<title level="m">Natural language processing with python</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Scaling instruction-finetuned language models</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melanie</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gretchen</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clemens</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><surname>Amodei ; Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shayne</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunxuan</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddhartha</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Brahma</surname></persName>
		</author>
		<author>
			<persName><surname>Webson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shane</forename><surname>Shixiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuyun</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirac</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyun</forename><surname>Suzgun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanping</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongkun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Slav</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><surname>Wei</surname></persName>
		</author>
		<idno>CoRR, abs/2210.11416</idno>
	</analytic>
	<monogr>
		<title level="m">Hyung Won Chung</title>
		<editor>
			<persName><forename type="first">Marie</forename><surname>Pellat</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kevin</forename><surname>Robinson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Dasha</forename><surname>Valter</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Gaurav</forename><surname>Mishra</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Adams</forename><surname>Yu</surname></persName>
		</editor>
		<imprint>
			<publisher>Alex Castro-Ros</publisher>
			<date type="published" when="2020">2020. 2022</date>
		</imprint>
	</monogr>
	<note>Language models are few-shot learners</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dr Google in the ED: searching for online health information by adult emergency department patients</title>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Cocco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Zordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tracey</forename><surname>Weiland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stuart</forename><surname>Dilley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joyce</forename><surname>Kant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahesha</forename><surname>Dombagolla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Hendarto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fiona</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennie</forename><surname>Hutton</surname></persName>
		</author>
		<idno type="DOI">10.5694/mja17.00889</idno>
	</analytic>
	<monogr>
		<title level="j">The Medical Journal of Australia</title>
		<imprint>
			<biblScope unit="volume">209</biblScope>
			<biblScope unit="page" from="342" to="347" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Consumer health information and question answering: helping consumers find answers to their health-related information needs</title>
		<author>
			<persName><forename type="first">Dina</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yassine</forename><surname>Mrabet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asma</forename><surname>Ben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abacha</forename></persName>
		</author>
		<idno type="DOI">10.1093/jamia/ocz152</idno>
	</analytic>
	<monogr>
		<title level="j">JAMIA</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">31592532</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>pmid</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Online misinformation and vaccine hesitancy</title>
		<author>
			<persName><forename type="first">Renee</forename><surname>Garett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><forename type="middle">D</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transl. Behav. Med</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2194" to="2199" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Do patients understand?</title>
		<author>
			<persName><forename type="first">Suzanne</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Brookey</surname></persName>
		</author>
		<idno type="DOI">10.7812/tpp/07-144</idno>
	</analytic>
	<monogr>
		<title level="j">The Permanente journal</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="67" to="69" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Domain-specific language model pretraining for biomedical natural language processing</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Tinn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naoto</forename><surname>Usuyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Naumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
		<idno type="DOI">10.1145/3458754</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Comput. Healthcare</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Efficient natural language response suggestion for smart reply</title>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zora</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Icml</surname></persName>
		</author>
		<author>
			<persName><surname>Online</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rami</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun-Hsuan</forename><surname>Strope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">László</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiqi</forename><surname>Lukács</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjiv</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Balint</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ray</forename><surname>Miklos</surname></persName>
		</author>
		<author>
			<persName><surname>Kurzweil</surname></persName>
		</author>
		<idno type="DOI">10.5555/3524938.3525306</idno>
		<idno>CoRR, abs/1705.00652</idno>
		<imprint>
			<date type="published" when="2017">2020. 2017</date>
		</imprint>
	</monogr>
	<note>Realm: Retrievalaugmented language model pre-training</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The curious case of neural text degeneration</title>
		<author>
			<persName><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Lora: Low-rank adaptation of large language models</title>
		<author>
			<persName><forename type="first">Edward</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Wallis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeyuan</forename><surname>Allen-Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<idno>CoRR, abs/2106.09685</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The anti-vaccination movement: A regression in modern medicine</title>
		<author>
			<persName><forename type="first">Azhar</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Syed</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madiha</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheharyar</forename><surname>Hussain</surname></persName>
		</author>
		<idno type="DOI">10.7759/cureus.2919</idno>
		<idno type="PMCID">PMC6122668</idno>
	</analytic>
	<monogr>
		<title level="j">Cureus</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2919" to="e2919" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>pmcid</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The distribution of the flora in the alpine zone.1</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Jaccard</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1469-8137.1912.tb05611.x</idno>
	</analytic>
	<monogr>
		<title level="j">New Phytologist</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="37" to="50" />
			<date type="published" when="1912">1912</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Health card retrieval for consumer health search: An empirical investigation of methods</title>
		<author>
			<persName><forename type="first">Guido</forename><surname>Jimmy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bevan</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gianluca</forename><surname>Koopman</surname></persName>
		</author>
		<author>
			<persName><surname>Demartini</surname></persName>
		</author>
		<idno type="DOI">10.1145/3357384.3358128</idno>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2405" to="2408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">PubMedQA: A dataset for biomedical research question answering</title>
		<author>
			<persName><forename type="first">Qiao</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengping</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinghua</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1259</idno>
	</analytic>
	<monogr>
		<title level="m">EMNLP-IJCNLP</title>
		<meeting><address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2567" to="2577" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">MIMIC-III, a freely accessible critical care database</title>
		<author>
			<persName><forename type="first">Alistair</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li-Wei</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengling</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><surname>Mark</surname></persName>
		</author>
		<idno type="DOI">10.1038/sdata.2016.35</idno>
	</analytic>
	<monogr>
		<title level="j">Scientific Data</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">160035</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Susceptibility to misinformation about covid-19 around the world</title>
		<author>
			<persName><forename type="first">Roozenbeek</forename><surname>Jon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudia</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dryhurst</forename><surname>Sarah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kerr</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Freeman</forename><surname>Alexandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Recchia</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anne</forename><surname>Van Der Bles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Van</forename><surname>Marthe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linden</forename><surname>Der</surname></persName>
		</author>
		<author>
			<persName><surname>Sander</surname></persName>
		</author>
		<idno type="DOI">10.1098/rsos.201199</idno>
	</analytic>
	<monogr>
		<title level="j">R. Soc. Open. Sci</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Promptfree and efficient few-shot learning with language models</title>
		<author>
			<persName><forename type="first">Rabeeh</forename><surname>Karimi Mahabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lambert</forename><surname>Mathias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marzieh</forename><surname>Saeidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Majid</forename><surname>Yazdani</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.254</idno>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="3638" to="3652" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Results of the 4th edition of BioASQ challenge</title>
		<author>
			<persName><forename type="first">Anastasia</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasios</forename><surname>Nentidis</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W16-3101</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth BioASQ workshop</title>
		<meeting>the Fourth BioASQ workshop<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
	<note>Georgios Paliouras, and Ioannis Kakadiaris</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Internetaugmented language models through few-shot prompting for open-domain question answering</title>
		<author>
			<persName><forename type="first">Bridget</forename><forename type="middle">M</forename><surname>Kuehn</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2203.05115</idno>
		<idno>CoRR, abs/2203.05115</idno>
	</analytic>
	<monogr>
		<title level="j">American Medical Association</title>
		<editor>
			<persName><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Elena</forename><surname>Gribovskaya</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Wojciech</forename><surname>Stokowiec</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nikolai</forename><surname>Grigorev</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">309</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="756" to="757" />
			<date type="published" when="2013">2013. 2022</date>
		</imprint>
	</monogr>
	<note>More Than One-Third of US Individuals Use the Internet to Self-diagnose</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">ROUGE: A package for automatic evaluation of summaries</title>
		<author>
			<persName><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning</title>
		<author>
			<persName><forename type="first">Haokun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammed</forename><surname>Muqeeth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Mohta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tenghao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><forename type="middle">A</forename><surname>Raf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1950" to="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">What makes good in-context examples for GPT-3?</title>
		<author>
			<persName><forename type="first">Jiachang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dinghan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Carin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.deelio-1.10</idno>
	</analytic>
	<monogr>
		<title level="m">The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures</title>
		<meeting><address><addrLine>Dublin, Ireland and Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022. DeeLIO 2022</date>
			<biblScope unit="page" from="100" to="114" />
		</imprint>
	</monogr>
	<note>Proceedings of Deep Learning Inside Out</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Decoupled Weight Decay Regularization</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A unified approach to interpreting model predictions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Su-In</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="4765" to="4774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Memory-assisted prompt editing to improve GPT-3 after deployment</title>
		<author>
			<persName><forename type="first">Aman</forename><surname>Madaan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niket</forename><surname>Tandon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<meeting><address><addrLine>Abu Dhabi, United Arab Emirates</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2833" to="2861" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName><surname>Ncbi</surname></persName>
		</author>
		<ptr target="https://pubmed.ncbi.nlm.nih.gov/" />
		<imprint>
			<date type="published" when="2023-01">2023. Jan-2023</date>
			<biblScope unit="volume">20</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The danger of misinformation in the COVID-19 crisis</title>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicole</forename><surname>Kagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Critchlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Hillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mo. Med</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="510" to="512" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">covid-19 queries</title>
		<idno type="DOI">10.1016/j.jbi.2022.104005</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="page">104005</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno>CoRR, abs/1910.14424</idno>
		<title level="m">Multi-stage document ranking with BERT</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Training language models to follow instructions with human feedback</title>
		<author>
			<persName><forename type="first">Long</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diogo</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carroll</forename><forename type="middle">L</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katarina</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fraser</forename><surname>Kelton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maddie</forename><surname>Simens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Christiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Leike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<idno>CoRR, abs/2203.02155</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Chansung</forename><surname>Park</surname></persName>
		</author>
		<ptr target="https://huggingface.co/chansung/gpt4-alpaca-lora-7b" />
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="4" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">140</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Sentence-BERT: Sentence embeddings using Siamese BERTnetworks</title>
		<author>
			<persName><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1410</idno>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<meeting><address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3982" to="3992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Overview of the TREC 2017 Precision Medicine track</title>
		<author>
			<persName><forename type="first">Kirk</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dina</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Lazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shubham</forename><surname>Pant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TREC</title>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Overview of the TREC 2020 Precision Medicine Track</title>
		<author>
			<persName><forename type="first">Kirk</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dina</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TREC</title>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Overview of the TREC 2018 Precision Medicine Track</title>
		<author>
			<persName><forename type="first">Kirk</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dina</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Lazar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TREC</title>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Overview of the TREC 2019 Precision Medicine Track</title>
		<author>
			<persName><forename type="first">Kirk</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dina</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Lazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shubham</forename><surname>Pant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Funda</forename><surname>Meric-Bernstam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TREC</title>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">State-ofthe-art in biomedical literature retrieval for clinical cases: A survey of the TREC 2014 CDS track</title>
		<author>
			<persName><forename type="first">Kirk</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dina</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Hersh</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10791-015-9259-x</idno>
	</analytic>
	<monogr>
		<title level="j">Inf Retr</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="113" to="148" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Overview of the TREC 2015 clinical decision support track</title>
		<author>
			<persName><forename type="first">Kirk</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TREC</title>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Okapi at TREC-3</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Micheline</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Gatford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TREC</title>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Adafactor: Adaptive learning rates with sublinear memory cost</title>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitchell</forename><surname>Stern</surname></persName>
		</author>
		<idno>CoRR, abs/1804.04235</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Mednli -a natural language inference dataset for the clinical domain</title>
		<author>
			<persName><forename type="first">Chaitanya</forename><surname>Shivade</surname></persName>
		</author>
		<idno type="DOI">10.13026/C2RS98</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>version 1.0.0. PhysioNet</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<author>
			<persName><forename type="first">Rohan</forename><surname>Taori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuechen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsunori</forename><forename type="middle">B</forename><surname>Hashimoto</surname></persName>
		</author>
		<ptr target="https://github.com/tatsu-lab/stanford_alpaca" />
		<title level="m">Stanford alpaca: An instruction-following llama model</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">ChiMed: A Chinese medical corpus for question answering</title>
		<author>
			<persName><forename type="first">Yuanhe</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weicheng</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Song</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W19-5027</idno>
		<idno>CoRR, abs/2302.13971</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th BioNLP Workshop and Shared Task</title>
		<editor>
			<persName><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thibaut</forename><surname>Lavril</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Xavier</forename><surname>Martinet</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Timothée</forename><surname>Lacroix</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Baptiste</forename><surname>Rozière</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Eric</forename><surname>Hambro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Faisal</forename><surname>Azhar</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Aurelien</forename><surname>Rodriguez</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</editor>
		<meeting>the 18th BioNLP Workshop and Shared Task<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019. 2023</date>
			<biblScope unit="page" from="250" to="260" />
		</imprint>
	</monogr>
	<note>Llama: Open and efficient foundation language models</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Sanne Van Hees, and Birgitte Schoenmakers. 2017. The effect of dr google on doctor-patient encounters in primary care: a quantitative, observational, cross-sectional study</title>
		<author>
			<persName><forename type="first">Noor</forename><surname>Van Riel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koen</forename><surname>Auwerx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieterjan</forename><surname>Debbaut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BJGP Open</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="17X" to="100833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">TREC-COVID: Constructing a pandemic information retrieval test collection</title>
		<author>
			<persName><forename type="first">Ellen</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alam</forename><surname>Tasmeer</surname></persName>
		</author>
		<author>
			<persName><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hersh</forename><surname>Dina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName><surname>Lo</surname></persName>
		</author>
		<idno type="DOI">10.1145/3451964.3451965</idno>
	</analytic>
	<monogr>
		<title level="j">ACM SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Overview of the TREC 2012 medical records track</title>
		<author>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TREC</title>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Redhot: A corpus of annotated medical questions, experiences, and claims on social media</title>
		<author>
			<persName><forename type="first">Somin</forename><surname>Wadhwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvio</forename><surname>Vivek Khetan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Byron</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName><surname>Wallace</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL: Findings</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">BERT-based dense retrievers require interpolation with bm25 for effective passage retrieval</title>
		<author>
			<persName><forename type="first">Shuai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengyao</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guido</forename><surname>Zuccon</surname></persName>
		</author>
		<idno type="DOI">10.1145/3471158.3472233</idno>
	</analytic>
	<monogr>
		<title level="m">ICTIR</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="317" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Finetuned language models are zero-shot learners</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<editor>ICLR, Online</editor>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Answering factoid questions in the biomedical domain</title>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Weißenborn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Tsatsaronis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Schroeder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">1094</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">HuggingFace&apos;s Transformers: State-of-the-art Natural Language Processing</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Remi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Brew</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.03771</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">From neural re-ranking to neural ranking: Learning a sparse representation for inverted indexing</title>
		<author>
			<persName><forename type="first">Hamed</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Learned-Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaap</forename><surname>Kamps</surname></persName>
		</author>
		<idno type="DOI">10.1145/3269206.3271800</idno>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<meeting><address><addrLine>Torino, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="497" to="506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Multi-scale attentive interaction networks for chinese medical question answer selection</title>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lixiang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shanshan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2018.2883637</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="74061" to="74071" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Moverscore: Text generation evaluating with contextualized embeddings and earth mover distance</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxime</forename><surname>Peyrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><forename type="middle">M</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Eger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<meeting><address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Question answering with long multiple-span answers</title>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aman</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Da-Cheng</forename><surname>Juan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandan</forename><forename type="middle">K</forename><surname>Reddy</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.342</idno>
	</analytic>
	<monogr>
		<title level="m">EMNLP (Findings)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3840" to="3849" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Worst performing generation example (Alpaca FT) based on MoverScore and the baseline counterpart</title>
	</analytic>
	<monogr>
		<title level="j">Table</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
