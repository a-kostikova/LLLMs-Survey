<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">IndIE: A Multilingual Open Information Extraction Tool For Indic Languages</title>
				<funder ref="#_ZqAK6yn">
					<orgName type="full">Infosys Center for AI</orgName>
				</funder>
				<funder>
					<orgName type="full">Center of Excellence in Healthcare at IIIT Delhi</orgName>
				</funder>
				<funder>
					<orgName type="full">Center of Design and New Media</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ritwik</forename><surname>Mishra</surname></persName>
							<email>ritwikm@iiitd.ac.in</email>
						</author>
						<author>
							<persName><forename type="first">Simranjeet</forename><surname>Singh</surname></persName>
							<email>simranjeets.ec18@nsut.ac.in</email>
						</author>
						<author>
							<persName><forename type="first">Rajiv</forename><forename type="middle">Ratn</forename><surname>Shah</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ponnurangam</forename><surname>Kumaraguru</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Pushpak</forename><surname>Bhattacharyya</surname></persName>
						</author>
						<author>
							<persName><surname>Iiit</surname></persName>
						</author>
						<author>
							<persName><surname>Delhi</surname></persName>
						</author>
						<author>
							<persName><surname>Nsut</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Iiit</forename><surname>Hyderabad</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Iit</forename><surname>Bombay</surname></persName>
						</author>
						<title level="a" type="main">IndIE: A Multilingual Open Information Extraction Tool For Indic Languages</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">535C72700533AE493AEEA2213B6AE096</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-05-29T13:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Open Information Extraction (OIE) is the process of extracting informative facts from opendomain natural language text. A multilingual OIE tool, IndIE, has been proposed, which performs chunking, creates a Merged-phrase Dependency Tree (MDT), and generates triples using hand-crafted rules. It is observed that fine-tuned transformer-based chunker outperforms other traditional methods of chunking. A benchmark called Hindi-BenchIE has also been developed for automatically evaluating Hindi triples. The developed OIE tool, IndIE, has been automatically evaluated on the goldentriples of 112 Hindi sentences. Compared to other multilingual methods, the IndIE method generates more meaningful triples with 0.51 F1-score. It is observed that IndIE generates more fine-grained triples than other methods. It is conjectured that IndIE has the ability to generate meaningful triples for Urdu, Tamil, and Telugu sentences as well because the developed chunker is shown to generalize across various natural languages, and the triple generation rules are based on dependency relations that are common to the aforementioned Indic languages.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>India is a linguistically diverse country. Among the top 20 most spoken languages globally, six are native to India <ref type="bibr">(eth, 2021; cen, 2011)</ref>. Despite being spoken by billions of people, many Indic languages are considered low-resource due to the lack of annotated resources and automated systems available for them <ref type="bibr" target="#b25">(Hirschberg and Manning, 2015)</ref>. Consequently, there has also been a scarcity of tools for information extraction in Indian languages due to a lack of research work in the field <ref type="bibr" target="#b23">(Gupta et al., 2019;</ref><ref type="bibr" target="#b24">Harish and Rangan, 2020)</ref>.</p><p>Introduced in the mid-1960s, the concept of Information Extraction (IE) deals with extracting structured facts from unstructured text written in a natural language <ref type="bibr" target="#b47">(WILKS, 1964)</ref>. Extraction of informative facts irrespective of the text domain is called Open Information Extraction (OIE). A standard convention to represent facts is through triples &lt;head, relation, tail&gt; where relation denotes the link between the two entities, head and tail. For example, consider the sentence "PM Modi to visit UAE in Jan marking 50 yrs of diplomatic ties", one of the possible meaningful triple would be &lt;PM Modi, to visit, UAE&gt;.</p><p>The biggest strength of OIE tools is their ability to extract triples from large amounts of texts in an unsupervised manner <ref type="bibr" target="#b19">(Gamallo et al., 2012)</ref>. OIE also serves as an initial step in building or augmenting a knowledge graph out of an unstructured text <ref type="bibr" target="#b34">(Muhammad et al., 2020;</ref><ref type="bibr" target="#b29">Lin et al., 2020)</ref>.</p><p>A triple can be extracted in many different ways depending on the word-order constraints in the given natural language and the expected level of detail in the triples. Consider the sentence, John sliced an apple with a knife. Two possible ways to extract facts from this sentence are: (i) &lt;John, sliced, an apple with a knife&gt; (ii) &lt;John, sliced, an apple&gt;, and &lt;John, sliced, with a knife&gt;. Both ways represent the same fact but with different levels of detail. In the case of languages with free word order, like Hindi <ref type="bibr" target="#b32">(Mohanan, 1994)</ref>, one fact can be represented by many permutations of the elements of a triple. For example, both the following triples &lt; , , e º&gt; [&lt;rAm ne, khAya, ek seb&gt;]<ref type="foot" target="#foot_0">1</ref> and &lt;e º, , &gt; [&lt;ek seb, khAya, rAm ne&gt;] represents the same information as the following English triple: &lt;Ram, ate, an apple&gt;. However, since the Hindi language uses postpositions (kaarak) instead of prepositions <ref type="bibr" target="#b35">(Nagendra, 2019)</ref>, those word permutations are prohibited that detach the postposition word from its intended subject word because the meaning of the triple changes. For example, the following triple &lt;e º, , &gt; [&lt;ek seb, ne khAya, rAm&gt;] conveys that &lt;An apple, ate, Ram&gt;.</p><p>Our work is primarily focused on automatically extracting triples from Hindi sentences since all the authors of this work are familiar with the language. However, the proposed tool can extract triples from other low-resource Indic languages such as Tamil, Telugu, and Urdu. The main contributions of this paper are as follows:</p><p>1. We create and release an OIE benchmark dataset for Hindi sentences, Hindi-BenchIE, to facilitate the automatic evaluation of machinegenerated triples. To our knowledge, it is the first benchmark that can handle the free-word order nature of Hindi and diverse triple extractions from different OIE systems.</p><p>2. We fine-tune a transformer model on manually annotated chunks from six natural languages (Hindi, English, Urdu, Nepali, Gujarati, and Bengali). The resulting model is able to perform chunking on languages it has not seen during the fine-tuning phase.</p><p>3. In our research, we also observed that when fine-tuning a pretrained encoder for sequence labeling tasks like chunking, taking an average of subword embeddings or taking the last subword embedding consistently outperformed the traditional way of taking the first subword embedding.</p><p>4. We propose a greedy algorithm to extract triples from Hindi text. All the resources and source code will be publicly available on https://github.com/ritwikmishra/IndIE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Earlier works have used a combination of shallow parsing and hand-crafted rules to extract meaningful entities from English language text <ref type="bibr">(Mohanty et al., 2005;</ref><ref type="bibr" target="#b14">Etzioni et al., 2008;</ref><ref type="bibr" target="#b7">Christensen et al., 2011;</ref><ref type="bibr" target="#b15">Fader et al., 2011)</ref>. <ref type="bibr" target="#b30">Mausam et al. (2012)</ref> used hand-crafted rules and dependency parsing to develop OLLIE, which captured relations mediated by non-verbal phrases like "is the president of " extracted triples from English sentences. OLLIE was found to be performing at par with an SRL-based triple extractor. While most of the works dealt with extracting facts in the form of triples, KrakeN was developed to extract facts as N-ary tuples using dependency parsing <ref type="bibr" target="#b1">(Akbik and Löser, 2012)</ref>. One drawback of earlier rule-based OIE methodologies was their strictly extractive nature, i.e., triples could contain only those explicitly mentioned words in the sentence. Hence, appositive relationships 2 were not extracted by such tools <ref type="bibr" target="#b49">(Zhan and Zhao, 2020)</ref>.</p><p>The method we used to extract such appositive relationships is discussed in section 3.3. Del Corro and Gemulla (2013) developed ClausIE, which identified clauses in an English sentence and then extracted facts by classifying the identified clauses using rules. In order to identify the relations or entities, dependency parsing of sentences was a crucial step in ClausIE and many other works <ref type="bibr" target="#b46">(White et al., 2016;</ref><ref type="bibr" target="#b50">Zhang et al., 2018;</ref><ref type="bibr" target="#b19">Gamallo et al., 2012;</ref><ref type="bibr" target="#b18">Gamallo and Garcia, 2015)</ref>. Built as an improvement to ClausIE, the MinIE <ref type="bibr" target="#b20">(Gashteovski et al., 2017)</ref> tool generated much more fine-grained and concise facts as compared to ClausIE. The triples generated by MinIE had dictionary-like attributes containing information about certainty, polarity, and knowledge source. Due to the availability of manually annotated data for the English, much of the recent OIE research is based on deep neural architectures where the triple extraction problem is divided into the following two sub-problems: (a) Relation extraction and (b) Argument (head/tail) extraction using features from the extracted relation <ref type="bibr" target="#b39">(Ro et al., 2020)</ref>. Span selection (using sequence labeling paradigm) is a common practice to extract relations and their corresponding arguments in such OIE methods <ref type="bibr" target="#b49">(Zhan and Zhao, 2020)</ref>.</p><p>The development of OIE tools for languages other than English is impeded by the need for annotated resources available for them. However, the field of language-independent (multilingual) OIE started in 2015 with two methods. The first method was developed by Manaal and Kumar (M&amp;K) <ref type="bibr" target="#b16">(Faruqui and Kumar, 2015)</ref>, where the authors translated the source language to English using Google translate and then extracted triples using the OLLIE tool. The English triples were projected back to their source language through word alignments. It could handle as many languages as Google can translate, but machine translation has not been regarded as a sustainable solution for OIE 2 It is a grammatical construction where two noun phrases are written adjacent to each other to convey additional information. For example: My brother, Bob, likes ice cream due to translation errors <ref type="bibr" target="#b8">(Claro et al., 2019)</ref>. The second method was a rule-based triple extractor called ArgOE <ref type="bibr" target="#b18">(Gamallo and Garcia, 2015)</ref>. In order to generate triples, it expects dependency parse of a sentence in CoNLL format as input. However, the extracted triples contain only verb-mediated relations. PredPatt (White et al., 2016) was developed a year later, which also relied on a dependency parse tree and hand-crafted rules to identify predicate-argument structure in a sentence. Another work called Multi2OIE modeled the problem of identifying predicate-argument structure through two sequence-labeling tasks using mBERT embeddings and multi-head attention blocks <ref type="bibr" target="#b39">(Ro et al., 2020)</ref>. The first task identified all the predicates in a sentence, and the second task identified all arguments associated with each predicate. One limitation in identifying predicates with the sequence labeling paradigm is its inability to identify overlapping predicates. For example, consider the following sentence "Nehru became the prime minister of India in 1947". Depending on the level of detail (granularity) in triples, two predicates that can be extracted among numerous possible predicates are "became" and "became the prime minister". <ref type="bibr" target="#b27">Kolluru et al. (2022)</ref> introduced a novel approach to multilingual Open Information Extraction that leverages Natural Language Generation (NLG) techniques and cross-lingual projections. Their method is capable of extracting overlapping relations (predicates) and triple arguments. However, their proposed AACTrans algorithm required parallel corpora for training, and they utilized off-theshelf translation systems in their experiments. In order to compare the performance of IndIE, we have taken the five methods mentioned above (M&amp;K, Ar-gOE, PredPatt, Multi2OIE, and Gen2OIE) as our baselines since they are on similar lines as that of our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>Our method takes raw text as input and uses the Stanza library <ref type="bibr" target="#b38">(Qi et al., 2020)</ref> (version 1.1.1) to perform sentence segmentation and dependency parsing. The primary motivation behind using the Stanza library was its ability to perform shallow parsing on multiple Indic languages. Figure <ref type="figure" target="#fig_0">1</ref> describes the overall procedure of generating triples. It is divided into the following three primary steps: (a) performing chunking and identifying the semantic phrases in the given sentence, (b) creating a Merged-phrases Dependency Tree using the dependency parse tree, and (c) generating triples through our hand-crafted rules. In the following subsections, we discuss the three steps in a more detailed manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Chunking</head><p>The process of chunking can be defined by capturing non-overlapping multi-word entities in a sentence and classifying them into different syntactic phrases <ref type="bibr" target="#b44">(Tjong Kim Sang and Buchholz, 2000)</ref>. Chunking is modeled as a sequence labeling task where one chunk tag is predicted for every token of the given sentence. Each chunk tag consists of (i) a boundary label and (ii) a chunk label. The chunk labels can be classified into different syntactic categories, like Noun-Phrases (NP), Verb-Phrases (VP), Adjective-Phrases (JJP), etc. <ref type="bibr" target="#b3">(Bharati et al., 2006)</ref>. Whereas different notations, like BIO or BIOES, can be used to represent the non-overlapping boundary labels. We use BI notation to mark boundary labels because earlier works have shown its superior precision over other notations <ref type="bibr" target="#b42">(Singh et al., 2005;</ref><ref type="bibr" target="#b41">Sharma et al., 2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Dataset</head><p>We develop a multilingual chunking tool by finetuning a pre-trained transformer on multilingual chunk annotated data. Our chunker is fine-tuned on chunk annotated sentences from Jha (2010)<ref type="foot" target="#foot_1">3</ref> and Bhat et al. ( <ref type="formula">2017</ref>) <ref type="foot" target="#foot_2">4</ref> . The former data source comprises 70K chunk-labelled sentences in English, Hindi, Bengali, Nepali, and Gujarati each, whereas the latter data source consists of 16K and 5K chunk-labelled sentences in Hindi and Urdu, respectively. The primary motivation behind using two data sources is to have a large amount of fine-tuning data. The two data sources gave us 0.37 million chunk annotated sentences in total.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Model</head><p>Using transformers library <ref type="bibr" target="#b48">(Wolf et al., 2020)</ref>, we fine-tune different pretrained transformer-based models for the task of chunking because earlier works have shown their superior ability to perform well on shallow parsing tasks <ref type="bibr" target="#b45">(Tran et al., 2020;</ref><ref type="bibr" target="#b13">Doostmohammadi et al., 2020;</ref><ref type="bibr" target="#b28">Li et al., 2021)</ref>. The word embeddings are obtained by taking an unweighted average of all its subword embeddings. To compare the performance of a transformer-based chunker, we train a Conditional Random Field (CRF) model using the scikit-learn <ref type="bibr" target="#b36">(Pedregosa et al., 2011)</ref> library. We also implemented a secondorder Hidden Markov Model (HMM) with Viterbi decoding to predict the chunk tags. Both the models are the traditional methods used for chunking in Indic languages <ref type="bibr" target="#b2">(Bharati and Mannem, 2007)</ref>. Appendix B contains the implementation details for the baseline models.</p><p>A given text is parsed by the Stanza library <ref type="bibr" target="#b38">(Qi et al., 2020)</ref>, which performs sentence segmentation, POS tagging, and dependency parsing. Each segmented sentence is passed to our chunker, which predicts the chunk tags for each token. The predicted chunk tags identify the non-overlapping phrases (or multi-word expressions). A syntactically rich phrase is constructed by concatenating all the attributes of its member tokens. Each phrase is stored in a list in order of its appearance in the sentence. The list of phrases is then passed to the next step, which creates the Merged-phrases Dependency Tree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Merged-phrases Dependency Tree (MDT)</head><p>Dependency trees have been used extensively in OIE to aid in the generation of triples from raw text <ref type="bibr" target="#b46">(White et al., 2016;</ref><ref type="bibr" target="#b50">Zhang et al., 2018;</ref><ref type="bibr" target="#b19">Gamallo et al., 2012;</ref><ref type="bibr" target="#b18">Gamallo and Garcia, 2015;</ref><ref type="bibr" target="#b10">Del Corro and Gemulla, 2013)</ref>. A traditional dependency tree is constructed at a token level, i.e., the leaves of the tree are the tokens present in the sentence, and the edges connecting them represent the dependency relation between the two tokens. A Mergedphrases Dependency Tree (MDT) is a coarse tree where each node contains a phrase or a multi-word expression from the sentence. An online tool by explosion.ai<ref type="foot" target="#foot_3">5</ref> illustrates the difference very well. One head is identified in each phrase (similar to Dobrovolskii ( <ref type="formula">2021</ref>)), and the dependency relation between two heads is used as the dependency relation between the two corresponding phrases. The token-level dependency tree serves as a guiding tool to identify the dependency relationships between the identified phrases. Figure <ref type="figure" target="#fig_1">2</ref> illustrates the comparison between a traditional dependency tree and a generated MDT using an example of a Hindi sentence. It differs from a constituency tree as it does not conserve the syntactic relationships between the head and the rest of the tokens in each phrase. To the best of our knowledge, there is no publicly available tool for either constituency tree parsing or MDT parsing of sentences in Indic languages. Therefore, we developed a rule-based method to generate MDT from a traditional dependency tree.</p><p>The phenomenon of Complex Predicates (CPs) is common in Hindi, where a single action is represented by a noun-verb combination (called conjunct verbs) or a verb-verb combination (called compound verbs) <ref type="bibr" target="#b6">(Burton-Page, 1957;</ref><ref type="bibr" target="#b17">Fatma, 2018)</ref>. An MDT proves to be more useful in representing a sentence where the traditional dependency tree fails to parse CPs in languages like Hindi. For example, consider the sentence pr Ú º hm Ú Ú</p><p>[prarambhik khagolvido ka mAn-na tha ki prithvi brahm-And ke kendr me hae] (Early astronomers believed that Earth is in the center of the universe), where the action of believed is represented by the Hindi compound verb [mAn-na tha]. In the token-level dependency tree of this sentence, the following parent → child structure is generated:</p><p>[tha] (past-tense-inflection) nsubj ---→ [mAn-na] (to believe), which is incorrect; the correct structure would be [mAnna] (to believe) aux --→ [tha] (past-tense-inflection). A chunker identifies compound verbs as a single Verb Phrase, thus generating a meaningful MDT. It has also been observed that, without a Multi-word Entity Recognition tool, identification of triple arguments becomes difficult by using dependency parsing alone <ref type="bibr" target="#b19">(Gamallo et al., 2012)</ref>. <ref type="bibr" target="#b22">Gulordava and Merlo (2016)</ref> also have shown that the performance of a dependency parser degrades for natural languages having free word-order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Triple generation</head><p>We use hand-crafted rules for capturing the head, relation, and tail from the MDT of a sentence. Similar to <ref type="bibr" target="#b31">Mesquita et al. (2013)</ref>, our hand-crafted rules are constructed by studying all the possible dependency relations in Hindi<ref type="foot" target="#foot_4">6</ref> . The rules are developed by carefully analyzing 80 different Hindi sentences, covering 26 out of 27 possible dependency relations in Hindi. One dependency relation that is not covered in our chosen Hindi sentences is vocative. Since it occurs only in 6 out of 16K dependency-annotated sentences in the data by <ref type="bibr" target="#b5">Bhat et al. (2017)</ref>, we observed that the Stanza dependency parsing tool fails to predict vocative relation in Hindi. In the dependency annotated data<ref type="foot" target="#foot_5">7</ref> of Tamil, Telugu, and Urdu, the percentage of nodes that are connected to their parents using a Hindi dependency relation are 96%, 98%, and nearly 100%, respectively. Hence, the authors are of the opinion that triple extraction rules based on Hindi dependency relations have wide coverage and could find their applicability in other Indic languages.</p><p>In the final set of rules, there are more than 100 decision-making statements (such as if-else). Therefore, we will not be explaining all the triple extraction rules here for the sake of brevity. Appendix E contains an abstracted algorithm illustrating the triple extraction procedure.</p><p>One novel property of our hand-crafted rules is their ability to capture appositive relationships between two entities. Earlier multilingual meth-ods were unable to capture such appositive relationships. For example, in the sentence, º a dm r [sharmila taegore ke bete saef ali khAn ko mila padm shri puraskAr] (Son of Sharmila Tagore, Saif Ali Khan, was awarded Padma Shri), there exists an appositive is-a relationship between Saif Ali Khan and Son of Sharmila Tagore. Our system captures such appositive relationships that are expressed by nominal modifier (nmod) and appositional modifier (appos) dependency relation in the MDT. Our method selects the parent of these relations as &lt;head&gt;, and the child as &lt;tail&gt; of the triple. <ref type="bibr" target="#b31">Mesquita et al. (2013)</ref> used the English auxiliary verb 'be' to represent the &lt;relation&gt; for appositive relationships in English. We used the Hindi auxiliary verb [hae] (is/be) to denote the &lt;relation&gt; of a triple that contains an appositive relationship in a Hindi sentence. The overall dataflow of the proposed architecture is illustrated in Appendix A using an example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Triple Evaluation</head><p>The quality of generated triples is generally evaluated by getting them annotated by native speakers of that language. However, the procedure is time and cost intensive. Moreover, the lack of availability of Indic language annotators creates a hurdle in the manual evaluation process. On the other hand, automatic evaluation methods based on gold annotations (like CaRB <ref type="bibr" target="#b4">(Bhardwaj et al., 2019)</ref>) do not consider the fact that there can be multiple ways to extract meaningful triples. Therefore, extending a work titled BenchIE <ref type="bibr" target="#b21">(Gashteovski et al., 2021)</ref>, we developed an automatic evaluation method, Hindi-BenchIE, based on multiple gold annotations to evaluate Hindi triples generated by any OIE tool.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hindi-BenchIE</head><p>A natural language sentence is generally composed of one or more facts. In the original work of BenchIE <ref type="bibr" target="#b21">(Gashteovski et al., 2021)</ref>, multiple triples were written manually (called golden triples) to represent a single fact of the sentence. In our proposed benchmark, Hindi-BenchIE, we extend the BenchIE notations by introducing the following two subcategories of golden triples: (a) essentialtriples and (b) compensatory-triples. An essentialtriple is a triple that contains all the information needed to represent a fact. There might be some phrases in an essential-triple without which the rest of the triple remains meaningful. We term such phrases as vulnerable-phrases in this work. However, an ideal OIE benchmark should ensure that no information is lost in the automatically generated triples. Moreover, if any information is lost, then the given OIE methodology should be penalized for it. Therefore, a compensatory-triple contains the information that is lost in the absence of a vulnerable-phrase in the generated triple. Moreover, Hindi-BenchIE supports the interchangeability of head and tail in a triple since Hindi is a free word-order language. These modifications facilitate annotation, as manually extracting triples for free word-order languages would otherwise require significant human effort.</p><p>In order to differentiate apposition relationships, we use an explicit keyword named 'property' as a relation. In this work, a single-annotator manually extracted golden-triples for 112 Hindi sentences in different clusters. We release 8 the manually extracted triples for Hindi sentences since such resources are scarce in the field of multilingual OIE <ref type="bibr" target="#b8">(Claro et al., 2019)</ref>.</p><p>The number of True Positives and False Positives is calculated over all the golden-triples of the corresponding sentence (much like the BenchIE). In our work, False Negatives are calculated as the number of missing essential-triples, and the number of missing compensatory-triples that corresponds to a missing vulnerable-phrase (if any).</p><p>8 https://github.com/ritwikmishra/hindi-benchie</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>In order to compare our fine-tuned chunker with other traditional methods, we divided the chunk annotated data into training-set and test-set in a 50:50 ratio. We observed that the overall accuracy of our fine-tuned xlm-roberta-base <ref type="bibr" target="#b9">(Conneau et al., 2020)</ref> chunker (91%) was superior to the other baselines of CRF (84%) and HMM (12%). The low performance on HMM is due to the sparsity in the emission matrix because of Out Of Vocabulary (OOV) words. Over multiple random splits, we observed that more than 80% of the test-set word bigrams were absent in the HMM training set. Due to the poor performance of HMM, we decided to use only the CRF for further comparisons. To test our chunker's multilingual nature, we curated language-specific test-sets and removed them from the training-set. This approach aligns with the principles of Leave One Language Out (LOLO) strategy, a technique documented in prior research <ref type="bibr">(Ahuja et al., 2022;</ref><ref type="bibr" target="#b43">Srinivasan et al., 2021)</ref>. Compared to CRF, the transformer-based chunker gave better accuracy on the languages it had never seen during the learning or fine-tuning phase. Table <ref type="table" target="#tab_0">1</ref> compares our fine-tuned chunker and CRF chunker.</p><p>We also observed that a single linear layer and an unweighted average of subword embeddings gave the best chunking accuracy. It is important to note, however, that employing subword embedding averaging introduces a temporal overhead into the chunking process. As an alternative to the unweighted average, we observed that taking the last subword embedding is consistently better than the the conventional approach of taking the first subword embedding, a practice suggested by <ref type="bibr" target="#b11">(Devlin et al., 2018)</ref> for Named Entity Recognition (NER) task, which is similar to chunking as both are sequence labeling tasks. For a comprehensive presentation of the results derived from our chunker ablation studies, please refer to Appendix C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">IndIE vs Others</head><p>To compare the performance of our triple extractor (IndIE), we used the following five baselines: (i) M&amp;K <ref type="bibr" target="#b16">(Faruqui and Kumar, 2015)</ref>, (ii) ArgOE <ref type="bibr" target="#b18">(Gamallo and Garcia, 2015)</ref>, (iii) PredPatt (White et al., 2016), (iv) Multi2OIE <ref type="bibr" target="#b39">(Ro et al., 2020)</ref>, and (v) Gen2OIE <ref type="bibr" target="#b27">(Kolluru et al., 2022)</ref> , because of their multilingual nature. The source code for M&amp;K is not publicly available, but the authors have released a dataset of sentences and the corresponding triples generated by their method 9 . We randomly sampled sentences from M&amp;K to create the Hindi-BenchIE benchmark. We used a fixed seed in order to make the random sampling reproducible.</p><p>It is essential to convey here that PredPatt is not designed as a triple extractor. The output generated by the method resembles an entity extractor. Appendix D shows the output of PredPatt on a Hindi sentence and the rules we developed to convert PredPatt output to triples format.</p><p>Our method, IndIE, performs better than other methods on Hindi-BenchIE golden set. Table <ref type="table" target="#tab_1">2</ref> compares different OIE methods' performance. In this metric, failing to generate any triple on a given sentence penalizes the recall value of that method. In such cases, the smallest number of essentialtriples are added to the False Negatives while calculating the recall. The overall results indicate that our proposed method, IndIE, extracted more meaningful triples from Hindi sentences than other 9 https://www.kaggle.com/shankkumar/ multilingualopenrelations15 multilingual OIE tools.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>Motivated by qualitative observations, Table <ref type="table">presents</ref> quantitative insights about the generated triples from various methods. We observed that methods such as ArgOE and PredPatt generated more coarse triples than other methods. Coarse triples have a high sentence coverage percentage. They identify the root action in the sentence, and the remaining text is placed in the argument of triple. For example, for the following sentence 007 pt pr d eя º Ú a я Ú । [007 ke nAm se prasidha yeh Ejant phleming ki bArah pustakon va do laghukathaon me maaujUd hae] (Renowned by the name of 007, this agent appears in twelve books and two short stories by Fleming.). The triple extracted by ArgOE is as follows: &lt;007 pt pr d eя , , º Ú a я Ú&gt; [&lt;007 ke nAm se prasidha yeh Ejant, hae, phleming ki bArah pustakon va do laghukathaon me maaujUd&gt;] (&lt;Renowned by the name of 007 this agent, is, present in twelve books and two short stories by Fleming&gt;). Fine-grained triples are essential for downstream tasks, such as creating a knowledge-base from raw text <ref type="bibr" target="#b51">(Zhang et al., 2021)</ref>, whereas coarse triples could result in overspecific relations or entities.</p><p>The yield of triples by Gen2OIE method is better than other methods. However, since the source code of M&amp;K is unavailable, we cannot determine the number of sentences for which the method returns no triples. Since M&amp;K and Gen2OIE method generates triples in English and then uses word alignments to obtain Hindi triples, they often generate non-meaningful Hindi triples because the incorrect word alignments separate the postpositional word (kaarak) from its preceding word. As a result, more triples are generated with misplaced kaarak. For example, for the given sentence яº ky a e Ê । [jab koi mataekya nahin hua to vikram ne ek hal sochA] (When there was no consensus, Vikram thought of a solution.), the Gen2OIE method generated a triple as &lt; , Ê , e &gt; [&lt;vikram, sochA, ne ek hal&gt;] (Ungrammatical). Similar to Gen2OIE, the IndIE can generate overlapped arguments in the extracted triples. For instance, the two triples generated for the following sentence Ú a  i r tt u । [main shabd ki Atma samajhkar hee is shreshth tatv ki upAsna karta hun] (I worship this supreme element after understanding the soul of the word.) are as follows &lt; ,u ,i r tt &gt; [&lt;main, upAsna karta hun, is shrestha tatv ki&gt;] (&lt;I, worship, this supreme element&gt;) and &lt;i r tt u , ,a &gt; [&lt;is shreshtha tatv ki upAsna karta hoon, samajhkar hee, Atma&gt;] (&lt;worship this supreme element, after understanding, soul&gt;).</p><p>In our experiments, the zero-shot Multi2OIE method performs poorly on every metric, which is expected since neural methods are known to generate incorrect facts as compared to rule-based methods <ref type="bibr" target="#b21">(Gashteovski et al., 2021)</ref>. Therefore, a promising direction is to train a neural OIE method based on the output of a rule-based OIE tool for a given language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Limitations</head><p>The utilization of hand-crafted rules in the triple extraction process imposes constraints on the scalability and versatility of the IndIE pipeline. Furthermore, while we provide a rationale supporting the potential application of the IndIE tool to other Indic languages, we encountered challenges in creating a benchmark akin to Hindi-BenchIE due to a scarcity of annotators for these languages. Consequently, the performance of IndIE on other Indic languages remains a matter of conjecture. The number of sentences in our automatic evalua-tion benchmark, Hindi-BenchIE, is much smaller than the original work of BenchIE. Since manually generating triples requires more effort than triple annotation, the single-annotator of Hindi-BenchIE was able to generate more than 500 triples for 112 Hindi sentences only. Hence, we believe that the benchmark can be further refined with the efforts of the Indic-nlp community. We also acknowledge the fact that the multilingual nature of IndIE is limited to the intersection between the set of languages on which xlm-roberta-base has been pretrained and the set of languages supported by the Stanza library.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>The low resource nature of Indic languages has been an impediment in the development of their NLP tools. In this work, we developed an Open Information Extraction (OIE) tool, IndIE, that generates triples from unstructured Hindi sentences. It first predicts the chunk tags for the given sentence and then creates a Merged-Phrase Dependency Tree (MDT) to generate the triples using the hand-crafted rules. We used a multilingual pretrained transformer model and fine-tuned it with chunk annotated sentences from English and five Indic languages. It was observed that, in sequence labeling tasks (such as chunking), taking the average of subword token embeddings is more valuable than other paradigms. We created Hindi-BenchIE, a benchmark for automatically evaluating Hindi triples based on a set of 112 Hindi sentences to compare the performance of various multilingual OIE tools. It was observed that the IndIE generates more informative and fine-grained triples than other baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Future Work</head><p>We plan to explore different methods to merge the fine-grained triples to make them more informative. Further linguistic efforts are needed to analyze and capture the appositive relationships in Agglutinative Indic languages such as Tamil and Telugu. Expanding the golden triples in Hindi-BenchIE and developing similar benchmarks for other Indic languages is also an important direction to keep the field of OIE in Indic languages alive. Co-reference resolution is an important area to explore to generate more meaningful triples with resolved pronominal references. Moreover, the viability of OIEbased approaches needs to be explored where the length of input text sequence exceeds the capability of transformer-based models, like open-domain Question-Answering and document-level textual similarity.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Chunking Baselines</head><p>We used the scikit-learn scikit-learn python library to implement<ref type="foot" target="#foot_6">10</ref> the CRF model. The following features were used for each word of the sentence: (a) bias ← 1.0, (b) word text, (c) POS tag of the word, (d) POS tags of preceding two words, and (e) POS tags of succeeding two words. The values of L1 and L2 regularization were obtained through grid search. We used the word text and its POS tag as features for the HMM model.</p><p>Our fine-tuned chunker is an end-to-end model for chunking because it takes input in raw text. However, CRF and HMM model expects already POS tagged sentences. The chunk annotated sentences from the Bhat et al. ( <ref type="formula">2017</ref>) are POS tagged in upos format <ref type="bibr" target="#b37">(Petrov et al., 2012)</ref>, whereas sentences from the Jha (2010) are POS tagged with a scheme called AnnCorra <ref type="bibr" target="#b3">(Bharati et al., 2006)</ref>. It is an extension to the Penn tagset and tailored for Indian languages. In the absence of a publicly available POS tagger for AnnCorra, we created a mapping from AnnCorra to upos tagset for standardizing the POS tags in the entire dataset. We passed all the Hindi and English sentences from the (?) dataset through Stanza library, generating POS tags in upos format. Therefore, we create a mapping from AnnCorra (Penn tagset) to upos tagset which helped us in standardizing the POS tag format across all sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Chunking Ablation</head><p>We experimented with three approaches to handle sub-word token embeddings and observed that averaging sub-word token embeddings gave better accuracy as compared to the first sub-word token embedding or last sub-word token embedding, as shown in Table <ref type="table" target="#tab_5">5</ref>. Since averaging the sub-word token embeddings requires additional processing, its fine-tuning time (6 hours/epoch) and inference time (29 milliseconds/sentence) is more than finetuning time (45 minutes/epoch) and inference time (17 milliseconds/sentence) for the other two approaches. Hence, if accuracy is preferred over inference time, then we recommend taking an average of sub-word token embeddings for a sequence labeling task; otherwise simply taking the last subword token embedding gives better performance with equal inference time than the traditional technique of taking the first sub-word token embedding.</p><p>In our experiments, we used the embeddings from last_hidden_state of the model. However, since some methods in the literature suggest that early layers of a transformer are responsible for learning shallow features of the text <ref type="bibr" target="#b40">(Rogers et al., 2020)</ref>, we experimented by taking average embeddings of the first two hidden layers of the model as well. It turns out that using embeddings from early layers actually decreased the accuracy (86%) for the chunking task. Confirming the findings of Jain et al. <ref type="bibr" target="#b26">(Jain et al., 2020)</ref>, we observed that xlmroberta-base <ref type="bibr" target="#b9">(Conneau et al., 2020)</ref> gave the best accuracy (92%) over other pretrained models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D PredPatt</head><p>Figure <ref type="figure" target="#fig_4">4</ref> shows the output of PredPatt on a Hindi sentence. Table <ref type="table">6</ref> contains the rules we developed to convert PredPatt output to triples format. º tt pr kt [abhrak Adi ki khAno me mombattiya bhi prayukt hoti hae] (In the mines of Mica candles are also used). In the given sentence, candles is the Entity1, and it is represented with '?a' notation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Algorithm</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classification Layers</head><p>First sub-word token embedding</p><p>Last sub-word token embedding</p><p>Average embedding of all sub-word tokens 1 82±10 (50±20) 89±0.5 (62±1.0) 91±0.0 (65±0.5) 2 86±1.8 (51±6.2) 89±0.5 (54±7.4) 90±0.5 (54±4.5) 3 79±14 (43±13) 82±11 (41±12) 90±0.5 (48±2.2) Any other sentence structure Discard</p><p>Table <ref type="table">6</ref>: The rules we used to extract triples from PredPatt output. Considering the sentence given in Figure <ref type="figure" target="#fig_4">4</ref>, Rule number 1 is applied to the sentence. The symbol ^indicates the start of the sentence, and the symbol $ indicates the end of the sentence.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overall architecture of the IndIE tool. The three primary steps are (a) Chunk tag prediction, (b) Creating Merged-phrases Dependency Tree (MDT), and (c) Triple generation. The three steps are run for each sentence segmented by the Stanza library (Qi et al., 2020).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A comparison between a traditional dependency tree (left) and a Merged-phrases Dependency Tree (right) for the given Hindi sentence: i ( я : 17 Ê 1990 ) º Ú । [saina nehwAl ( janm 17 mArch 1990 ) bhArtiye badminton khilAri hae] which translates to Saina Nehwal ( born:17 March 1990) is (an) Indian badminton player . where predicted chunk labels are Noun Phrase (NP) , Verb Phrase (VP) , and Miscellaneous (BLK)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The generated MDTs after sentence segmentation, chunking, and dependency parsing of the following raw text: º a 2010 dm r । e a । [sharmila taegor ke bete saef ali khAn ko 2010 me padm shri puraskAr mila. veh ek bhArtiye abhinetA hae] (Son of Sharmila Tagore, Saif Ali Khan, was awarded with Padma Shri award in 2010. He is an Indian actor).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>[</head><label></label><figDesc>padm shri puraskAr] (Padma Shri award)}_NP , { [mila] (awarded)}_VGF Sentence 2 -{ [veh] (He)}_NP , {e a [ek bhArtiye abhinetA] (an Indian actor)}_NP , { [hae] (is)}_VGF The chunked phrases and dependency tree for each sentence are passed to the stage (b) of the architecture to construct MDT for sentence. Figure 3 illustrates the MDTs generated at the output of stage (b). For each sentence, triples are generated using its corresponding MDT and our hand-crafted rules. All the triples extracted by the IndIE tool for the aforementioned raw text are shown in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Output of PredPatt on a Hindi sentence a a Úº tt pr kt [abhrak Adi ki khAno me mombattiya bhi prayukt hoti hae] (In the mines of Mica candles are also used). In the given sentence, candles is the Entity1, and it is represented with '?a' notation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>A comparison of (fine-tuned) XLM chunker and CRF chunker on the languages which are removed from training-set. The numbers represent the accuracy obtained by each model when sentences from the given language are used only in the test-set. We observe that XLM chunker always perform better on unseen languages.</figDesc><table><row><cell cols="7">Model Hindi English Urdu Nepali Gujarati Bengali</cell></row><row><cell>XLM</cell><cell>78%</cell><cell>60%</cell><cell cols="2">84% 65%</cell><cell>56%</cell><cell>66%</cell></row><row><cell>CRF</cell><cell>67%</cell><cell>56%</cell><cell>71%</cell><cell>58%</cell><cell>53%</cell><cell>53%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Performance of different OIE methods on Hindi-BenchIE golden set. It is observed that IndIE outperforms other methods on the Hindi-BenchIE golden set.</figDesc><table><row><cell></cell><cell cols="6">ArgOE M&amp;K Multi2OIE PredPatt Gen2OIE IndIE</cell></row><row><cell>Precision</cell><cell>0.17</cell><cell>0.07</cell><cell>0.005</cell><cell>0.22</cell><cell>0.23</cell><cell>0.49</cell></row><row><cell>Recall</cell><cell>0.04</cell><cell>0.08</cell><cell>0.01</cell><cell>0.05</cell><cell>0.35</cell><cell>0.53</cell></row><row><cell>F1-score</cell><cell>0.07</cell><cell>0.08</cell><cell>0.008</cell><cell>0.09</cell><cell>0.28</cell><cell>0.51</cell></row><row><cell></cell><cell></cell><cell cols="6">ArgOE M&amp;K Multi2OIE PredPatt Gen2OIE IndIE</cell></row><row><cell># Triples</cell><cell></cell><cell>51</cell><cell>199</cell><cell>59</cell><cell>48</cell><cell>278</cell><cell>277</cell></row><row><cell cols="2"># Sentences with no triples</cell><cell>69</cell><cell>NA</cell><cell>68</cell><cell>66</cell><cell>0</cell><cell>2</cell></row><row><cell cols="2">Avg. Tokens in a Triple</cell><cell>12</cell><cell>10</cell><cell>7</cell><cell>12</cell><cell>10</cell><cell>7</cell></row><row><cell cols="2">Avg. Sentence Coverage of a Triple</cell><cell>73%</cell><cell>64%</cell><cell>49%</cell><cell>76%</cell><cell>66%</cell><cell>46%</cell></row><row><cell cols="2">Triples with misplaced kaarak</cell><cell>1.9%</cell><cell>44%</cell><cell>20%</cell><cell>39%</cell><cell>16%</cell><cell>0.7%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Triple statistics of different OIE methods on Hindi-BenchIE golden set of 112 sentences. Non-unique tokens are considered while counting the number of tokens in a triple. Sentence coverage is calculated by 1 -|unique(sent) -unique(triple)|/|unique(sent)| . It can be observed that IndIE triples have the least sentence coverage and kaarak errors. Hence, IndIE generates more fine-grained triples than other methods.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>The output of stage (c) consists of the following three types: (i) a list of segmented sentences, (ii) extracted triples, and (iii) execution time for each sentence.</figDesc><table><row><cell></cell><cell>&lt;head&gt;</cell><cell>&lt;relation&gt;</cell><cell cols="2">&lt;tail&gt;</cell></row><row><cell></cell><cell>dm r</cell><cell></cell><cell>a</cell></row><row><cell></cell><cell>[padm shri puraskAr]</cell><cell>[mila]</cell><cell cols="2">[saef ali khAn ko]</cell></row><row><cell></cell><cell>(Padma Shri award)</cell><cell>(awarded)</cell><cell cols="2">(to Saif Ali Khan)</cell></row><row><cell>Sentence 1</cell><cell>2010 [2010 me]</cell><cell>[mila]</cell><cell cols="2">dm r [padm shri puraskAr]</cell></row><row><cell></cell><cell>(in 2010)</cell><cell>(awarded)</cell><cell cols="2">(Padma Shri award)</cell></row><row><cell></cell><cell>a</cell><cell></cell><cell>º</cell></row><row><cell></cell><cell>[saef ali khAn ko]</cell><cell>[hae]</cell><cell cols="2">[bete]</cell></row><row><cell></cell><cell>(to Saif Ali Khan)</cell><cell>(is)</cell><cell>(son)</cell></row><row><cell></cell><cell>º</cell><cell></cell><cell></cell></row><row><cell></cell><cell>[bete]</cell><cell>[hae]</cell><cell cols="2">[sharmila taegore ke]</cell></row><row><cell></cell><cell>(son)</cell><cell>(is)</cell><cell cols="2">(Sharmila Tagore's)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>e</cell><cell>a</cell></row><row><cell>Sentence 2</cell><cell>[veh]</cell><cell>[hae]</cell><cell cols="2">[ek bhArtiye abhinetA]</cell></row><row><cell></cell><cell>(He)</cell><cell>(is)</cell><cell cols="2">(an Indian actor)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell cols="4">: Triples extracted through hand-crafted rules</cell></row><row><cell cols="4">of the proposed IndIE tool for the following raw text</cell></row><row><cell>in Hindi:</cell><cell>º</cell><cell></cell><cell>a</cell></row><row><cell>2010</cell><cell>dm r</cell><cell>।</cell><cell>e</cell></row><row><cell>a</cell><cell cols="3">। [sharmila taegor ke bete saef ali khAn</cell></row><row><cell cols="4">ko 2020 me padm shri puraskAr mila. veh ek bhArtiye</cell></row><row><cell cols="4">abhinetA hae] (Son of Sharmila Tagore, Saif Ali Khan,</cell></row><row><cell cols="4">was awarded with Padma Shri award in 2010. He is an</cell></row><row><cell cols="2">Indian actor).</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>A comparison of three approaches for solving the sub-word token embeddings for chunking task. Four different random seeds were used to calculate the mean and standard deviation for the given samples. All the experiments were run on the combined data of Jha et al.(Jha, 2010)  and<ref type="bibr" target="#b5">Bhat et al.(Bhat et al., 2017)</ref>. The numbers written outside round brackets represent the accuracy, whereas numbers inside round brackets represent the macro average.</figDesc><table><row><cell>Rule No.</cell><cell>Sentence Structure</cell><cell>Extracted Triple</cell></row><row><cell>1</cell><cell>^phrase1 Entity1 phrase2 $</cell><cell>&lt;phrase1 , phrase2 , Entity1&gt;</cell></row><row><cell></cell><cell>^Entity1 phrase1 Entity2 phrase2 $</cell><cell></cell></row><row><cell>2</cell><cell>^Entity1 Entity2 phrase1 $ ^phrase1 Entity1 Entity2 $</cell><cell>&lt;Entity1 , phrase1 , Entity2&gt;</cell></row><row><cell></cell><cell>^Entity1 phrase1 Entity2 $</cell><cell></cell></row><row><cell></cell><cell>^phrase1 Entity1 Entity2 phrase2 $</cell><cell></cell></row><row><cell>3</cell><cell>^phrase1 Entity1 phrase2 Entity2 $</cell><cell>&lt;Entity1 , phrase2 , Entity2&gt;</cell></row><row><cell></cell><cell>^phrase1 Entity1 phrase2 Entity2 phrase3 $</cell><cell></cell></row><row><cell>4</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Italicized text written in square brackets represents the ITRANS transliteration, whereas the italicized text in round brackets represents the English translation of the preceding Hindi phrase/sentence</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>from http://tdil-dc.in</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>from https://universaldependencies.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>https://explosion.ai/demos/displacy/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>https://universaldependencies.org/ treebanks/hi_hdtb/index.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5"><p>from https://universaldependencies.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_6"><p>https://sklearn-crfsuite.readthedocs. io/en/latest/tutorial.html</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>Ritwik Mishra wishes to extend his appreciation to the <rs type="institution">University Grant Commission (UGC) of India</rs> for their partial support through the <rs type="grantName">UGC Junior Research Fellowship (JRF) program</rs>. He would also like to express his gratitude to <rs type="institution">ACM-India</rs> for his selection as a recipient of the Anveshan-Setu fellowship and for assigning <rs type="person">Prof. Pushpak Bhattacharya</rs> as his mentor. <rs type="person">Rajiv Ratn Shah</rs> is partly supported by the <rs type="funder">Infosys Center for AI</rs>, the <rs type="funder">Center of Design and New Media</rs>, and the <rs type="funder">Center of Excellence in Healthcare at IIIT Delhi</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_ZqAK6yn">
					<orgName type="grant-name">UGC Junior Research Fellowship (JRF) program</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Illustration</head><p>The overall dataflow of the proposed architecture is illustrated using the following raw (multi-sentence) text in Hindi: º a 2010 dm r । e a । [sharmila taegor ke bete saef ali khAn ko 2010 me padm shri puraskAr mila. veh ek bhArtiye abhinetA hae] (Son of Sharmila Tagore, Saif Ali Khan, was awarded with Padma Shri award in 2010. He is an Indian actor). The raw text is fed to the Stanza library for sentence segmentation and dependency parsing of each sentence. In stage (a) of the architecture, as shown in Figure <ref type="figure">1</ref>, segmented sentences are passed to the chunking model to predict the chunk tags for each word of the given sentence. Predicted chunked phrases from the stage (a) are as follows: Head ← q.T ail + q.Rel where (q ∈ Q ∧ t.parent ∈ q) 12:</p><p>Rel, T ail ← t , FIND_TAIL(M DT, t) 13: else if 'acl' == t.dep_rel then 14:</p><p>Head ← t.closest_phrase(q.T ail, q.Head) where (q ∈ Q ∧ t.parent ∈ q) 15:</p><p>Rel, T ail ← t , FIND_TAIL(M DT, t) if ∃q ∈ Q such that q.Head == t.parent then 18:</p><p>Head, Rel, T ail ← t , q.Rel , q.T ail 19:</p><p>else if ∃q ∈ Q such that q.T ail == t.parent then 20:</p><p>Head, Rel, T ail ← q.Head , q.Rel , t </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Sandipan Dandapat, Sunayana Sitaram, and Vishrav Chaudhary. 2022. The sumeval 2022 shared task on performance prediction of multilingual pre-trained language models</title>
		<author>
			<persName><forename type="first">Kabir</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonios</forename><surname>Anastasopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barun</forename><surname>Patra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monojit</forename><surname>Choudhury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Scaling Up Multilingual Evaluation</title>
		<meeting>the First Workshop on Scaling Up Multilingual Evaluation</meeting>
		<imprint>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Kraken: N-ary facts in open information extraction</title>
		<author>
			<persName><forename type="first">Alan</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Löser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction (AKBC-WEKEX)</title>
		<meeting>the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction (AKBC-WEKEX)</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="52" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Introduction to shallow parsing contest on south asian languages</title>
		<author>
			<persName><forename type="first">Akshar</forename><surname>Bharati</surname></persName>
		</author>
		<author>
			<persName><surname>Prashanth R Mannem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IJCAI and the Workshop On Shallow Parsing for South Asian Languages (SPSAL)</title>
		<meeting>the IJCAI and the Workshop On Shallow Parsing for South Asian Languages (SPSAL)</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Anncorra: Annotating corpora guidelines for pos and chunk annotation for indian languages</title>
		<author>
			<persName><forename type="first">Akshar</forename><surname>Bharati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Sangal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipti</forename><forename type="middle">Misra</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lakshmi</forename><surname>Bai</surname></persName>
		</author>
		<idno>LTRC-TR31</idno>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">CaRB: A crowdsourced benchmark for open IE</title>
		<author>
			<persName><forename type="first">Sangnie</forename><surname>Bhardwaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samarth</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mausam</forename><surname>Mausam</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1651</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on EMNLP-IJCNLP</title>
		<meeting>the 2019 Conference on EMNLP-IJCNLP<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6262" to="6267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The hindi/urdu treebank project</title>
		<author>
			<persName><forename type="first">Ahmad</forename><surname>Riyaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajesh</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Annahita</forename><surname>Bhatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prescott</forename><surname>Farudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhuvana</forename><surname>Klassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martha</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Owen</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipti</forename><forename type="middle">Misra</forename><surname>Rambow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashwini</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><surname>Vaidya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramagurumurthy</forename><surname>Sri</surname></persName>
		</author>
		<author>
			<persName><surname>Vishnu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of linguistic annotation</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="659" to="697" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Compound and conjunct verbs in hindi1</title>
		<author>
			<persName><forename type="first">John</forename><surname>Burton-Page</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bulletin of the School of Oriental and African Studies</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="469" to="478" />
			<date type="published" when="1957">1957</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An analysis of open information extraction based on semantic role labeling</title>
		<author>
			<persName><forename type="first">Janara</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixth international conference on Knowledge capture</title>
		<meeting>the sixth international conference on Knowledge capture</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="113" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multilingual open information extraction: Challenges and opportunities</title>
		<author>
			<persName><forename type="first">Daniela</forename><surname>Barreiro Claro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marlo</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clarissa</forename><forename type="middle">Castellã</forename><surname>Xavier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leandro</forename><surname>Oliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">228</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unsupervised cross-lingual representation learning at scale</title>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kartikay</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Clausie: clause-based open information extraction</title>
		<author>
			<persName><forename type="first">Luciano</forename><surname>Del</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Corro</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Rainer</forename><surname>Gemulla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd international conference on World Wide Web</title>
		<meeting>the 22nd international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="355" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno>CoRR, abs/1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Word-level coreference resolution</title>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Dobrovolskii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="7670" to="7675" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Persian ezafe recognition using transformers and its role in part-of-speech tagging</title>
		<author>
			<persName><forename type="first">Ehsan</forename><surname>Doostmohammadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minoo</forename><surname>Nassajian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adel</forename><surname>Rahimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="961" to="971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Open information extraction from the web</title>
		<author>
			<persName><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="68" to="74" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Identifying relations for open information extraction</title>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 conference on empirical methods in natural language processing</title>
		<meeting>the 2011 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1535" to="1545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multilingual open relation extraction using cross-lingual projection</title>
		<author>
			<persName><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shankar</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Chapter of the ACL: Human Language Technologies</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1351" to="1356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Conjunct verbs in hindi</title>
		<author>
			<persName><forename type="first">Shamim</forename><surname>Fatma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Trends in Hindi Linguistics</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="217" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multilingual open information extraction</title>
		<author>
			<persName><forename type="first">Pablo</forename><surname>Gamallo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcos</forename><surname>Garcia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Portuguese Conference on Artificial Intelligence</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="711" to="722" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dependency-based open information extraction</title>
		<author>
			<persName><forename type="first">Pablo</forename><surname>Gamallo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcos</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Santiago</forename><surname>Fernández-Lanza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the joint workshop on unsupervised and semi-supervised learning in NLP</title>
		<meeting>the joint workshop on unsupervised and semi-supervised learning in NLP</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Minie: minimizing facts in open information extraction</title>
		<author>
			<persName><forename type="first">Kiril</forename><surname>Gashteovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rainer</forename><surname>Gemulla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luciano</forename><surname>Del</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Corro</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>Association for Computational Linguistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Benchie: Open information extraction evaluation based on facts, not tokens</title>
		<author>
			<persName><forename type="first">Kiril</forename><surname>Gashteovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingying</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhushan</forename><surname>Kotnis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carolin</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Goran</forename><surname>Glavas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathias</forename><surname>Niepert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.06850</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multilingual dependency parsing evaluation: a large-scale analysis of word order properties using artificial data</title>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Gulordava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paola</forename><surname>Merlo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="343" to="356" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Advanced machine learning techniques in natural language processing for indian languages</title>
		<author>
			<persName><forename type="first">Vaishali</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nisheeth</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iti</forename><surname>Mathur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Smart Techniques for a Smarter Planet</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="117" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A comprehensive survey on indian regional language processing</title>
		<author>
			<persName><surname>Bs Harish And R Kasturi Rangan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SN Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Advances in natural language processing</title>
		<author>
			<persName><forename type="first">Julia</forename><surname>Hirschberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">349</biblScope>
			<biblScope unit="issue">6245</biblScope>
			<biblScope unit="page" from="261" to="266" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Girish Nath Jha. 2010. The TDIL program and the Indian langauge corpora intitiative (ILCI)</title>
		<author>
			<persName><forename type="first">Kushal</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adwait</forename><surname>Deshpande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kumar</forename><surname>Shridhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Laumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayushman</forename><surname>Dash</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.02323</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC&apos;10)</title>
		<meeting>the Seventh International Conference on Language Resources and Evaluation (LREC&apos;10)<address><addrLine>Valletta, Malta</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Indictransformers: An analysis of transformer language models for indian languages. European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Alignmentaugmented consistent translation for multilingual open information extraction</title>
		<author>
			<persName><forename type="first">Keshav</forename><surname>Kolluru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muqeeth</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shubham</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumen</forename><surname>Chakrabarti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2502" to="2517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Part-of-speech tagging with rule-based data preprocessing and transformer</title>
		<author>
			<persName><forename type="first">Hongwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyan</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingzi</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electronics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">56</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Kbpearl: a knowledge base population system supported by joint entity and relation linking</title>
		<author>
			<persName><forename type="first">Xueling</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zijian</forename><surname>Hao Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1035" to="1049" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Open language learning for information extraction</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Mausam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oren</forename><surname>Bart</surname></persName>
		</author>
		<author>
			<persName><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Korea</addrLine></address></meeting>
		<imprint>
			<publisher>Jeju Island</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="523" to="534" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Effectiveness and efficiency of open relation extraction</title>
		<author>
			<persName><forename type="first">Filipe</forename><surname>Mesquita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Schmidek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denilson</forename><surname>Barbosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="447" to="457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Case ocp: A constraint on word order in hindi. Theoretical perspectives on word order in South Asian languages</title>
		<author>
			<persName><forename type="first">Tara</forename><surname>Mohanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="page">216</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Semantically relatable sets: building blocks for representing semantics</title>
	</analytic>
	<monogr>
		<title level="m">Rajat Mohanty</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
	<note>MT Summit</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Open information extraction for knowledge graph construction</title>
		<author>
			<persName><forename type="first">Iqra</forename><surname>Muhammad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Kearney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carrol</forename><surname>Gamble</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frans</forename><surname>Coenen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paula</forename><surname>Williamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Database and Expert Systems Applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="103" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Basic grammar, hindi</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jaya</surname></persName>
		</author>
		<author>
			<persName><surname>Nagendra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">A Brief History of Languages</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">190</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A universal part-of-speech tagset</title>
		<author>
			<persName><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC&apos;12)</title>
		<meeting>the Eighth International Conference on Language Resources and Evaluation (LREC&apos;12)</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2089" to="2096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Stanza: A Python natural language processing toolkit for many human languages</title>
		<author>
			<persName><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Bolton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Multi 2 oie: Multilingual open information extraction based on multi-head attention with bert</title>
		<author>
			<persName><forename type="first">Youngbin</forename><surname>Ro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yukyung</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pilsung</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: Findings</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1107" to="1117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A primer in bertology: What we know about how bert works</title>
		<author>
			<persName><forename type="first">Anna</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olga</forename><surname>Kovaleva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Rumshisky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="842" to="866" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Shallow parsing pipeline-hindi-english code-mixed social media text</title>
		<author>
			<persName><forename type="first">Arnav</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sakshi</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raveesh</forename><surname>Motlani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piyush</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manish</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radhika</forename><surname>Mamidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipti</forename><forename type="middle">Misra</forename><surname>Sharma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter</title>
		<meeting>the 2016 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1340" to="1345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Hmm based chunker for hindi</title>
		<author>
			<persName><forename type="first">Akshay</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sushma</forename><surname>Bendre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajeev</forename><surname>Sangal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">Anirudh</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunayana</forename><surname>Sitaram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanuja</forename><surname>Ganu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandipan</forename><surname>Dandapat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kalika</forename><surname>Bali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monojit</forename><surname>Choudhury</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.08875</idno>
		<title level="m">Predicting the performance of multilingual nlp models</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">Kim</forename><surname>Ef Tjong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName><surname>Buchholz</surname></persName>
		</author>
		<title level="m">Introduction to the conll-2000 shared task: Chunking. ACL</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Improving sequence tagging for vietnamese text using transformer-based neural models</title>
		<author>
			<persName><forename type="first">Thi</forename><surname>Oanh Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phuong</forename><forename type="middle">Le</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th Pacific Asia Conference on Language, Information and Computation</title>
		<meeting>the 34th Pacific Asia Conference on Language, Information and Computation</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="13" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Universal decompositional semantics on universal dependencies</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Steven White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Drew</forename><surname>Reisinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keisuke</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Vieira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Rudinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Rawlins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1713" to="1723" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Text searching with templates. Cambridge Language Research Unit Memo</title>
		<author>
			<persName><forename type="first">Yorick</forename><surname>Wilks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ML</title>
		<imprint>
			<biblScope unit="issue">165</biblScope>
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rémi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariama</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Span model for open information extraction on accurate corpus</title>
		<author>
			<persName><forename type="first">Junlang</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="9523" to="9530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Cross-lingual decompositional semantic parsing</title>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xutai</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Rudinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1664" to="1675" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Fine-grained information extraction from biomedical literature based on knowledgeenriched abstract meaning representation</title>
		<author>
			<persName><forename type="first">Zixuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolaus</forename><surname>Parulian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Skatje</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6261" to="6270" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
