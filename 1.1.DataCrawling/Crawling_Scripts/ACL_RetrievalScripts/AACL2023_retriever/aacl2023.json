[
    {
        "title": "Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)",
        "authors": [
            "Jong C. Park",
            "Yuki Arase",
            "Baotian Hu",
            "Wei Lu",
            "Derry Wijaya",
            "Ayu Purwarianti",
            "Adila Alfa Krisnadhi"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.0.pdf",
        "abstract": "The joint conferences of IJCNLP and AACL are organized by alternating leadership in the Asia-Pacific region, in odd years by Asian Federation of Natural Language Processing (AFNLP) and in even years by AACL, except when the annual meetings of ACL are offered in the region every three years, in which case the conferences will be offered and organized solely by ACL. This year, the conference is organized by AFNLP.As President of AFNLP, I have formed the Conference Coordination Committee (CCC) last year with executive members of AFNLP: Sadao Kurohashi (Vice President), Min Zhang (Secretary), Liang-Chih Yu (Honorary Treasurer), and Minghui Dong (Web Master). Xuanjing Huang has participated in the meetings of the committee as AACL Representative. I am truly thankful for their dedication in the initial stages as CCC members, in particular during the selection of the Local Chairs together with the conference venue and the nomination and appointment of General Chair and Program Committee Chairs, and, after it is decided that I also serve as General Chair of the conference, for their service as respective chairs throughout the conference preparation stages. Their continued support has been of tremendous help and is much appreciated. I would also like to thank deeply the entire organizing committee of the conference for their hardwork and superb handling of difficult situations, most of all due to the much limited time to address their respective tasks.• Program Committe Chairs: Yuki Arase, Baotian Hu and Wei Lu have managed the most critical task of establishing the main program of the conference, which includes, among many others, forming and coordinating the Program Committee, constructing the call for papers with a timely theme track, overseeing the review process on both Softconf and ARR, making decisions on paper acceptance, selecting keynote speakers and putting together the program schedule, and most of all communicating with the reviewers, authors, and other committee members over numerous times during the entire process. This is a formidable task, and their efforts for leading to its successful completion are so much appreciated.• Tutorial Chairs: Yun-Nung (Vivian) Chen and Sadao Kurohashi have gone through the tutorial proposals to select six tutorials that are well balanced both topically and geographically, actively fostering diversity and inclusion.• Workshop Chairs: Kehai Chen and Lun-Wei Ku have gone over the workshop proposals to select eight strong workshops, NLPMC, WIESP, Eval4NLP, SocialNLP, SEA, FinNLP, NLInt, and ArtOfSafety.• Demo Chairs: Sriparna Saha and Herry Sujaini have overseen the process of selecting papers among those submitted to the system demonstration session independently of the main program.• Publication Chairs: Minghui Dong and Kotaro Funakoshi have put together all the documents and articles to construct the conference proceedings expertly, cordially and in a timely manner.• Sponsorship Chairs: Min Zhang, Satoshi Sekine, Haofeng Wang, and Zhongqing Wang have worked hard to solicit funding to support the conference, and successfully, despite the short time to operate. We are all much grateful to the funding organizations for their generous help."
    },
    {
        "title": "Toward Unified Controllable Text Generation via Regular Expression Instruction",
        "authors": [
            "Xin Zheng",
            "Hongyu Lin",
            "Xianpei Han",
            "Le Sun"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.1.pdf",
        "abstract": "Controllable text generation is a fundamental aspect of natural language generation, with numerous methods proposed for different constraint types. However, these approaches often require significant architectural or decoding modifications, making them challenging to apply to additional constraints or resolve different constraint combinations. To address this, our paper introduces Regular Expression Instruction (REI), which utilizes an instructionbased mechanism to fully exploit regular expressions' advantages to uniformly model diverse constraints. Specifically, our REI supports all popular fine-grained controllable generation constraints, i.e., lexical, positional, and length, as well as their complex combinations, via regular expression-style instructions. Our method only requires fine-tuning on mediumscale language models or few-shot, in-context learning on large language models, and requires no further adjustment when applied to various constraint combinations. Experiments demonstrate that our straightforward approach yields high success rates and adaptability to various constraints while maintaining competitiveness in automatic metrics and outperforming most previous baselines. 1"
    },
    {
        "title": "Don’t be Blind to Questions: Question-Oriented Math Word Problem Solving",
        "authors": [
            "Zhenwen Liang",
            "Jipeng Zhang",
            "Xiangliang Zhang"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.2.pdf",
        "abstract": "Solving math word problems (MWP) is a challenging task for natural language processing systems, as it requires to not only identify and comprehend the problem description within the context, but also to deduce a solution in accordance with the posed question. Previous solvers have been found to prioritize the context over the question, resulting in low performance when solving multiple questions under the same context. In this paper, we present a question-oriented strategy to address this issue and improve the generalizability of MWP solvers. Our approach features an entity-aware encoder that enhances the connection between MWP context and question via entities in established dependency graphs, aiming at obtaining better problem representations. Then, a question-guided decoder is trained using a contrastive learning strategy to enhance the question representations. Empirical evaluations on four benchmarks demonstrate that our method outperforms previous solvers and exhibits a favorable balance between efficacy and efficiency in MWP solving. In addition, our solver is not reliant on any specific pre-trained model and demonstrates seamless compatibility with different pre-trained model backbones."
    },
    {
        "title": "SILVER: Self Data Augmentation for Out-of-Scope Detection in Dialogues",
        "authors": [
            "Chunpeng Ma",
            "Takuya Makino"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.3.pdf",
        "abstract": "Detecting out-of-scope (OOS) utterances is crucial in task-oriented dialogue systems, but obtaining enough annotated OOS dialogues to train a binary classifier directly is difficult in practice. Existing data augmentation methods generate OOS dialogues automatically, but their performance usually depends on an external corpus. This dependence not only induces uncertainty, but also reduces the quality of generated dialogues. Specifically, all of them are out-of-domain (OOD).Herein we propose SILVER, a self data augmentation method that does not use external data. It addresses issues of previous research and improves the accuracy of OOS detection (false positive rate: 90.5% → 47.4%). Furthermore, SILVER successfully generates highquality in-domain (IND) OOS dialogues in terms of naturalness (percentage: 8% → 68%) and OOS correctness (percentage: 74% → 88%), as evaluated by human workers."
    },
    {
        "title": "MQAG: Multiple-choice Question Answering and Generation for Assessing Information Consistency in Summarization",
        "authors": [
            "Potsawee Manakul",
            "Adian Liusie",
            "Mark Gales"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.4.pdf",
        "abstract": "State-of-the-art summarization systems can generate highly fluent summaries. These summaries, however, may contain factual inconsistencies and/or information not present in the source. Hence, an important component of assessing the quality of summaries is to determine whether there is information consistency between the source and the summary. Existing approaches are typically based on lexical matching or representation-based methods. In this work, we introduce an alternative scheme based on standard information-theoretic measures in which the information present in the source and summary is directly compared. We propose a Multiple-choice Question Answering and Generation framework, MQAG, which approximates the information consistency by computing the expected statistical distance between summary and source answer distributions over automatically generated multiple-choice questions. This approach exploits multiple-choice answer probabilities, as predicted answer distributions can be compared. We conduct experiments on four summary evaluation datasets: QAG-CNNDM/XSum, XSum-Hallucination, Podcast Assessment, and SummEval. Experiments show that MQAG, using models trained on SQuAD or RACE, outperforms existing evaluation methods on the majority of tasks. 1"
    },
    {
        "title": "MCML: A Novel Memory-based Contrastive Meta-Learning Method for Few Shot Slot Tagging",
        "authors": [
            "Hongru Wang",
            "Zezhong Wang",
            "Wai Chung Kwan",
            "Kam-Fai Wong"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.5.pdf",
        "abstract": "Meta-learning is widely used for few-shot slot tagging in task of few-shot learning. The performance of existing methods is, however, seriously affected by sample forgetting issue, where the model forgets the historically learned meta-training tasks while solely relying on support sets when adapting to new tasks. To overcome this predicament, we propose the Memory-based Contrastive Meta-Learning (aka, MCML) method, including learn-from-the-memory and adaption-from-thememory modules, which bridge the distribution gap between training episodes and between training and testing respectively. Specifically, the former uses an explicit memory bank to keep track of the label representations of previously trained episodes, with a contrastive constraint between the label representations in the current episode with the historical ones stored in the memory. In addition, the adaption-frommemory mechanism is introduced to learn more accurate and robust representations based on the shift between the same labels embedded in the testing episodes and memory. Experimental results show that the MCML outperforms several state-of-the-art methods on both SNIPS and NER datasets and demonstrates strong scalability with consistent improvement when the number of shots gets more."
    },
    {
        "title": "RECESS: Resource for Extracting Cause, Effect, and Signal Spans",
        "authors": [
            "Fiona Anting Tan",
            "Hansi Hettiarachchi",
            "Ali Hürriyetoğlu",
            "Nelleke Oostdijk",
            "Tommaso Caselli",
            "Tadashi Nomoto",
            "Onur Uca",
            "Farhana Ferdousi Liza",
            "See-Kiong Ng"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.6.pdf",
        "abstract": "Causality expresses the relation between two arguments, one of which represents the cause and the other the effect (or consequence). Causal relations are fundamental to human decision making and reasoning, and extracting them from natural language texts is crucial for building effective natural language understanding models. However, the scarcity of annotated corpora for causal relations poses a challenge in the development of such tools. Thus, we created Resource for Extracting Cause, Effect, and Signal Spans (RECESS), a comprehensive corpus annotated for causality at different levels, including Cause, Effect, and Signal spans. The corpus contains 3,767 sentences, of which, 1,982 are causal sentences that contain a total of 2,754 causal relations. We report baseline experiments on two natural language tasks (Causal Sentence Classification, and Cause-Effect-Signal Span Detection), and establish initial benchmarks for future work. We conduct an in-depth analysis of the corpus and the properties of causal relations in text. RECESS is a valuable resource for developing and evaluating causal relation extraction models, benefiting researchers working on topics from information retrieval to natural language understanding and inference."
    },
    {
        "title": "SYNC: A Structurally Guided Hard Negative Curricula for Generalizable Neural Code Search",
        "authors": [
            "Atharva Naik",
            "Soumitra Das",
            "Jyothi Vedurada",
            "Somak Aditya"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.7.pdf",
        "abstract": "In neural code search, a Transformers-based pre-trained language model (such as Code-BERT) is used to embed both the query (NL) and the code snippet (PL) into a joint representation space; which is used to retrieve the relevant PLs satisfying the query. These models often make mistakes such as retrieving snippets with incorrect data types, and incorrect method names or signatures. The generalization ability beyond training data is also limited (as the code retrieval datasets vary in the ways NL-PL pairs are collected). In this work, we propose a novel contrastive learning technique (SYNC) that enables efficient finetuning of code LMs with soft and hard negatives, where the hard negatives are constructed using a set of structure-aware AST-based perturbations; targeted towards possible syntactic and semantic variations. Our method achieves significant improvements in retrieval performance for three code LMs (CodeBERT, GraphCode-BERT, UniXCoder) over four Python code retrieval datasets. We also open source our code for reproducibility 1 ."
    },
    {
        "title": "On a Benefit of Masked Language Model Pretraining: Robustness to Simplicity Bias",
        "authors": [
            "Ting-Rui Chiang"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.8.pdf",
        "abstract": "Despite the success of pretrained masked language models (MLM), why MLM pretraining is useful is still a question not fully answered. In this work we theoretically and empirically show that MLM pretraining makes models robust to lexicon-level spurious features, partly answering the question. Our explanation is that MLM pretraining may alleviate problems brought by simplicity bias (Shah et al., 2020), which refers to the phenomenon that a deep model tends to rely excessively on simple features. In NLP tasks, those simple features could be token-level features whose spurious association with the label can be learned easily. We show that MLM pretraining makes learning from the context easier. Thus, pretrained models are less likely to rely excessively on a single token. We also explore the theoretical explanations of MLM's efficacy in causal settings. Compared withWei et al. (2021), we achieve similar results with milder assumptions. Finally, we close the gap between our theories and real-world practices by conducting experiments on real-world tasks."
    },
    {
        "title": "Conversation Style Transfer using Few-Shot Learning",
        "authors": [
            "Shamik Roy",
            "Raphael Shu",
            "Nikolaos Pappas",
            "Elman Mansimov",
            "Yi Zhang",
            "Saab Mansour",
            "Dan Roth"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.9.pdf",
        "abstract": "Conventional text style transfer approaches focus on sentence-level style transfer without considering contextual information, and the style is described with attributes (e.g., formality). When applying style transfer in conversations such as task-oriented dialogues, existing approaches suffer from these limitations as context can play an important role and the style attributes are often difficult to define in conversations. In this paper, we introduce conversation style transfer as a few-shot learning problem, where the model learns to perform style transfer by observing only a few example dialogues in the target style. We propose a novel in-context learning approach to solve the task with stylefree dialogues as a pivot. Human evaluation shows that by incorporating multi-turn context, the model is able to match the target style while having better appropriateness and semantic correctness compared to utterance/sentence-level style transfer. Additionally, we show that conversation style transfer can also benefit downstream tasks. For example, in multi-domain intent classification tasks, the F1 scores improve after transferring the style of training data to match the style of the test data."
    },
    {
        "title": "MasakhaNEWS: News Topic Classification for African languages",
        "authors": [
            "David Ifeoluwa Adelani",
            "Marek Masiak",
            "Israel Abebe Azime",
            "Jesujoba Alabi",
            "Atnafu Lambebo Tonja",
            "Christine Mwase",
            "Odunayo Ogundepo",
            "Bonaventure F. P. Dossou",
            "Akintunde Oladipo",
            "Doreen Nixdorf",
            "Chris Chinenye Emezue",
            "Sana Al-azzawi",
            "Blessing Sibanda",
            "Davis David",
            "Lolwethu Ndolela",
            "Jonathan Mukiibi",
            "Tunde Ajayi",
            "Tatiana Moteu",
            "Brian Odhiambo",
            "Abraham Owodunni",
            "Nnaemeka Obiefuna",
            "Muhidin Mohamed",
            "Shamsuddeen Hassan Muhammad",
            "Teshome Mulugeta Ababu",
            "Saheed Abdullahi Salahudeen",
            "Mesay Gemeda Yigezu",
            "Tajuddeen Gwadabe",
            "Idris Abdulmumin",
            "Mahlet Taye",
            "Oluwabusayo Awoyomi",
            "Iyanuoluwa Shode",
            "Tolulope Adelani",
            "Habiba Abdulganiyu",
            "Abdul-Hakeem Omotayo",
            "Adetola Adeeko",
            "Abeeb Afolabi",
            "Anuoluwapo Aremu",
            "Olanrewaju Samuel",
            "Clemencia Siro",
            "Wangari Kimotho",
            "Onyekachi Ogbu",
            "Chinedu Mbonu",
            "Chiamaka Chukwuneke",
            "Samuel Fanijo",
            "Jessica Ojo",
            "Oyinkansola Awosan",
            "Tadesse Kebede",
            "Toadoum Sari Sakayo",
            "Pamela Nyatsine",
            "Freedmore Sidume",
            "Oreen Yousuf",
            "Mardiyyah Oduwole",
            "Kanda Tshinu",
            "Ussen Kimanuka",
            "Thina Diko",
            "Siyanda Nxakama",
            "Sinodos Nigusse",
            "Abdulmejid Johar",
            "Shafie Mohamed",
            "Fuad Mire Hassan",
            "Moges Ahmed Mehamed",
            "Evrard Ngabire",
            "Jules Jules",
            "Ivan Ssenkungu",
            "Pontus Stenetorp"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.10.pdf",
        "abstract": "Despite representing roughly a fifth of the world population, African languages are underrepresented in NLP research, in part due to a lack of datasets. While there are individual language-specific datasets for several tasks, only a handful of tasks (e.g. named entity recognition and machine translation) have datasets covering geographical and typologically-diverse African languages. In this paper, we develop MasakhaNEWS-the largest dataset for news topic classification covering 16 languages widely spoken in Africa. We provide and evaluate a set of baseline models by training classical machine learning models and fine-tuning several language models. Furthermore, we explore several alternatives * Equal contribution"
    },
    {
        "title": "Automatic Translation of Span-Prediction Datasets",
        "authors": [
            "Ofri Masad",
            "Kfir Bar",
            "Amir Cohen"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.11.pdf",
        "abstract": "Generating high-quality non-English language datasets is crucial for achieving high performance in various Natural Language Processing (NLP) tasks. In this paper, we propose a new approach for translating NLP datasets that relies on a two-phase pipeline and online translation services. Our approach focuses on solving the alignment problem that affects span prediction tasks and utilizes automatically labeled data for training an alignment model. We demonstrate that our model-based approach shows higher accuracy than any other alignment method and improves the average F1 score on several Question-Answering (QA) datasets, specifically on the XQuAD Translated-train dataset, achieving new state-of-the-art results."
    },
    {
        "title": "Human-Like Distractor Response in Vision-Language Model",
        "authors": [
            "Xiaonan Xu",
            "Haoshuo Chen"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.12.pdf",
        "abstract": "Previous studies exploring the human-like capabilities of machine-learning models have primarily focused on pure language models. Limited attention has been given to investigating whether models exhibit human-like behavior when performing tasks that require the integration of visual and language information. In this study, we investigate the impact of tags of semantic, phonological, and bilingual features on the visual question-answering task performance of an unsupervised model. Our findings reveal its similarities with the influence of distractors in the picture-naming task (known as the picture-word-interference paradigm) observed in human experiments: 1) Semanticallyrelated tags have a more negative effect on task performance compared to unrelated tags, indicating a more robust competition between visual and tag information which are semantically closer to each other when generating an answer. 2) Even presenting a partial section (wordpiece) of the originally detected tag significantly improves task performance, with the portion that plays a lesser role in determining the overall meaning of the original tag leading to a more pronounced improvement. 3) Tags in two languages that refer to the same meaning exhibit a symmetrical-like effect on performance in balanced bilingual models. Datasets and code of this project are released at https: //github.com/NLPbelllabs/PWI"
    },
    {
        "title": "Phylogeny-Inspired Soft Prompts For Data-to-Text Generation in Low-Resource Languages",
        "authors": [
            "William Soto Martinez",
            "Yannick Parmentier",
            "Claire Gardent"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.13.pdf",
        "abstract": "Most work on verbalising Knowledge-Graphs (KG) has focused on high-resource languages such as English, Russian, Czech or Arabic. In this paper, we focus on KG-to-Text generation where the output text is in Breton, Irish or Welsh. To overcome the small size of the parallel training data, we combine the strengths of a multilingual encoder-decoder model with denoising fine-tuning on monolingual data and Soft Prompt fine-tuning on a small quantity of KG/text data. We furthermore structure the soft prompt into multiple sub-prompts designed to capture the similarities and differences between English, Knowledge graphs and the three target languages. Our experiments show that our approach outperforms strong baselines and that all sub-prompts contribute to performance 1 ."
    },
    {
        "title": "Analysing Cross-Lingual Transfer in Low-Resourced African Named Entity Recognition",
        "authors": [
            "Michael Beukman",
            "Manuel Fokam"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.14.pdf",
        "abstract": "Transfer learning has led to large gains in performance for nearly all NLP tasks while making downstream models easier and faster to train. This has also been extended to lowresourced languages, with some success. We investigate the properties of cross-lingual transfer learning between ten low-resourced languages, from the perspective of a named entity recognition task. We specifically investigate how much adaptive fine-tuning and the choice of transfer language affect zero-shot transfer performance. We find that models that perform well on a single language often do so at the expense of generalising to others, while models with the best generalisation to other languages suffer in individual language performance. Furthermore, the amount of data overlap between the source and target datasets is a better predictor of transfer performance than either the geographical or genetic distance between the languages. 1"
    },
    {
        "title": "A Multimodal Analysis of Influencer Content on Twitter",
        "authors": [
            "Danae Sánchez Villegas",
            "Catalina Goanta",
            "Nikolaos Aletras"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.15.pdf",
        "abstract": "Influencer marketing involves a wide range of strategies in which brands collaborate with popular content creators (i.e., influencers) to leverage their reach, trust, and impact on their audience to promote and endorse products or services. Because followers of influencers are more likely to buy a product after receiving an authentic product endorsement rather than an explicit direct product promotion, the line between personal opinions and commercial content promotion is frequently blurred. This makes automatic detection of regulatory compliance breaches related to influencer advertising (e.g., misleading advertising or hidden sponsorships) particularly difficult. In this work, we (1) introduce a new Twitter (now X) dataset consisting of 15, 998 influencer posts mapped into commercial and noncommercial categories for assisting in the automatic detection of commercial influencer content; (2) experiment with an extensive set of predictive models that combine text and visual information showing that our proposed cross-attention approach outperforms state-ofthe-art multimodal models; and (3) conduct a thorough analysis of strengths and limitations of our models. We show that multimodal modeling is useful for identifying commercial posts, reducing the amount of false positives, and capturing relevant context that aids in the discovery of undisclosed commercial posts."
    },
    {
        "title": "Reimagining Complaint Analysis: Adopting Seq2Path for a Generative Text-to-Text Framework",
        "authors": [
            "Apoorva Singh",
            "Raghav Jain",
            "Sriparna Saha"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.16.pdf",
        "abstract": "The escalating volume and frequency of social media complaints necessitate robust automated complaint analysis techniques. Much of the existing body of research in this area has been devoted to two primary aspects: identifying complaint-specific content amidst other noncomplaint communications, and predicting the severity of a complaint, which involves classifying complaints into different severity levels based on the anticipated resolution from the complainant's perspective. These automated analysis tools equip companies with the means to effectively manage complaints and generate suitable responses. In our study, we present a unified generative approach for complaint detection, transforming the multitask learning problem into a text-to-text generation task. As part of our training strategy, we adopt the Seq2Path training paradigm that conceptualizes the outcome as a tree structure as opposed to a traditional sequence. This innovative approach tackles the drawbacks of conventional sequences, such as the lack of order among the outputs, yielding a more coherent and structured output. Our model's effectiveness is assessed against the benchmark Complaints dataset, highlighting its superior performance across diverse evaluation metrics when compared with state-of-the-art models and other baselines 1 ."
    },
    {
        "title": "FollowupQG: Towards information-seeking follow-up question generation",
        "authors": [
            "Yan Meng",
            "Liangming Pan",
            "Yixin Cao",
            "Min-Yen Kan"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.17.pdf",
        "abstract": "Humans ask follow-up questions driven by curiosity, which reflects a creative human cognitive process. We introduce the task of realworld information-seeking follow-up question generation (FQG), which aims to generate follow-up questions seeking a more in-depth understanding of an initial question and answer. We construct FOLLOWUPQG, a dataset 1 of over 3K real-world (initial question, answer, follow-up question) tuples collected from a Reddit forum providing layman-friendly explanations for open-ended questions.In contrast to existing datasets, questions in FOLLOWUPQG use more diverse pragmatic strategies to seek information, and they also show higher-order cognitive skills (such as applying and relating). We evaluate current question generation models on their efficacy for generating follow-up questions, exploring how to generate specific types of follow-up questions based on step-by-step demonstrations. Our results validate FOLLOWUPQG as a challenging benchmark, as model-generated questions are adequate but far from human-raised questions in terms of informativeness and complexity. * Authors contributed equally. 1 Data available at https://github.com/vivian-my/ FollowupQG Answer: Yes, there is a placenta blood barrier. One of the placenta's jobs is to make sure blood from the mother and fetus never mixes. The placenta acts as an exchange surface between the mother and the fetus. Nutrients and oxygen are passed over by diffusion only.Initial Question: Is a pregnant mother's blood kept separate from her fetus' blood?"
    },
    {
        "title": "Zero-shot Triplet Extraction by Template Infilling",
        "authors": [
            "Bosung Kim",
            "Hayate Iso",
            "Nikita Bhutani",
            "Estevam Hruschka",
            "Ndapa Nakashole",
            "Tom Mitchell"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.18.pdf",
        "abstract": "The task of triplet extraction aims to extract pairs of entities and their corresponding relations from unstructured text. Most existing methods train an extraction model on training data involving specific target relations, and are incapable of extracting new relations that were not observed at training time. Generalizing the model to unseen relations typically requires fine-tuning on synthetic training data which is often noisy and unreliable. We show that by reducing triplet extraction to a template infilling task over a pre-trained language model (LM), we can equip the extraction model with zero-shot learning capabilities and eliminate the need for additional training data. We propose a novel framework, ZETT (ZEro-shot Triplet extraction by Template infilling), that aligns the task objective to the pre-training objective of generative transformers to generalize to unseen relations. Experiments on FewRel and Wiki-ZSL datasets demonstrate that ZETT shows consistent and stable performance, outperforming previous state-of-the-art methods, even when using automatically generated templates. 1 * The work was partially done when Bosung Kim was a research intern at Megagon Labs."
    },
    {
        "title": "Generating and Answering Simple and Complex Questions from Text and from Knowledge Graphs",
        "authors": [
            "Kelvin Han",
            "Claire Gardent"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.19.pdf",
        "abstract": "While both text and Knowledge Graphs (KG) may be used to answer a question, most current Question Answering and Generation models only work on a single modality. In this paper, we introduce a multi-task model such that questions can be generated and answered from both KG and text. The model has wide coverage and handles both simple (one KG fact) and complex (more than one KG fact) questions. Extensive internal, cross-modal and external consistency checks, and analysis of the quality of the generated questions, show that our approach outperforms previous work. Our data and modeling also leads to improvements in downstream tasks, including better performance with finetuning Open-Domain QA architectures and better correlation with human judgments than the Data-QuestEval metric which was previously proposed for evaluating the semantic adequacy of KG-to-Text generations."
    },
    {
        "title": "Faithful Chain-of-Thought Reasoning",
        "authors": [
            "Qing Lyu",
            "Shreya Havaldar",
            "Adam Stein",
            "Li Zhang",
            "Delip Rao",
            "Eric Wong",
            "Marianna Apidianaki",
            "Chris Callison-Burch"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.20.pdf",
        "abstract": "While Chain-of-Thought (CoT) prompting boosts Language Models' (LM) performance on a gamut of complex reasoning tasks, the generated reasoning chain does not necessarily reflect how the model arrives at the answer (aka. faithfulness). We propose Faithful CoT, a reasoning framework involving two stages: Translation (Natural Language query → symbolic reasoning chain) and Problem Solving (reasoning chain → answer), using an LM and a deterministic solver respectively. This guarantees that the reasoning chain provides a faithful explanation of the final answer. Aside from interpretability, Faithful CoT also improves empirical performance: it outperforms standard CoT on 9 of 10 benchmarks from 4 diverse domains, with a relative accuracy gain of 6.3% on Math Word Problems (MWP), 3.4% on Planning, 5.5% on Multi-hop Question Answering (QA), and 21.4% on Relational Inference. Furthermore, with GPT-4 and Codex, it sets the new state-of-the-art few-shot performance on 7 datasets (with 95.0+ accuracy on 6 of them), showing a strong synergy between faithfulness and accuracy. 1 * Equal contribution. 1 Our code, data, and prompts are available at https:// github.com/veronica320/Faithful-COT."
    },
    {
        "title": "Linguistic Productivity: the Case of Determiners in English",
        "authors": [
            "Raquel G. Alhama",
            "Ruthe Foushee",
            "Daniel Byrne",
            "Allyson Ettinger",
            "Susan Goldin-Meadow",
            "Afra Alishahi"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.21.pdf",
        "abstract": "Having heard \"a pimwit\", English-speakers assume that \"the pimwit\" is also possible. This type of productivity is attributed to syntactic categories such as NOUN and DETERMINER, but the key question is how do humans become endowed with these categories in the first place. We propose a novel approach that combines corpus analysis with computational modeling to analyze the productivity of DETER-MINER+NOUN constructions in child-produced utterances. Our experiments on two corpora of child-adult interactions using two different methods of quantifying linguistic productivity show that children do not display productivity at early stages. Using a model trained on child-directed utterances, we simulate children's developmental trajectory with great precision, suggesting that the emergence of productivity in human language can be explained without the need to postulate a priori access to syntactic categories."
    },
    {
        "title": "Informative Evidence-guided Prompt-based Fine-tuning for English-Korean Critical Error Detection",
        "authors": [
            "DaHyun Jung",
            "Sugyeong Eo",
            "Chanjun Park",
            "Hyeonseok Moon",
            "Jaehyung Seo",
            "Heuiseok Lim"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.22.pdf",
        "abstract": "Critical error detection (CED) aims to identify the presence of catastrophic meaning distortion in machine translation. Fatal errors require significant attention because of their potential to cause personal or societal harm. The CED for Korean, an agglutinative language, is particularly highlighted, as minor variations in morphemes often bring substantial shifts in semantic interpretation. However, research on Korean is still underexplored and has room for improvement. In this study, we conduct the first investigation of CED for English-Korean to the best of our knowledge. We adopt prompt-based fine-tuning and propose various informative evidence to incorporate into the input prompt. Subsequently, we perform comprehensive verification and analysis to identify the most helpful guidance for detecting critical errors. The experimental results show that prompt-based fine-tuning with informative evidence outperforms standard fine-tuning by a large margin, demonstrating its remarkable effectiveness in English-Korean CED. 1"
    },
    {
        "title": "Assessment of Pre-Trained Models Across Languages and Grammars",
        "authors": [
            "Alberto Muñoz-Ortiz",
            "David Vilares",
            "Carlos Gómez-Rodríguez"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.23.pdf",
        "abstract": "We present an approach for assessing how multilingual large language models (LLMs) learn syntax in terms of multi-formalism syntactic structures. We aim to recover constituent and dependency structures by casting parsing as sequence labeling. To do so, we select a few LLMs and study them on 13 diverse UD treebanks for dependency parsing and 10 treebanks for constituent parsing. Our results show that: (i) the framework is consistent across encodings, (ii) pre-trained word vectors do not favor constituency representations of syntax over dependencies, (iii) sub-word tokenization is needed to represent syntax, in contrast to character-based models, and (iv) occurrence of a language in the pretraining data is more important than the amount of task data when recovering syntax from the word vectors."
    },
    {
        "title": "Rethinking the Role of Entity Type in Relation Classification",
        "authors": [
            "Xiang Dai",
            "Sarvnaz Karimi",
            "Stephen Wan"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.24.pdf",
        "abstract": "Relation Classification (RC)-the task of identifying the relation between a pair of target entities-is a fundamental sub-task of information extraction. RC models built on top of entity information are prevalent, with different variants using entity information, especially entity type information, differently. However, RC models are often benchmarked on datasets that human annotators provide near-perfect entity information, and, state-of-the-art results are reported using gold entity type information. We believe there is a need to understand how the effectiveness of RC models is affected by the correctness of entity type information because in practice this information is provided by imperfect entity recognition models. Our results on six datasets across four domains show that although using gold entity type improves the effectiveness of RC models, incorrect entity types may cause large effectiveness drops on some (but not all) datasets. We propose using Pointwise Mutual Information (PMI) to identify datasets on which RC models may be negatively impacted by incorrect entity type information."
    },
    {
        "title": "Improving Neural Machine Translation with Offline Evaluations",
        "authors": [
            "Min-Kyung Park",
            "Byung-Jun Lee"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.25.pdf",
        "abstract": "Reinforcement learning (RL) offers a principled framework for optimizing a given reward function and has been applied to a neural machine translation (NMT) problem to maximize arbitrary task metrics. However, previously adopted RL algorithms for NMT (e.g., policy gradient) are generally slow as they require online data collection, and limits the algorithm's applicability to specific reward functions that can be evaluated online. In this paper, we present an offline RL algorithm called CER (conservative expectile regression). Despite the demanding nature of offline RL tasks, which are even more difficult with large models, this algorithm is capable to learn stably by explicitly exploiting the properties of NMT's RL formulation, such as the deterministic transition function. We analyze and discuss the design choices of CER, and demonstrate in the experiments that the proposed method outperforms its competitors for offline reward optimization in NMT."
    },
    {
        "title": "Query Rewriting for Effective Misinformation Discovery",
        "authors": [
            "Ashkan Kazemi",
            "Artem Abzaliev",
            "Naihao Deng",
            "Rui Hou",
            "Scott A. Hale",
            "Veronica Perez-Rosas",
            "Rada Mihalcea"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.26.pdf",
        "abstract": "We propose a novel system to help factcheckers formulate search queries for known misinformation claims and effectively search across multiple social media platforms. We introduce an adaptable rewriting strategy, where editing actions for queries containing claims (e.g., swap a word with its synonym; change verb tense into present simple) are automatically learned through offline reinforcement learning. Our model uses a decision transformer to learn a sequence of editing actions that maximizes query retrieval metrics such as mean average precision. We conduct a series of experiments showing that our query rewriting system achieves a relative increase in the effectiveness of the queries of up to 42%, while producing editing action sequences that are human interpretable."
    },
    {
        "title": "24-bit Languages",
        "authors": [
            "Yiran Wang",
            "Taro Watanabe",
            "Masao Utiyama",
            "Yuji Matsumoto"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.27.pdf",
        "abstract": "We propose a contrastive hashing method to compress and interpret the contextual representation of pre-trained language models into binary codes. Unlike previous work that generates token-level tags, our method narrows the representation bottleneck to codes with only 24 bits, retaining task-relevant information in a more interpretable and fine-grained format without sacrificing performance (in most cases).We provide experiments and discussions on various structured prediction tasks, such as part-ofspeech tagging, named entity recognition, and constituency parsing, to demonstrate the effectiveness and interpretability of our method."
    },
    {
        "title": "DisCGen: A Framework for Discourse-Informed Counterspeech Generation",
        "authors": [
            "Sabit Hassan",
            "Malihe Alikhani"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.28.pdf",
        "abstract": "Counterspeech can be an effective method for battling hateful content on social media. Automated counterspeech generation can aid in this process. Generated counterspeech, however, can be viable only when grounded in the context of topic, audience and sensitivity as these factors influence both the efficacy and appropriateness. In this work, we propose a novel framework based on theories of discourse to study the inferential links that connect counter speeches to the hateful comment. Within this framework, we propose: i) a taxonomy of counterspeech derived from discourse frameworks, and ii) discourse-informed prompting strategies for generating contextually-grounded counterspeech. To construct and validate this framework, we present a process for collecting an in-the-wild dataset of counterspeech from Reddit. Using this process, we manually annotate a dataset of 3.9k Reddit comment pairs for the presence of hatespeech and counterspeech 1 . The positive pairs are annotated for 10 classes in our proposed taxonomy. We annotate these pairs with paraphrased counterparts to remove offensiveness and first-person references. We show that by using our dataset and framework, large language models can generate contextually-grounded counterspeech informed by theories of discourse. According to our human evaluation, our approaches can act as a safeguard against critical failures of discourseagnostic models."
    },
    {
        "title": "Question Answer Generation in Bengali: Mitigating the scarcity of QA datasets in a low-resource language",
        "authors": [
            "Md Shihab Shahriar",
            "Ahmad Al Fayad Chowdhury",
            "Md. Amimul Ehsan",
            "Abu Raihan Kamal"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.29.pdf",
        "abstract": "The scarcity of comprehensive, high-quality Question-Answering (QA) datasets in lowresource languages has greatly limited the progress of research on QA for these languages.This has inspired research on Question-Answer Generation (QAG) which seeks to synthetically generate QA pairs and minimize the human effort required to compile labeled datasets. In this paper, we present the first QAG pipeline for the Bengali language, which consists of an answer span extraction model, a question generation model, and roundtrip consistency filtering to discard inconsistent QA pairs. To train our QAG pipeline, we translate SQuAD1.1 and SQuAD2.0 using the state-of-the-art NLLB machine translation model and accurately mark the answer spans using a novel embedding-based answer alignment algorithm to construct two Bengali QA datasets that we show are superior to the only two existing machine-translated datasets in terms of quality and quantity. We use our QAG pipeline to generate more than 170,000 QA pairs to build BanglaQA, a synthetic QA dataset from 16,000 Bengali news articles spanning 5 different news categories. We demonstrate the quality of BanglaQA by human evaluation on a variety of metrics. The bestperforming model among several baselines on our dataset achieves an F1 score of 86.14 falling behind human performance of 95.72 F1. Our codebase and curated datasets are publicly available at https://github.com/ shihabshahriar16/BengaliQAG.git."
    },
    {
        "title": "One Sense per Translation",
        "authors": [
            "Bradley Hauer",
            "Grzegorz Kondrak"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.30.pdf",
        "abstract": "Word sense disambiguation (WSD) is the task of determining the sense of a word in context. Translations have been used in WSD as a source of knowledge, and even as a means of delimiting word senses. In this paper, we define three theoretical properties of the relationship between senses and translations, and argue that they constitute necessary conditions for using translations as sense inventories. The key property of One Sense per Translation (OSPT) provides a foundation for a translation-based WSD method. The results of an intrinsic evaluation experiment indicate that our method achieves a precision of approximately 93% compared to manual corpus annotations. Our extrinsic evaluation experiments demonstrate WSD improvements of up to 4.6% F1-score on difficult WSD datasets."
    },
    {
        "title": "Interactive-Chain-Prompting: Ambiguity Resolution for Crosslingual Conditional Generation with Interaction",
        "authors": [
            "Jonathan Pilault",
            "Xavier Garcia",
            "Arthur Bražinskas",
            "Orhan Firat"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.31.pdf",
        "abstract": "Crosslingual conditional generation (e.g., machine translation) has long enjoyed the benefits of scaling. Nonetheless, there are still issues that scale alone may not overcome. A source query in one language, for instance, may yield several translation options in another language without any extra context. Only one translation could be acceptable however, depending on the translator's preferences and goals. Choosing the incorrect option might significantly affect translation usefulness and quality. We propose a novel method interactive-chain prompting -a series of question, answering and generation intermediate steps between a Translator model and a User model -that reduces translations into a list of subproblems addressing ambiguities and then resolving such subproblems before producing the final text to be translated. To check ambiguity resolution capabilities and evaluate translation quality, we create a dataset exhibiting different linguistic phenomena which leads to ambiguities at inference for four languages. To encourage further exploration in this direction, we release all datasets. We note that interactive-chain prompting, using eight interactions as exemplars, consistently surpasses prompt-based methods with direct access to background information to resolve ambiguities.'\\ nU : \" about \" means approximately .\\ nA : aproximadamente , cerca de , alrededor de , casi , mas o menos ',"
    },
    {
        "title": "J-Guard: Journalism Guided Adversarially Robust Detection of AI-generated News",
        "authors": [
            "Tharindu Kumarage",
            "Amrita Bhattacharjee",
            "Djordje Padejski",
            "Kristy Roschke",
            "Dan Gillmor",
            "Scott Ruston",
            "Huan Liu",
            "Joshua Garland"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.32.pdf",
        "abstract": "The rapid proliferation of AI-generated text online is profoundly reshaping the information landscape. Among various types of AIgenerated text, AI-generated news presents a significant threat as it can be a prominent source of misinformation online. While several recent efforts have focused on detecting AI-generated text in general, these methods require enhanced reliability, given concerns about their vulnerability to simple adversarial attacks. Furthermore, due to the eccentricities of news writing, applying these detection methods for AI-generated news can produce false positives, potentially damaging the reputation of news organizations. To address these challenges, we leverage the expertise of an interdisciplinary team to develop a framework, J-Guard, capable of steering existing supervised AI text detectors for detecting AI-generated news while boosting adversarial robustness. By incorporating stylistic cues inspired by the unique journalistic attributes, J-Guard effectively distinguishes between real-world journalism and AIgenerated news articles. Our experiments on news articles generated by a vast array of AI models, including ChatGPT (GPT3.5), demonstrate the effectiveness of J-Guard in enhancing detection capabilities while maintaining an average performance decrease of as low as 7% when faced with adversarial attacks."
    },
    {
        "title": "We Need to Talk About Classification Evaluation Metrics in NLP",
        "authors": [
            "Peter Vickers",
            "Loic Barrault",
            "Emilio Monti",
            "Nikolaos Aletras"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.33.pdf",
        "abstract": "In Natural Language Processing (NLP) classification tasks such as topic categorisation and sentiment analysis, model generalizability is generally measured with standard metrics such as Accuracy, F-Measure, or AUC-ROC. The diversity of metrics, and the arbitrariness of their application suggest that there is no agreement within NLP on a single best metric to use. This lack suggests there has not been sufficient examination of the underlying heuristics which each metric encodes. To address this we compare several standard classification metrics with more 'exotic' metrics and demonstrate that a random-guess normalised Informedness metric is a parsimonious baseline for task performance. To show how important the choice of metric is, we perform extensive experiments on a wide range of NLP tasks including a synthetic scenario, natural language understanding, question answering and machine translation. Across these tasks we use a superset of metrics to rank models and find that Informedness best captures the ideal model characteristics. Finally, we release a Python implementation of Informedness following the SciKitLearn classifier format. 1"
    },
    {
        "title": "Investigating Zero- and Few-shot Generalization in Fact Verification",
        "authors": [
            "Liangming Pan",
            "Yunxiang Zhang",
            "Min-Yen Kan"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.34.pdf",
        "abstract": "We explore zero-and few-shot generalization for fact verification (FV), which aims to generalize the FV model trained on well-resourced domains (e.g., Wikipedia) to low-resourced domains that lack human annotations. To this end, we first construct a benchmark dataset collection which contains 11 FV datasets representing 6 domains. We conduct an empirical analysis of generalization across these FV datasets, finding that current models generalize poorly. Our analysis reveals that several factors affect generalization, including dataset size, length of evidence, and the type of claims. Finally, we show that two directions of work improve generalization: 1) incorporating domain knowledge via pretraining on specialized domains, and 2) automatically generating training data via claim generation."
    },
    {
        "title": "Attacking Open-domain Question Answering by Injecting Misinformation",
        "authors": [
            "Liangming Pan",
            "Wenhu Chen",
            "Min-Yen Kan",
            "William Yang Wang"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.35.pdf",
        "abstract": "With a rise in false, inaccurate, and misleading information in propaganda, news, and social media, real-world Question Answering (QA) systems face the challenges of synthesizing and reasoning over misinformation-polluted contexts to derive correct answers. This urgency gives rise to the need to make QA systems robust to misinformation, a topic previously unexplored. We study the risk of misinformation to QA models by investigating the sensitivity of open-domain QA models to corpus pollution with misinformation documents. We curate both human-written and model-generated false documents that we inject into the evidence corpus of QA models, and assess the impact on the performance of these systems. Experiments show that QA models are vulnerable to even small amounts of evidence contamination brought by misinformation, with large absolute performance drops on all models. Misinformation attack brings more threat when fake documents are produced at scale by neural models or the attacker targets on hacking specific questions of interest. To defend against such a threat, we discuss the necessity of building a misinformation-aware QA system that integrates question-answering and misinformation detection in a joint fashion."
    },
    {
        "title": "Emerging Challenges in Personalized Medicine: Assessing Demographic Effects on Biomedical Question Answering Systems",
        "authors": [
            "Sagi Shaier",
            "Kevin Bennett",
            "Lawrence Hunter",
            "Katharina Kann"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.36.pdf",
        "abstract": "State-of-the-art question answering (QA) models exhibit a variety of social biases (e.g., with respect to sex or race), generally explained by similar issues in their training data. However, what has been overlooked so far is that in the critical domain of biomedicine, any unjustified change in model output due to patient demographics is problematic: it results in the unfair treatment of patients. Selecting only questions on biomedical topics whose answers do not depend on ethnicity, sex, or sexual orientation, we ask the following research questions: (RQ1) Do the answers of QA models change when being provided with irrelevant demographic information? (RQ2) Does the answer of RQ1 differ between knowledge graph (KG)-grounded and text-based QA systems? We find that irrelevant demographic information change up to 15% of the answers of a KG-grounded system and up to 23% of the answers of a text-based system, including changes that affect accuracy. We conclude that unjustified answer changes caused by patient demographics are a frequent phenomenon, which raises fairness concerns and should be paid more attention to. Code and data can be found here: https://github.com/ Shaier/personalized_medicine_ challenges."
    },
    {
        "title": "Smoothing Entailment Graphs with Language Models",
        "authors": [
            "Nick McKenna",
            "Tianyi Li",
            "Mark Johnson",
            "Mark Steedman"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.37.pdf",
        "abstract": "The diversity and Zipfian frequency distribution of natural language predicates in corpora leads to sparsity in Entailment Graphs (EGs) built by Open Relation Extraction (ORE). EGs are computationally efficient and explainable models of natural language inference, but as symbolic models, they fail if a novel premise or hypothesis vertex is missing at test-time. We present theory and methodology for overcoming such sparsity in symbolic models. First, we introduce a theory of optimal smoothing of EGs by constructing transitive chains. We then demonstrate an efficient, open-domain, and unsupervised smoothing method using an off-the-shelf Language Model to find approximations of missing premise predicates. This improves recall by 25.1 and 16.3 percentage points on two difficult directional entailment datasets, while raising average precision and maintaining model explainability. Further, in a QA task we show that EG smoothing is most useful for answering questions with lesser supporting text, where missing premise predicates are more costly. Finally, controlled experiments with WordNet confirm our theory and show that hypothesis smoothing is difficult, but possible in principle. 1"
    },
    {
        "title": "FastRAT: Fast and Efficient Cross-lingual Text-to-SQL Semantic Parsing",
        "authors": [
            "Pavlos Vougiouklis",
            "Nikos Papasarantopoulos",
            "Danna Zheng",
            "David Tuckey",
            "Chenxin Diao",
            "Zhili Shen",
            "Jeff Pan"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.38.pdf",
        "abstract": "Recent advances of large pre-trained language models have motivated significant breakthroughs in various Text-to-SQL tasks. However, a number of challenges inhibit the deployment of SQL parsers in commercial applications. In this paper, we focus on two such challenges: decoding speed and multilingual input, and introduce FastRAT, a model that includes (i) a decoder-free framework to quickly generate SQL queries from natural language questions based on SQL Semantic Predictions, (ii) a cross-lingual multi-task pre-training scheme, and (iii) a method, based on distant supervision, to extend a semantic parser to new languages.We apply FastRAT on CSpider and Spider, two challenging zero-shot semantic parsing benchmarks. Our system achieves an average of 10x decoding speedup over a set of competitive baselines based on auto-or semi-autoregressive decoding. In the cross-lingual CSpider dataset, our approach achieves an exact query match accuracy score of 61.3, outperforming the relevant competition. In the monolingual task, it maintains competitive performance by exhibiting < 5% accuracy drop compared to disproportionately slower solutions."
    },
    {
        "title": "ProMap: Effective Bilingual Lexicon Induction via Language Model Prompting",
        "authors": [
            "Abdellah El Mekki",
            "Muhammad Abdul-Mageed",
            "ElMoatez Billah Nagoudi",
            "Ismail Berrada",
            "Ahmed Khoumsi"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.39.pdf",
        "abstract": "Bilingual Lexicon Induction (BLI), where words are translated between two languages, is an important NLP task. While noticeable progress on BLI in rich resource languages using static word embeddings has been achieved. The word translation performance can be further improved by incorporating information from contextualized word embeddings. In this paper, we introduce ProMap, a novel approach for BLI that leverages the power of prompting pretrained multilingual and multidialectal language models to address these challenges. To overcome the employment of subword tokens in these models, ProMap relies on an effective padded prompting of language models with a seed dictionary that achieves good performance when used independently. We also demonstrate the effectiveness of ProMap in re-ranking results from other BLI methods such as with aligned static word embeddings. When evaluated on both rich-resource and low-resource languages, ProMap consistently achieves stateof-the-art results. Furthermore, ProMap enables strong performance in few-shot scenarios (even with less than 10 training examples), making it a valuable tool for low-resource language translation. Overall, we believe our method offers both exciting and promising direction for BLI in general and low-resource languages in particular. ProMap code and data are available at https://github.com/4mekki4/promap."
    },
    {
        "title": "ConDA: Contrastive Domain Adaptation for AI-generated Text Detection",
        "authors": [
            "Amrita Bhattacharjee",
            "Tharindu Kumarage",
            "Raha Moraffah",
            "Huan Liu"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.40.pdf",
        "abstract": "Large language models (LLMs) are increasingly being used for generating text in a variety of use cases, including journalistic news articles. Given the potential malicious nature in which these LLMs can be used to generate disinformation at scale, it is important to build effective detectors for such AI-generated text. Given the surge in development of new LLMs, acquiring labeled training data for supervised detectors is a bottleneck. However, there might be plenty of unlabeled text data available, without information on which generator it came from. In this work we tackle this data problem, in detecting AI-generated news text, and frame the problem as an unsupervised domain adaptation task. Here the domains are the different text generators, i.e. LLMs, and we assume we have access to only the labeled source data and unlabeled target data. We develop a Contrastive Domain Adaptation framework, called ConDA, that blends standard domain adaptation techniques with the representation power of contrastive learning to learn domain invariant representations that are effective for the final unsupervised detection task. Our experiments demonstrate the effectiveness of our framework, resulting in average performance gains of 31.7% from the best performing baselines, and within 0.8% margin of a fully supervised detector. All our code and data is available here."
    },
    {
        "title": "A Review of Datasets for Aspect-based Sentiment Analysis",
        "authors": [
            "Siva Uday Sampreeth Chebolu",
            "Franck Dernoncourt",
            "Nedim Lipka",
            "Thamar Solorio"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.41.pdf",
        "abstract": "Aspect-based sentiment analysis (ABSA) is a natural language processing problem that analyzes user-generated reviews to determine a) the target entity being reviewed, b) the highlevel aspect to which it belongs, and c) the sentiment expressed toward the targets and the aspects. Numerous yet scattered corpora for ABSA make it difficult for researchers to identify corpora best suited for a specific ABSA subtask quickly. This study presents a database of corpora that can be used to train and evaluate autonomous ABSA systems. Additionally, we provide an overview of the major corpora for ABSA and its subtasks and highlight several features that researchers should consider when selecting a corpus. Finally, we discuss the advantages and disadvantages of existing dataset collection approaches and make recommendations for future corpora creation. This survey examines 98 publicly available ABSA datasets covering over 25 domains, including 77 English and 21 other languages datasets (https://github.com/RiTUAL-UH/ ABSA-Datasets-Info)."
    },
    {
        "title": "MedRedQA for Medical Consumer Question Answering: Dataset, Tasks, and Neural Baselines",
        "authors": [
            "Vincent Nguyen",
            "Sarvnaz Karimi",
            "Maciej Rybinski",
            "Zhenchang Xing"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.42.pdf",
        "abstract": "Medical question answering for consumers aims to assist consumers in finding trustworthy and relevant information for their concerns. Although some datasets exist for consumer question answering, they use synthetic questions or present difficult-to-understand answers. We introduce MedRedQA, a large non-factoid English consumer Question Answering (QA) dataset containing 51,000 pairs of consumer questions and their corresponding expert answers. MedRedQA facilitates research that aims to provide consumer-friendly responses to realworld consumer questions. We propose and benchmark three tasks for consumer medical question answering for our dataset, including (1) candidate answer ranking, (2) open-ended answer generation, and (3) answer generation with scientific evidence. Our benchmarking experiments reveal that, for the ranking task, it is feasible to retrieve expert answers within five responses in an oracle retrieval. Though, in an answer generation task, it remains challenging to align the generation toward expert answers. However, our experiments show that including scientific evidence in the prompt may reduce hallucinations in an answer generation setup. 1"
    },
    {
        "title": "Valla: Standardizing and Benchmarking Authorship Attribution and Verification Through Empirical Evaluation and Comparative Analysis",
        "authors": [
            "Jacob Tyo",
            "Bhuwan Dhingra",
            "Zachary C. Lipton"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.43.pdf",
        "abstract": "Despite decades of research on authorship attribution (AA) and authorship verification (AV), inconsistent dataset splits/filtering and mismatched evaluation methods make it difficult to assess the state of the art. In this paper, we present a survey of the fields, resolve points of confusion, introduce VALLA that standardizes and benchmarks AA/AV datasets and metrics, provide a large-scale empirical evaluation, and provide apples-to-apples comparisons between existing methods. We evaluate eight promising methods on fifteen datasets (including distribution shifted challenge sets) and introduce a new dataset based on texts archived by Project Gutenberg. Surprisingly, we find that a traditional Ngram-based model performs best on 5 (of 7) AA tasks, achieving an average macro-accuracy of 76.50% (compared to 66.71% for a BERT-based model). However, on the two AA datasets with the greatest number of words per author, as well as on the AV datasets, BERT-based models perform best. While AV methods are easily applied to AA, they are seldom included as baselines in AA papers. We show that through the application of hard-negative mining, AV methods are competitive alternatives to AA methods. VALLA and all experiment code can be found here: https://github.com/JacobTyo/Valla"
    },
    {
        "title": "Sentiment Aided Graph Attentive Contextualization for Task Oriented Negotiation Dialogue Generation",
        "authors": [
            "Aritra Raut",
            "Sriparna Saha",
            "Anutosh Maitra",
            "Roshni Ramnani"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.44.pdf",
        "abstract": "Over the past several years, the demand and popularity of using virtual assistants to finish jobs like service scheduling and online shopping have increased. While keeping the user's request in mind, an effective task-oriented virtual agent must strive to improve the seller's profit. Therefore, in order to achieve the best possible trade-off between the parties, this form of virtual agent has to have strong negotiating abilities. Although current conversational agents are quite good at making fluent sentences, they are still unable to use strategic thinking. In order to more effectively contextualize the choice of the next set of negotiation methods while producing answers, we develop Nego-GAT, an end-to-end negotiation system that includes sentiment information and graph attention embedding into GPT-2. Our selfsupervised model outperforms earlier cuttingedge negotiation models in terms of both the precision of strategy/dialogue act prediction and the caliber of the generated dialogue responses 1 ."
    },
    {
        "title": "A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity",
        "authors": [
            "Yejin Bang",
            "Samuel Cahyawijaya",
            "Nayeon Lee",
            "Wenliang Dai",
            "Dan Su",
            "Bryan Wilie",
            "Holy Lovenia",
            "Ziwei Ji",
            "Tiezheng Yu",
            "Willy Chung",
            "Quyet V. Do",
            "Yan Xu",
            "Pascale Fung"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.45.pdf",
        "abstract": "This paper proposes a framework for quantitatively evaluating interactive LLMs such as ChatGPT using publicly available data sets, using 23 data sets covering 8 different common NLP application tasks. We extensively evaluate the multitask, multilingual, and multi-modal aspects of ChatGPT based on these data sets and a newly designed multimodal dataset. We find that ChatGPT outperforms LLMs with zeroshot learning on most tasks and even outperforms fine-tuned models on some tasks. We find that it is better at understanding non-Latin script languages than generating them. It is able to generate multimodal content from textual prompts via an intermediate code generation step. Moreover, we find that ChatGPT is 63.41% accurate on average in 10 different reasoning categories under logical reasoning, non-textual reasoning, and commonsense reasoning, hence making it an unreliable reasoner. ChatGPT suffers from hallucination problems like other LLMs. Finally, the interactive feature of ChatGPT enables human collaboration with the underlying LLM to improve its performance, i.e., 8% ROUGE-1 on summarization and 2% ChrF++ on machine translation, in a multi-turn \"prompt engineering\" fashion. We release a code for evaluation set extraction. 1 * Equal Contribution. 1 https://github.com/HLTCHKUST/chatgpt-evaluat ion References 2023. Chatgpt vs satya nadella over biryani: The chatbot is learning from its mistakes."
    },
    {
        "title": "Analyzing and Predicting Persistence of News Tweets",
        "authors": [
            "Maggie Liu",
            "Jing Wang",
            "Daniel Preotiuc-Pietro"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.46.pdf",
        "abstract": "News is read and consumed differently based on its topic and timeliness to the reader. Some stories attract readers immediately after they are published, while others capture readership consistently over multiple days after their publication, regardless of their overall popularity. This paper studies this less explored facet of news story consumption, which we name persistence, operationalized as the time for a story to reach a certain percent of its total interest. In particular, we study persistence though a novel, publicly available data set of news tweets from 353 news outlets. We perform an extensive linguistic analysis of persistence in social media to uncover the underlying topical and stylistic cues that impact short-or long-term interest in a story. We train several models for predicting persistence that achieve predictive performance of up to 0.353 Spearman correlation when extrapolating to tweets from days unseen in training and retain significant predictive performance even on tweets from accounts unseen in training. The ability to predict news persistence can be useful in several practical applications that drive news and social media consumption including alerting, search ranking or recommendations."
    },
    {
        "title": "Only 5% Attention Is All You Need: Efficient Long-range Document-level Neural Machine Translation",
        "authors": [
            "Zihan Liu",
            "Zewei Sun",
            "Shanbo Cheng",
            "Shujian Huang",
            "Mingxuan Wang"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.47.pdf",
        "abstract": "Document-level Neural Machine Translation (DocNMT) has been proven crucial for handling discourse phenomena by introducing document-level context information. One of the most important directions is to input the whole document directly to the standard Transformer model. In this case, efficiency becomes a critical concern due to the quadratic complexity of the attention module. Existing studies either focus on the encoder part, which cannot be deployed on sequence-to-sequence generation tasks, e.g., Machine Translation (MT), or suffer from a significant performance drop. In this work, we keep the translation performance while gaining 20% speed up by introducing extra selection layer based on lightweight attention that selects a small portion of tokens to be attended. It takes advantage of the original attention to ensure performance and dimension reduction to accelerate inference. Experimental results show that our method could achieve up to 95% sparsity (only 5% tokens attended) approximately, and save 93% computation cost on the attention module compared with the original Transformer, while maintaining the performance. * * Work was done while Z. Liu was an intern at ByteDance."
    },
    {
        "title": "Uncertainty Estimation for Debiased Models: Does Fairness Hurt Reliability?",
        "authors": [
            "Gleb Kuzmin",
            "Artem Vazhentsev",
            "Artem Shelmanov",
            "Xudong Han",
            "Simon Suster",
            "Maxim Panov",
            "Alexander Panchenko",
            "Timothy Baldwin"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.48.pdf",
        "abstract": "When deploying a machine learning model, one should aim not only to optimize performance metrics such as accuracy but also care about model fairness and reliability. Fairness means that the model is prevented from learning spurious correlations between a target variable and socio-economic attributes, and is generally achieved by applying debiasing techniques. Model reliability stems from the ability to determine whether we can trust model predictions for the given data. This can be achieved using uncertainty estimation (UE) methods. Debiasing and UE techniques potentially interfere with each other, raising the question of whether we can achieve both reliability and fairness at the same time. This work aims to answer this question empirically based on an extensive series of experiments combining state-of-the-art UE and debiasing methods, and examining the impact on model performance, fairness, and reliability. 1 * Research was conducted while working at TII."
    },
    {
        "title": "Semi-supervised News Discourse Profiling with Contrastive Learning",
        "authors": [
            "Ming Li",
            "Ruihong Huang"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.49.pdf",
        "abstract": "News Discourse Profiling seeks to scrutinize the event-related role of each sentence in a news article and has been proven useful across various downstream applications. Specifically, within the context of a given news discourse, each sentence is assigned to a pre-defined category contingent upon its depiction of the news event structure. However, existing approaches suffer from an inadequacy of available human-annotated data, due to the laborious and time-intensive nature of generating discourselevel annotations. In this paper, we present a novel approach, denoted as Intra-document Contrastive Learning with Distillation (ICLD), for addressing the news discourse profiling task, capitalizing on its unique structural characteristics. Notably, we are the first to apply a semi-supervised methodology within this task paradigm, and evaluation demonstrates the effectiveness of the presented approach. Codes, models, and data will be available. 1"
    },
    {
        "title": "Target-Aware Contextual Political Bias Detection in News",
        "authors": [
            "Iffat Maab",
            "Edison Marrese-Taylor",
            "Yutaka Matsuo"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.50.pdf",
        "abstract": "Media bias detection requires comprehensive integration of information derived from multiple news sources. Sentence-level political bias detection in news is no exception, and has proven to be a challenging task that requires an understanding of bias in consideration of the context. Inspired by the fact that humans exhibit varying degrees of writing styles, resulting in a diverse range of statements with different local and global contexts, previous work in media bias detection has proposed augmentation techniques to exploit this fact. Despite their success, we observe that these techniques introduce noise by over-generalizing bias context boundaries, which hinders performance. To alleviate this issue, we propose techniques to more carefully search for context using a bias-sensitive, target-aware approach for data augmentation. Comprehensive experiments on the well-known BASIL dataset show that when combined with pre-trained models such as BERT, our augmentation techniques lead to state-of-the-art results. Our approach outperforms previous methods significantly, obtaining an F1-score of 58.15 over state-of-the-art bias detection task."
    },
    {
        "title": "Controllable Discovery of Intents: Incremental Deep Clustering Using Semi-Supervised Contrastive Learning",
        "authors": [
            "Mrinal Rawat",
            "Hithesh Sankararaman",
            "Victor Barres"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.51.pdf",
        "abstract": "Deriving value from a conversational AI system depends on the capacity of a user to translate the prior knowledge into a configuration. In most cases, discovering the set of relevant turn-level speaker intents is often one of the key steps. Purely unsupervised algorithms provide a natural way to tackle discovery problems but make it difficult to incorporate constraints and only offer very limited control over the outcomes. Previous work has shown that semisupervised (deep) clustering techniques can allow the system to incorporate prior knowledge and constraints in the intent discovery process. However they did not address how to allow for control through human feedback. In our Controllable Discovery of Intents (CDI) framework domain and prior knowledge are incorporated using a sequence of unsupervised contrastive learning on unlabeled data followed by finetuning on partially labeled data, and finally iterative refinement of clustering and representations through repeated clustering and pseudolabel fine-tuning. In addition, we draw from continual learning literature and use learningwithout-forgetting to prevent catastrophic forgetting across those training stages. Finally, we show how this deep-clustering process can become part of an incremental discovery strategy with human-in-the-loop. We report results on both CLINC and BANKING datasets. CDI outperforms previous works by a significant margin: 10.26% and 11.72% respectively.Customer: Hello, I recently received my new credit card, and I'd like to activate it. Agent: Hi there! Could you please provide me with your card number for verification? Customer: Here's my card number : XXXX-XXXX-XXXX-XXXX Agent: Great, thank you for providing you details. Your card is now successfully activated. Is there anything else I can assist you with today? Customer: Yes, actually. I was trying to transfer money to a beneficiary, but I received a message that the beneficiary is not allowed. Can you help me understand why? Agent : Of course, I'd be happy to help. To better assist you, could you please provide me with the beneficiary's account number and the error message you received? Customer: ….."
    },
    {
        "title": "Benchmarking Procedural Language Understanding for Low-Resource Languages: A Case Study on Turkish",
        "authors": [
            "Arda Uzunoglu",
            "Gözde Şahin"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.52.pdf",
        "abstract": "Understanding procedural natural language (e.g., step-by-step instructions) is a crucial step to execution and planning. However, while there are ample corpora and downstream tasks available in English, the field lacks such resources for most languages. To address this gap, we conduct a case study on Turkish procedural texts. We first expand the number of tutorials in Turkish wikiHow from 2,000 to 52,000 using automated translation tools, where the translation quality and loyalty to the original meaning are validated by a team of experts on a random set. Then, we generate several downstream tasks on the corpus, such as linking actions, goal inference, and summarization. To tackle these tasks, we implement strong baseline models via fine-tuning large language-specific models such as TR-BART and BERTurk, as well as multilingual models such as mBART, mT5, and XLM. We find that language-specific models consistently outperform their multilingual models by a significant margin across most procedural language understanding (PLU) tasks. We release our corpus, downstream tasks and the baseline models with https://github.com/ GGLAB-KU/turkish-plu. *The work was done while the first author was at Eskişehir Bahçeşehir College."
    },
    {
        "title": "LexicoMatic: Automatic Creation of Multilingual Lexical-Semantic Dictionaries",
        "authors": [
            "Federico Martelli",
            "Luigi Procopio",
            "Edoardo Barba",
            "Roberto Navigli"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.53.pdf",
        "abstract": "Lexical-semantic resources such as wordnets and multilingual dictionaries often suffer from significant coverage issues, especially in languages other than English. While improving their coverage manually is a prohibitively expensive undertaking, current approaches to the automatic creation of such resources fail to investigate the latest advances achieved in relevant fields, such as cross-lingual annotation projection. In this work, we address these shortcomings and propose LEXICOMATIC, a novel resource-independent approach to the automatic construction and expansion of multilingual semantic dictionaries, in which we formulate the task as an annotation projection problem. In addition, we tackle the lack of a comprehensive multilingual evaluation framework and put forward a new entirely manually-curated benchmark featuring 9 languages. We evaluate LEXICOMATIC with an extensive array of experiments and demonstrate the effectiveness of our approach, achieving a new state of the art across all languages under consideration. We release our novel evaluation benchmark at: https://github.com/SapienzaNLP/lexicomatic."
    },
    {
        "title": "FiRo: Finite-context Indexing of Restricted Output Space for NLP Models Facing Noisy Input",
        "authors": [
            "Minh Nguyen",
            "Nancy Chen"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.54.pdf",
        "abstract": "NLP models excel on tasks with clean inputs, but are less accurate with noisy inputs. In particular, character-level noise such as humanwritten typos and adversarially-engineered realistic-looking misspellings often appears in text and can easily trip up NLP models. Prior solutions to address character-level noise often alter the content of the inputs (low fidelity), thus inadvertently lowering model accuracy on clean inputs. We proposed FiRo, an approach to boost NLP model performance on noisy inputs without sacrificing performance on clean inputs. FiRo sanitizes the input text while preserving its fidelity by inferring the noise-free form for each token in the input. FiRo uses finite-context aggregation to obtain contextual embeddings which is then used to find the noise-free form within a restricted output space. The output space is restricted to a small cluster of probable candidates in order to predict the noise-free tokens more accurately. Although the clusters are small, FiRo's effective vocabulary (union of all clusters) can be scaled up to better preserve the input content. Experimental results show NLP models that use FiRo outperforming baselines on six classification tasks and one sequence labeling task at various degrees of noise 1 ."
    },
    {
        "title": "Implicit Affordance Acquisition via Causal Action–Effect Modeling in the Video Domain",
        "authors": [
            "Hsiu-Yu Yang",
            "Carina Silberer"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.55.pdf",
        "abstract": "Affordance knowledge is a fundamental aspect of commonsense knowledge. Recent findings indicate that world knowledge emerges through large-scale self-supervised pretraining, motivating our exploration of acquiring affordance knowledge from the visual domain. To this end, we augment an existing instructional video resource to create the new Causal Action-Effect (CAE) dataset 1 and design two novel pretraining tasks-Masked Action Modeling (MAM) and Masked Effect Modeling (MEM)promoting the acquisition of two affordance properties in models: behavior and entity equivalence, respectively. We empirically demonstrate the effectiveness of our proposed methods in learning affordance properties. Furthermore, we show that a model pretrained on both tasks outperforms a strong image-based visuallinguistic foundation model (FLAVA) as well as pure linguistic models on a zero-shot physical reasoning probing task."
    },
    {
        "title": "Prover: Generating Intermediate Steps for NLI with Commonsense Knowledge Retrieval and Next-Step Prediction",
        "authors": [
            "Deepanway Ghosal",
            "Somak Aditya",
            "Monojit Choudhury"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.56.pdf",
        "abstract": "The Natural Language Inference (NLI) task often requires reasoning over multiple steps to reach the conclusion. While the necessity of generating such intermediate steps (instead of a summary explanation) has gained popular support, it is unclear how to generate such steps without complete end-to-end supervision and how such generated steps can be further utilized. In this work, we train and enhance a sequence-to-sequence next-step prediction model with external commonsense knowledge and search to generate intermediate steps with limited next-step supervision. We show the correctness of such generated steps through human verification, on MNLI and MED datasets (and discuss the limitations through qualitative examples). We show that such generated steps can help improve end-to-end NLI task performance using simple data augmentation strategies. Using a CHECKLIST dataset for NLI, we also explore the effect of augmentation on specific reasoning types. The code and human-evaluation dataset is available at https://github.com/deepanwayx/prover."
    },
    {
        "title": "Exploring the Impact of Training Data Distribution and Subword Tokenization on Gender Bias in Machine Translation",
        "authors": [
            "Bar Iluz",
            "Tomasz Limisiewicz",
            "Gabriel Stanovsky",
            "David Mareček"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.57.pdf",
        "abstract": "We study the effect of tokenization on gender bias in machine translation, an aspect that has been largely overlooked in previous works. Specifically, we focus on the interactions between the frequency of gendered profession names in training data, their representation in the subword tokenizer's vocabulary, and gender bias. We observe that female and nonstereotypical gender inflections of profession names (e.g., Spanish \"doctora\" for \"female doctor\") tend to be split into multiple subword tokens. Our results indicate that the imbalance of gender forms in the model's training corpus is a major factor contributing to gender bias and has a greater impact than subword splitting. We show that analyzing subword splits provides good estimates of gender-form imbalance in the training data and can be used even when the corpus is not publicly available. We also demonstrate that fine-tuning just the token embedding layer can decrease the gap in gender prediction accuracy between female and male forms without impairing the translation quality.1 * Equal contribution. † Work partially done while visiting the Hebrew University."
    },
    {
        "title": "GrailQA++: A Challenging Zero-Shot Benchmark for Knowledge Base Question Answering",
        "authors": [
            "Ritam Dutt",
            "Sopan Khosla",
            "Vinayshekhar Bannihatti Kumar",
            "Rashmi Gangadharaiah"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.58.pdf",
        "abstract": "Most benchmarks designed for question answering over knowledge bases (KBQA) operate with the i.i.d. assumption where one encounters the same schema items during inference as those observed during training. Recently, the GrailQA dataset was established to evaluate zero-shot generalization capabilities of KBQA models as a departure from the i.i.d. assumption. Reasonable performance of current KBQA systems on the zero-shot GrailQA split hints that the field might be moving towards more generalizable systems. In this work, we observe a bias in the GrailQA dataset towards simpler one or two-hop questions, which results in an inaccurate assessment of the aforementioned prowess. We propose GrailQA++, a challenging zero-shot KBQA test set that contains more questions relying on complex reasoning. We leverage the concept of graph isomorphisms to control the complexity of the questions and to ensure that our proposed test set has a fair distribution of simple and complex questions. Existing KBQA models suffer a substantial drop in performance on our constructed new test set as compared to the GrailQA zero-shot split. Our analysis reveals how isomorphisms can be used to understand the complementary strengths of different KBQA models and provide a deeper insight into model mispredictions. Overall, our paper highlights the non-generalizability of existing models and the necessity for designing more challenging benchmarks. Our dataset is available at https://github.com/sopankhosla/ GrailQA-PlusPlus * Work conducted during an internship at Amazon."
    },
    {
        "title": "Model-based Subsampling for Knowledge Graph Completion",
        "authors": [
            "Xincan Feng",
            "Hidetaka Kamigaito",
            "Katsuhiko Hayashi",
            "Taro Watanabe"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.59.pdf",
        "abstract": "Subsampling is effective in Knowledge Graph Embedding (KGE) for reducing overfitting caused by the sparsity in Knowledge Graph (KG) datasets. However, current subsampling approaches consider only frequencies of queries that consist of entities and their relations. Thus, the existing subsampling potentially underestimates the appearance probabilities of infrequent queries even if the frequencies of their entities or relations are high.To address this problem, we propose Modelbased Subsampling (MBS) and Mixed Subsampling (MIX) to estimate their appearance probabilities through predictions of KGE models. Evaluation results on datasets FB15k-237, WN18RR, and YAGO3-10 showed that our proposed subsampling methods actually improved the KG completion performances for popular KGE models, RotatE, TransE, HAKE, Com-plEx, and DistMult."
    },
    {
        "title": "NusaWrites: Constructing High-Quality Corpora for Underrepresented and Extremely Low-Resource Languages",
        "authors": [
            "Samuel Cahyawijaya",
            "Holy Lovenia",
            "Fajri Koto",
            "Dea Adhista",
            "Emmanuel Dave",
            "Sarah Oktavianti",
            "Salsabil Akbar",
            "Jhonson Lee",
            "Nuur Shadieq",
            "Tjeng Wawan Cenggoro",
            "Hanung Linuwih",
            "Bryan Wilie",
            "Galih Muridan",
            "Genta Winata",
            "David Moeljadi",
            "Alham Fikri Aji",
            "Ayu Purwarianti",
            "Pascale Fung"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.60.pdf",
        "abstract": "Democratizing access to natural language processing (NLP) technology is crucial, especially for underrepresented and extremely lowresource languages. Previous research has focused on developing labeled and unlabeled corpora for these languages through online scraping and document translation. While these methods have proven effective and costefficient, we have identified limitations in the resulting corpora, including a lack of lexical diversity and cultural relevance to local communities. To address this gap, we conduct a case study on Indonesian local languages. We compare the effectiveness of online scraping, human translation, and paragraph writing by native speakers in constructing datasets. Our findings demonstrate that datasets generated through paragraph writing by native speakers exhibit superior quality in terms of lexical diversity and cultural content. In addition, we present the NusaWrites benchmark, encompassing 12 underrepresented and extremely lowresource languages spoken by millions of individuals in Indonesia. Our empirical experiment results using existing multilingual large language models emphasize the need to extend these models to more underrepresented languages. We release the NusaWrites dataset 1 and code involved in our experiment at https: //github.com/IndoNLP/nusa-writes."
    },
    {
        "title": "The Persuasive Memescape: Understanding Effectiveness and Societal Implications of Internet Memes",
        "authors": [
            "Gitanjali Kumari",
            "Pranali Shinde",
            "Asif Ekbal"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.61.pdf",
        "abstract": "Persuasive meme identification is a crucial task in automatically categorizing memes based on their persuasive nature. Memes, being highly influential in online communication, have the ability to shape individuals' attitudes, behaviors, and beliefs, both positively and negatively. They can be utilized to promote positive actions, challenge social norms, and raise awareness, but they can also perpetuate harmful ideologies, spread misinformation, stereotype, and manipulate emotions. In this paper, we are addressing this challenge by empirically investigating three novel tasks, viz. (i) Task 1: Persuasive meme detection, (ii) Task 2: Identification of the effectiveness of persuasive memes, and (iii) Task 3: Identification of persuasion techniques used in persuasive memes. To this end, we make the very first attempt to release a highquality, large-scale dataset, Persuasive_meme 1 , since there is no publicly available such dataset for the Hindi-English code-mixed (Hinglish) domain. 2 We further developed several baseline unimodal and multimodal models for these tasks. Empirical evaluation with respect to both, qualitative and quantitative analysis, on the Persuasive_meme dataset highlight the significance of multimodality in addressing these tasks effectively. Additionally, we discuss the limitations of the current models and emphasize the need for further research to overcome these challenges."
    },
    {
        "title": "Generation of Korean Offensive Language by Leveraging Large Language Models via Prompt Design",
        "authors": [
            "Jisu Shin",
            "Hoyun Song",
            "Huije Lee",
            "Fitsum Gaim",
            "Jong Park"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.62.pdf",
        "abstract": "Warning: This paper contains content that can be offensive or upsetting.The research for detecting offensive language on online platforms has much advanced. However, the majority of these studies have primarily focused on English. Given the unique characteristics of offensive language, where social and cultural contexts significantly influence content understanding, language-specific datasets are essential. Acquiring comprehensive datasets in Korean, a less-resourced language, has mostly relied on human annotations, suffering from inherent limitations in terms of labor intensity and potential annotator bias. Automatic generation of datasets using generative methods offers an alternative approach to address these limitations, yet faces challenges in capturing linguistic and cultural diversities while maintaining native-level fluency. To address these challenges, we introduce a prompt design methodology, Korean Offensive language Machine Generation (K-OMG), using large language models. By manipulating three prompt factors, we find an effective prompt design to generate culturally aligned offensive language with fluent expressions. Experimental results demonstrate the high quality and utility of our automatically generated dataset. Our detailed analysis shows that the proposed approach achieves exceptional fluency in generating texts while effectively incorporating social and cultural diversities."
    },
    {
        "title": "PICK: Polished & Informed Candidate Scoring for Knowledge-Grounded Dialogue Systems",
        "authors": [
            "Bryan Wilie",
            "Yan Xu",
            "Willy Chung",
            "Samuel Cahyawijaya",
            "Holy Lovenia",
            "Pascale Fung"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.63.pdf",
        "abstract": "Grounding dialogue response generation on external knowledge is proposed to produce informative and engaging responses. However, current knowledge-grounded dialogue (KGD) systems often fail to align the generated responses with human-preferred qualities due to several issues like hallucination and the lack of coherence. Upon analyzing multiple language model generations, we observe the presence of alternative generated responses within a single decoding process. These alternative responses are more faithful and exhibit a comparable or higher level of relevance to prior conversational turns compared to the optimal responses prioritized by the decoding processes. To address these challenges and driven by these observations, we propose Polished & Informed Candidate Scoring (PICK), a generation re-scoring framework that empowers models to generate faithful and relevant responses without requiring additional labeled data or model tuning. Through comprehensive automatic and human evaluations, we demonstrate the effectiveness of PICK in generating responses that are more faithful while keeping them relevant to the dialogue history. Furthermore, PICK consistently improves the system's performance with both oracle and retrieved knowledge in all decoding strategies. We provide the detailed implementation in 1 ."
    },
    {
        "title": "Towards LLM-based Fact Verification on News Claims with a Hierarchical Step-by-Step Prompting Method",
        "authors": [
            "Xuan Zhang",
            "Wei Gao"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.64.pdf",
        "abstract": "While large pre-trained language models (LLMs) have shown their impressive capabilities in various NLP tasks, they are still underexplored in the misinformation domain. In this paper, we examine LLMs with in-context learning (ICL) for news claim verification, and find that only with 4-shot demonstration examples, the performance of several prompting methods can be comparable with previous supervised models. To further boost performance, we introduce a Hierarchical Step-by-Step (HiSS) prompting method which directs LLMs to separate a claim into several subclaims and then verify each of them via multiple questionsanswering steps progressively. Experiment results on two public misinformation datasets show that HiSS prompting outperforms stateof-the-art fully-supervised approach and strong few-shot ICL-enabled baselines.Chain-of-Thought Promp1ngClaim: Professor Lieber was arrested for hiding funds from a Chinese lab tied to the new coronavirus.Professor Lieber was arrested due to alleged funds from WUT and ties to a Chinese government program, unrelated to the novel coronavirus. Among [label set], the claim is classified as false.Claim: Donald Trump has said he loves war, \"including with nukes.\"Human fact checker: half-true.Vanilla CoT output: true.During his term as the 45th President of the US, Donald Trump gave speeches proclaiming his love for war. Among [label set], the claim is classified as true.Trump did say the phrase \"I love war in a certain way\" . But regarding 'including nukes', he suggested Japan could benefit from having them, not the US using them."
    },
    {
        "title": "Retrieval Augmented Generation with Rich Answer Encoding",
        "authors": [
            "Wenyu Huang",
            "Mirella Lapata",
            "Pavlos Vougiouklis",
            "Nikos Papasarantopoulos",
            "Jeff Pan"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.65.pdf",
        "abstract": "Knowledge-intensive generation tasks like generative question answering require models to retrieve appropriate passages from external knowledge sources to support answer generation. The generation quality relies heavily on the retrieved passages, which serve as contextual information. State-of-the-art Retrieval Augmented Generation models with marginalized output dominate this area but focus too much on label-relevant passages, rather than question-relevant passages and answers. This work addresses this issue by incorporating rich answer encoding through Dense Knowledge Similarity (DKS) and Retriever as Answer Classifier (RAC). We demonstrate the advantages of our proposed approach in open domain question answering (MSMARCO) and conversation (Wizard of Wikipedia) datasets, reporting both generation and retrieval metrics. In the MSMARCO development set, our best model achieves 12.1% relative improvement 1 on Recall@1 and 4.5% relative improvement on BLEU-4 compared to the baseline model. In the KILT-WoW leaderboard, our best model achieves 8.9% relative improvement on R-Precision and 13.3% relative improvement on KILT-RL compared to the baseline model. Our codes and models are available at https://github.com/hwy9855/rag-ae. * Work done while at Huawei Edinburgh Research Centre. † Corresponding author. 1 In this paper, we mainly report relative improvement for better comparison between different methods.Question: Definition of tactful personality Reference Answer (label): Tactful is someone or something that shows a regard for other people's feelings."
    },
    {
        "title": "Examining Consistency of Visual Commonsense Reasoning based on Person Grounding",
        "authors": [
            "Huiju Kim",
            "Youjin Kang",
            "SangKeun Lee"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.66.pdf",
        "abstract": "Given an image depicting multiple individuals, humans are capable of inferring each individual's emotions, intentions, and social norms based on commonsense understanding. However, a machine's ability of commonsense reasoning about distinct individuals in images remains underexplored. In this study, we examine the consistency of visual commonsense reasoning based on person grounding. We introduce a novel test dataset called Visual Commonsense Reasoning-Contrast Sets (VCR-CS) to evaluate whether models can reason about individual people in an image by changing the person tags in the questions and answers. We benchmark various vision-language models on VCR-CS and observe that they fail in consistent commonsense reasoning about different people in one image, showing a performance decrease of up to 31.5%. To mitigate such failures, we propose a multi-task learning framework called Personcentric groundIng eNhanced Tuning (PINT). Our framework enhances a model's ability to perform person-grounded commonsense reasoning by leveraging two novel person-centric pretraining tasks: Image Person-based Text Matching and Person-Masked Language Modeling. The experimental results revealed the effectiveness of PINT by showing the lowest performance degradation on VCR-CS and the improvements in consistency and sensitivity metrics. Our dataset and code are publicly available 1 ."
    },
    {
        "title": "Self-Consistent Narrative Prompts on Abductive Natural Language Inference",
        "authors": [
            "Chunkit Chan",
            "Xin Liu",
            "Tsz Ho Chan",
            "Jiayang Cheng",
            "Yangqiu Song",
            "Ginny Wong",
            "Simon See"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.67.pdf",
        "abstract": "Abduction has long been seen as crucial for narrative comprehension and reasoning about everyday situations. The abductive natural language inference (αNLI) task has been proposed, and this narrative text-based task aims to infer the most plausible hypothesis from the candidates given two observations. However, the inter-sentential coherence and the model consistency have not been well exploited in the previous works on this task. In this work, we propose a prompt tuning model α-PACE 1 , which takes self-consistency and intersentential coherence into consideration. Besides, we propose a general self-consistent framework that considers various narrative sequences (e.g., linear narrative and reverse chronology) for guiding the pre-trained language model in understanding the narrative context of input. We conduct extensive experiments and thorough ablation studies to illustrate the necessity and effectiveness of α-PACE. The performance of our method shows significant improvement against extensive competitive baselines."
    },
    {
        "title": "KoBigBird-large: Transformation of Transformer for Korean Language Understanding",
        "authors": [
            "Kisu Yang"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.68.pdf",
        "abstract": "This work presents KoBigBird-large, a large size of Korean BigBird that achieves state-ofthe-art performance and allows long sequence processing for Korean language understanding. Without further pretraining, we only transform the architecture and extend the positional encoding with our proposed Tapered Absolute Positional Encoding Representations (TAPER). In experiments, KoBigBird-large shows stateof-the-art overall performance on Korean language understanding benchmarks and the best performance on document classification and question answering tasks for longer sequences against the competitive baseline models. We publicly release our model here 1 ."
    },
    {
        "title": "Reranking for Natural Language Generation from Logical Forms: A Study based on Large Language Models",
        "authors": [
            "Levon Haroutunian",
            "Zhuang Li",
            "Lucian Galescu",
            "Philip Cohen",
            "Raj Tumuluri",
            "Gholamreza Haffari"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.69.pdf",
        "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in natural language generation. However, their output quality can be inconsistent, posing challenges for generating natural language from logical forms (LFs). This task requires the generated outputs to embody the exact semantics of LFs, without missing any LF semantics or creating any hallucinations. In this work, we tackle this issue by proposing a novel generate-and-rerank approach. Our approach involves initially generating a set of candidate outputs by prompting an LLM and subsequently reranking them using a task-specific reranker model. In addition, we curate a manually collected dataset to evaluate the alignment between different ranking metrics and human judgements. The chosen ranking metrics are utilized to enhance the training and evaluation of the reranker model. By conducting extensive experiments on three diverse datasets, we demonstrate that the candidates selected by our reranker outperform those selected by baseline methods in terms of semantic consistency and fluency, as measured by three comprehensive metrics. Our findings provide strong evidence for the effectiveness of our approach in improving the quality of generated outputs."
    },
    {
        "title": "Exploring Methods for Cross-lingual Text Style Transfer: The Case of Text Detoxification",
        "authors": [
            "Daryna Dementieva",
            "Daniil Moskovskiy",
            "David Dale",
            "Alexander Panchenko"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.70.pdf",
        "abstract": "Text detoxification is the task of transferring the style of text from toxic to neutral. While there are approaches yielding promising results in monolingual setup, e.g.,(Dale et al., 2021;Hallinan et al., 2022), cross-lingual transfer for this task remains a challenging open problem(Moskovskiy et al., 2022). In this work, we present a large-scale study of strategies for cross-lingual text detoxification -given a parallel detoxification corpus for one language; the goal is to transfer detoxification ability to another language for which we do not have such a corpus. Moreover, we are the first to explore a new task where text translation and detoxification are performed simultaneously, providing several strong baselines for this task. Finally, we introduce new automatic detoxification evaluation metrics with higher correlations with human judgments than previous benchmarks. We assess the most promising approaches also with manual markup, determining the answer for the best strategy to transfer the knowledge of text detoxification between languages."
    },
    {
        "title": "PACT: Pretraining with Adversarial Contrastive Learning for Text Classification",
        "authors": [
            "Md Tawkat Islam Khondaker",
            "Muhammad Abdul-Mageed",
            "Laks Lakshmanan, V.S."
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.71.pdf",
        "abstract": "We present PACT (Pretraining with Adversarial Contrastive Learning for Text Classification), a novel self-supervised framework for text classification. Instead of contrasting against inbatch negatives, a popular approach in the literature, PACT mines negatives closer to the anchor representation. PACT operates by endowing the standard pretraining mechanisms of BERT with adversarial contrastive learning objectives, allowing for effective joint optimization of token-and sentence-level pretraining of the BERT model. Our experiments on 13 diverse datasets including token-level, singlesentence, and sentence-pair text classification tasks show that PACT achieves consistent improvements over SOTA baselines. We further show that PACT regularizes both token-level and sentence-level embedding spaces into more uniform representations, thereby alleviating the undesirable anisotropic phenomenon of language models. 1"
    },
    {
        "title": "VACASPATI: A Diverse Corpus of Bangla Literature",
        "authors": [
            "Pramit Bhattacharyya",
            "Joydeep Mondal",
            "Subhadip Maji",
            "Arnab Bhattacharya"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-main.72.pdf",
        "abstract": "Bangla (or Bengali) is the fifth most spoken language globally; yet, the state-of-the-art NLP in Bangla is lagging for even simple tasks such as lemmatization, POS tagging, etc. This is partly due to lack of a varied quality corpus. To alleviate this need, we build V ĀCASPATI, a diverse corpus of Bangla literature. The literary works are collected from various websites; only those works that are publicly available without copyright violations or restrictions are collected. We believe that published literature captures the features of a language much better than newspapers, blogs or social media posts which tend to follow only a certain literary pattern and, therefore, miss out on language variety and vocabulary. Our corpus V ĀCASPATI is varied from multiple aspects, including type of composition, topic, author, time, space, etc. It contains more than 11 million sentences and 115 million words. We have also built a word embedding model, V ĀC-FT, using Fast-Text from V ĀCASPATI as well as trained an Electra model, V ĀC-BERT, using the corpus. V ĀC-BERT has far fewer parameters and requires only a fraction of resources compared to other state-of-the-art transformer models and yet performs either better or similar on various downstream tasks. Similarly, V ĀC-FT outperforms other FastText-based models on multiple downstream tasks. We also demonstrate the efficacy of V ĀCASPATI as a corpus by showing that similar models built from other corpora are not as effective. The models are available at https://bangla.iitk.ac.in/ projects/vacaspati.html."
    },
    {
        "title": "Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics (Volume 2: Short Papers)",
        "authors": [
            "Jong C. Park",
            "Yuki Arase",
            "Baotian Hu",
            "Wei Lu",
            "Derry Wijaya",
            "Ayu Purwarianti",
            "Adila Alfa Krisnadhi"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-short.0.pdf",
        "abstract": "The joint conferences of IJCNLP and AACL are organized by alternating leadership in the Asia-Pacific region, in odd years by Asian Federation of Natural Language Processing (AFNLP) and in even years by AACL, except when the annual meetings of ACL are offered in the region every three years, in which case the conferences will be offered and organized solely by ACL. This year, the conference is organized by AFNLP."
    },
    {
        "title": "Self-Augmentation Improves Zero-Shot Cross-Lingual Transfer",
        "authors": [
            "Fei Wang",
            "Kuan-Hao Huang",
            "Kai-Wei Chang",
            "Muhao Chen"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-short.1.pdf",
        "abstract": "Zero-shot cross-lingual transfer is a central task in multilingual NLP, allowing models trained in languages with more sufficient training resources to generalize to other low-resource languages. Earlier efforts on this task use parallel corpora, bilingual dictionaries, or other annotated alignment data to improve cross-lingual transferability, which are typically expensive to obtain. In this paper, we propose a simple yet effective method, SALT, to improve the zero-shot cross-lingual transfer of the multilingual pretrained language models without the help of such external data. By incorporating code-switching and embedding mixup with self-augmentation, SALT effectively distills cross-lingual knowledge from the multilingual PLM and enhances its transferability on downstream tasks. Experimental results on XNLI and PAWS-X show that our method is able to improve zero-shot cross-lingual transferability without external data. 1"
    },
    {
        "title": "Learning to Predict Concept Ordering for Common Sense Generation",
        "authors": [
            "Tianhui Zhang",
            "Danushka Bollegala",
            "Bei Peng"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-short.2.pdf",
        "abstract": "Prior work has shown that the ordering in which concepts are shown to a commonsense generator plays an important role, affecting the quality of the generated sentence. However, it remains a challenge to determine the optimal ordering of a given set of concepts such that a natural sentence covering all the concepts could be generated from a pretrained generator. To understand the relationship between the ordering of the input concepts and the quality of the generated sentences, we conduct a systematic study considering multiple language models (LMs) and concept ordering strategies. We find that BART-large model consistently outperforms all other LMs considered in this study when fine-tuned using the ordering of concepts as they appear in CommonGen training data as measured using multiple evaluation metrics. Moreover, the larger GPT3-based large language models (LLMs) variants do not necessarily outperform much smaller LMs on this task, even when fine-tuned on task-specific training data. Interestingly, human annotators significantly reorder input concept sets when manually writing sentences covering those concepts, and this ordering provides the best sentence generations independently of the LM used for the generation, outperforming a probabilistic concept ordering baseline. 1"
    },
    {
        "title": "SQUARE: Automatic Question Answering Evaluation using Multiple Positive and Negative References",
        "authors": [
            "Matteo Gabburo",
            "Siddhant Garg",
            "Rik Koncel-Kedziorski",
            "Alessandro Moschitti"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-short.3.pdf",
        "abstract": "Evaluation of QA systems is very challenging and expensive, with the most reliable approach being human annotations of correctness of answers for questions. Recent works (AVA, BEM) have shown that transformer LM encoder based similarity metrics transfer well for QA evaluation, but they are limited by the usage of a single correct reference answer. We propose a new evaluation metric: SQuArE (Sentence-level QUestion AnsweRing Evaluation), using multiple reference answers (combining multiple correct and incorrect references) for sentence-form QA. We evaluate SQuArE on both sentencelevel extractive (Answer Selection) and generative (GenQA) QA systems, across multiple academic and industrial datasets, and show that it outperforms previous baselines and obtains the highest correlation with human annotations."
    },
    {
        "title": "The Impact of Debiasing on the Performance of Language Models in Downstream Tasks is Underestimated",
        "authors": [
            "Masahiro Kaneko",
            "Danushka Bollegala",
            "Naoaki Okazaki"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-short.4.pdf",
        "abstract": "Pre-trained language models trained on largescale data have learned serious levels of social biases. Consequently, various methods have been proposed to debias pre-trained models. Debiasing methods need to mitigate only discriminatory bias information from the pretrained models, while retaining information that is useful for the downstream tasks. In previous research, whether useful information is retained has been confirmed by the performance of downstream tasks in debiased pretrained models. On the other hand, it is not clear whether these benchmarks consist of data pertaining to social biases and are appropriate for investigating the impact of debiasing. For example in gender-related social biases, data containing female words (e.g. \"she, female, woman\"), male words (e.g. \"he, male, man\"), and stereotypical words (e.g. \"nurse, doctor, professor\") are considered to be the most affected by debiasing. If there is not much data containing these words in a benchmark dataset for a target task, there is the possibility of erroneously evaluating the effects of debiasing. In this study, we compare the impact of debiasing on performance across multiple downstream tasks using a wide-range of benchmark datasets that containing female, male, and stereotypical words. Experiments show that the effects of debiasing are consistently underestimated across all tasks. Moreover, the effects of debiasing could be reliably evaluated by separately considering instances containing female, male, and stereotypical words than all of the instances in a benchmark dataset."
    },
    {
        "title": "Enhancing Volatility Forecasting in Financial Markets: A General Numeral Attachment Dataset for Understanding Earnings Calls",
        "authors": [
            "Ming-Xuan Shi",
            "Chung-Chi Chen",
            "Hen-Hsen Huang",
            "Hsin-Hsi Chen"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-short.5.pdf",
        "abstract": "Volatility, a crucial statistical measure in the financial market, serves as an indicator of financial instrument risk. Accurate volatility capture aids in predicting stock movements and is valuable in derivative trading, such as options trading. While recent research focuses on volatility forecasting using earnings call transcriptions, most approaches rely on end-to-end models that directly process textual or vocal data. However, limited efforts have been made to simulate the reading and comprehension processes of financial professionals, thereby enhancing the capabilities of language models. To address this gap, we propose a general numeral attachment dataset designed to train language models to understand earnings calls with the expertise of professionals. Additionally, we introduce a pre-training process that improves the semantic understanding of earnings calls. Experimental results demonstrate that our pretrained language model enhances the accuracy of 3-day volatility forecasting."
    },
    {
        "title": "Do the Benefits of Joint Models for Relation Extraction Extend to Document-level Tasks?",
        "authors": [
            "Pratik Saini",
            "Tapas Nayak",
            "Indrajit Bhattacharya"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-short.6.pdf",
        "abstract": "Two distinct approaches have been proposedfor relational triple extraction -pipeline and joint. Joint models, which capture interactions across triples, are the more recent development, and have been shown to outperform pipeline models for sentence-level extraction tasks. Document-level extraction is a more challenging setting where interactions across triples can be long-range, and individual triples can also span across sentences. Joint models have not been applied for document-level tasks so far. In this paper, we benchmark state-ofthe-art pipeline and joint extraction models on sentence-level as well as document-level datasets. Our experiments show that while joint models outperform pipeline models significantly for sentence-level extraction, their performance drops sharply below that of pipeline models for the document-level dataset."
    },
    {
        "title": "On the Challenges of Fully Incremental Neural Dependency Parsing",
        "authors": [
            "Ana Ezquerro",
            "Carlos Gómez-Rodríguez",
            "David Vilares"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-short.7.pdf",
        "abstract": "Since the popularization of BiLSTMs and Transformer-based bidirectional encoders, state-of-the-art syntactic parsers have lacked incrementality, requiring access to the whole sentence and deviating from human language processing. This paper explores whether fully incremental dependency parsing with modern architectures can be competitive. We build parsers combining strictly left-to-right neural encoders with fully incremental sequencelabeling and transition-based decoders. The results show that fully incremental parsing with modern architectures considerably lags behind bidirectional parsing, noting the challenges of psycholinguistically plausible parsing."
    },
    {
        "title": "Learning a Better Initialization for Soft Prompts via Meta-Learning",
        "authors": [
            "Yukun Huang",
            "Kun Qian",
            "Zhou Yu"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-short.8.pdf",
        "abstract": "Prompt tuning (PT) is an effective approach to adapting pre-trained language models to downstream tasks. However, prompt tuning doesn't perform well under few-shot settings due to the poor initialization. So pre-trained prompt tuning (PPT)(Gu et al., 2022)is proposed to adapt prompt tuning to few-shot settings by initializing prompts with source data. We propose Meta-learned Prompt Tuning (MetaPT) to further improve PPT's few-shot learning performance by considering latent structure within the source data. Specifically, we introduce the framework by first clustering source data into different meta-training tasks in an unsupervised manner. Then we leverage these tasks to metatrain prompts with a meta-learning algorithm. Such a process enables prompts to learn a better initialization by discovering commonalities among these meta-training tasks. We evaluate our method on seven downstream sentiment tasks. The results demonstrate that our MetaPT achieves better performance and stability than the state-of-the-art method."
    },
    {
        "title": "Issues Surrounding the Use of ChatGPT in Similar Languages: The Case of Malay and Indonesian",
        "authors": [
            "Hiroki Nomoto"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-short.9.pdf",
        "abstract": "We report a problem that one faces when using ChatGPT in similar languages, taking Malay and Indonesian as examples: ChatGPT often responds to prompts in Malay (the language with fewer speakers) in Indonesian (the language with more speakers). We examined ChatGPT's identification (LangID) ability to find out whether this language choice problem arises from LangID errors. The results show that LangID errors alone cannot explain the problem's severity. By comparing the patterns of responses to Malay prompts and those to Javanese prompts, we conclude that the problem happens mainly because ChatGPT does not treat Malay and Indonesian equally as distinct languages. Rather, it behaves as if Malay were a non-standard variety of Indonesian. We also discuss social issues the language choice problem causes and possible solutions to them."
    },
    {
        "title": "Can You Translate for Me? Code-Switched Machine Translation with Large Language Models",
        "authors": [
            "Jyotsana Khatri",
            "Vivek Srivastava",
            "Lovekesh Vig"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-short.10.pdf",
        "abstract": "Large language models (LLMs) have shown remarkable performance on a variety of multilingual NLP tasks. Code-switching is one of the most convenient styles of communication in multilingual communities. It is known to present several challenges to the existing language models and task-specific models. In this paper, we evaluate the capability of multilingual LLMs for the code-switched machine translation (CSMT) task in traditional and novel settings and present our insights. We observe that ChatGPT outperforms other LLMs and shows competitive performance to the supervised fine-tuned models. Though promising, ChatGPT shows major limitations, such as high gender bias, stereotypes, and factual inconsistencies. It further demands a multi-dimensional large-scale evaluation of the multilingual LLMs for code-switched languages.* https://github.com/mjpost/sacrebleu * We used GPT3.5-turbo May12, 2023 API version in our experiments."
    },
    {
        "title": "Efficient Zero-Shot Cross-lingual Inference via Retrieval",
        "authors": [
            "Genta Winata",
            "Lingjue Xie",
            "Karthik Radhakrishnan",
            "Yifan Gao",
            "Daniel Preotiuc-Pietro"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-short.11.pdf",
        "abstract": "Resources for building NLP applications, such as data and models, are usually only created and curated for a limited set of high resource languages. Thus, the ability to transfer knowledge to a new language is a key way in which to enable access to NLP technology for a wider population. This paper presents a framework to perform zero-shot inference in a target language by using cross-lingual retrieval from another language where limited annotated data for a comparable domain is available. Results on two large-scale multilingual datasets show that, in this setup, this framework improves over fine-tuning multilingual models or translating annotated data, and achieves results relatively close to fine-tuning the model on the target language directly. These results show that models can be transferred efficiently across languages for a given task and domain, even for languages not covered by multilingual model training approaches."
    },
    {
        "title": "Minimum Bayes’ Risk Decoding for System Combination of Grammatical Error Correction Systems",
        "authors": [
            "Vyas Raina",
            "Mark Gales"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-short.12.pdf",
        "abstract": "For sequence-to-sequence tasks it is challenging to combine individual system outputs. Further, there is also often a mismatch between the decoding criterion and the one used for assessment. Minimum Bayes' Risk (MBR) decoding can be used to combine system outputs in a manner that encourages better alignment with the final assessment criterion. This paper examines MBR decoding for Grammatical Error Correction (GEC) systems, where performance is usually evaluated in terms of edits and an associated F-score. Hence, we propose a novel MBR loss function directly linked to this form of criterion. Furthermore, an approach to expand the possible set of candidate sentences is described. This builds on a current max-voting combination scheme, as well as individual editlevel selection. Experiments on three popular GEC datasets and with state-of-the-art GEC systems demonstrate the efficacy of the proposed MBR approach. Additionally, the paper highlights how varying reward metrics within the MBR decoding framework can provide control over precision, recall, and the F-score in combined GEC systems. 1"
    },
    {
        "title": "Who Are All The Stochastic Parrots Imitating? They Should Tell Us!",
        "authors": [
            "Sagi Shaier",
            "Lawrence Hunter",
            "Katharina Kann"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-short.13.pdf",
        "abstract": "Both standalone language models (LMs) as well as LMs within downstream-task systems have been shown to generate statements which are factually untrue. This problem is especially severe for low-resource languages, where training data is scarce and of worse quality than for high-resource languages. In this opinion piece, we argue that LMs in their current state will never be fully trustworthy in critical settings and suggest a possible novel strategy to handle this issue: by building LMs such that can cite their sources -i.e., point a user to the parts of their training data that back up their outputs. We first discuss which current NLP tasks would or would not benefit from such models. We then highlight the expected benefits such models would bring, e.g., quick verifiability of statements. We end by outlining the individual tasks that would need to be solved on the way to developing LMs with the ability to cite. We hope to start a discussion about the field's current approach to building LMs, especially for low-resource languages, and the role of the training data in explaining model generations."
    },
    {
        "title": "Incorporating Singletons and Mention-based Features in Coreference Resolution via Multi-task Learning for Better Generalization",
        "authors": [
            "Yilun Zhu",
            "Siyao Peng",
            "Sameer Pradhan",
            "Amir Zeldes"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-short.14.pdf",
        "abstract": "Previous attempts to incorporate a mention detection step into end-to-end neural coreference resolution for English have been hampered by the lack of singleton mention span data as well as other entity information. This paper presents a coreference model that learns singletons as well as features such as entity type and information status via a multi-task learning-based approach. This approach achieves new stateof-the-art scores on the OntoGUM benchmark (+2.7 points) and increases robustness on multiple out-of-domain datasets (+2.3 points on average), likely due to greater generalizability for mention detection and utilization of more data from singletons when compared to only coreferent mention pair matching."
    },
    {
        "title": "All Labels Together: Low-shot Intent Detection with an Efficient Label Semantic Encoding Paradigm",
        "authors": [
            "Jiangshu Du",
            "Congying Xia",
            "Wenpeng Yin",
            "Tingting Liang",
            "Philip Yu"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-short.15.pdf",
        "abstract": "In intent detection tasks, leveraging meaningful semantic information from intent labels can be particularly beneficial for few-shot scenarios. However, existing few-shot intent detection methods either ignore the intent labels, (e.g. treating intents as indices) or do not fully utilize this information (e.g. only using part of the intent labels). In this work, we present an endto-end One-to-All system that enables the comparison of an input utterance with all label candidates. The system can then fully utilize label semantics in this way. Experiments on three few-shot intent detection tasks demonstrate that One-to-All is especially effective when the training resource is extremely scarce, achieving state-of-the-art performance in 1-, 3-and 5-shot settings. Moreover, we present a novel pretraining strategy for our model that utilizes indirect supervision from paraphrasing, enabling zeroshot cross-domain generalization on intent detection tasks. Our code is at https://github. com/jiangshdd/AllLablesTogether."
    },
    {
        "title": "Theia: Weakly Supervised Multimodal Event Extraction from Incomplete Data",
        "authors": [
            "Farhad Moghimifar",
            "Fatemeh Shiri",
            "Van Nguyen",
            "Yuan-Fang Li",
            "Gholamreza Haffari"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-short.16.pdf",
        "abstract": "Event extraction from multimodal documents is an important yet under-explored problem. One challenge faced by this task is the scarcity of paired image-text datasets, making it difficult to fully exploit the strong representation power of multimodal language models. In this paper, we present Theia, an end-to-end multimodal event extraction framework that can be trained on incomplete data. Specifically, we couple a generation-based event extraction model with a customised image synthesizer that can generate images from text. Our model leverages capabilities of pre-trained visionlanguage models and can be trained on incomplete (i.e. text-only) data. Experimental results on existing multimodal datasets demonstrate the effectiveness of our approach for both synthesising missing data and extracting events over state-of-the-art approaches."
    },
    {
        "title": "Perplexity-Driven Case Encoding Needs Augmentation for CAPITALIZATION Robustness",
        "authors": [
            "Rohit Jain",
            "Huda Khayrallah",
            "Roman Grundkiewicz",
            "Marcin Junczys-Dowmunt"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-short.17.pdf",
        "abstract": "Subword segmentation methods are the predominant solution to vocab sparsity in NMT. However, they cannot currently handle capitalization well. We re-encode case to allow the perplexity-driven SPM unigram language model algorithm to learn how to segment capitalization. Since naturally occurring data accurately describes the prevalence of capitalization but underestimates the importance humans ascribe to capitalization robustness, we propose data augmentation to fill this gap. We demonstrate that our proposed method improves translation quality on ALL CAPS, lower cased, and Title Case, while maintaining quality on standard test sets. In contrast to prior work, our proposed method has minimal impact on decoding speed. We release our code: github.com/marian-nmt/sentencepiece."
    },
    {
        "title": "Enhancing Open-Domain Table Question Answering via Syntax- and Structure-aware Dense Retrieval",
        "authors": [
            "Nengzheng Jin",
            "Dongfang Li",
            "Junying Chen",
            "Joanna Siebert",
            "Qingcai Chen"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-short.18.pdf",
        "abstract": "Open-domain table question answering aims to provide answers to a question by retrieving and extracting information from a large collection of tables. Existing studies of open-domain table QA either directly adopt text retrieval methods or consider the table structure only in the encoding layer for table retrieval, which may cause syntactical and structural information loss during table scoring. To address this issue, we propose a syntax-and structure-aware retrieval method for the open-domain table QA task. It provides syntactical representations for the question and uses the structural header and value representations for the tables to avoid the loss of fine-grained syntactical and structural information. Then, a syntactical-to-structural aggregator is used to obtain the matching score between the question and a candidate table by mimicking the human retrieval process. Experimental results show that our method achieves the state-of-the-art on the NQ-tables dataset and overwhelms strong baselines on a newly curated open-domain Text-to-SQL dataset 1 ."
    },
    {
        "title": "The Language Model, Resources, and Computational Pipelines for the Under-Resourced Iranian Azerbaijani",
        "authors": [
            "Marzia Nouri",
            "Mahsa Amani",
            "Reihaneh Zohrabi",
            "Ehsaneddin Asgari"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-short.19.pdf",
        "abstract": "Iranian Azerbaijani is a dialect of the Azerbaijani language spoken by more than 16% of the population in Iran (>14 million). Unfortunately, a lack of computational resources is one of the factors that puts this language and its rich culture at risk of extinction. This work aims to create fundamental natural language processing (NLP) resources and pipelines for the processing and analysis of Iranian Azerbaijani introducing standard datasets and starter models for various NLP tasks such as language modeling, text classification, part-of-speech (POS) tagging, and machine translation. The proposed resources have been curated and preprocessed to facilitate the development of NLP models for Iranian Azerbaijani and provide a strong baseline for further research and development. This study is an example of bridging the gap in NLP for low-resource languages and promoting the advancement of language technologies in underrepresented languages. To the best of our knowledge, for the first time, this paper presents major infrastructures for the processing and analysis of Iranian Azerbaijani, with the ultimate goal of improving communication and information access for millions of individuals. Furthermore, our translation model's online demo is accessible at https://azeri.parsi.ai/."
    },
    {
        "title": "Borderless Azerbaijani Processing: Linguistic Resources and a Transformer-based Approach for Azerbaijani Transliteration",
        "authors": [
            "Reihaneh Zohrabi",
            "Mostafa Masumi",
            "Omid Ghahroodi",
            "Parham AbedAzad",
            "Hamid Beigy",
            "Mohammad Hossein Rohban",
            "Ehsaneddin Asgari"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-short.20.pdf",
        "abstract": "Recent advancements in neural language models have revolutionized natural language understanding. However, many languages still face the risk of being left behind without the benefits of such advancements, potentially leading to their extinction. One such language is Azerbaijani in Iran, which suffers from limited digital resources and a lack of alignment between spoken and written forms. In contrast, Azerbaijani in the Republic of Azerbaijan has seen more resources and is not considered as low-resource as its Iranian counterpart. In this context, our research focuses on the computational progress made in Iranian Azerbaijani language. We propose a transliteration model that leverages an Azerbaijani parallel dataset, effectively bridging the gap between the Latin and Persian scripts. By enabling seamless communication between these two scripts, our model facilitates cultural exchange and serves as a valuable tool for transfer learning. The effectiveness of our approach surpasses traditional rule-based methods, as evidenced by the significant improvements in performance metrics. We observe a minimum 15% increase in BLEU scores and a reduction of at least 1/3 in edit distance. Furthermore, our model's online demo is accessible at https://azeri.parsi.ai/."
    },
    {
        "title": "Are Machine Reading Comprehension Systems Robust to Context Paraphrasing?",
        "authors": [
            "Yulong Wu",
            "Viktor Schlegel",
            "Riza Batista-Navarro"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-short.21.pdf",
        "abstract": "Investigating the behaviour of Machine Reading Comprehension (MRC) models under various types of test-time perturbations can shed light on the enhancement of their robustness and generalisation capability, despite the superhuman performance they have achieved on existing benchmark datasets. In this paper, we study the robustness of contemporary MRC systems to context paraphrasing, i.e., whether these models are still able to correctly answer the questions once the reading passages have been paraphrased. To this end, we systematically design a pipeline to semi-automatically generate perturbed MRC instances which ultimately lead to the creation of a paraphrased test set. We conduct experiments on this dataset with six state-of-the-art neural MRC models and we find that even the minimum performance drop of all these models exceeds 41%, whereas human performance remains high. Retraining models with augmented perturbed examples results in improved robustness, though the performance remains lower than on the original dataset. These results demonstrate that the existing high-performing MRC systems are still far away from real language understanding 1 ."
    },
    {
        "title": "It’s not only What You Say, It’s also Who It’s Said to: Counterfactual Analysis of Interactive Behavior in the Courtroom",
        "authors": [
            "Biaoyan Fang",
            "Trevor Cohn",
            "Timothy Baldwin",
            "Lea Frermann"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.ijcnlp-short.22.pdf",
        "abstract": "To what extent do personal attributes affect the way we are spoken to? Answering this question requires the precise reproduction of a conversational context except for one personal attribute of interest, amounting to a classical, yet infeasible, causal inference problem. We present a method based on counterfactual analysis by manipulating speaker attributes in observational data. We propose a case study of Advocate responses to Justices in debates in the Supreme Court of the United States. Specifically, we measure changes in politeness and coordination of Advocates when responding to (a) real Justices and (b) counterfactually-manipulated Justices, with responses generated with GPT2. We first validate our method, showing that GPT2generated outputs capture coordination and politeness. Our results confirm a known impact of the attribute gender, and suggest a weaker effect of seniority on coordination. 1"
    },
    {
        "title": "Findings of the Association for Computational Linguistics: IJCNLP-AACL 2023 (Findings)",
        "authors": [
            "Jong C. Park",
            "Yuki Arase",
            "Baotian Hu",
            "Wei Lu",
            "Derry Wijaya",
            "Ayu Purwarianti",
            "Adila Alfa Krisnadhi"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.0.pdf",
        "abstract": "The joint conferences of IJCNLP and AACL are organized by alternating leadership in the Asia-Pacific region, in odd years by Asian Federation of Natural Language Processing (AFNLP) and in even years by AACL, except when the annual meetings of ACL are offered in the region every three years, in which case the conferences will be offered and organized solely by ACL. This year, the conference is organized by AFNLP."
    },
    {
        "title": "Localize, Retrieve and Fuse: A Generalized Framework for Free-Form Question Answering over Tables",
        "authors": [
            "Wenting Zhao",
            "Ye Liu",
            "Yao Wan",
            "Yibo Wang",
            "Zhongfen Deng",
            "Philip S. Yu"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.1.pdf",
        "abstract": "Question answering on tabular data (a.k.a TableQA), which aims at generating answers to questions grounded on a provided table, has gained significant attention recently. Prior work primarily produces concise factual responses through information extraction from individual or limited table cells, lacking the ability to reason across diverse table cells. Yet, the realm of free-form TableQA, which demands intricate strategies for selecting relevant table cells and the sophisticated integration and inference of discrete data fragments, remains mostly unexplored. To this end, this paper proposes a generalized three-stage approach: Table-to-Graph conversion and cell localizing, external knowledge retrieval, and the fusion of table and text (called TAG-QA), to address the challenge of inferring long free-form answers in generative TableQA. In particular, TAG-QA (1) locates relevant table cells using a graph neural network to gather intersecting cells between relevant rows and columns, (2) leverages external knowledge from Wikipedia, and (3) generates answers by integrating both tabular data and natural linguistic information. Experiments showcase the superior capabilities of TAG-QA in generating sentences that are both faithful and coherent, particularly when compared to several state-of-the-art baselines. Notably, TAG-QA surpasses the robust pipelinebased baseline TAPAS by 17% and 14% in terms of BLEU-4 and PARENT F-score, respectively. Furthermore, TAG-QA outperforms the end-to-end model T5 by 16% and 12% on BLEU-4 and PARENT F-score, respectively. 1"
    },
    {
        "title": "Named Entity Recognition via Machine Reading Comprehension: A Multi-Task Learning Approach",
        "authors": [
            "Yibo Wang",
            "Wenting Zhao",
            "Yao Wan",
            "Zhongfen Deng",
            "Philip Yu"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.2.pdf",
        "abstract": "Named Entity Recognition (NER) aims to extract and classify entity mentions in the text into pre-defined types (e.g., organization or person name). Recently, many works have been proposed to shape the NER as a machine reading comprehension problem (also termed MRC-based NER), in which entity recognition is achieved by answering the formulated questions related to pre-defined entity types through MRC, based on the contexts. However, these works ignore the label dependencies among entity types, which are critical for precisely recognizing named entities. In this paper, we propose to incorporate the label dependencies among entity types into a multi-task learning framework for better MRC-based NER. We decompose MRC-based NER into multiple tasks and use a self-attention module to capture label dependencies. Comprehensive experiments on both nested NER and flat NER datasets are conducted to validate the effectiveness of the proposed Multi-NER. Experimental results show that Multi-NER can achieve better performance on all datasets."
    },
    {
        "title": "SPEC5G: A Dataset for 5G Cellular Network Protocol Analysis",
        "authors": [
            "Imtiaz Karim",
            "Kazi Samin Mubasshir",
            "Mirza Masfiqur Rahman",
            "Elisa Bertino"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.3.pdf",
        "abstract": "5G is the 5 th generation state-of-the-art cellular network protocol designed to connect virtually everyone and everything with increased speed and reduced latency. Therefore, its development, analysis, and security are critical. However, all approaches to the 5G protocol development and security analysis, e.g., property extraction, protocol summarization, and semantic analysis of the protocol specifications and implementations are completely manual. To reduce such manual efforts, in this paper, we curate SPEC5G-the first-ever public 5G dataset for NLP research. The dataset contains 3,547,587 sentences with 134M words, from 13094 cellular network specifications and 13 online websites. By leveraging large-scale pre-trained language models that have achieved state-of-the-art results on NLP tasks, we use this dataset for security-related text classification and summarization. Security-related text classification can be used to extract relevant security-related properties for protocol testing. On the other hand, summarization can help developers and practitioners understand the highlevel idea of the protocol, which is itself a daunting task. To ensure the research community can benefit from this work, all the datasets and accompanying codebase are made publicly available 1 ."
    },
    {
        "title": "PRiSM: Enhancing Low-Resource Document-Level Relation Extraction with Relation-Aware Score Calibration",
        "authors": [
            "Minseok Choi",
            "Hyesu Lim",
            "Jaegul Choo"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.4.pdf",
        "abstract": "Document-level relation extraction (DocRE)aims to extract relations of all entity pairs in a document. A key challenge in DocRE is the cost of annotating such data which requires intensive human effort. Thus, we investigate the case of DocRE in a low-resource setting, and we find that existing models trained on low data overestimate the NA (\"no relation\") label, causing limited performance. In this work, we approach the problem from a calibration perspective and propose PRiSM, which learns to adapt logits based on relation semantic information. We evaluate our method on three DocRE datasets and demonstrate that integrating existing models with PRiSM improves performance by as much as 26.38 F1 score, while the calibration error drops as much as 36 times when trained with about 3% of data. The code is publicly available at https: //github.com/brightjade/PRiSM."
    },
    {
        "title": "Improving Query-Focused Meeting Summarization with Query-Relevant Knowledge",
        "authors": [
            "Tiezheng Yu",
            "Ziwei Ji",
            "Pascale Fung"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.5.pdf",
        "abstract": "Query-Focused Meeting Summarization (QFMS) aims to generate a summary of a given meeting transcript conditioned upon a query. The main challenges for QFMS are the long input text length and sparse query-relevant information in the meeting transcript. In this paper, we propose a knowledge-enhanced two-stage framework called Knowledge-Aware Summarizer (KAS) to tackle the challenges. In the first stage, we introduce knowledge-aware scores to improve the query-relevant segment extraction. In the second stage, we incorporate query-relevant knowledge in the summary generation.Experimental results on the QMSum dataset show that our approach achieves state-of-the-art performance. Further analysis proves the competency of our methods in generating relevant and faithful summaries. 1"
    },
    {
        "title": "Learning to Diversify Neural Text Generation via Degenerative Model",
        "authors": [
            "Jimin Hong",
            "ChaeHun Park",
            "Jaegul Choo"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.6.pdf",
        "abstract": "Neural language models often fail to generate diverse and informative texts, limiting their applicability in real-world problems. While previous approaches have proposed to address these issues by identifying and penalizing undesirable behaviors (e.g., repetition, overuse of frequent words) from language models, we propose an alternative approach based on an observation: models primarily learn attributes within examples that are likely to cause degeneration problems. Based on this observation, we propose a new approach to prevent degeneration problems by training two models. Specifically, we first train a model that is designed to amplify undesirable patterns. We then enhance the diversity of the second model by focusing on patterns that the first model fails to learn. Extensive experiments on two tasks, namely language modeling and dialogue generation, demonstrate the effectiveness of our approach."
    },
    {
        "title": "A Neighbourhood-Aware Differential Privacy Mechanism for Static Word Embeddings",
        "authors": [
            "Danushka Bollegala",
            "Shuichi Otake",
            "Tomoya Machide",
            "Ken-ichi Kawarabayashi"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.7.pdf",
        "abstract": "We propose a Neighbourhood-Aware Differential Privacy (NADP) mechanism considering the neighbourhood of a word in a pretrained static word embedding space to determine the minimal amount of noise required to guarantee a specified privacy level. We first construct a nearest neighbour graph over the words using their embeddings, and factorise it into a set of connected components (i.e. neighbourhoods). We then separately apply different levels of Gaussian noise to the words in each neighbourhood, determined by the set of words in that neighbourhood. Experiments show that our proposed NADP mechanism consistently outperforms multiple previously proposed DP mechanisms such as Laplacian, Gaussian, and Mahalanobis in multiple downstream tasks, while guaranteeing higher levels of privacy."
    },
    {
        "title": "PhraseSumm: Abstractive Short Phrase Summarization",
        "authors": [
            "Kasturi Bhattacharjee",
            "Kathleen McKeown",
            "Rashmi Gangadharaiah"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.8.pdf",
        "abstract": "Prior work in the field of text summarization mostly focuses on generating summaries that are a sentence or two long. In this work, we introduce the task of abstractive short-phrase summarization (PhraseSumm), which aims at capturing the central theme of a document through a generated short phrase. We explore BART & T5-based neural summarization models, and measure their effectiveness for the task using both standard summarization metrics as well as human evaluation. Our work showcases the benefits of pre-training the summarization models using tasks such as phrasal paraphrase alignment and NLI before fine-tuning on the task itself, both of which help the model with abstraction and thereby yield improvements over the baselines. Human evaluation reveals that model generated summaries are often judged better than or equal to reference summaries, demonstrating that ROUGE scores underestimate true performance. Finally, we create and release a dataset for this task to enable further research in the area."
    },
    {
        "title": "Location Aware Modular Biencoder for Tourism Question Answering",
        "authors": [
            "Haonan Li",
            "Martin Tomko",
            "Timothy Baldwin"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.9.pdf",
        "abstract": "Answering real-world tourism questions that seek Point-of-Interest (POI) recommendations is challenging, as it requires both spatial and non-spatial reasoning, over a large candidate pool. The traditional method of encoding each pair of question and POI becomes inefficient when the number of candidates increases, making it infeasible for real-world applications. To overcome this, we propose treating the QA task as a dense vector retrieval problem, where we encode questions and POIs separately and retrieve the most relevant POIs for a question by utilizing embedding space similarity. We use pretrained language models (PLMs) to encode textual information, and train a location encoder to capture spatial information of POIs. Experiments on a real-world tourism QA dataset demonstrate that our approach is effective, efficient, and outperforms previous methods across all metrics. Enabled by the dense retrieval architecture, we further build a global evaluation baseline, expanding the search space by 20 times compared to previous work. We also explore several factors that impact on the model's performance through follow-up experiments. Our code and model are publicly available at https://github. com/haonan-li/LAMB."
    },
    {
        "title": "Joint Representations of Text and Knowledge Graphs for Retrieval and Evaluation",
        "authors": [
            "Teven Le Scao",
            "Claire Gardent"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.10.pdf",
        "abstract": "A key feature of neural models is that they can produce semantic vector representations of objects (texts, images, speech, etc.) ensuring that similar objects are close to each other in the vector space. While much work has focused on learning representations for other modalities, there are no aligned crossmodal representations for text and knowledge base (KB) elements. One challenge for learning such representations is the lack of parallel data, which we use contrastive training on heuristics-based datasets and data augmentation to overcome, training embedding models on (KB graph, text) pairs. On WEBNLG, a cleaner manually crafted dataset, we show that they learn aligned representations suitable for retrieval. We then fine-tune on annotated data to create EREDAT (Ensembled Representations for Evaluation of DAta-to-Text), a similarity metric between English text and KB graphs. EREDAT outperforms or matches state-of-theart metrics in terms of correlation with human judgments on WEBNLG even though, unlike them, it does not require a reference text to compare against."
    },
    {
        "title": "Unsupervised Multi-document Summarization with Holistic Inference",
        "authors": [
            "Haopeng Zhang",
            "Sangwoo Cho",
            "Kaiqiang Song",
            "Xiaoyang Wang",
            "Hongwei Wang",
            "Jiawei Zhang",
            "Dong Yu"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.11.pdf",
        "abstract": "Multi-document summarization aims to obtain core information from a collection of documents written on the same topic. This paper proposes a new holistic framework for unsupervised multi-document extractive summarization. Our method incorporates the holistic beam search inference method associated with the holistic measurements, named Subset Representative Index (SRI). SRI balances the importance and diversity of a subset of sentences from the source documents and can be calculated in unsupervised and adaptive manners. To demonstrate the effectiveness of our method, we conduct extensive experiments on both small and large-scale multi-document summarization datasets under both unsupervised and adaptive settings. The proposed method outperforms strong baselines by a significant margin, as indicated by the resulting ROUGE scores and diversity measures. Our findings also suggest that diversity is essential for improving multi-document summary performance."
    },
    {
        "title": "Predicting Terms in IS-A Relations with Pre-trained Transformers",
        "authors": [
            "Irina Nikishina",
            "Polina Chernomorchenko",
            "Anastasiia Demidova",
            "Alexander Panchenko",
            "Chris Biemann"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.12.pdf",
        "abstract": "In this paper, we explore the ability of the generative transformers to predict objects in IS-A (hypo-hypernym) relations. We solve the task for both directions of the relations: we learn to predict hypernyms given the input word and hyponyms, given the input concept and its neighbourhood from the taxonomy. To the best of our knowledge, this is the first paper which provides a comprehensive analysis of transformerbased models for the task of hypernymy extraction. Apart from the standard finetuning of various generative models, we experiment with different input formats and prefixes, zeroand few-shot learning strategies, and generation parameters. Results show that higher performance on both subtasks can be achieved by generative transformers with no additional data (like definitions or lemma names). Such models have phenomenally high abilities at the task given a little training and proper prompts in comparison to specialized rule-based and statistical methods as well as encoder-based transformer models."
    },
    {
        "title": "Context Helps Determine Spatial Knowledge from Tweets",
        "authors": [
            "Zhaomin Xiao",
            "Yan Huang",
            "Eduardo Blanco"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.13.pdf",
        "abstract": "This paper introduces the problem of determining whether people are located in the locations they mention in their Twitter streams. In particular, we investigate the role of context-tweets published before and after a tweet mentioning a location-in this challenging problem. We present a new corpus of Twitter streams with spatial information. Our analyses show that context is key to define the ground truth, as human judgments depend on whether annotators have access to context. Experimental results show that a neural architecture that takes into account context in addition to the tweet mentioning a location yields better results. We also conduct an error analysis to provide insights into the errors made by our best model."
    },
    {
        "title": "Multilingual Non-Autoregressive Machine Translation without Knowledge Distillation",
        "authors": [
            "Chenyang Huang",
            "Fei Huang",
            "Zaixiang Zheng",
            "Osmar Zaïane",
            "Hao Zhou",
            "Lili Mou"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.14.pdf",
        "abstract": "Multilingual neural machine translation (MNMT) aims at using one single model for multiple translation directions. Recent work applies non-autoregressive Transformers to improve the efficiency of MNMT, but requires expensive knowledge distillation (KD) processes. To this end, we propose an M-DAT approach to non-autoregressive multilingual machine translation. Our system leverages the recent advance of the directed acyclic Transformer (DAT), which does not require KD. We further propose a pivot back-translation (PivotBT) approach to improve the generalization to unseen translation directions. Experiments show that our M-DAT achieves state-of-the-art performance in non-autoregressive MNMT. 1"
    },
    {
        "title": "Knowledge Injection with Perturbation-based Constrained Attention Network for Word Sense Disambiguation",
        "authors": [
            "Fumiyo Fukumoto",
            "Shou Asakawa"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.15.pdf",
        "abstract": "Supervised Word Sense Disambiguation (WSD) has been studied intensively for over three decades. However, disentangling diverse contexts is still a challenging problem. This paper addresses the problem and proposes a Perturbation-based constrained attention network (Pconan) for injecting lexical knowledge derived from the WordNet. The Pconan allows modeling beneficial dependencies between the segments/words within the input sequence with the mask-attention technique. We incorporate a perturbation method into our model to mitigate the overfitting problem resulting from intensive learning. The experimental results by using a benchmark dataset show that our method is comparable to the SOTA WSD methods. Our source codes are available online 1 ."
    },
    {
        "title": "The Glass Ceiling of Automatic Evaluation in Natural Language Generation",
        "authors": [
            "Pierre Colombo",
            "Maxime Peyrard",
            "Nathan Noiry",
            "Robert West",
            "Pablo Piantanida"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.16.pdf",
        "abstract": "Automatic evaluation metrics capable of replacing human judgments are critical to allowing fast development of new methods. Thus, numerous research efforts have focused on crafting such metrics. In this work, we take a step back and analyze recent progress by comparing the body of existing automatic metrics and human metrics altogether. As metrics are used based on how they rank systems, we compare metrics in the space of system rankings. Our extensive statistical analysis reveals surprising findings: automatic metrics -old and neware much more similar to each other than to humans. Automatic metrics are not complementary and rank systems similarly. Strikingly, human metrics predict each other much better than the combination of all automatic metrics used to predict a human metric. It is surprising because human metrics are often designed to be independent, to capture different aspects of quality, e.g. content fidelity or readability. We provide a discussion of these findings and recommendations for future work in the field of evaluation."
    },
    {
        "title": "A Novel Information Theoretic Objective to Disentangle Representations for Fair Classification",
        "authors": [
            "Pierre Colombo",
            "Nathan Noiry",
            "Guillaume Staerman",
            "Pablo Piantanida"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.17.pdf",
        "abstract": "One of the pursued objectives of deep learning is to provide tools that learn abstract representations of reality from the observation of multiple contextual situations. More precisely, one wishes to extract disentangled representations which are (i) low dimensional and (ii) whose components are independent and correspond to concepts capturing the essence of the objects under consideration (Locatello et al., 2019b). One step towards this ambitious project consists in learning disentangled representations with respect to a predefined (sensitive) attribute, e.g., the gender or age of the writer. Perhaps one of the main application for such disentangled representations is fair classification. Existing methods extract the last layer of a neural network trained with a loss that is composed of a cross-entropy objective and a disentanglement regularizer. In this work, we adopt an information-theoretic view of this problem which motivates a novel family of regularizers that minimizes the mutual information between the latent representation and the sensitive attribute conditional to the target. The resulting set of losses, called CLINIC, is parameter free and thus, it is easier and faster to train. CLINIC losses are studied through extensive numerical experiments by training over 2k neural networks. We demonstrate that our methods offer a better disentanglement/accuracy trade-off than previous techniques, and generalize better than training with cross-entropy loss solely provided that the disentanglement task is not too constraining."
    },
    {
        "title": "Large Language Models and Low-Resource Languages: An Examination of Armenian NLP",
        "authors": [
            "Hayastan Avetisyan",
            "David Broneske"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.18.pdf",
        "abstract": "This paper presents a comprehensive review of Natural Language Processing (NLP) research on Armenian, a language that, despite its rich history and unique linguistic characteristics, is currently low-resource in the field of NLP. We critically synthesize and evaluate various studies in Armenian NLP, highlighting key advancements, challenges, and areas for improvement. A notable aspect of our work is the underlined lack of application of Large Language Models (LLMs) in Armenian NLP, signifying an area of potential exploration and development. Identifying and discussing these challenges and opportunities lays the groundwork for future research directions in Armenian NLP. The emphasis on Armenian also advocates for increased attention to low-resource languages in NLP research, stressing the importance of linguistic diversity and equity. To the best of our knowledge, this is the first paper providing such an extensive review of Armenian NLP, marking a significant contribution to the field."
    },
    {
        "title": "Multi-Target Semantic Parsing with Collaborative Deliberation Network",
        "authors": [
            "Xiang Li",
            "Fangyu Lei",
            "Shizhu He",
            "Kang Liu",
            "Jun Zhao"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.19.pdf",
        "abstract": "Semantic parsing aims at mapping natural language utterances into machine-interpretable meaning representations, facilitating user accesses to knowledge bases. However, knowledge in real-world scenarios is often duplicated in multiple storages and different representations. Although researchers have made great success by improving neural semantic parsers, existing works can only handle a specific kind of meaning representation, i.e., the single-target semantic parsing. In this paper, we introduce a multi-target semantic parsing model based on a collaborative deliberation network, which can not only decode multiple meaning representations simultaneously but also allow meaning representations to make use of information from each other while decoding. Experiments show that the proposed model improves the EM accuracy of four MRs averagely by 2.48% to 5.05% on three public datasets 1 ."
    },
    {
        "title": "Improving Machine Reading Comprehension through A Simple Masked-Training Scheme",
        "authors": [
            "Xun Yao",
            "Junlong Ma",
            "Xinrong Hu",
            "Jie Yang",
            "Yuan-Fang Li"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.20.pdf",
        "abstract": "Extractive Question Answering (EQA) is a fundamental problem in Natural Language Understanding, aiming at answering given questions via extracting a contiguous sequence or span of words from a passage. Recent work on EQA has achieved promising performance with the help of pre-trained language models, for which Masked Language Modeling (MLM) is usually adopted as a pre-training task to predict masked tokens. This paper revisits MLM and proposes a simple yet effective method to improve the EQA performance, termed the [Mask]-for-Answering method (M4A). Specifically, three masking strategies are first introduced, which produce masked copies of the original passages. Instead of predicting masked tokens as in MLM, both original samples and masked copies are utilized simultaneously for training the EQA model. Importantly, a discrepancy loss is further incorporated to ensure that masked copies remain semantically close to the originals. As such, M4A is able to produce robust embeddings for both original and masked samples and infer correct answers even with masked context. Experimental study on several highly-competitive benchmarks consistently demonstrates the superiority of our proposed method over existing methods. M4A also achieves strong performance in low-resource settings and out-of-domain generalization. * corresponding author Limit Context: Portugal has the largest aquarium in Europe, the Lisbon Oceanarium, and the Portuguese have several other notable organizations focused on science-related exhibits and divulgation, like the state agency Ciência Viva, a programme of the Portuguese Ministry of Science and Technology to the promotion of a scientific and technological culture among the Portuguese population, the Science Museum of the University of Coimbra, the National Museum of Natural History at the University of Lisbon, and the Visionarium."
    },
    {
        "title": "A Comprehensive Neural and Behavioral Task Taxonomy Method for Transfer Learning in NLP",
        "authors": [
            "Yunhao Zhang",
            "Chong Li",
            "Xiaohan Zhang",
            "Xinyi Dong",
            "Shaonan Wang"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.21.pdf",
        "abstract": "Transfer learning is frequently utilized in scenarios with limited labeled examples, where a crucial step is to identify a related task to the target task. CogTaskonomy (Luo et al., 2022)  was proposed to acquire a taxonomy of NLP tasks, specifically focusing on assessing the similarities between tasks. This method, inspired by cognitive processes, exhibits notable time efficiency. Nevertheless, it does not fully exploit the task-related information present in cognitive data and lacks a comprehensive evaluation of various types of cognitive data. To address these limitations, this paper proposes a comprehensive neural and behavioral method to investigate the relationship among NLP tasks. Our approach utilizes cognitive data, encompassing both neural data such as fMRI and EEG, as well as behavioral data including eye-tracking and semantic feature ratings. Each data modality is employed to establish a common representation space with Representation Similarity Analysis for projecting task-related representations. To fully leverage the cognitive information, we effectively extract the task-relevant information extracted from neural data through feature ranking. Experimental results on 12 NLP tasks demonstrate that our proposed method outperforms state-of-the-art methods on evaluating task similarity."
    },
    {
        "title": "My Boli: Code-mixed Marathi-English Corpora, Pretrained Language Models and Evaluation Benchmarks",
        "authors": [
            "Tanmay Chavan",
            "Omkar Gokhale",
            "Aditya Kane",
            "Shantanu Patankar",
            "Raviraj Joshi"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.22.pdf",
        "abstract": "The research on code-mixed data is limited due to the unavailability of dedicated code-mixed datasets and pre-trained language models. In this work, we focus on the low-resource Indian language Marathi which lacks any prior work in code-mixing. We present L3Cube-MeCorpus, a large code-mixed Marathi-English (Mr-En) corpus with 10 million social media sentences for pretraining. We also release L3Cube-MeBERT and MeRoBERTa, code-mixed BERT-based transformer models pre-trained on MeCorpus. Furthermore, for benchmarking, we present three supervised datasets MeHate, MeSent, and MeLID for downstream tasks like codemixed Mr-En hate speech detection, sentiment analysis, and language identification respectively. These evaluation datasets individually consist of manually annotated ~12,000 Marathi-English code-mixed tweets. Ablations show that the models trained on this novel corpus significantly outperform the existing state-of-the-art BERT models. This is the first work that presents artifacts for code-mixed Marathi research. All datasets and models are publicly released at https://github.com/ l3cube-pune/MarathiNLP."
    },
    {
        "title": "Template Filling for Controllable Commonsense Reasoning",
        "authors": [
            "Dheeraj Rajagopal",
            "Vivek Khetan",
            "Bogdan Sacaleanu",
            "Anatole Gershman",
            "Andrew E. Fano Fano",
            "Eduard Hovy"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.23.pdf",
        "abstract": "Large-scale sequence-to-sequence models have shown to be adept at both multiple-choice and open-domain commonsense reasoning tasks. However, the current formulations do not provide the ability to control the various attributes of the reasoning chain. To enable better controllability, we propose to study the commonsense reasoning as a template filling task (TemplateCSR) -where the language models fills reasoning templates with the given constraints as control factors. As an approach to TemplateCSR, we (i) propose a dataset of commonsense reasoning templateexpansion pairs for healthcare and well-being domain and (ii) introduce ITO, an instruction fine-tuned sequence-to-sequence model that performs commonsense reasoning across concepts in the template. Our experiments show that our approach outperforms baseline both in generation metrics and factuality metrics. We also present a detailed error analysis on our approach's ability to reliably perform template based commonsense reasoning 1 ."
    },
    {
        "title": "Temporal Relation Classification in Hebrew",
        "authors": [
            "Guy Yanko",
            "Shahaf Pariente",
            "Kfir Bar"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.24.pdf",
        "abstract": "Temporal Relation Classification (TRC) is a fundamental task in natural language processing (NLP) and is essential for achieving a comprehensive understanding of a natural language. Given a document containing two event mentions, the objective of this task is to discern which of the two events happened first. Existing TRC datasets predominantly consist of texts written in English. To accommodate the growing interest in relevant NLP applications for Hebrew, we introduce a new TRC dataset for Hebrew. Professional annotators labeled Hebrew documents with TRC labels, adhering to guidelines adapted from a similar project on English and with some changes required to address some unique aspects of the Hebrew language. Overall, we annotated a corpus of 28,757 words, corresponding to 7,260 pairs of events. In addition to releasing the new dataset, which can be accessed at https://github.com/ shahafp/TRC-Hebrew, we train several baseline models for TRC and report their performance."
    },
    {
        "title": "Privacy Adhering Machine Un-learning in NLP",
        "authors": [
            "Vinayshekhar Bannihatti Kumar",
            "Rashmi Gangadharaiah",
            "Dan Roth"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.25.pdf",
        "abstract": "Regulations introduced General Data Protection Regulation (GDPR) in the EU or California Consumer Privacy Act (CCPA) in the US have included provisions on the right to be forgotten that mandates industry applications to remove data related to an individual from their systems. In several real world industry applications that use Machine Learning to build models on user data, such mandates require significant effort both in terms of data cleansing as well as model retraining while ensuring the models do not deteriorate in prediction quality due to removal of data. As a result, continuous removal of data and model retraining steps do not scale if these applications receive such requests at a very high frequency. Recently, a few researchers proposed the idea of Machine Unlearning to tackle this challenge. Despite the significant importance of this task, the area of Machine Unlearning is under-explored in Natural Language Processing (NLP) tasks. In this paper, we explore the Unlearning framework on various GLUE tasks(Wang et al., 2018), such as, QQP, SST and MNLI. We propose computationally efficient approaches (SISA-FC and SISA-A) to perform guaranteed Unlearning that provides significant reduction in terms of both memory (90-95%), time (100x) and space consumption (99%) in comparison to the baselines while having minimal impact on model performance. 1 ."
    },
    {
        "title": "GECTurk: Grammatical Error Correction and Detection Dataset for Turkish",
        "authors": [
            "Atakan Kara",
            "Farrin Marouf Sofian",
            "Andrew Bond",
            "Gözde Şahin"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.26.pdf",
        "abstract": "Grammatical Error Detection and Correction (GEC) tools have proven useful for native speakers and second language learners. Developing such tools requires a large amount of parallel, annotated data, which is unavailable for most languages. Synthetic data generation is a common practice to overcome the scarcity of such data. However, it is not straightforward for morphologically rich languages like Turkish due to complex writing rules that require phonological, morphological, and syntactic information. In this work, we present a flexible and extensible synthetic data generation pipeline for Turkish covering more than 20 expert-curated grammar and spelling rules (a.k.a., writing rules) implemented through complex transformation functions. Using this pipeline, we derive 130,000 high-quality parallel sentences from professionally edited articles. Additionally, we create a more realistic test set by manually annotating a set of movie reviews. We implement three baselines formulating the task as i) neural machine translation, ii) sequence tagging, and iii) prefix tuning with a pretrained decoder-only model, achieving strong results. Furthermore, we perform exhaustive experiments on out-of-domain datasets to gain insights on the transferability and robustness of the proposed approaches. Our results suggest that our corpus, GECTurk, is high-quality and allows knowledge transfer for the out-of-domain setting. To encourage further research on Turkish GEC, we release our datasets, baseline models, and the synthetic data generation pipeline at https: //github.com/GGLAB-KU/gecturk."
    },
    {
        "title": "Interactively Learning Social Media Representations Improves News Source Factuality Detection",
        "authors": [
            "Nikhil Mehta",
            "Dan Goldwasser"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.27.pdf",
        "abstract": "The rise of social media has enabled the widespread propagation of fake news, text that is published with an intent to spread misinformation and sway beliefs. Rapidly detecting fake news, especially as new events arise, is important to prevent misinformation.While prior works have tackled this problem using supervised learning systems, automatedly modeling the complexities of the social media landscape that enables the spread of fake news is challenging. On the contrary, having humans fact check all news is not scalable. Thus, in this paper, we propose to approach this problem interactively, where humans can interact to help an automated system learn a better social media representation quality. On real world events, our experiments show performance improvements in detecting factuality of news sources, even after few human interactions."
    },
    {
        "title": "IndIE: A Multilingual Open Information Extraction Tool For Indic Languages",
        "authors": [
            "Ritwik Mishra",
            "Simranjeet Singh",
            "Rajiv Ratn Shah",
            "Ponnurangam Kumaraguru",
            "Pushpak Bhattacharyya"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.28.pdf",
        "abstract": "Open Information Extraction (OIE) is the process of extracting informative facts from opendomain natural language text. A multilingual OIE tool, IndIE, has been proposed, which performs chunking, creates a Merged-phrase Dependency Tree (MDT), and generates triples using hand-crafted rules. It is observed that fine-tuned transformer-based chunker outperforms other traditional methods of chunking. A benchmark called Hindi-BenchIE has also been developed for automatically evaluating Hindi triples. The developed OIE tool, IndIE, has been automatically evaluated on the goldentriples of 112 Hindi sentences. Compared to other multilingual methods, the IndIE method generates more meaningful triples with 0.51 F1-score. It is observed that IndIE generates more fine-grained triples than other methods. It is conjectured that IndIE has the ability to generate meaningful triples for Urdu, Tamil, and Telugu sentences as well because the developed chunker is shown to generalize across various natural languages, and the triple generation rules are based on dependency relations that are common to the aforementioned Indic languages."
    },
    {
        "title": "Mitigating Word Bias in Zero-shot Prompt-based Classifiers",
        "authors": [
            "Adian Liusie",
            "Potsawee Manakul",
            "Mark Gales"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.29.pdf",
        "abstract": "Prompt-based classifiers are an attractive approach for zero-shot classification. However, the precise choice of the prompt template and label words can largely influence performance, with semantically equivalent settings often showing notable performance difference. This discrepancy can be partly attributed to word biases, where the classifier may be biased towards classes. To address this problem, it is possible to optimise classification thresholds on a labelled data set, however, this mitigates some of the advantages of prompt-based classifiers. This paper instead approaches this problem by examining the expected marginal probabilities of the classes. Here, probabilities are reweighted to have a uniform prior over classes, in an unsupervised fashion. Further, we draw a theoretical connection between the class priors and the language models' word prior, and offer the ability to set a threshold in a zero-resource fashion. We show that matching class priors correlates strongly with the oracle upper bound performance and demonstrate large consistent performance gains for prompt settings over a range of NLP tasks. 1"
    },
    {
        "title": "Mixing It Up: Inducing Empathy and Politeness using Multiple Behaviour-aware Generators for Conversational Systems",
        "authors": [
            "Mauajama Firdaus",
            "Priyanshu Priya",
            "Asif Ekbal"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.30.pdf",
        "abstract": "Politeness is a key component that can assist in building a strong customer-agent relationship. With the ongoing increase in customer-care systems, it is crucial to have healthy relations with the users providing satisfaction and a better customer experience. In this regard, it is significant to model the different polite behaviors in an agent to help the user in reaching the intended objectives. In our current work, we propose the task of polite behavior-aware generation considering the affective state of the user and the conversational context. We design a Transformer based encoder-decoder framework with three major components i.e., Affective tracker, Behaviour-aware generators, and Polite generator. The affective tracker is a context encoder that captures the contextual information along with the affective information in the utterances; the behavior-aware generators independently attends to the context information to compute behavior-aware polite representations and finally, polite generator generates the final polite response considering the representations from different generators. Experimental results on the CYCCD dataset prove that our approach generates contextually correct and relevant responses compared to the state-of-the-art approaches and the baselines."
    },
    {
        "title": "Few-Shot Adaptation for Parsing Contextual Utterances with LLMs",
        "authors": [
            "Kevin Lin",
            "Patrick Xia",
            "Hao Fang"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.31.pdf",
        "abstract": "We evaluate the ability of semantic parsers based on large language models (LLMs) to handle contextual utterances. In real-world settings, there typically exists only a limited number of annotated contextual utterances due to annotation cost, resulting in an imbalance compared to non-contextual utterances. Therefore, parsers must adapt to contextual utterances with a few training examples. We examine four major paradigms for doing so in conversational semantic parsing i.e., Parse-with-Utterance-History, Parse-with-Reference-Program, Parsethen-Resolve, and Rewrite-then-Parse. To facilitate such cross-paradigm comparisons, we construct SMCalFlow-EventQueries, a subset of contextual examples from SMCalFlow with additional annotations. Experiments with in-context learning and fine-tuning suggest that Rewrite-then-Parse is the most promising paradigm when holistically considering parsing accuracy, annotation cost, and error types."
    },
    {
        "title": "Exploring the Use of Large Language Models for Reference-Free Text Quality Evaluation: An Empirical Study",
        "authors": [
            "Yi Chen",
            "Rui Wang",
            "Haiyun Jiang",
            "Shuming Shi",
            "Ruifeng Xu"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.32.pdf",
        "abstract": "Evaluating the quality of generated text is a challenging task in NLP, due to the inherent complexity and diversity of text. Recently, large language models (LLMs) have garnered significant attention due to their impressive performance in various tasks. Therefore, we present this paper to investigate the effectiveness of LLMs, especially ChatGPT, and explore ways to optimize their use in assessing text quality. We compared three kinds of referencefree evaluation methods. The experimental results prove that ChatGPT is capable of evaluating text quality effectively from various perspectives without reference and demonstrates superior performance than most existing automatic metrics. In particular, the Explicit Score, which utilizes ChatGPT to generate a numeric score measuring text quality, is the most effective and reliable method among the three exploited approaches. However, directly comparing the quality of two texts may lead to suboptimal results. We believe this paper will provide valuable insights for evaluating text quality with LLMs and have released the used data 1 ."
    },
    {
        "title": "A Text-to-Text Model for Multilingual Offensive Language Identification",
        "authors": [
            "Tharindu Ranasinghe",
            "Marcos Zampieri"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.33.pdf",
        "abstract": "The ubiquity of offensive content on social media is a growing cause for concern among companies and government organizations. Recently, transformer-based models such as BERT, XL-NET, and XLM-R have achieved state-of-theart performance in detecting various forms of offensive content (e.g. hate speech, cyberbullying, and cyberaggression). However, the majority of these models are limited in their capabilities due to their encoder-only architecture, which restricts the number and types of labels in downstream tasks. Addressing these limitations, this study presents the first pretrained model with encoder-decoder architecture for offensive language identification with text-to-text transformers (T5) trained on two large offensive language identification datasets; SOLID and CCTK. We investigate the effectiveness of combining two datasets and selecting an optimal threshold in semi-supervised instances in SOLID in the T5 retraining step. Our pre-trained T5 model outperforms other transformer-based models fine-tuned for offensive language detection, such as fBERT and HateBERT, in multiple English benchmarks. Following a similar approach, we also train the first multilingual pre-trained model for offensive language identification using mT5 and evaluate its performance on a set of six different languages (German, Hindi, Korean, Marathi, Sinhala, and Spanish). The results demonstrate that this multilingual model achieves a new state-of-the-art on all the above datasets, showing its usefulness in multilingual scenarios. Our proposed T5-based models will be made freely available to the community."
    },
    {
        "title": "Few-shot Named Entity Recognition with Supported and Dependent Label Representations",
        "authors": [
            "Yasuhide Miura",
            "Takumi Takahashi"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.34.pdf",
        "abstract": "We explore the problem of few-shot named entity recognition (NER) by introducing two ideas to improve label representations. Recently, the use of token representations with a distance metric has been shown to be effective in few-shot NER, and we take an approach to use label representations along with token representations. Firstly, we add support examples to a label name (e.g., \"person; example: Federic Krupp, Gao, Honecker, Bush, Deverow\") when obtaining a label representation. Secondly, we estimate a transition score among labels with a bilinear function among label representations. The proposed approach is evaluated on 4 open few-shot NER datasets and we found that the approach can improve the performance of one-stage few-shot NER."
    },
    {
        "title": "What Learned Representations and Influence Functions Can Tell Us About Adversarial Examples",
        "authors": [
            "Shakila Mahjabin Tonni",
            "Mark Dras"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.35.pdf",
        "abstract": "Adversarial examples, deliberately crafted using small perturbations to fool deep neural networks, were first studied in image processing and more recently in NLP. While approaches to detecting adversarial examples in NLP have largely relied on search over input perturbations, image processing has seen a range of techniques that aim to characterise adversarial subspaces over the learned representations.In this paper, we adapt two such approaches to NLP, one based on nearest neighbors and influence functions and one on Mahalanobis distances. The former in particular produces a state-of-the-art detector when compared against several strong baselines; moreover, the novel use of influence functions provides insight into how the nature of adversarial example subspaces in NLP relate to those in image processing, and also how they differ depending on the kind of NLP task."
    },
    {
        "title": "Supervised Clustering Loss for Clustering-Friendly Sentence Embeddings: an Application to Intent Clustering",
        "authors": [
            "Giorgio Barnabò",
            "Antonio Uva",
            "Sandro Pollastrini",
            "Chiara Rubagotti",
            "Davide Bernardi"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.36.pdf",
        "abstract": "Modern virtual assistants are trained to classify customer requests into a taxonomy of predesigned intents. Requests that fall outside of this taxonomy, however, are often unhandled and need to be clustered to define new experiences. Recently, state-of-the-art results in intent clustering were achieved by training a neural network with a latent structured prediction loss. Unfortunately, though, this new approach suffers from a quadratic bottleneck as it requires to compute a joint embedding representation for all pairs of utterances to cluster. To overcome this limitation, we instead cast the problem into a representation learning task, and we adapt the latent structured prediction loss to fine-tune sentence encoders, thus making it possible to obtain clustering-friendly single-sentence embeddings. Our experiments show that the supervised clustering loss returns state-of-the-art results in terms of clustering accuracy and adjusted mutual information."
    },
    {
        "title": "STRONG – Structure Controllable Legal Opinion Summary Generation",
        "authors": [
            "Yang Zhong",
            "Diane Litman"
        ],
        "published": "2023",
        "pdf_link": "https://aclanthology.org/2023.findings-ijcnlp.37.pdf",
        "abstract": "We propose an approach for the structure controllable summarization of long legal opinions that considers the argument structure of the document. Our approach involves using predicted argument role information to guide the model in generating coherent summaries that follow a provided structure pattern. We demonstrate the effectiveness of our approach on a dataset of legal opinions and show that it outperforms several strong baselines with respect to ROUGE, BERTScore, and structure similarity."
    }
]